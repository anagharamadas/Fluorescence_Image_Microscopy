{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f22918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66105849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef display_transposedimages_from_hdf5(file_path, num_images_to_display=12):\\n    with h5py.File(file_path, \\'r\\') as f:\\n        # Access the dataset\\n        images_dataset = f[\\'images\\']\\n        num_images, height, width, num_channels = images_dataset.shape\\n        print(images_dataset.shape)\\n        \\n        print(f\"Dataset contains {num_images} images with {num_channels} channels each, of size {height}x{width}.\")\\n\\n        # Display the first few images\\n        \\n        plt.figure(figsize=(20, 20))\\n        for i in range(min(num_images_to_display, num_images)):\\n            for j in range(images_dataset.shape[-1]):  # Loop over channels in NHWC format\\n                img = images_dataset[i, :, :, j]\\n                plt.subplot(num_images_to_display, images_dataset.shape[-1], i * images_dataset.shape[-1] + j + 1)\\n                plt.imshow(img, cmap=\\'inferno\\')\\n                plt.title(f\\'Image {i}, Channel {j}\\')\\n                plt.axis(\\'off\\')\\n            \\n        plt.show()\\n        return images_dataset\\n \\noutput_file_path = \\'fluor_images_transposed.h5\\'\\nimages_dataset_transposed = display_transposedimages_from_hdf5(output_file_path)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def display_transposedimages_from_hdf5(file_path, num_images_to_display=12):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        # Access the dataset\n",
    "        images_dataset = f['images']\n",
    "        num_images, height, width, num_channels = images_dataset.shape\n",
    "        print(images_dataset.shape)\n",
    "        \n",
    "        print(f\"Dataset contains {num_images} images with {num_channels} channels each, of size {height}x{width}.\")\n",
    "\n",
    "        # Display the first few images\n",
    "        \n",
    "        plt.figure(figsize=(20, 20))\n",
    "        for i in range(min(num_images_to_display, num_images)):\n",
    "            for j in range(images_dataset.shape[-1]):  # Loop over channels in NHWC format\n",
    "                img = images_dataset[i, :, :, j]\n",
    "                plt.subplot(num_images_to_display, images_dataset.shape[-1], i * images_dataset.shape[-1] + j + 1)\n",
    "                plt.imshow(img, cmap='inferno')\n",
    "                plt.title(f'Image {i}, Channel {j}')\n",
    "                plt.axis('off')\n",
    "            \n",
    "        plt.show()\n",
    "        return images_dataset\n",
    " \n",
    "output_file_path = 'fluor_images_transposed.h5'\n",
    "images_dataset_transposed = display_transposedimages_from_hdf5(output_file_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "234f1583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:10:22.806893: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-07 03:10:22.973504: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-07 03:10:24.303986: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-07 03:10:24.304071: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-07 03:10:24.304079: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f24f8",
   "metadata": {},
   "source": [
    "**PatchGAN Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963c9d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 128, 128, 1,  0           ['input_1[0][0]']                \n",
      "                                 1)                                                               \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 128, 128, 1,  0           ['lambda[0][0]']                 \n",
      "                                 6)                                                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 128, 128, 6)  0           ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 128, 128, 6  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128, 128, 12  0           ['reshape[0][0]',                \n",
      "                                )                                 'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 128, 128, 12  0           ['concatenate[0][0]']            \n",
      "                                , 1)                                                              \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 64, 64, 6, 6  4160        ['reshape_1[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 64, 64, 6, 6  0           ['conv3d[0][0]']                 \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 32, 32, 3, 1  524416      ['leaky_re_lu[0][0]']            \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 3, 1  512        ['conv3d_1[0][0]']               \n",
      " alization)                     28)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 32, 32, 3, 1  0           ['batch_normalization[0][0]']    \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 16, 16, 2, 2  2097408     ['leaky_re_lu_1[0][0]']          \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 16, 2, 2  1024       ['conv3d_2[0][0]']               \n",
      " rmalization)                   56)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 16, 16, 2, 2  0           ['batch_normalization_1[0][0]']  \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)              (None, 8, 8, 1, 512  8389120     ['leaky_re_lu_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 1, 512  2048       ['conv3d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 8, 8, 1, 512  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)              (None, 8, 8, 1, 512  16777728    ['leaky_re_lu_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 8, 8, 1, 512  2048       ['conv3d_4[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 8, 8, 1, 512  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)              (None, 8, 8, 1, 1)   32769       ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 8, 8, 1, 1)   0           ['conv3d_5[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,831,233\n",
      "Trainable params: 27,828,417\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:10:26.332853: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-07 03:10:26.353974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-07 03:10:26.354586: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-07 03:10:26.355470: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-07 03:10:26.355838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-07 03:10:26.356415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-07 03:10:26.356946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-07 03:10:27.038547: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-07 03:10:27.039191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-07 03:10:27.039746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-07 03:10:27.040259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13779 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv3D, LeakyReLU, Activation, Concatenate, BatchNormalization, Lambda, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "def define_discriminator(input_shape_2d, output_shape_3d):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    # source image input (2D brightfield)\n",
    "    in_src_image = Input(shape=input_shape_2d)\n",
    "    \n",
    "    # target image input (3D fluorescence)\n",
    "    in_target_image = Input(shape=output_shape_3d)\n",
    "    \n",
    "    # Expand dimensions of source image to match target image\n",
    "    #expanded_src = Lambda(lambda x: tf.expand_dims(x, axis=-1), \n",
    "                          #output_shape=lambda input_shape: input_shape + (1,))(in_src_image)\n",
    "\n",
    "    \n",
    "    # Expand dimensions of source image to match target image\n",
    "    expanded_src = Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "                          output_shape=lambda input_shape: input_shape + (1,))(in_src_image)\n",
    "\n",
    "    expanded_src = Lambda(lambda x: tf.tile(x, [1, 1, 1, 1, output_shape_3d[-1]]),\n",
    "                          output_shape=lambda input_shape: input_shape[:-1] + (output_shape_3d[-1],))(expanded_src)\n",
    "\n",
    "    expanded_src = Reshape((input_shape_2d[0], input_shape_2d[1], output_shape_3d[-1]))(expanded_src)\n",
    "\n",
    "    # concatenate images channel-wise\n",
    "    merged = Concatenate(axis=-1)([expanded_src, in_target_image])\n",
    "    \n",
    "    # Reshape merged tensor to 5D for Conv3D\n",
    "    merged = Reshape((128, 128, output_shape_3d[-1] * 2, 1))(merged)\n",
    "    \n",
    "    # C64\n",
    "    d = Conv3D(64, (4,4,4), strides=(2,2,2), padding='same', kernel_initializer=init)(merged)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # C128\n",
    "    d = Conv3D(128, (4,4,4), strides=(2,2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # C256\n",
    "    d = Conv3D(256, (4,4,4), strides=(2,2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # C512\n",
    "    d = Conv3D(512, (4,4,4), strides=(2,2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # second last output layer\n",
    "    d = Conv3D(512, (4,4,4), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # patch output\n",
    "    d = Conv3D(1, (4,4,4), padding='same', kernel_initializer=init)(d)\n",
    "    patch_out = Activation('sigmoid')(d)\n",
    "    \n",
    "    # define model\n",
    "    model = Model([in_src_image, in_target_image], patch_out)\n",
    "    \n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# define image shapes\n",
    "input_shape_2d = (128, 128, 1)  # 2D brightfield image\n",
    "output_shape_3d = (128, 128, 6)  # 3D fluorescence image with 6 channels\n",
    "\n",
    "# create the model\n",
    "model = define_discriminator(input_shape_2d, output_shape_3d)\n",
    "\n",
    "# summarize the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f49f866b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# After defining your model\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"discriminator_model_plot.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True,\n",
    "    dpi=96,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9fa192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.image import ssim\n",
    "import tensorflow as tf\n",
    "\n",
    "class SSIMLoss(Loss):\n",
    "    def __init__(self, max_val=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.max_val = max_val\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return 1 - tf.reduce_mean(ssim(y_true, y_pred, max_val=self.max_val))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"max_val\": self.max_val})\n",
    "        return config\n",
    "\n",
    "# Register the custom object\n",
    "tf.keras.utils.get_custom_objects()['SSIMLoss'] = SSIMLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb115c50",
   "metadata": {},
   "source": [
    "# U-Net Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b85278f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 64, 64, 64)   1088        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 64, 64, 64)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 128)  131200      ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 32, 32, 128)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 16, 256)  524544      ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 16, 16, 256)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 512)    2097664     ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 8, 8, 512)   2048        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 8, 8, 512)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 4, 4, 512)    4194816     ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 4, 4, 512)   2048        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 4, 4, 512)    0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 2, 2, 512)    4194816     ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 2, 2, 512)   2048        ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 2, 2, 512)    0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 1, 1, 512)    4194816     ['leaky_re_lu_10[0][0]']         \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 1, 1, 512)    0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 2, 2, 512)   4194816     ['activation_1[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 2, 2, 512)   2048        ['conv2d_transpose[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2, 2, 512)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2, 2, 1024)   0           ['dropout[0][0]',                \n",
      "                                                                  'leaky_re_lu_10[0][0]']         \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 2, 2, 1024)   0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 4, 4, 512)   8389120     ['activation_2[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_transpose_1[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4, 4, 512)    0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 4, 4, 1024)   0           ['dropout_1[0][0]',              \n",
      "                                                                  'leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 4, 4, 1024)   0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 8, 8, 512)   8389120     ['activation_3[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_transpose_2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 8, 8, 512)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 8, 8, 1024)   0           ['dropout_2[0][0]',              \n",
      "                                                                  'leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 8, 8, 1024)   0           ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 16, 16, 256)  4194560    ['activation_4[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_transpose_3[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 16, 16, 512)  0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 16, 512)  0           ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 32, 32, 128)  1048704    ['activation_5[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 128)  512        ['conv2d_transpose_4[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 32, 32, 256)  0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 32, 256)  0           ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 64, 64, 64)  262208      ['activation_6[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 64, 64, 64)  256         ['conv2d_transpose_5[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 64, 64, 128)  0           ['batch_normalization_14[0][0]', \n",
      "                                                                  'leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 64, 64, 128)  0           ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 128, 128, 6)  12294      ['activation_7[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 41,845,382\n",
      "Trainable params: 41,837,574\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# example of defining a u-net encoder-decoder generator model\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# define an encoder block\n",
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # add downsampling layer\n",
    "    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init, data_format='channels_last')(layer_in)\n",
    "    # conditionally add batch normalization\n",
    "    if batchnorm:\n",
    "        g = BatchNormalization()(g, training=True)\n",
    "    # leaky relu activation\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    return g\n",
    "\n",
    "# define a decoder block\n",
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # add upsampling layer\n",
    "    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init, data_format='channels_last')(layer_in)\n",
    "    # add batch normalization\n",
    "    g = BatchNormalization()(g, training=True)\n",
    "    # conditionally add dropout\n",
    "    if dropout:\n",
    "        g = Dropout(0.5)(g, training=True)\n",
    "    # merge with skip connection\n",
    "    g = Concatenate()([g, skip_in])\n",
    "    # relu activation\n",
    "    g = Activation('relu')(g)\n",
    "    return g\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(image_shape=(128, 128, 1), output_channels = 6):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    # encoder model: C64-C128-C256-C512-C512-C512-C512-C512\n",
    "    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "    e2 = define_encoder_block(e1, 128)\n",
    "    e3 = define_encoder_block(e2, 256)\n",
    "    e4 = define_encoder_block(e3, 512)\n",
    "    e5 = define_encoder_block(e4, 512)\n",
    "    e6 = define_encoder_block(e5, 512)\n",
    "    #e7 = define_encoder_block(e6, 512)\n",
    "    # bottleneck, no batch norm and relu\n",
    "    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init, data_format='channels_last')(e6)\n",
    "    b = Activation('relu')(b)\n",
    "    # decoder model: CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
    "    d1 = decoder_block(b, e6, 512)\n",
    "    d2 = decoder_block(d1, e5, 512)\n",
    "    d3 = decoder_block(d2, e4, 512)\n",
    "    #d4 = decoder_block(d3, e4, 512, dropout=False)\n",
    "    d4 = decoder_block(d3, e3, 256, dropout=False)\n",
    "    d5 = decoder_block(d4, e2, 128, dropout=False)\n",
    "    d6 = decoder_block(d5, e1, 64, dropout=False)\n",
    "    # output\n",
    "    out_image = Conv2DTranspose(output_channels, (4,4), strides=(2,2), padding='same', kernel_initializer=init, data_format='channels_last')(d6)\n",
    "    #out_image = Activation('tanh')(g)\n",
    "    # define model\n",
    "    model = Model(in_image, out_image)\n",
    "    ssim_loss = SSIMLoss(max_val=1.0)\n",
    "    model.compile(optimizer='adam', loss=ssim_loss)\n",
    "    return model\n",
    "\n",
    "# define image shape\n",
    "image_shape = (128, 128, 1)\n",
    "\n",
    "output_channels = 6\n",
    "# create the model\n",
    "model = define_generator(image_shape, output_channels)\n",
    "# summarize the model\n",
    "model.summary()\n",
    "# plot the model\n",
    "#plot_model(model, to_file='generator_model_plot.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "015d40ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# After defining your model\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"generator_model_plot.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True,\n",
    "    dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d50c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model, image_shape):\n",
    "    # make weights in the discriminator not trainable\n",
    "    for layer in d_model.layers:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = True\n",
    "    # define the source image\n",
    "    in_src = Input(shape=image_shape)\n",
    "    # connect the source image to the generator input\n",
    "    gen_out = g_model(in_src)\n",
    "    # connect the source input and generator output to the discriminator input\n",
    "    dis_out = d_model([in_src, gen_out])\n",
    "    # src image as input, generated image and classification output\n",
    "    model = Model(in_src, [dis_out, gen_out])\n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    ssim_loss = SSIMLoss(max_val=1.0)\n",
    "    model.compile(loss = ['binary_crossentropy', ssim_loss], optimizer=opt, loss_weights = [1,100])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ff201d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {'SSIMLoss': SSIMLoss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2309802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, 128, 128, 6)  41845382    ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " model_2 (Functional)           (None, 8, 8, 1, 1)   27831233    ['input_7[0][0]',                \n",
      "                                                                  'model_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 69,676,615\n",
      "Trainable params: 69,665,991\n",
      "Non-trainable params: 10,624\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# define image shape\n",
    "image_shape = (128, 128, 1)\n",
    "output_shape_3d = (128, 128, 6)\n",
    "# define the models\n",
    "d_model = define_discriminator(image_shape, output_shape_3d)\n",
    "g_model = define_generator(image_shape)\n",
    "# define the composite model\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "# summarize the model\n",
    "gan_model.summary()\n",
    "# plot the model\n",
    "plot_model(gan_model, to_file='gan_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e67f3",
   "metadata": {},
   "source": [
    "# Updating the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "882baaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from numpy import ones\n",
    "from numpy import zeros\n",
    "import tensorflow as tf\n",
    "\n",
    "def split_dataset(dataset):\n",
    "    # Check the dimensions of the dataset\n",
    "    if dataset.shape != (2000, 128, 128, 7):\n",
    "        raise ValueError('Dataset dimensions do not match the expected shape (2000, 128, 128, 7)')\n",
    "    \n",
    "    \n",
    "    # Extract the brightfield images (channel 0)\n",
    "    brightfield_images = dataset[:, :, :, 0]\n",
    "\n",
    "    # Extract the fluorescence images (channels 1-6)\n",
    "    fluorescence_images = dataset[:, :, :, 1:7]\n",
    "\n",
    "    # Verify the shapes\n",
    "    print(\"Brightfield images shape:\", brightfield_images.shape)  # Should be (16338, 128, 128)\n",
    "    print(\"Fluorescence images shape:\", fluorescence_images.shape)  # Should be (16338, 128, 128, 6)\n",
    "\n",
    "    return brightfield_images, fluorescence_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bfad157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    # unpack dataset\n",
    "    trainA, trainB = split_dataset(dataset)\n",
    "    print('trainA shape:', trainA.shape)\n",
    "    print('trainB shape:', trainB.shape)\n",
    "    # choose random instances\n",
    "    ix = randint(0, trainA.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X1, X2 = trainA[ix], trainB[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return [X1, X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3bf3411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, patch_shape): \n",
    "    # Ensure samples are in channels_last format\n",
    "\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(samples)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = np.zeros((len(X),patch_shape, patch_shape, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e8d110f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef check_dataset_format(file_path):\\n    with h5py.File(file_path, \\'r\\') as f:\\n        # Access the dataset\\n        images_dataset = f[\\'images\\']\\n        num_images, height, width, num_channels = images_dataset.shape\\n        print(f\"Dataset shape: {images_dataset.shape}\")\\n        print(f\"Dataset contains {num_images} images with {num_channels} channels each, of size {height}x{width}.\")\\n        \\n        # Verify the datatype\\n        datatype = images_dataset.dtype\\n        print(f\"Image datatype: {datatype}\")\\n\\n        # Check if the dataset follows NHWC format\\n        if len(images_dataset.shape) == 4 and images_dataset.shape[1] == height and images_dataset.shape[2] == width and images_dataset.shape[3] == num_channels:\\n            print(\"Dataset follows NHWC format.\")\\n        else:\\n            print(\"Dataset does not follow NHWC format.\")\\n        \\n        return images_dataset\\n\\n# Usage\\nfile_path = \\'transposed_normalized_images.h5\\'\\nimages_dataset = check_dataset_format(file_path)\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def check_dataset_format(file_path):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        # Access the dataset\n",
    "        images_dataset = f['images']\n",
    "        num_images, height, width, num_channels = images_dataset.shape\n",
    "        print(f\"Dataset shape: {images_dataset.shape}\")\n",
    "        print(f\"Dataset contains {num_images} images with {num_channels} channels each, of size {height}x{width}.\")\n",
    "        \n",
    "        # Verify the datatype\n",
    "        datatype = images_dataset.dtype\n",
    "        print(f\"Image datatype: {datatype}\")\n",
    "\n",
    "        # Check if the dataset follows NHWC format\n",
    "        if len(images_dataset.shape) == 4 and images_dataset.shape[1] == height and images_dataset.shape[2] == width and images_dataset.shape[3] == num_channels:\n",
    "            print(\"Dataset follows NHWC format.\")\n",
    "        else:\n",
    "            print(\"Dataset does not follow NHWC format.\")\n",
    "        \n",
    "        return images_dataset\n",
    "\n",
    "# Usage\n",
    "file_path = 'transposed_normalized_images.h5'\n",
    "images_dataset = check_dataset_format(file_path)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f8d9790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Open the file and keep it open\\nf = h5py.File(file_path, 'r')\\nimages_dataset = f['images']\\nimport numpy as np\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batch = 1000\n",
    "n_patch = 8\n",
    "#print(images_dataset.shape)\n",
    "#file_path = 'transposed_normalized_images.h5'\n",
    "\n",
    "\n",
    "#data = np.load('fluor_images_transposed_asnumpy.npz')\n",
    "\n",
    "\n",
    "#print(data.files)\n",
    "#data = data['array']\n",
    "\n",
    "\"\"\"\n",
    "# Open the file and keep it open\n",
    "f = h5py.File(file_path, 'r')\n",
    "images_dataset = f['images']\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "\n",
    "# Number of images to extract\n",
    "#num_images_to_extract = 2000\n",
    "\n",
    "# Randomly select 2000 indices from the dataset\n",
    "#indices = np.arange(2000)\n",
    "\n",
    "# Extract the selected images\n",
    "#extracted_images = data[:num_images_to_extract]\n",
    "#images_dataset = extracted_images\n",
    "\n",
    "# Check the shape of the extracted images\n",
    "#print(\"Extracted images shape:\", extracted_images.shape)\n",
    "#print(\"Extracted images shape:\", images_dataset.shape)\n",
    "\n",
    "#images_dataset = normalized_dataset(images_dataset)\n",
    "\n",
    "\n",
    "# select a batch of real samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20217a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightfield_images(minimum_value, maximum_value, images_dataset):\n",
    "    for i in range(images_dataset.shape[0]):\n",
    "        img = images_dataset[i, :, :, 0]\n",
    "        if(np.min(img) <minimum_value):\n",
    "            minimum_value = np.min(img)\n",
    "        if(np.max(img) > maximum_value):\n",
    "            maximum_value = np.max(img)\n",
    "\n",
    "    return [minimum_value, maximum_value] \n",
    "\n",
    "def channel1_images(minimum_value, maximum_value, images_dataset):\n",
    "    for i in range(images_dataset.shape[0]):\n",
    "        img = images_dataset[i, :, :, 1]\n",
    "        if(np.min(img) <minimum_value):\n",
    "            minimum_value = np.min(img)\n",
    "        if(np.max(img) > maximum_value):\n",
    "            maximum_value = np.max(img)\n",
    "    return [minimum_value, maximum_value]\n",
    "\n",
    "\n",
    "def channel2_images(minimum_value, maximum_value, images_dataset):\n",
    "    for i in range(images_dataset.shape[0]):\n",
    "        img = images_dataset[i, :, :, 2]\n",
    "        if(np.min(img) < minimum_value):\n",
    "            minimum_value = np.min(img)\n",
    "        if(np.max(img) > maximum_value):\n",
    "            maximum_value = np.max(img)\n",
    "\n",
    "    return [minimum_value, maximum_value]\n",
    "\n",
    "def channel3_images(minimum_value, maximum_value, images_dataset):\n",
    "    for i in range(images_dataset.shape[0]):\n",
    "        img = images_dataset[i, :, :, 3]\n",
    "        if(np.min(img) < minimum_value):\n",
    "            minimum_value = np.min(img)\n",
    "        if(np.max(img) > maximum_value):\n",
    "            maximum_value = np.max(img)\n",
    "    return [minimum_value, maximum_value]\n",
    "\n",
    "def channel4_images(minimum_value, maximum_value, images_dataset):\n",
    "    for i in range(images_dataset.shape[0]):\n",
    "        img = images_dataset[i, :, :, 4]\n",
    "        if(np.min(img) < minimum_value):\n",
    "            minimum_value = np.min(img)\n",
    "        if(np.max(img) > maximum_value):\n",
    "            maximum_value = np.max(img)\n",
    "    return [minimum_value, maximum_value]\n",
    "\n",
    "def channel5_images(minimum_value, maximum_value, images_dataset):\n",
    "    for i in range(images_dataset.shape[0]):\n",
    "        img = images_dataset[i, :, :, 5]\n",
    "        if(np.min(img) < minimum_value):\n",
    "            minimum_value = np.min(img)\n",
    "        if(np.max(img) > maximum_value):\n",
    "            maximum_value = np.max(img)\n",
    "    return [minimum_value, maximum_value]\n",
    "\n",
    "def channel6_images(minimum_value, maximum_value, images_dataset):\n",
    "    for i in range(images_dataset.shape[0]):\n",
    "        img = images_dataset[i, :, :, 6]\n",
    "        if(np.min(img) < minimum_value):\n",
    "            minimum_value = np.min(img)\n",
    "        if(np.max(img) > maximum_value):\n",
    "            maximum_value = np.max(img)\n",
    "    return [minimum_value, maximum_value]\n",
    "\n",
    "def normalization_process(image, min_val, max_val):\n",
    "    image = (((image.astype(np.float32) - min_val) / (max_val - min_val)) * 65535).astype(np.float32)\n",
    "    image = (image.astype(np.float32)/ 65535).astype(np.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12221e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_of_images(images_dataset):\n",
    "    \n",
    "    minimum_value_bf =  np.min(images_dataset[:, :, :, 0])  \n",
    "    maximum_value_bf = np.max(images_dataset[:, :, :, 0])\n",
    "    \n",
    "    minimum_value_1 =  np.min(images_dataset[:, :, :, 1])  \n",
    "    maximum_value_1 = np.max(images_dataset[:, :, :, 1])\n",
    "    \n",
    "    minimum_value_2 =  np.min(images_dataset[:, :, :, 2])  \n",
    "    maximum_value_2 = np.max(images_dataset[:, :, :, 2])\n",
    "    \n",
    "    minimum_value_3 =  np.min(images_dataset[:, :, :, 3])  \n",
    "    maximum_value_3 = np.max(images_dataset[:, :, :, 3])\n",
    "    \n",
    "    minimum_value_4 =  np.min(images_dataset[:, :, :, 4])  \n",
    "    maximum_value_4 = np.max(images_dataset[:, :, :, 4])\n",
    "    \n",
    "    minimum_value_5 =  np.min(images_dataset[:, :, :, 5])  \n",
    "    maximum_value_5 = np.max(images_dataset[:, :, :, 5])\n",
    "\n",
    "    minimum_value_6 =  np.min(images_dataset[:, :, :, 6])  \n",
    "    maximum_value_6 = np.max(images_dataset[:, :, :, 6])\n",
    "    \n",
    "    \n",
    "    minimum_value_bf, maximum_value_bf =  brightfield_images(minimum_value_bf, maximum_value_bf, images_dataset) \n",
    "    minimum_value_1, maximum_value_1 =  channel1_images(minimum_value_1, maximum_value_1, images_dataset) \n",
    "    minimum_value_2, maximum_value_2 =  channel2_images(minimum_value_2, maximum_value_2, images_dataset) \n",
    "    minimum_value_3, maximum_value_3 =  channel3_images(minimum_value_3, maximum_value_3, images_dataset) \n",
    "    minimum_value_4, maximum_value_4 =  channel4_images(minimum_value_4, maximum_value_4, images_dataset) \n",
    "    minimum_value_5, maximum_value_5 =  channel5_images(minimum_value_5, maximum_value_5, images_dataset) \n",
    "    minimum_value_6, maximum_value_6 =  channel6_images(minimum_value_6, maximum_value_6, images_dataset) \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    for i in range(images_dataset.shape[0]):\n",
    "        for j in range(images_dataset.shape[-1]):\n",
    "            if(j==0):\n",
    "                image = images_dataset[i, :, :, j]\n",
    "                temp_image = normalization_process(image, minimum_value_bf, maximum_value_bf)\n",
    "                images_dataset[i, :, :, j] = temp_image\n",
    "                \n",
    "            if(j==1):\n",
    "                image = images_dataset[i, :, :, j]\n",
    "                temp_image = normalization_process(image, minimum_value_1, maximum_value_1)\n",
    "                images_dataset[i, :, :, j] = temp_image\n",
    "                \n",
    "            if(j==2):\n",
    "                image = images_dataset[i, :, :, j]\n",
    "                temp_image = normalization_process(image, minimum_value_1, maximum_value_2)\n",
    "                images_dataset[i, :, :, j] = temp_image\n",
    "            \n",
    "            if(j==3):\n",
    "                image = images_dataset[i, :, :, j]\n",
    "                temp_image = normalization_process(image, minimum_value_1, maximum_value_3)\n",
    "                images_dataset[i, :, :, j] = temp_image\n",
    "                \n",
    "            if(j==4):\n",
    "                image = images_dataset[i, :, :, j]\n",
    "                temp_image = normalization_process(image, minimum_value_1, maximum_value_4)\n",
    "                images_dataset[i, :, :, j] = temp_image\n",
    "                \n",
    "            if(j==5):\n",
    "                image = images_dataset[i, :, :, j]\n",
    "                temp_image = normalization_process(image, minimum_value_1, maximum_value_5)\n",
    "                images_dataset[i, :, :, j] = temp_image\n",
    "                \n",
    "            if(j==6):\n",
    "                image = images_dataset[i, :, :, j]\n",
    "                temp_image = normalization_process(image, minimum_value_1, maximum_value_6)\n",
    "                images_dataset[i, :, :, j] = temp_image\n",
    "            \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "                \n",
    "    print(\"minimum value in channel of brightfield images = \", minimum_value_bf)\n",
    "    print(\"maximum value in channel of brightfield images = \", maximum_value_bf)\n",
    "    print() \n",
    "    \n",
    "    print(\"minimum value in channel 1 of images = \", minimum_value_1)\n",
    "    print(\"maximum value in channel 1 of images = \", maximum_value_1)\n",
    "    print() \n",
    "    \n",
    "    print(\"minimum value in channel 2 of images = \", minimum_value_2)\n",
    "    print(\"maximum value in channel 2 of images = \", maximum_value_2)\n",
    "    print() \n",
    "    \n",
    "    print(\"minimum value in channel 3 of images = \", minimum_value_3)\n",
    "    print(\"maximum value in channel 3 of images = \", maximum_value_3)\n",
    "    print() \n",
    "    \n",
    "    print(\"minimum value in channel 4 of images = \", minimum_value_4)\n",
    "    print(\"maximum value in channel 4 of images = \", maximum_value_4)\n",
    "    print() \n",
    "    \n",
    "    print(\"minimum value in channel 5 of images = \", minimum_value_5)\n",
    "    print(\"maximum value in channel 5 of images = \", maximum_value_5)\n",
    "    print() \n",
    "    \n",
    "    print(\"minimum value in channel 6 of images = \", minimum_value_6)\n",
    "    print(\"maximum value in channel 6 of images = \", maximum_value_6)\n",
    "    print()\n",
    "    \n",
    "    print(\"shape of normalized images dataset = \", images_dataset.shape)\n",
    "    #print(\"maximum value in channel 6 of images = \", maximum_value_6)\n",
    "    print()\n",
    "    \n",
    "    return images_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "886a6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images_dataset = normalization_of_images(images_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be69a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(images_dataset.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33dfbd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_and_max_images(images_dataset):    \n",
    "    minimum_value_bf =  np.min(images_dataset[:, :, :, 0])  \n",
    "    maximum_value_bf = np.max(images_dataset[:, :, :, 0])\n",
    "\n",
    "    minimum_value_1 =  np.min(images_dataset[:, :, :, 1])  \n",
    "    maximum_value_1 = np.max(images_dataset[:, :, :, 1])\n",
    "\n",
    "    minimum_value_2 =  np.min(images_dataset[:, :, :, 2])  \n",
    "    maximum_value_2 = np.max(images_dataset[:, :, :, 2])\n",
    "\n",
    "    minimum_value_3 =  np.min(images_dataset[:, :, :, 3])  \n",
    "    maximum_value_3 = np.max(images_dataset[:, :, :, 3])\n",
    "\n",
    "    minimum_value_4 =  np.min(images_dataset[:, :, :, 4])  \n",
    "    maximum_value_4 = np.max(images_dataset[:, :, :, 4])\n",
    "\n",
    "    minimum_value_5 =  np.min(images_dataset[:, :, :, 5])  \n",
    "    maximum_value_5 = np.max(images_dataset[:, :, :, 5])\n",
    "\n",
    "    minimum_value_6 =  np.min(images_dataset[:, :, :, 6])  \n",
    "    maximum_value_6 = np.max(images_dataset[:, :, :, 6])\n",
    "    \n",
    "                    \n",
    "    print(\"minimum value in channel of brightfield images = \", minimum_value_bf)\n",
    "    print(\"maximum value in channel of brightfield images = \", maximum_value_bf)\n",
    "    print() \n",
    "    \n",
    "    print(\"minimum value in channel 1 of images = \", minimum_value_1)\n",
    "    print(\"maximum value in channel 1 of images = \", maximum_value_1)\n",
    "    print() \n",
    "    \n",
    "    print(\"minimum value in channel 2 of images = \", minimum_value_2)\n",
    "    print(\"maximum value in channel 2 of images = \", maximum_value_2)\n",
    "    print() \n",
    "    \n",
    "    print(\"minimum value in channel 3 of images = \", minimum_value_3)\n",
    "    print(\"maximum value in channel 3 of images = \", maximum_value_3)\n",
    "    print() \n",
    "    \n",
    "    print(\"minimum value in channel 4 of images = \", minimum_value_4)\n",
    "    print(\"maximum value in channel 4 of images = \", maximum_value_4)\n",
    "    print() \n",
    "    \n",
    "    print(\"minimum value in channel 5 of images = \", minimum_value_5)\n",
    "    print(\"maximum value in channel 5 of images = \", maximum_value_5)\n",
    "    print() \n",
    "    \n",
    "    print(\"minimum value in channel 6 of images = \", minimum_value_6)\n",
    "    print(\"maximum value in channel 6 of images = \", maximum_value_6)\n",
    "    print()\n",
    "    \n",
    "    print(\"shape of normalized images dataset = \", images_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b6666b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_and_max_images(images_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b314cc42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26681/4218355121.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mX_realA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_realA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_realB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "[X_realA, X_realB], y_real = generate_real_samples(images_dataset, n_batch, n_patch)\n",
    "print(X_realA.shape)\n",
    "print(X_realB.shape)\n",
    "print(y_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b74a86a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26681/166429463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Display the first image, first channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdisplay_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'images_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "def display_image(image, channel=0):\n",
    "    plt.imshow(image[:,:,channel], cmap='inferno', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display the first image, first channel\n",
    "display_image(images_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a25122e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_realA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26681/3749802948.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# generate a batch of fake samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_fakeB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_realA' is not defined"
     ]
    }
   ],
   "source": [
    "...\n",
    "\n",
    "# generate a batch of fake samples\n",
    "X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "002b6a11",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_fakeB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26681/922881702.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_fakeB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m7\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inferno'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_fakeB' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for j in range(5):\n",
    "    img = X_fakeB[0,:, :, j]\n",
    "    plt.subplot(1, 7, 0 * 7 + j + 1)\n",
    "    plt.imshow(img, cmap='inferno')\n",
    "    plt.title(f'Image {1}, Channel {j}')\n",
    "    plt.axis('off')\n",
    "    print(img.min(), img.max())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3ea210b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_realA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26681/4112926253.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_realA shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_realB shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_real shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_fakeB shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fakeB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_fake shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_realA' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"X_realA shape:\", X_realA.shape)\n",
    "print(\"X_realB shape:\", X_realB.shape)\n",
    "print(\"y_real shape:\", y_real.shape)\n",
    "print(\"X_fakeB shape:\", X_fakeB.shape)\n",
    "print(\"y_fake shape:\", y_fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc6a7714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_realA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26681/2141017721.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the discriminator's output for the generated images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisc_generated_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_realA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fakeB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_realA' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the discriminator's output for the generated images\n",
    "disc_generated_output = d_model([X_realA, X_fakeB])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0e680c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example model compilation for multiple outputs\n",
    "d_model.compile(optimizer='Adam', loss='binary_crossentropy')\n",
    "d_model.trainable = True\n",
    "# update discriminator for real samples\n",
    "#d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "# update discriminator for generated samples\n",
    "#d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26f0095c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_realA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26681/1982701583.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssim_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_realA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_realA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mX_realB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_realB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_realA' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have already defined and created the gan_model\n",
    "# Define the optimizer and compile the GAN model\n",
    "from keras.optimizers import SGD\n",
    " \n",
    "opt = Adam(learning_rate=0.0002)\n",
    "ssim_loss = SSIMLoss(max_val=1.0)\n",
    "gan_model.compile(loss=['binary_crossentropy', ssim_loss], optimizer=opt, loss_weights=[1, 100])\n",
    "\n",
    "X_realA = X_realA.astype(np.float32)\n",
    "X_realB = X_realB.astype(np.float32)\n",
    "\n",
    "X_realA = (X_realA - 127.5) / 127.5\n",
    "X_realB = (X_realB - 127.5) / 127.5\n",
    "\n",
    "# Now you can call train_on_batch\n",
    "#g_loss = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "#print(f\"Generator loss on fake samples: {g_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18fea32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class CustomModelCheckpoint(Callback):\n",
    "    def __init__(self, g_model, d_model, gan_model, filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1):\n",
    "        super(CustomModelCheckpoint, self).__init__()\n",
    "        self.g_model = g_model\n",
    "        self.d_model = d_model\n",
    "        self.gan_model = gan_model\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.period = period\n",
    "        self.epochs_since_last_save = 0\n",
    "        self.best = float('inf') if mode == 'min' else float('-inf')\n",
    "        self.monitor_op = np.less if mode == 'min' else np.greater\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            mode = 'auto'\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best = float('inf')\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n",
    "                self.monitor_op = np.greater\n",
    "                self.best = float('-inf')\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "                self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "            current = logs.get(self.monitor)\n",
    "            if isinstance(current, list):\n",
    "                current = current[0]  # Assuming the first value is what you want\n",
    "            if current is None:\n",
    "                warnings.warn(f'Can save best model only with {self.monitor} available, skipping.', RuntimeWarning)\n",
    "            else:\n",
    "                if self.save_best_only:\n",
    "                    if self.monitor_op(current, self.best):\n",
    "                        if self.verbose > 0:\n",
    "                            print(f'\\nEpoch {epoch + 1}: {self.monitor} improved from {self.best:.5f} to {current:.5f}, saving model to {self.filepath}')\n",
    "                        self.best = current\n",
    "                        self._save_model(self.filepath.format(epoch=epoch + 1, val_loss=current), overwrite=True)\n",
    "                    else:\n",
    "                        if self.verbose > 0:\n",
    "                            print(f'\\nEpoch {epoch + 1}: {self.monitor} did not improve from {self.best:.5f}')\n",
    "                else:\n",
    "                    if self.verbose > 0:\n",
    "                        print(f'\\nEpoch {epoch + 1}: saving model to {self.filepath}')\n",
    "                    self._save_model(self.filepath.format(epoch=epoch + 1, val_loss=current), overwrite=True)\n",
    "\n",
    "    def _save_model(self, filepath, overwrite=True):\n",
    "        if self.save_weights_only:\n",
    "            self.g_model.save_weights(filepath + '_generator.h5', overwrite=overwrite)\n",
    "            self.d_model.save_weights(filepath + '_discriminator.h5', overwrite=overwrite)\n",
    "            self.gan_model.save_weights(filepath + '_gan.h5', overwrite=overwrite)\n",
    "        else:\n",
    "            self.g_model.save(filepath + '_generator.keras', overwrite=overwrite)\n",
    "            self.d_model.save(filepath + '_discriminator.keras', overwrite=overwrite)\n",
    "            self.gan_model.save(filepath + '_gan.keras', overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30757d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Clear previous checkpoints\n",
    "checkpoint_dir = 'checkpoints'\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"checkpoint directory exists\")\n",
    "    shutil.rmtree(checkpoint_dir)\n",
    "os.makedirs(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c45deb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import glob\n",
    "\n",
    "checkpoint_dir = 'checkpoints'\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17c7ed60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No complete set of checkpoints found. Starting from scratch.\n"
     ]
    }
   ],
   "source": [
    "latest_checkpoint = None\n",
    "\n",
    "# Find the latest checkpoint file for each model\n",
    "generator_checkpoints = glob.glob(os.path.join(checkpoint_dir, '*_generator.keras'))\n",
    "discriminator_checkpoints = glob.glob(os.path.join(checkpoint_dir, '*_discriminator.keras'))\n",
    "gan_checkpoints = glob.glob(os.path.join(checkpoint_dir, '*_gan.keras'))\n",
    "\n",
    "if generator_checkpoints and discriminator_checkpoints and gan_checkpoints:\n",
    "    latest_generator = max(generator_checkpoints, key=os.path.getctime)\n",
    "    latest_discriminator = max(discriminator_checkpoints, key=os.path.getctime)\n",
    "    latest_gan = max(gan_checkpoints, key=os.path.getctime)\n",
    "    \n",
    "    print(f\"Found checkpoints:\\nGenerator: {latest_generator}\\nDiscriminator: {latest_discriminator}\\nGAN: {latest_gan}\")\n",
    "    latest_checkpoint = True\n",
    "else:\n",
    "    print(\"No complete set of checkpoints found. Starting from scratch.\")\n",
    "    latest_checkpoint = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5997054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstarting_epoch = 0\\nif latest_checkpoint:\\n    print(f\"Found checkpoint: {latest_checkpoint}\")\\n    epoch_str = os.path.basename(latest_checkpoint).split(\\'_\\')[2]\\n    starting_epoch = int(epoch_str)\\n    print(f\"Resuming from epoch {starting_epoch}\")\\nelse:\\n    print(\"No checkpoints found. Starting from scratch.\")\\n    starting_epoch = 0\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\"\"\"\n",
    "starting_epoch = 0\n",
    "if latest_checkpoint:\n",
    "    print(f\"Found checkpoint: {latest_checkpoint}\")\n",
    "    epoch_str = os.path.basename(latest_checkpoint).split('_')[2]\n",
    "    starting_epoch = int(epoch_str)\n",
    "    print(f\"Resuming from epoch {starting_epoch}\")\n",
    "else:\n",
    "    print(\"No checkpoints found. Starting from scratch.\")\n",
    "    starting_epoch = 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d41c022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_2d = (128, 128, 1)\n",
    "output_shape_3d = (128, 128, 6)\n",
    "image_shape = (128, 128, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "296917f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = define_discriminator(input_shape_2d, output_shape_3d)\n",
    "g_model = define_generator(image_shape)\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3ecb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "starting_epoch = 0\n",
    "if latest_checkpoint:\n",
    "    print(\"Loading weights from checkpoints...\")\n",
    "    try:\n",
    "        # Load weights for each model separately\n",
    "        g_model.load_weights(latest_generator)\n",
    "        d_model.load_weights(latest_discriminator)\n",
    "        gan_model.load_weights(latest_gan)\n",
    "        epoch_str = os.path.basename(latest_generator).split('_')[2]\n",
    "        starting_epoch = int(epoch_str)\n",
    "        print(f\"Resuming from epoch {starting_epoch}\")\n",
    "        print(\"Weights loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading weights: {str(e)}\")\n",
    "        print(\"Initializing models with random weights.\")\n",
    "        # If loading fails, we'll start with fresh models\n",
    "        g_model = define_generator(image_shape)\n",
    "        d_model = define_discriminator(input_shape_2d, output_shape_3d)\n",
    "        gan_model = define_gan(g_model, d_model, image_shape)\n",
    "\n",
    "# Create the custom checkpoint callback\n",
    "custom_checkpoint = CustomModelCheckpoint(\n",
    "    g_model=g_model,\n",
    "    d_model=d_model,\n",
    "    gan_model=gan_model,\n",
    "    filepath=os.path.join(checkpoint_dir, 'model_checkpoint_{epoch:02d}_{val_loss:.2f}'),\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='min',\n",
    "    period=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "855d7da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstarting_epoch = 0\\nif latest_checkpoint:\\n    # Extract the epoch number from the checkpoint file name\\n    starting_epoch = int(latest_checkpoint.split('-')[-1].split('.')[0])\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "starting_epoch = 0\n",
    "if latest_checkpoint:\n",
    "    # Extract the epoch number from the checkpoint file name\n",
    "    starting_epoch = int(latest_checkpoint.split('-')[-1].split('.')[0])\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19599568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, file_path, batch_size, patch_shape, generator_model):\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_shape = patch_shape\n",
    "        \n",
    "        self.data = np.load(file_path)['array']\n",
    "        self.data = self.data[:2000]\n",
    "        print(self.data.shape)\n",
    "        self.data = normalization_of_images(self.data)\n",
    "\n",
    "        self.indices = np.arange(self.data.shape[0])\n",
    "        self.generator_model = generator_model\n",
    "        self.trainA, self.trainB = split_dataset(self.data)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.trainA) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        # Generate data\n",
    "        X_realA, X_realB, y_real, X_fakeB, y_fake = self.__data_generation(indexes)\n",
    "        return [X_realA, X_realB], [y_real, X_fakeB, y_fake]\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.trainA))\n",
    "        np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        # Generate real samples\n",
    "        X_realA, X_realB = self.trainA[indexes], self.trainB[indexes]\n",
    "        y_real = np.ones((self.batch_size, self.patch_shape, self.patch_shape, 1))\n",
    "        \n",
    "        # Generate fake samples\n",
    "        X_fakeB = self.generator_model.predict(X_realA)\n",
    "        y_fake = np.zeros((self.batch_size, self.patch_shape, self.patch_shape, 1))\n",
    "        \n",
    "    \n",
    "        \n",
    "        return X_realA, X_realB, y_real, X_fakeB, y_fake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57659d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Define loss functions\\ndef mae_loss(y_true, y_pred):\\n    return tf.reduce_mean(tf.abs(y_true - y_pred))\\n    '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Define loss functions\n",
    "def mae_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3719d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def calculate_ssim_loss(real_images, generated_images):\n",
    "    # Ensure the images are in the range [0, 1]\n",
    "    real_images = tf.convert_to_tensor(real_images, dtype=tf.float32)\n",
    "    generated_images = tf.convert_to_tensor(generated_images, dtype=tf.float32)\n",
    "    \n",
    "    # Calculate SSIM scores\n",
    "    ssim_scores = tf.image.ssim(real_images, generated_images, max_val=1.0)\n",
    "    \n",
    "    # Calculate mean SSIM score\n",
    "    mean_ssim = tf.reduce_mean(ssim_scores)\n",
    "    \n",
    "    # Convert SSIM to loss (1 - SSIM)\n",
    "    ssim_loss = 1 - mean_ssim\n",
    "    \n",
    "    return ssim_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "175f899b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef combined_mae_ssim_loss(y_true, y_pred, mae_weight=0.5, ssim_weight=0.5):\\n    mae = mae_loss(y_true, y_pred)\\n    ssim = ssim_loss(y_true, y_pred)\\n    return mae_weight * mae + ssim_weight * ssim\\n\\n# Compile the generator with the custom loss function\\ng_model.compile(optimizer='adam', loss=combined_mae_ssim_loss)\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def combined_mae_ssim_loss(y_true, y_pred, mae_weight=0.5, ssim_weight=0.5):\n",
    "    mae = mae_loss(y_true, y_pred)\n",
    "    ssim = ssim_loss(y_true, y_pred)\n",
    "    return mae_weight * mae + ssim_weight * ssim\n",
    "\n",
    "# Compile the generator with the custom loss function\n",
    "g_model.compile(optimizer='adam', loss=combined_mae_ssim_loss)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7be1fb08-7361-4a24-8d67-24bab038103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found: fluor_images_transposed_asnumpy.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = 'fluor_images_transposed_asnumpy.npz'\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"File found: {file_path}\")\n",
    "    data = np.load(file_path)\n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "    # Handle the error (e.g., exit the script or use a default dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26d4b8cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 128, 128, 7)\n",
      "minimum value in channel of brightfield images =  1072.0\n",
      "maximum value in channel of brightfield images =  3368.0\n",
      "\n",
      "minimum value in channel 1 of images =  38.0\n",
      "maximum value in channel 1 of images =  788.0\n",
      "\n",
      "minimum value in channel 2 of images =  45.0\n",
      "maximum value in channel 2 of images =  956.0\n",
      "\n",
      "minimum value in channel 3 of images =  34.0\n",
      "maximum value in channel 3 of images =  784.0\n",
      "\n",
      "minimum value in channel 4 of images =  28.0\n",
      "maximum value in channel 4 of images =  595.0\n",
      "\n",
      "minimum value in channel 5 of images =  63.0\n",
      "maximum value in channel 5 of images =  702.0\n",
      "\n",
      "minimum value in channel 6 of images =  13.0\n",
      "maximum value in channel 6 of images =  317.0\n",
      "\n",
      "shape of normalized images dataset =  (2000, 128, 128, 7)\n",
      "\n",
      "Brightfield images shape: (2000, 128, 128)\n",
      "Fluorescence images shape: (2000, 128, 128, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:11:55.899052: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:11:56.554787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n",
      "2024-08-07 03:11:57.126379: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:12:00.690473: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x2369ddd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-07 03:12:00.690510: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-08-07 03:12:00.695747: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-07 03:12:00.777232: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-08-07 03:12:00.842595: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-08-07 03:12:10.294351: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch: 1, SSIM Loss: 0.9913100004196167\n",
      "Epoch: 1, Batch: 1, D Loss Real: 1.0383479595184326, D Loss Fake: 1.8943774700164795, G Loss: [100.50177001953125, 1.3700573444366455, 0.9913171529769897]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 2, SSIM Loss: 0.9803450107574463\n",
      "Epoch: 1, Batch: 2, D Loss Real: 0.5037863850593567, D Loss Fake: 2.636932849884033, G Loss: [98.72676086425781, 0.7034488916397095, 0.9802331328392029]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 1, Batch: 3, SSIM Loss: 0.9579285383224487\n",
      "Epoch: 1, Batch: 3, D Loss Real: 0.10674479603767395, D Loss Fake: 2.1520915031433105, G Loss: [96.71163940429688, 0.8819602131843567, 0.9582967758178711]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 4, SSIM Loss: 0.8892903923988342\n",
      "Epoch: 1, Batch: 4, D Loss Real: 0.10327726602554321, D Loss Fake: 1.6226513385772705, G Loss: [90.15945434570312, 1.217188835144043, 0.8894226551055908]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 5, SSIM Loss: 0.7923724055290222\n",
      "Epoch: 1, Batch: 5, D Loss Real: 0.11394008249044418, D Loss Fake: 1.2883507013320923, G Loss: [80.70269012451172, 1.389449119567871, 0.7931324243545532]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1, Batch: 6, SSIM Loss: 0.7381929755210876\n",
      "Epoch: 1, Batch: 6, D Loss Real: 0.1249120756983757, D Loss Fake: 1.1203380823135376, G Loss: [75.11028289794922, 1.2567546367645264, 0.7385352849960327]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1, Batch: 7, SSIM Loss: 0.6388265490531921\n",
      "Epoch: 1, Batch: 7, D Loss Real: 0.10088072717189789, D Loss Fake: 1.0749540328979492, G Loss: [65.03030395507812, 1.2155375480651855, 0.6381477117538452]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 8, SSIM Loss: 0.5265445709228516\n",
      "Epoch: 1, Batch: 8, D Loss Real: 0.060280319303274155, D Loss Fake: 0.9605255722999573, G Loss: [53.91698455810547, 1.1822603940963745, 0.5273472666740417]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 9, SSIM Loss: 0.5163047313690186\n",
      "Epoch: 1, Batch: 9, D Loss Real: 0.047663185745477676, D Loss Fake: 0.856685996055603, G Loss: [52.73617172241211, 1.1546871662139893, 0.5158148407936096]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 10, SSIM Loss: 0.4511425495147705\n",
      "Epoch: 1, Batch: 10, D Loss Real: 0.03551850840449333, D Loss Fake: 0.7605942487716675, G Loss: [46.18361282348633, 1.280428171157837, 0.4490318298339844]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 11, SSIM Loss: 0.4292893409729004\n",
      "Epoch: 1, Batch: 11, D Loss Real: 0.027207545936107635, D Loss Fake: 0.9059421420097351, G Loss: [44.17439270019531, 0.9082757234573364, 0.43266117572784424]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 12, SSIM Loss: 0.38142454624176025\n",
      "Epoch: 1, Batch: 12, D Loss Real: 0.02438182942569256, D Loss Fake: 0.8923799395561218, G Loss: [39.029144287109375, 0.8631731271743774, 0.38165968656539917]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 13, SSIM Loss: 0.38000911474227905\n",
      "Epoch: 1, Batch: 13, D Loss Real: 0.02128273993730545, D Loss Fake: 0.8522213697433472, G Loss: [38.75083923339844, 0.8798587918281555, 0.3787097930908203]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 14, SSIM Loss: 0.34671539068222046\n",
      "Epoch: 1, Batch: 14, D Loss Real: 0.0190766341984272, D Loss Fake: 0.795717179775238, G Loss: [35.46406173706055, 0.8586785793304443, 0.3460538387298584]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 15, SSIM Loss: 0.34022247791290283\n",
      "Epoch: 1, Batch: 15, D Loss Real: 0.016712084412574768, D Loss Fake: 0.8529641628265381, G Loss: [34.651329040527344, 0.9002163410186768, 0.3375111222267151]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 16, SSIM Loss: 0.30808132886886597\n",
      "Epoch: 1, Batch: 16, D Loss Real: 0.015386171638965607, D Loss Fake: 0.7553013563156128, G Loss: [31.654006958007812, 0.8693764805793762, 0.3078463077545166]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 17, SSIM Loss: 0.2901644706726074\n",
      "Epoch: 1, Batch: 17, D Loss Real: 0.014804420061409473, D Loss Fake: 0.8119044303894043, G Loss: [30.029197692871094, 0.8572418689727783, 0.29171955585479736]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 18, SSIM Loss: 0.28349220752716064\n",
      "Epoch: 1, Batch: 18, D Loss Real: 0.013861540704965591, D Loss Fake: 0.7822044491767883, G Loss: [29.371936798095703, 0.9237724542617798, 0.28448164463043213]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 19, SSIM Loss: 0.27134692668914795\n",
      "Epoch: 1, Batch: 19, D Loss Real: 0.014769626781344414, D Loss Fake: 0.7224897742271423, G Loss: [27.929819107055664, 0.8731620907783508, 0.27056658267974854]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 20, SSIM Loss: 0.24555259943008423\n",
      "Epoch: 1, Batch: 20, D Loss Real: 0.013919144868850708, D Loss Fake: 0.73387610912323, G Loss: [25.559741973876953, 0.8581772446632385, 0.24701565504074097]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 21, SSIM Loss: 0.24098408222198486\n",
      "Epoch: 1, Batch: 21, D Loss Real: 0.013202822767198086, D Loss Fake: 0.7357335090637207, G Loss: [24.76106834411621, 0.8694285750389099, 0.23891639709472656]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 22, SSIM Loss: 0.5619049072265625\n",
      "Epoch: 1, Batch: 22, D Loss Real: 0.012281043455004692, D Loss Fake: 0.8890092968940735, G Loss: [57.83113479614258, 1.073542594909668, 0.5675759315490723]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 23, SSIM Loss: 0.34572887420654297\n",
      "Epoch: 1, Batch: 23, D Loss Real: 0.019167454913258553, D Loss Fake: 0.7170416116714478, G Loss: [35.50628662109375, 0.9537982940673828, 0.3455249071121216]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 24, SSIM Loss: 0.2871798276901245\n",
      "Epoch: 1, Batch: 24, D Loss Real: 0.015725066885352135, D Loss Fake: 0.7939038872718811, G Loss: [29.65790557861328, 0.9222569465637207, 0.28735649585723877]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 25, SSIM Loss: 0.2399439811706543\n",
      "Epoch: 1, Batch: 25, D Loss Real: 0.013027587905526161, D Loss Fake: 0.7234761714935303, G Loss: [24.94923973083496, 0.9254093766212463, 0.24023830890655518]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 26, SSIM Loss: 0.2361401915550232\n",
      "Epoch: 1, Batch: 26, D Loss Real: 0.014723931439220905, D Loss Fake: 0.7073003053665161, G Loss: [24.678998947143555, 0.8897303342819214, 0.23789268732070923]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 27, SSIM Loss: 0.2241065502166748\n",
      "Epoch: 1, Batch: 27, D Loss Real: 0.013621226884424686, D Loss Fake: 0.7259629964828491, G Loss: [23.133283615112305, 0.8979064226150513, 0.2223537564277649]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 28, SSIM Loss: 0.2367289662361145\n",
      "Epoch: 1, Batch: 28, D Loss Real: 0.011838368140161037, D Loss Fake: 0.7216354608535767, G Loss: [24.156829833984375, 0.9192306995391846, 0.23237597942352295]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 29, SSIM Loss: 0.22641891241073608\n",
      "Epoch: 1, Batch: 29, D Loss Real: 0.011785349808633327, D Loss Fake: 0.6977300643920898, G Loss: [23.534099578857422, 0.9278101325035095, 0.22606289386749268]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 30, SSIM Loss: 0.21974611282348633\n",
      "Epoch: 1, Batch: 30, D Loss Real: 0.011452365666627884, D Loss Fake: 0.6803466081619263, G Loss: [22.850421905517578, 0.8696826100349426, 0.21980738639831543]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 31, SSIM Loss: 0.1871812343597412\n",
      "Epoch: 1, Batch: 31, D Loss Real: 0.01093948446214199, D Loss Fake: 0.6755229830741882, G Loss: [19.593517303466797, 0.8585909605026245, 0.18734925985336304]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 32, SSIM Loss: 0.2124805450439453\n",
      "Epoch: 1, Batch: 32, D Loss Real: 0.010233731009066105, D Loss Fake: 0.6896417140960693, G Loss: [21.949291229248047, 0.8462955951690674, 0.21102994680404663]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1, Batch: 33, SSIM Loss: 0.18912464380264282\n",
      "Epoch: 1, Batch: 33, D Loss Real: 0.011417195200920105, D Loss Fake: 0.6891916990280151, G Loss: [19.665550231933594, 0.8432029485702515, 0.1882234811782837]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 34, SSIM Loss: 0.2178298830986023\n",
      "Epoch: 1, Batch: 34, D Loss Real: 0.010445887222886086, D Loss Fake: 0.6909303665161133, G Loss: [22.70069694519043, 0.8735594749450684, 0.2182713747024536]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 1, Batch: 35, SSIM Loss: 0.21188730001449585\n",
      "Epoch: 1, Batch: 35, D Loss Real: 0.008823812007904053, D Loss Fake: 0.6853587031364441, G Loss: [21.9813232421875, 0.9481786489486694, 0.21033143997192383]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 36, SSIM Loss: 0.2101263403892517\n",
      "Epoch: 1, Batch: 36, D Loss Real: 0.010022999718785286, D Loss Fake: 0.6719794273376465, G Loss: [21.968759536743164, 0.9162192940711975, 0.21052539348602295]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 37, SSIM Loss: 0.22588104009628296\n",
      "Epoch: 1, Batch: 37, D Loss Real: 0.009029984474182129, D Loss Fake: 0.6933268308639526, G Loss: [23.699310302734375, 0.9677678942680359, 0.22731542587280273]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 38, SSIM Loss: 0.23265695571899414\n",
      "Epoch: 1, Batch: 38, D Loss Real: 0.009291660971939564, D Loss Fake: 0.6846437454223633, G Loss: [24.27939224243164, 1.0519812107086182, 0.2322741150856018]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 39, SSIM Loss: 0.2112501859664917\n",
      "Epoch: 1, Batch: 39, D Loss Real: 0.01399890799075365, D Loss Fake: 0.6755200624465942, G Loss: [22.086013793945312, 1.0164403915405273, 0.21069574356079102]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 40, SSIM Loss: 0.20826584100723267\n",
      "Epoch: 1, Batch: 40, D Loss Real: 0.010980010032653809, D Loss Fake: 0.6847841739654541, G Loss: [21.7603759765625, 0.9527878165245056, 0.2080758810043335]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 41, SSIM Loss: 0.20150816440582275\n",
      "Epoch: 1, Batch: 41, D Loss Real: 0.008563201874494553, D Loss Fake: 0.6703605055809021, G Loss: [21.236133575439453, 0.9745231866836548, 0.20261609554290771]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1, Batch: 42, SSIM Loss: 0.19488507509231567\n",
      "Epoch: 1, Batch: 42, D Loss Real: 0.008096951991319656, D Loss Fake: 0.6664333939552307, G Loss: [20.51321029663086, 0.9618156552314758, 0.19551396369934082]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1, Batch: 43, SSIM Loss: 0.19399499893188477\n",
      "Epoch: 1, Batch: 43, D Loss Real: 0.008597142994403839, D Loss Fake: 0.6599823832511902, G Loss: [20.259742736816406, 0.944922685623169, 0.1931481957435608]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 44, SSIM Loss: 0.18975436687469482\n",
      "Epoch: 1, Batch: 44, D Loss Real: 0.007683944888412952, D Loss Fake: 0.6639524102210999, G Loss: [19.851200103759766, 0.9333766102790833, 0.1891782283782959]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 45, SSIM Loss: 0.20061224699020386\n",
      "Epoch: 1, Batch: 45, D Loss Real: 0.009113091975450516, D Loss Fake: 0.6780909299850464, G Loss: [20.940322875976562, 0.9369025230407715, 0.20003420114517212]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1, Batch: 46, SSIM Loss: 0.17883551120758057\n",
      "Epoch: 1, Batch: 46, D Loss Real: 0.02538217417895794, D Loss Fake: 0.6697219610214233, G Loss: [18.81064224243164, 0.921708345413208, 0.17888933420181274]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 47, SSIM Loss: 0.18726158142089844\n",
      "Epoch: 1, Batch: 47, D Loss Real: 0.014616280794143677, D Loss Fake: 0.682517945766449, G Loss: [19.582008361816406, 0.8831609487533569, 0.1869884729385376]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 48, SSIM Loss: 0.21733534336090088\n",
      "Epoch: 1, Batch: 48, D Loss Real: 0.0099720424041152, D Loss Fake: 0.700157880783081, G Loss: [22.59839630126953, 0.9806318283081055, 0.21617764234542847]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 49, SSIM Loss: 0.1955091953277588\n",
      "Epoch: 1, Batch: 49, D Loss Real: 0.014305723831057549, D Loss Fake: 0.6272042393684387, G Loss: [20.418331146240234, 0.954930305480957, 0.19463402032852173]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 50, SSIM Loss: 0.17485809326171875\n",
      "Epoch: 1, Batch: 50, D Loss Real: 0.009706789627671242, D Loss Fake: 0.6707671880722046, G Loss: [18.32952117919922, 0.8618481159210205, 0.17467671632766724]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1, Batch: 51, SSIM Loss: 0.1701338291168213\n",
      "Epoch: 1, Batch: 51, D Loss Real: 0.008333513513207436, D Loss Fake: 0.6676924228668213, G Loss: [17.94698143005371, 0.9127681255340576, 0.17034214735031128]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 52, SSIM Loss: 0.1698371171951294\n",
      "Epoch: 1, Batch: 52, D Loss Real: 0.010622135363519192, D Loss Fake: 0.6554455757141113, G Loss: [17.93492317199707, 0.9200560450553894, 0.17014867067337036]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 53, SSIM Loss: 0.16296935081481934\n",
      "Epoch: 1, Batch: 53, D Loss Real: 0.018671903759241104, D Loss Fake: 0.6514764428138733, G Loss: [17.25528907775879, 0.9334867000579834, 0.16321802139282227]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 54, SSIM Loss: 0.16029095649719238\n",
      "Epoch: 1, Batch: 54, D Loss Real: 0.03885677456855774, D Loss Fake: 0.6562000513076782, G Loss: [16.955699920654297, 0.9017483592033386, 0.16053950786590576]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 55, SSIM Loss: 0.15201258659362793\n",
      "Epoch: 1, Batch: 55, D Loss Real: 0.025849303230643272, D Loss Fake: 0.6943119168281555, G Loss: [16.297353744506836, 0.9257993102073669, 0.15371555089950562]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 56, SSIM Loss: 0.1575872302055359\n",
      "Epoch: 1, Batch: 56, D Loss Real: 0.008117424324154854, D Loss Fake: 0.6285337209701538, G Loss: [16.654937744140625, 0.8991296887397766, 0.15755808353424072]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 57, SSIM Loss: 0.17049598693847656\n",
      "Epoch: 1, Batch: 57, D Loss Real: 0.007331994827836752, D Loss Fake: 0.6556676626205444, G Loss: [17.978885650634766, 0.8580469489097595, 0.17120838165283203]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 58, SSIM Loss: 0.17145216464996338\n",
      "Epoch: 1, Batch: 58, D Loss Real: 0.006313612684607506, D Loss Fake: 0.6530317664146423, G Loss: [17.856985092163086, 0.8929418921470642, 0.1696404218673706]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 59, SSIM Loss: 0.16574198007583618\n",
      "Epoch: 1, Batch: 59, D Loss Real: 0.0053175222128629684, D Loss Fake: 0.652503252029419, G Loss: [17.278453826904297, 0.8939353227615356, 0.16384518146514893]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 60, SSIM Loss: 0.15913599729537964\n",
      "Epoch: 1, Batch: 60, D Loss Real: 0.01395905390381813, D Loss Fake: 0.6336546540260315, G Loss: [16.81240463256836, 0.8702900409698486, 0.1594211459159851]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 1, Batch: 61, SSIM Loss: 0.15863382816314697\n",
      "Epoch: 1, Batch: 61, D Loss Real: 0.016668757423758507, D Loss Fake: 0.6462603807449341, G Loss: [16.73531723022461, 0.8990058898925781, 0.15836310386657715]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 1, Batch: 62, SSIM Loss: 0.14416778087615967\n",
      "Epoch: 1, Batch: 62, D Loss Real: 0.006749673280864954, D Loss Fake: 0.6336942911148071, G Loss: [15.295893669128418, 0.8604774475097656, 0.14435416460037231]\n",
      "1/1 [==============================] - 0s 139ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:13:40.414897: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:13:41.846207: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch: 1, SSIM Loss: 0.15471792221069336\n",
      "Epoch: 2, Batch: 1, D Loss Real: 0.005107431206852198, D Loss Fake: 0.6637686491012573, G Loss: [16.471097946166992, 0.8887797594070435, 0.15582317113876343]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 2, SSIM Loss: 0.1442713737487793\n",
      "Epoch: 2, Batch: 2, D Loss Real: 0.004923767410218716, D Loss Fake: 0.6579489707946777, G Loss: [15.418697357177734, 0.8837647438049316, 0.14534932374954224]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 2, Batch: 3, SSIM Loss: 0.17907941341400146\n",
      "Epoch: 2, Batch: 3, D Loss Real: 0.018926922231912613, D Loss Fake: 0.6748290061950684, G Loss: [18.85576820373535, 1.003987193107605, 0.17851781845092773]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 4, SSIM Loss: 0.17146170139312744\n",
      "Epoch: 2, Batch: 4, D Loss Real: 0.016182826831936836, D Loss Fake: 0.7365481853485107, G Loss: [18.192237854003906, 0.9987878799438477, 0.17193448543548584]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 5, SSIM Loss: 0.16446751356124878\n",
      "Epoch: 2, Batch: 5, D Loss Real: 0.025676114484667778, D Loss Fake: 0.6097230911254883, G Loss: [17.521942138671875, 0.9935154914855957, 0.16528427600860596]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 2, Batch: 6, SSIM Loss: 0.15313708782196045\n",
      "Epoch: 2, Batch: 6, D Loss Real: 0.021157167851924896, D Loss Fake: 0.5975942015647888, G Loss: [16.246408462524414, 0.9536209106445312, 0.15292787551879883]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 7, SSIM Loss: 0.1572859287261963\n",
      "Epoch: 2, Batch: 7, D Loss Real: 0.01613553799688816, D Loss Fake: 0.6175382137298584, G Loss: [16.8302059173584, 0.9382011294364929, 0.1589200496673584]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 8, SSIM Loss: 0.14772683382034302\n",
      "Epoch: 2, Batch: 8, D Loss Real: 0.01077208947390318, D Loss Fake: 0.6250088810920715, G Loss: [15.62482738494873, 0.8763377666473389, 0.1474848985671997]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 2, Batch: 9, SSIM Loss: 0.15140080451965332\n",
      "Epoch: 2, Batch: 9, D Loss Real: 0.005783152300864458, D Loss Fake: 0.6495122909545898, G Loss: [16.096412658691406, 0.8884004950523376, 0.15208011865615845]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 10, SSIM Loss: 0.13702696561813354\n",
      "Epoch: 2, Batch: 10, D Loss Real: 0.004783674143254757, D Loss Fake: 0.6414826512336731, G Loss: [14.535497665405273, 0.8465046286582947, 0.13688993453979492]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 11, SSIM Loss: 0.14127588272094727\n",
      "Epoch: 2, Batch: 11, D Loss Real: 0.005060071591287851, D Loss Fake: 0.655254602432251, G Loss: [14.988990783691406, 0.8475378751754761, 0.14141452312469482]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 12, SSIM Loss: 0.14434140920639038\n",
      "Epoch: 2, Batch: 12, D Loss Real: 0.007336351554840803, D Loss Fake: 0.6337088346481323, G Loss: [15.248117446899414, 0.8498173356056213, 0.14398300647735596]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 13, SSIM Loss: 0.1510329246520996\n",
      "Epoch: 2, Batch: 13, D Loss Real: 0.005341754760593176, D Loss Fake: 0.655160665512085, G Loss: [15.97597599029541, 0.8621215224266052, 0.1511385440826416]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 14, SSIM Loss: 0.14471185207366943\n",
      "Epoch: 2, Batch: 14, D Loss Real: 0.011726539582014084, D Loss Fake: 0.6314085721969604, G Loss: [15.355344772338867, 0.8775084018707275, 0.14477837085723877]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 15, SSIM Loss: 0.14686810970306396\n",
      "Epoch: 2, Batch: 15, D Loss Real: 0.01616494171321392, D Loss Fake: 0.625246524810791, G Loss: [15.553240776062012, 0.8747739791870117, 0.14678466320037842]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 2, Batch: 16, SSIM Loss: 0.13780701160430908\n",
      "Epoch: 2, Batch: 16, D Loss Real: 0.041053541004657745, D Loss Fake: 0.7050721645355225, G Loss: [14.625579833984375, 0.9449672698974609, 0.13680613040924072]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 17, SSIM Loss: 0.13708627223968506\n",
      "Epoch: 2, Batch: 17, D Loss Real: 0.08643420785665512, D Loss Fake: 0.7887082695960999, G Loss: [14.755062103271484, 1.00946843624115, 0.13745594024658203]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 2, Batch: 18, SSIM Loss: 0.14364027976989746\n",
      "Epoch: 2, Batch: 18, D Loss Real: 0.09942620247602463, D Loss Fake: 0.6136668920516968, G Loss: [15.017744064331055, 0.9022079110145569, 0.14115536212921143]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 2, Batch: 19, SSIM Loss: 0.14054018259048462\n",
      "Epoch: 2, Batch: 19, D Loss Real: 0.1121007427573204, D Loss Fake: 0.6579446792602539, G Loss: [14.90828800201416, 0.8469212055206299, 0.14061367511749268]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 20, SSIM Loss: 0.1587446928024292\n",
      "Epoch: 2, Batch: 20, D Loss Real: 0.006021160166710615, D Loss Fake: 0.7524510622024536, G Loss: [16.29610252380371, 0.8821394443511963, 0.15413963794708252]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 21, SSIM Loss: 0.16233962774276733\n",
      "Epoch: 2, Batch: 21, D Loss Real: 0.0058397212997078896, D Loss Fake: 0.6321794390678406, G Loss: [17.3239803314209, 0.9712539911270142, 0.163527250289917]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 22, SSIM Loss: 0.1581488847732544\n",
      "Epoch: 2, Batch: 22, D Loss Real: 0.008003000169992447, D Loss Fake: 0.6843143105506897, G Loss: [16.77618980407715, 0.9690009355545044, 0.1580718755722046]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 23, SSIM Loss: 0.1545044183731079\n",
      "Epoch: 2, Batch: 23, D Loss Real: 0.008313172496855259, D Loss Fake: 0.6187341213226318, G Loss: [16.43898582458496, 0.993706464767456, 0.15445280075073242]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 24, SSIM Loss: 0.1561412811279297\n",
      "Epoch: 2, Batch: 24, D Loss Real: 0.010651666671037674, D Loss Fake: 0.6103922128677368, G Loss: [16.6350154876709, 1.0211681127548218, 0.15613847970962524]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 25, SSIM Loss: 0.15112674236297607\n",
      "Epoch: 2, Batch: 25, D Loss Real: 0.0047227791510522366, D Loss Fake: 0.6195113658905029, G Loss: [15.973236083984375, 0.9103434681892395, 0.150628924369812]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 26, SSIM Loss: 0.14902067184448242\n",
      "Epoch: 2, Batch: 26, D Loss Real: 0.006803566124290228, D Loss Fake: 0.6521346569061279, G Loss: [15.6928129196167, 0.9047991633415222, 0.14788013696670532]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 27, SSIM Loss: 0.14336752891540527\n",
      "Epoch: 2, Batch: 27, D Loss Real: 0.006261774804443121, D Loss Fake: 0.6156508326530457, G Loss: [15.190845489501953, 0.9101564884185791, 0.14280688762664795]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 2, Batch: 28, SSIM Loss: 0.1380246877670288\n",
      "Epoch: 2, Batch: 28, D Loss Real: 0.004507779143750668, D Loss Fake: 0.6336110234260559, G Loss: [14.739396095275879, 0.9221330285072327, 0.13817262649536133]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 2, Batch: 29, SSIM Loss: 0.15327095985412598\n",
      "Epoch: 2, Batch: 29, D Loss Real: 0.005261045880615711, D Loss Fake: 0.6727655529975891, G Loss: [16.349855422973633, 1.0000965595245361, 0.153497576713562]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 30, SSIM Loss: 0.15378111600875854\n",
      "Epoch: 2, Batch: 30, D Loss Real: 0.014406150206923485, D Loss Fake: 0.6161429286003113, G Loss: [16.489866256713867, 1.0251601934432983, 0.15464705228805542]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 31, SSIM Loss: 0.1416306495666504\n",
      "Epoch: 2, Batch: 31, D Loss Real: 0.08855747431516647, D Loss Fake: 0.5848714709281921, G Loss: [14.963086128234863, 0.9470664858818054, 0.1401602029800415]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 32, SSIM Loss: 0.1479138731956482\n",
      "Epoch: 2, Batch: 32, D Loss Real: 0.10615639388561249, D Loss Fake: 0.6210129857063293, G Loss: [15.702778816223145, 0.9047993421554565, 0.14797979593276978]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 2, Batch: 33, SSIM Loss: 0.15820932388305664\n",
      "Epoch: 2, Batch: 33, D Loss Real: 0.01086170319467783, D Loss Fake: 0.6925129890441895, G Loss: [16.714494705200195, 0.9707154631614685, 0.15743780136108398]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 34, SSIM Loss: 0.1555699110031128\n",
      "Epoch: 2, Batch: 34, D Loss Real: 0.005330453161150217, D Loss Fake: 0.6286311149597168, G Loss: [16.447744369506836, 0.8970725536346436, 0.15550673007965088]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 35, SSIM Loss: 0.12821859121322632\n",
      "Epoch: 2, Batch: 35, D Loss Real: 0.006707150023430586, D Loss Fake: 0.6509252190589905, G Loss: [13.78514575958252, 0.9020313024520874, 0.128831148147583]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 36, SSIM Loss: 0.1442546844482422\n",
      "Epoch: 2, Batch: 36, D Loss Real: 0.004711643327027559, D Loss Fake: 0.6264560222625732, G Loss: [15.357029914855957, 0.9260894656181335, 0.144309401512146]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 37, SSIM Loss: 0.14425146579742432\n",
      "Epoch: 2, Batch: 37, D Loss Real: 0.006886005401611328, D Loss Fake: 0.6337177157402039, G Loss: [15.481367111206055, 0.9461308717727661, 0.14535236358642578]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 2, Batch: 38, SSIM Loss: 0.16751611232757568\n",
      "Epoch: 2, Batch: 38, D Loss Real: 0.009360039606690407, D Loss Fake: 0.6929740905761719, G Loss: [17.822139739990234, 0.9828851222991943, 0.16839253902435303]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 39, SSIM Loss: 0.14463025331497192\n",
      "Epoch: 2, Batch: 39, D Loss Real: 0.06061508506536484, D Loss Fake: 0.6909793615341187, G Loss: [15.49569320678711, 1.040541172027588, 0.14455151557922363]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 2, Batch: 40, SSIM Loss: 0.14911437034606934\n",
      "Epoch: 2, Batch: 40, D Loss Real: 0.026691939681768417, D Loss Fake: 0.6041305065155029, G Loss: [15.884780883789062, 0.9027121067047119, 0.14982068538665771]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 41, SSIM Loss: 0.1322886347770691\n",
      "Epoch: 2, Batch: 41, D Loss Real: 0.00800279714167118, D Loss Fake: 0.5973296165466309, G Loss: [14.219754219055176, 0.9653862714767456, 0.132543683052063]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 42, SSIM Loss: 0.1362900733947754\n",
      "Epoch: 2, Batch: 42, D Loss Real: 0.005604741163551807, D Loss Fake: 0.6051609516143799, G Loss: [14.569375991821289, 0.9062094688415527, 0.13663166761398315]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 43, SSIM Loss: 0.1376948356628418\n",
      "Epoch: 2, Batch: 43, D Loss Real: 0.003873821347951889, D Loss Fake: 0.6877182126045227, G Loss: [14.682826042175293, 0.9222356677055359, 0.13760590553283691]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 44, SSIM Loss: 0.12973415851593018\n",
      "Epoch: 2, Batch: 44, D Loss Real: 0.006523875519633293, D Loss Fake: 0.6142518520355225, G Loss: [13.878973007202148, 0.9098791480064392, 0.12969094514846802]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 45, SSIM Loss: 0.15046656131744385\n",
      "Epoch: 2, Batch: 45, D Loss Real: 0.0149443494156003, D Loss Fake: 0.6257163286209106, G Loss: [15.9209623336792, 0.9002339839935303, 0.1502072811126709]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 46, SSIM Loss: 0.1302778720855713\n",
      "Epoch: 2, Batch: 46, D Loss Real: 0.01711929216980934, D Loss Fake: 0.6315402984619141, G Loss: [13.92037296295166, 0.9171133041381836, 0.13003259897232056]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 47, SSIM Loss: 0.1481989026069641\n",
      "Epoch: 2, Batch: 47, D Loss Real: 0.006736982613801956, D Loss Fake: 0.6225576400756836, G Loss: [15.701761245727539, 0.8773115873336792, 0.14824450016021729]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 48, SSIM Loss: 0.14561772346496582\n",
      "Epoch: 2, Batch: 48, D Loss Real: 0.004182953853160143, D Loss Fake: 0.6027976274490356, G Loss: [15.560667991638184, 0.9070385098457336, 0.14653629064559937]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 49, SSIM Loss: 0.13810014724731445\n",
      "Epoch: 2, Batch: 49, D Loss Real: 0.0032493637409061193, D Loss Fake: 0.6529974937438965, G Loss: [14.754762649536133, 0.9120372533798218, 0.1384272575378418]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 50, SSIM Loss: 0.13089615106582642\n",
      "Epoch: 2, Batch: 50, D Loss Real: 0.004489638842642307, D Loss Fake: 1.8181936740875244, G Loss: [14.154754638671875, 1.0464296340942383, 0.13108325004577637]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 2, Batch: 51, SSIM Loss: 0.13497817516326904\n",
      "Epoch: 2, Batch: 51, D Loss Real: 0.7626594305038452, D Loss Fake: 0.5661735534667969, G Loss: [14.424887657165527, 0.9568548798561096, 0.13468033075332642]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 52, SSIM Loss: 0.13601666688919067\n",
      "Epoch: 2, Batch: 52, D Loss Real: 0.41401270031929016, D Loss Fake: 0.7444958686828613, G Loss: [14.423168182373047, 0.8058543801307678, 0.13617312908172607]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 53, SSIM Loss: 0.13380157947540283\n",
      "Epoch: 2, Batch: 53, D Loss Real: 0.08277261257171631, D Loss Fake: 1.2986830472946167, G Loss: [14.257282257080078, 0.8684694766998291, 0.1338881254196167]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 54, SSIM Loss: 0.13534533977508545\n",
      "Epoch: 2, Batch: 54, D Loss Real: 0.15874116122722626, D Loss Fake: 1.329795479774475, G Loss: [14.65333080291748, 1.1007721424102783, 0.13552558422088623]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 55, SSIM Loss: 0.11838340759277344\n",
      "Epoch: 2, Batch: 55, D Loss Real: 0.34931719303131104, D Loss Fake: 0.6428006887435913, G Loss: [12.665786743164062, 0.853309154510498, 0.11812478303909302]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 56, SSIM Loss: 0.13594180345535278\n",
      "Epoch: 2, Batch: 56, D Loss Real: 0.17302623391151428, D Loss Fake: 0.6487589478492737, G Loss: [14.525468826293945, 0.8123714327812195, 0.1371309757232666]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 57, SSIM Loss: 0.14516019821166992\n",
      "Epoch: 2, Batch: 57, D Loss Real: 0.05928213149309158, D Loss Fake: 0.6834869384765625, G Loss: [15.335335731506348, 0.7663391828536987, 0.1456899642944336]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 58, SSIM Loss: 0.14110219478607178\n",
      "Epoch: 2, Batch: 58, D Loss Real: 0.016952555626630783, D Loss Fake: 0.7084540128707886, G Loss: [14.999595642089844, 0.7581390142440796, 0.14241456985473633]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 59, SSIM Loss: 0.1334584355354309\n",
      "Epoch: 2, Batch: 59, D Loss Real: 0.00860446598380804, D Loss Fake: 0.6976670026779175, G Loss: [14.125872611999512, 0.781137228012085, 0.13344734907150269]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 60, SSIM Loss: 0.13217228651046753\n",
      "Epoch: 2, Batch: 60, D Loss Real: 0.006172263994812965, D Loss Fake: 0.7160984873771667, G Loss: [13.986483573913574, 0.7894794940948486, 0.13197004795074463]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 2, Batch: 61, SSIM Loss: 0.13334977626800537\n",
      "Epoch: 2, Batch: 61, D Loss Real: 0.007722067181020975, D Loss Fake: 0.7283536195755005, G Loss: [14.152570724487305, 0.8312302827835083, 0.13321340084075928]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 2, Batch: 62, SSIM Loss: 0.12636065483093262\n",
      "Epoch: 2, Batch: 62, D Loss Real: 0.005976032931357622, D Loss Fake: 0.6761447787284851, G Loss: [13.503341674804688, 0.8490550518035889, 0.126542866230011]\n",
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:15:03.423042: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:15:04.895447: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch: 1, SSIM Loss: 0.12770617008209229\n",
      "Epoch: 3, Batch: 1, D Loss Real: 0.007013050839304924, D Loss Fake: 0.6776421666145325, G Loss: [13.612228393554688, 0.8664782047271729, 0.12745749950408936]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 2, SSIM Loss: 0.12209874391555786\n",
      "Epoch: 3, Batch: 2, D Loss Real: 0.006977648939937353, D Loss Fake: 0.6773108839988708, G Loss: [13.070060729980469, 0.8680658936500549, 0.1220199465751648]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 3, SSIM Loss: 0.13971549272537231\n",
      "Epoch: 3, Batch: 3, D Loss Real: 0.014034874737262726, D Loss Fake: 0.6785815954208374, G Loss: [14.863982200622559, 0.8698421716690063, 0.13994139432907104]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 4, SSIM Loss: 0.13970565795898438\n",
      "Epoch: 3, Batch: 4, D Loss Real: 0.01221877709031105, D Loss Fake: 0.6517626047134399, G Loss: [14.834330558776855, 0.8661485314369202, 0.13968181610107422]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 5, SSIM Loss: 0.13668179512023926\n",
      "Epoch: 3, Batch: 5, D Loss Real: 0.007719449698925018, D Loss Fake: 0.7913113832473755, G Loss: [14.646994590759277, 0.8735643625259399, 0.1377342939376831]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 6, SSIM Loss: 0.1299542784690857\n",
      "Epoch: 3, Batch: 6, D Loss Real: 0.05124422162771225, D Loss Fake: 2.0869643688201904, G Loss: [14.112278938293457, 1.121815800666809, 0.1299046277999878]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 3, Batch: 7, SSIM Loss: 0.14172041416168213\n",
      "Epoch: 3, Batch: 7, D Loss Real: 0.36013972759246826, D Loss Fake: 0.5214642286300659, G Loss: [15.262442588806152, 1.034879446029663, 0.1422756314277649]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 8, SSIM Loss: 0.13094890117645264\n",
      "Epoch: 3, Batch: 8, D Loss Real: 0.23557275533676147, D Loss Fake: 0.5992816090583801, G Loss: [14.000090599060059, 0.8923438787460327, 0.13107746839523315]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 9, SSIM Loss: 0.13908952474594116\n",
      "Epoch: 3, Batch: 9, D Loss Real: 0.07850618660449982, D Loss Fake: 0.6987898349761963, G Loss: [14.735929489135742, 0.8508309721946716, 0.13885098695755005]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 3, Batch: 10, SSIM Loss: 0.12580347061157227\n",
      "Epoch: 3, Batch: 10, D Loss Real: 0.012906894087791443, D Loss Fake: 0.749513566493988, G Loss: [13.471375465393066, 0.8692132830619812, 0.1260216236114502]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 11, SSIM Loss: 0.12923532724380493\n",
      "Epoch: 3, Batch: 11, D Loss Real: 0.011655225418508053, D Loss Fake: 0.7167141437530518, G Loss: [13.813516616821289, 0.9010528922080994, 0.12912464141845703]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 12, SSIM Loss: 0.13092494010925293\n",
      "Epoch: 3, Batch: 12, D Loss Real: 0.017077915370464325, D Loss Fake: 0.6430883407592773, G Loss: [14.02598762512207, 0.882472038269043, 0.13143515586853027]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 13, SSIM Loss: 0.143049418926239\n",
      "Epoch: 3, Batch: 13, D Loss Real: 0.013892125338315964, D Loss Fake: 0.6584970951080322, G Loss: [15.178740501403809, 0.8515422940254211, 0.14327198266983032]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 3, Batch: 14, SSIM Loss: 0.1346219778060913\n",
      "Epoch: 3, Batch: 14, D Loss Real: 0.007898544892668724, D Loss Fake: 0.6734663248062134, G Loss: [14.306923866271973, 0.8376328349113464, 0.13469290733337402]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 15, SSIM Loss: 0.13752925395965576\n",
      "Epoch: 3, Batch: 15, D Loss Real: 0.007987462915480137, D Loss Fake: 0.7424159049987793, G Loss: [14.597846031188965, 0.8670633435249329, 0.13730782270431519]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 16, SSIM Loss: 0.127785325050354\n",
      "Epoch: 3, Batch: 16, D Loss Real: 0.029222359880805016, D Loss Fake: 0.6635499596595764, G Loss: [13.646337509155273, 0.8815554976463318, 0.12764781713485718]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 17, SSIM Loss: 0.12693274021148682\n",
      "Epoch: 3, Batch: 17, D Loss Real: 0.015589246526360512, D Loss Fake: 0.6345788836479187, G Loss: [13.575615882873535, 0.8651516437530518, 0.12710464000701904]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 18, SSIM Loss: 0.1309201717376709\n",
      "Epoch: 3, Batch: 18, D Loss Real: 0.008084980770945549, D Loss Fake: 0.6628383994102478, G Loss: [13.857952117919922, 0.8472830057144165, 0.13010668754577637]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 19, SSIM Loss: 0.1344543695449829\n",
      "Epoch: 3, Batch: 19, D Loss Real: 0.011293318122625351, D Loss Fake: 0.6707934737205505, G Loss: [14.313481330871582, 0.8484468460083008, 0.1346503496170044]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 20, SSIM Loss: 0.13523948192596436\n",
      "Epoch: 3, Batch: 20, D Loss Real: 0.014809972606599331, D Loss Fake: 0.6876221299171448, G Loss: [14.396114349365234, 0.8722971677780151, 0.1352381706237793]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 21, SSIM Loss: 0.12726008892059326\n",
      "Epoch: 3, Batch: 21, D Loss Real: 0.12439659982919693, D Loss Fake: 0.6882845163345337, G Loss: [13.613588333129883, 0.9106698632240295, 0.1270291805267334]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 22, SSIM Loss: 0.17673581838607788\n",
      "Epoch: 3, Batch: 22, D Loss Real: 0.008048810064792633, D Loss Fake: 1.0442193746566772, G Loss: [18.065826416015625, 1.0196828842163086, 0.17046141624450684]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 23, SSIM Loss: 0.15934360027313232\n",
      "Epoch: 3, Batch: 23, D Loss Real: 0.05685390159487724, D Loss Fake: 0.4851611256599426, G Loss: [17.0047607421875, 1.1103601455688477, 0.1589440107345581]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 24, SSIM Loss: 0.15887153148651123\n",
      "Epoch: 3, Batch: 24, D Loss Real: 0.14761704206466675, D Loss Fake: 0.5179815888404846, G Loss: [16.998048782348633, 1.079555630683899, 0.15918493270874023]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 25, SSIM Loss: 0.14471745491027832\n",
      "Epoch: 3, Batch: 25, D Loss Real: 0.019746407866477966, D Loss Fake: 0.6555216312408447, G Loss: [15.329401016235352, 0.8398692011833191, 0.14489531517028809]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 26, SSIM Loss: 0.1503409743309021\n",
      "Epoch: 3, Batch: 26, D Loss Real: 0.00976566318422556, D Loss Fake: 1.0530973672866821, G Loss: [15.741974830627441, 0.8468033075332642, 0.1489517092704773]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 27, SSIM Loss: 0.14079946279525757\n",
      "Epoch: 3, Batch: 27, D Loss Real: 0.023175153881311417, D Loss Fake: 0.8835702538490295, G Loss: [15.18640422821045, 1.1051281690597534, 0.14081275463104248]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 28, SSIM Loss: 0.1410691738128662\n",
      "Epoch: 3, Batch: 28, D Loss Real: 0.43912214040756226, D Loss Fake: 0.588417112827301, G Loss: [15.008295059204102, 0.9724557995796204, 0.14035838842391968]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 29, SSIM Loss: 0.1494385004043579\n",
      "Epoch: 3, Batch: 29, D Loss Real: 0.09954527020454407, D Loss Fake: 0.7269675731658936, G Loss: [15.767638206481934, 0.8077253103256226, 0.1495991349220276]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 30, SSIM Loss: 0.15548646450042725\n",
      "Epoch: 3, Batch: 30, D Loss Real: 0.03141801059246063, D Loss Fake: 0.8427171111106873, G Loss: [16.43402099609375, 0.8093911409378052, 0.15624630451202393]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 31, SSIM Loss: 0.138022780418396\n",
      "Epoch: 3, Batch: 31, D Loss Real: 0.016378680244088173, D Loss Fake: 0.7007242441177368, G Loss: [14.629759788513184, 0.8566285967826843, 0.13773131370544434]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 32, SSIM Loss: 0.1519014835357666\n",
      "Epoch: 3, Batch: 32, D Loss Real: 0.00887610949575901, D Loss Fake: 0.7290289402008057, G Loss: [15.912971496582031, 0.8610399961471558, 0.15051931142807007]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 3, Batch: 33, SSIM Loss: 0.14779973030090332\n",
      "Epoch: 3, Batch: 33, D Loss Real: 0.006839368958026171, D Loss Fake: 0.7714625597000122, G Loss: [15.58688735961914, 0.9466515779495239, 0.14640235900878906]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 34, SSIM Loss: 0.15415608882904053\n",
      "Epoch: 3, Batch: 34, D Loss Real: 0.019004903733730316, D Loss Fake: 0.6734133958816528, G Loss: [16.40657615661621, 1.004193902015686, 0.15402382612228394]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 35, SSIM Loss: 0.12903541326522827\n",
      "Epoch: 3, Batch: 35, D Loss Real: 0.02608715184032917, D Loss Fake: 0.610947847366333, G Loss: [13.91382884979248, 0.9768792390823364, 0.12936949729919434]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 3, Batch: 36, SSIM Loss: 0.1476370096206665\n",
      "Epoch: 3, Batch: 36, D Loss Real: 0.008999943733215332, D Loss Fake: 0.6751548051834106, G Loss: [15.566469192504883, 0.880003809928894, 0.146864652633667]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 37, SSIM Loss: 0.14172112941741943\n",
      "Epoch: 3, Batch: 37, D Loss Real: 0.006989181041717529, D Loss Fake: 0.725482165813446, G Loss: [14.98638916015625, 0.9066332578659058, 0.14079755544662476]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 38, SSIM Loss: 0.15685784816741943\n",
      "Epoch: 3, Batch: 38, D Loss Real: 0.007103213109076023, D Loss Fake: 0.7537311911582947, G Loss: [16.59231948852539, 0.9567342400550842, 0.1563558578491211]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 39, SSIM Loss: 0.13824903964996338\n",
      "Epoch: 3, Batch: 39, D Loss Real: 0.007149974349886179, D Loss Fake: 0.6440590620040894, G Loss: [14.813711166381836, 0.9713072776794434, 0.13842403888702393]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 40, SSIM Loss: 0.14181196689605713\n",
      "Epoch: 3, Batch: 40, D Loss Real: 0.00820959359407425, D Loss Fake: 0.641900897026062, G Loss: [15.156686782836914, 0.9464631080627441, 0.14210224151611328]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 41, SSIM Loss: 0.12862545251846313\n",
      "Epoch: 3, Batch: 41, D Loss Real: 0.006808770354837179, D Loss Fake: 0.6935369968414307, G Loss: [13.848388671875, 0.959062397480011, 0.12889325618743896]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 42, SSIM Loss: 0.13449609279632568\n",
      "Epoch: 3, Batch: 42, D Loss Real: 0.009958358481526375, D Loss Fake: 0.6468774080276489, G Loss: [14.455086708068848, 0.9328793287277222, 0.13522207736968994]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 43, SSIM Loss: 0.1362595558166504\n",
      "Epoch: 3, Batch: 43, D Loss Real: 0.011011327616870403, D Loss Fake: 0.7001338005065918, G Loss: [14.546006202697754, 0.9278466105461121, 0.13618159294128418]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 3, Batch: 44, SSIM Loss: 0.13055634498596191\n",
      "Epoch: 3, Batch: 44, D Loss Real: 0.0067613557912409306, D Loss Fake: 0.7294553518295288, G Loss: [14.065958976745605, 0.9594935774803162, 0.13106465339660645]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 3, Batch: 45, SSIM Loss: 0.14997506141662598\n",
      "Epoch: 3, Batch: 45, D Loss Real: 0.00970124639570713, D Loss Fake: 0.6316553354263306, G Loss: [15.983509063720703, 0.9803882837295532, 0.1500312089920044]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 46, SSIM Loss: 0.13094353675842285\n",
      "Epoch: 3, Batch: 46, D Loss Real: 0.008604811504483223, D Loss Fake: 0.6792388558387756, G Loss: [14.0795316696167, 0.968453049659729, 0.1311107873916626]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 47, SSIM Loss: 0.14890581369400024\n",
      "Epoch: 3, Batch: 47, D Loss Real: 0.012605131603777409, D Loss Fake: 0.6159298419952393, G Loss: [15.831503868103027, 0.9368278980255127, 0.14894676208496094]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 48, SSIM Loss: 0.15082943439483643\n",
      "Epoch: 3, Batch: 48, D Loss Real: 0.011572727933526039, D Loss Fake: 0.6854392290115356, G Loss: [16.04930877685547, 0.9535078406333923, 0.15095800161361694]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 49, SSIM Loss: 0.14067983627319336\n",
      "Epoch: 3, Batch: 49, D Loss Real: 0.006535414606332779, D Loss Fake: 0.7536035776138306, G Loss: [14.896259307861328, 0.9299736618995667, 0.13966286182403564]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 50, SSIM Loss: 0.13891279697418213\n",
      "Epoch: 3, Batch: 50, D Loss Real: 0.006910352036356926, D Loss Fake: 0.667129635810852, G Loss: [14.886260986328125, 0.9639507532119751, 0.1392230987548828]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 51, SSIM Loss: 0.1360723376274109\n",
      "Epoch: 3, Batch: 51, D Loss Real: 0.014284874312579632, D Loss Fake: 0.6352617144584656, G Loss: [14.635268211364746, 0.9672319889068604, 0.13668036460876465]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 52, SSIM Loss: 0.13911056518554688\n",
      "Epoch: 3, Batch: 52, D Loss Real: 0.013159520924091339, D Loss Fake: 0.6360514760017395, G Loss: [14.839661598205566, 0.9548842906951904, 0.13884776830673218]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 53, SSIM Loss: 0.1359882354736328\n",
      "Epoch: 3, Batch: 53, D Loss Real: 0.008053522557020187, D Loss Fake: 0.6305465698242188, G Loss: [14.519091606140137, 0.9300963878631592, 0.1358899474143982]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 54, SSIM Loss: 0.13556593656539917\n",
      "Epoch: 3, Batch: 54, D Loss Real: 0.03207124024629593, D Loss Fake: 0.7065008282661438, G Loss: [14.470787048339844, 0.9400792121887207, 0.13530707359313965]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 55, SSIM Loss: 0.12288153171539307\n",
      "Epoch: 3, Batch: 55, D Loss Real: 0.01896212063729763, D Loss Fake: 0.8301258683204651, G Loss: [13.301775932312012, 0.9824730753898621, 0.12319302558898926]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 56, SSIM Loss: 0.13135260343551636\n",
      "Epoch: 3, Batch: 56, D Loss Real: 0.11038203537464142, D Loss Fake: 0.6311724185943604, G Loss: [14.189180374145508, 0.9927483797073364, 0.1319643259048462]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 57, SSIM Loss: 0.14635545015335083\n",
      "Epoch: 3, Batch: 57, D Loss Real: 0.01618693210184574, D Loss Fake: 0.6368311047554016, G Loss: [15.574246406555176, 0.9525231122970581, 0.1462172269821167]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 58, SSIM Loss: 0.1414278745651245\n",
      "Epoch: 3, Batch: 58, D Loss Real: 0.005116341635584831, D Loss Fake: 0.7606122493743896, G Loss: [15.101614952087402, 0.9804877042770386, 0.14121127128601074]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 59, SSIM Loss: 0.13519299030303955\n",
      "Epoch: 3, Batch: 59, D Loss Real: 0.011920147575438023, D Loss Fake: 0.7204182147979736, G Loss: [14.467260360717773, 0.9735080003738403, 0.13493752479553223]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 60, SSIM Loss: 0.13507020473480225\n",
      "Epoch: 3, Batch: 60, D Loss Real: 0.08705531060695648, D Loss Fake: 0.7963401079177856, G Loss: [14.50286865234375, 1.0142420530319214, 0.1348862648010254]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 61, SSIM Loss: 0.13212990760803223\n",
      "Epoch: 3, Batch: 61, D Loss Real: 0.03642939776182175, D Loss Fake: 0.582155168056488, G Loss: [14.182381629943848, 0.9866947531700134, 0.13195687532424927]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 3, Batch: 62, SSIM Loss: 0.1266648769378662\n",
      "Epoch: 3, Batch: 62, D Loss Real: 0.012991221621632576, D Loss Fake: 0.6444298028945923, G Loss: [13.650671005249023, 0.9331613183021545, 0.12717509269714355]\n",
      "1/1 [==============================] - 0s 148ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:16:26.676665: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:16:28.137997: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch: 1, SSIM Loss: 0.12578225135803223\n",
      "Epoch: 4, Batch: 1, D Loss Real: 0.007876230403780937, D Loss Fake: 0.7127915620803833, G Loss: [13.670300483703613, 0.9416336417198181, 0.12728667259216309]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 2, SSIM Loss: 0.11982518434524536\n",
      "Epoch: 4, Batch: 2, D Loss Real: 0.012043713591992855, D Loss Fake: 0.6707598567008972, G Loss: [12.964028358459473, 0.981480598449707, 0.11982548236846924]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 4, Batch: 3, SSIM Loss: 0.13823539018630981\n",
      "Epoch: 4, Batch: 3, D Loss Real: 0.048622291535139084, D Loss Fake: 0.77926105260849, G Loss: [14.858627319335938, 1.0002849102020264, 0.13858342170715332]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 4, SSIM Loss: 0.13637393712997437\n",
      "Epoch: 4, Batch: 4, D Loss Real: 0.019774824380874634, D Loss Fake: 0.5971702337265015, G Loss: [14.603835105895996, 1.002812385559082, 0.13601022958755493]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 5, SSIM Loss: 0.13916826248168945\n",
      "Epoch: 4, Batch: 5, D Loss Real: 0.01103475783020258, D Loss Fake: 0.6339933276176453, G Loss: [14.54199504852295, 0.9812652468681335, 0.1356073021888733]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 6, SSIM Loss: 0.12799131870269775\n",
      "Epoch: 4, Batch: 6, D Loss Real: 0.006902697961777449, D Loss Fake: 0.6763433814048767, G Loss: [13.806090354919434, 0.9964683055877686, 0.12809622287750244]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 7, SSIM Loss: 0.13280713558197021\n",
      "Epoch: 4, Batch: 7, D Loss Real: 0.0735490694642067, D Loss Fake: 0.7426342368125916, G Loss: [14.285261154174805, 1.002973198890686, 0.13282287120819092]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 8, SSIM Loss: 0.12629151344299316\n",
      "Epoch: 4, Batch: 8, D Loss Real: 0.012461140751838684, D Loss Fake: 0.6536190509796143, G Loss: [13.573147773742676, 0.9802358150482178, 0.1259291172027588]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 9, SSIM Loss: 0.13656193017959595\n",
      "Epoch: 4, Batch: 9, D Loss Real: 0.017329495400190353, D Loss Fake: 0.6620638370513916, G Loss: [14.641963958740234, 0.9704701900482178, 0.13671493530273438]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 10, SSIM Loss: 0.1234017014503479\n",
      "Epoch: 4, Batch: 10, D Loss Real: 0.0074600400403141975, D Loss Fake: 0.6555023789405823, G Loss: [13.31689453125, 1.0062099695205688, 0.12310683727264404]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 4, Batch: 11, SSIM Loss: 0.1264439821243286\n",
      "Epoch: 4, Batch: 11, D Loss Real: 0.028633179143071175, D Loss Fake: 0.6752126216888428, G Loss: [13.648082733154297, 0.9738222360610962, 0.12674260139465332]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 12, SSIM Loss: 0.13236427307128906\n",
      "Epoch: 4, Batch: 12, D Loss Real: 0.02585931494832039, D Loss Fake: 0.6462705135345459, G Loss: [14.160567283630371, 0.9479340314865112, 0.1321263313293457]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 13, SSIM Loss: 0.14191585779190063\n",
      "Epoch: 4, Batch: 13, D Loss Real: 0.011208189651370049, D Loss Fake: 0.6483259797096252, G Loss: [15.167577743530273, 0.9425349235534668, 0.1422504186630249]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 14, SSIM Loss: 0.13544607162475586\n",
      "Epoch: 4, Batch: 14, D Loss Real: 0.0090875755995512, D Loss Fake: 0.7229995131492615, G Loss: [14.474727630615234, 0.9496891498565674, 0.13525038957595825]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 15, SSIM Loss: 0.1366654634475708\n",
      "Epoch: 4, Batch: 15, D Loss Real: 0.011369775980710983, D Loss Fake: 0.8972804546356201, G Loss: [14.710272789001465, 1.0278593301773071, 0.1368241310119629]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 16, SSIM Loss: 0.127951979637146\n",
      "Epoch: 4, Batch: 16, D Loss Real: 0.3629753589630127, D Loss Fake: 1.2553730010986328, G Loss: [13.982745170593262, 1.196154236793518, 0.12786591053009033]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 17, SSIM Loss: 0.1278281807899475\n",
      "Epoch: 4, Batch: 17, D Loss Real: 0.5601378679275513, D Loss Fake: 0.5977564454078674, G Loss: [13.72875690460205, 0.9404376149177551, 0.1278831958770752]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 18, SSIM Loss: 0.13259559869766235\n",
      "Epoch: 4, Batch: 18, D Loss Real: 0.06738889217376709, D Loss Fake: 0.663302481174469, G Loss: [14.102684020996094, 0.8906235098838806, 0.13212060928344727]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 19, SSIM Loss: 0.13484078645706177\n",
      "Epoch: 4, Batch: 19, D Loss Real: 0.018622618168592453, D Loss Fake: 0.7153025269508362, G Loss: [14.350923538208008, 0.8495173454284668, 0.13501405715942383]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 20, SSIM Loss: 0.1355224847793579\n",
      "Epoch: 4, Batch: 20, D Loss Real: 0.011059576645493507, D Loss Fake: 0.7492802739143372, G Loss: [14.493637084960938, 0.8982523679733276, 0.1359538435935974]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 21, SSIM Loss: 0.12877249717712402\n",
      "Epoch: 4, Batch: 21, D Loss Real: 0.014284295961260796, D Loss Fake: 0.7101579308509827, G Loss: [14.017229080200195, 0.9091129899024963, 0.13108116388320923]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 22, SSIM Loss: 0.13181161880493164\n",
      "Epoch: 4, Batch: 22, D Loss Real: 0.0481204055249691, D Loss Fake: 0.6802622079849243, G Loss: [14.176675796508789, 0.9362667202949524, 0.13240408897399902]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 23, SSIM Loss: 0.13470089435577393\n",
      "Epoch: 4, Batch: 23, D Loss Real: 0.017080403864383698, D Loss Fake: 0.6899514198303223, G Loss: [14.411019325256348, 0.9266904592514038, 0.13484328985214233]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 24, SSIM Loss: 0.13459688425064087\n",
      "Epoch: 4, Batch: 24, D Loss Real: 0.01026053074747324, D Loss Fake: 0.7726307511329651, G Loss: [14.467287063598633, 1.00584077835083, 0.1346144676208496]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 25, SSIM Loss: 0.12798643112182617\n",
      "Epoch: 4, Batch: 25, D Loss Real: 0.010462767444550991, D Loss Fake: 0.5901470184326172, G Loss: [13.738899230957031, 0.9498295783996582, 0.1278907060623169]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 26, SSIM Loss: 0.1274486780166626\n",
      "Epoch: 4, Batch: 26, D Loss Real: 0.02625347673892975, D Loss Fake: 0.6683230996131897, G Loss: [13.72243595123291, 0.9128140211105347, 0.12809622287750244]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 27, SSIM Loss: 0.12390154600143433\n",
      "Epoch: 4, Batch: 27, D Loss Real: 0.007919304072856903, D Loss Fake: 0.6827820539474487, G Loss: [13.293643951416016, 0.9497718811035156, 0.12343871593475342]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 28, SSIM Loss: 0.11992847919464111\n",
      "Epoch: 4, Batch: 28, D Loss Real: 0.008682982064783573, D Loss Fake: 0.6589145064353943, G Loss: [12.916631698608398, 0.9399371147155762, 0.1197669506072998]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 29, SSIM Loss: 0.13580691814422607\n",
      "Epoch: 4, Batch: 29, D Loss Real: 0.017074912786483765, D Loss Fake: 0.6645361185073853, G Loss: [14.514849662780762, 0.9425265789031982, 0.13572323322296143]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 30, SSIM Loss: 0.13716840744018555\n",
      "Epoch: 4, Batch: 30, D Loss Real: 0.008563024923205376, D Loss Fake: 0.6403089761734009, G Loss: [14.712874412536621, 0.9377702474594116, 0.137751042842865]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 4, Batch: 31, SSIM Loss: 0.12673866748809814\n",
      "Epoch: 4, Batch: 31, D Loss Real: 0.00993532408028841, D Loss Fake: 0.6630316376686096, G Loss: [13.657190322875977, 0.936241626739502, 0.12720948457717896]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 32, SSIM Loss: 0.13408106565475464\n",
      "Epoch: 4, Batch: 32, D Loss Real: 0.007286995183676481, D Loss Fake: 0.6824215054512024, G Loss: [14.388580322265625, 0.97330242395401, 0.13415277004241943]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 33, SSIM Loss: 0.13276654481887817\n",
      "Epoch: 4, Batch: 33, D Loss Real: 0.012257984839379787, D Loss Fake: 0.7736558318138123, G Loss: [14.300973892211914, 1.0455024242401123, 0.13255470991134644]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 4, Batch: 34, SSIM Loss: 0.13870269060134888\n",
      "Epoch: 4, Batch: 34, D Loss Real: 0.024223245680332184, D Loss Fake: 0.5863359570503235, G Loss: [14.836607933044434, 0.9910454154014587, 0.13845562934875488]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 35, SSIM Loss: 0.11376678943634033\n",
      "Epoch: 4, Batch: 35, D Loss Real: 0.02304871194064617, D Loss Fake: 0.6362009644508362, G Loss: [12.35301399230957, 0.9757270216941833, 0.11377286911010742]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 36, SSIM Loss: 0.1334373950958252\n",
      "Epoch: 4, Batch: 36, D Loss Real: 0.021845068782567978, D Loss Fake: 0.6632007360458374, G Loss: [14.377132415771484, 1.0276292562484741, 0.133495032787323]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 37, SSIM Loss: 0.12724405527114868\n",
      "Epoch: 4, Batch: 37, D Loss Real: 0.020580243319272995, D Loss Fake: 0.6642571091651917, G Loss: [13.702388763427734, 0.9714564681053162, 0.12730932235717773]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 38, SSIM Loss: 0.14501965045928955\n",
      "Epoch: 4, Batch: 38, D Loss Real: 0.010070298798382282, D Loss Fake: 0.6705867648124695, G Loss: [15.50107192993164, 1.011725902557373, 0.14489346742630005]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 39, SSIM Loss: 0.12880206108093262\n",
      "Epoch: 4, Batch: 39, D Loss Real: 0.006712389178574085, D Loss Fake: 0.6725140810012817, G Loss: [13.855257034301758, 0.9829666018486023, 0.1287229061126709]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 40, SSIM Loss: 0.12980449199676514\n",
      "Epoch: 4, Batch: 40, D Loss Real: 0.006248669233173132, D Loss Fake: 0.6377432346343994, G Loss: [14.031244277954102, 1.0190261602401733, 0.13012218475341797]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 41, SSIM Loss: 0.11713802814483643\n",
      "Epoch: 4, Batch: 41, D Loss Real: 0.008459033444523811, D Loss Fake: 0.740288496017456, G Loss: [12.734081268310547, 1.0347628593444824, 0.11699318885803223]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 42, SSIM Loss: 0.12471878528594971\n",
      "Epoch: 4, Batch: 42, D Loss Real: 0.06443993002176285, D Loss Fake: 0.8812879920005798, G Loss: [13.642191886901855, 1.1901142597198486, 0.12452077865600586]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 4, Batch: 43, SSIM Loss: 0.12448710203170776\n",
      "Epoch: 4, Batch: 43, D Loss Real: 0.04755701124668121, D Loss Fake: 0.5302751064300537, G Loss: [13.535881042480469, 1.0880110263824463, 0.12447869777679443]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 44, SSIM Loss: 0.11838603019714355\n",
      "Epoch: 4, Batch: 44, D Loss Real: 0.01848793774843216, D Loss Fake: 0.6049546003341675, G Loss: [12.893194198608398, 1.057953119277954, 0.11835241317749023]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 45, SSIM Loss: 0.1377321481704712\n",
      "Epoch: 4, Batch: 45, D Loss Real: 0.02695171721279621, D Loss Fake: 0.7064010500907898, G Loss: [14.816254615783691, 1.0753990411758423, 0.1374085545539856]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 46, SSIM Loss: 0.11993980407714844\n",
      "Epoch: 4, Batch: 46, D Loss Real: 0.3978062570095062, D Loss Fake: 0.9171579480171204, G Loss: [13.098053932189941, 1.101707100868225, 0.11996346712112427]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 47, SSIM Loss: 0.13962262868881226\n",
      "Epoch: 4, Batch: 47, D Loss Real: 0.05909403786063194, D Loss Fake: 0.6970615386962891, G Loss: [14.93792724609375, 0.9824180603027344, 0.13955509662628174]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 48, SSIM Loss: 0.13669300079345703\n",
      "Epoch: 4, Batch: 48, D Loss Real: 0.012988712638616562, D Loss Fake: 0.8244895935058594, G Loss: [14.62682056427002, 0.9417610168457031, 0.13685059547424316]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 49, SSIM Loss: 0.1267162561416626\n",
      "Epoch: 4, Batch: 49, D Loss Real: 0.012103771790862083, D Loss Fake: 0.7173047065734863, G Loss: [13.659200668334961, 1.0368084907531738, 0.12622392177581787]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 50, SSIM Loss: 0.12308907508850098\n",
      "Epoch: 4, Batch: 50, D Loss Real: 0.010380162857472897, D Loss Fake: 0.6133643388748169, G Loss: [13.37977409362793, 1.067086935043335, 0.12312686443328857]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 51, SSIM Loss: 0.1270841360092163\n",
      "Epoch: 4, Batch: 51, D Loss Real: 0.020571434870362282, D Loss Fake: 0.6746490597724915, G Loss: [13.713004112243652, 1.022621512413025, 0.12690383195877075]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 52, SSIM Loss: 0.12717103958129883\n",
      "Epoch: 4, Batch: 52, D Loss Real: 0.011700784787535667, D Loss Fake: 0.6143673658370972, G Loss: [13.693018913269043, 0.9893378019332886, 0.12703680992126465]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 53, SSIM Loss: 0.1264404058456421\n",
      "Epoch: 4, Batch: 53, D Loss Real: 0.0137197719886899, D Loss Fake: 0.7364044189453125, G Loss: [13.647797584533691, 1.0096696615219116, 0.1263812780380249]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 54, SSIM Loss: 0.12949395179748535\n",
      "Epoch: 4, Batch: 54, D Loss Real: 0.19589877128601074, D Loss Fake: 0.9120669960975647, G Loss: [13.939813613891602, 0.981620728969574, 0.12958192825317383]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 55, SSIM Loss: 0.11402285099029541\n",
      "Epoch: 4, Batch: 55, D Loss Real: 0.07698798924684525, D Loss Fake: 3.968933582305908, G Loss: [13.529008865356445, 2.171140670776367, 0.1135786771774292]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 4, Batch: 56, SSIM Loss: 0.12716364860534668\n",
      "Epoch: 4, Batch: 56, D Loss Real: 0.3954915702342987, D Loss Fake: 1.1661133766174316, G Loss: [14.360605239868164, 1.6586174964904785, 0.12701988220214844]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 57, SSIM Loss: 0.13860803842544556\n",
      "Epoch: 4, Batch: 57, D Loss Real: 0.376653254032135, D Loss Fake: 1.3303154706954956, G Loss: [15.230941772460938, 1.3395198583602905, 0.13891422748565674]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 58, SSIM Loss: 0.13751155138015747\n",
      "Epoch: 4, Batch: 58, D Loss Real: 0.30537399649620056, D Loss Fake: 1.342340350151062, G Loss: [14.946077346801758, 1.2020454406738281, 0.13744032382965088]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 4, Batch: 59, SSIM Loss: 0.1286919116973877\n",
      "Epoch: 4, Batch: 59, D Loss Real: 0.2682803273200989, D Loss Fake: 1.401058316230774, G Loss: [14.008827209472656, 1.1279054880142212, 0.12880921363830566]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 60, SSIM Loss: 0.12769949436187744\n",
      "Epoch: 4, Batch: 60, D Loss Real: 0.30938294529914856, D Loss Fake: 1.3233405351638794, G Loss: [13.904485702514648, 1.1163330078125, 0.12788152694702148]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 61, SSIM Loss: 0.12258744239807129\n",
      "Epoch: 4, Batch: 61, D Loss Real: 0.3051019608974457, D Loss Fake: 1.2387993335723877, G Loss: [13.36416244506836, 1.0769153833389282, 0.12287247180938721]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 4, Batch: 62, SSIM Loss: 0.12083041667938232\n",
      "Epoch: 4, Batch: 62, D Loss Real: 0.3122461140155792, D Loss Fake: 1.3093962669372559, G Loss: [13.09014892578125, 1.002463936805725, 0.12087684869766235]\n",
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:17:50.009900: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:17:51.475688: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch: 1, SSIM Loss: 0.1189197301864624\n",
      "Epoch: 5, Batch: 1, D Loss Real: 0.2917201817035675, D Loss Fake: 1.2641810178756714, G Loss: [12.85484790802002, 0.9979695677757263, 0.1185687780380249]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 5, Batch: 2, SSIM Loss: 0.11420398950576782\n",
      "Epoch: 5, Batch: 2, D Loss Real: 0.28027915954589844, D Loss Fake: 1.2897626161575317, G Loss: [12.38156795501709, 0.9719091057777405, 0.11409658193588257]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 5, Batch: 3, SSIM Loss: 0.13000887632369995\n",
      "Epoch: 5, Batch: 3, D Loss Real: 0.29459676146507263, D Loss Fake: 1.2411656379699707, G Loss: [13.879518508911133, 0.9692957997322083, 0.12910223007202148]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 4, SSIM Loss: 0.13456284999847412\n",
      "Epoch: 5, Batch: 4, D Loss Real: 0.29961466789245605, D Loss Fake: 1.2113702297210693, G Loss: [14.477700233459473, 0.9596946239471436, 0.1351800560951233]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 5, Batch: 5, SSIM Loss: 0.12807458639144897\n",
      "Epoch: 5, Batch: 5, D Loss Real: 0.28237470984458923, D Loss Fake: 1.260000467300415, G Loss: [13.744772911071777, 0.9284025430679321, 0.12816369533538818]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 5, Batch: 6, SSIM Loss: 0.12283903360366821\n",
      "Epoch: 5, Batch: 6, D Loss Real: 0.28950032591819763, D Loss Fake: 1.2602708339691162, G Loss: [13.227212905883789, 0.9386186599731445, 0.12288594245910645]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 5, Batch: 7, SSIM Loss: 0.12937355041503906\n",
      "Epoch: 5, Batch: 7, D Loss Real: 0.2919759452342987, D Loss Fake: 1.195866584777832, G Loss: [13.883705139160156, 0.9309724569320679, 0.12952733039855957]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 8, SSIM Loss: 0.12253075838088989\n",
      "Epoch: 5, Batch: 8, D Loss Real: 0.278352826833725, D Loss Fake: 1.2230536937713623, G Loss: [13.164016723632812, 0.9114949703216553, 0.12252521514892578]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 5, Batch: 9, SSIM Loss: 0.13013988733291626\n",
      "Epoch: 5, Batch: 9, D Loss Real: 0.2801040709018707, D Loss Fake: 1.2388155460357666, G Loss: [13.936919212341309, 0.903683602809906, 0.130332350730896]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 10, SSIM Loss: 0.11914491653442383\n",
      "Epoch: 5, Batch: 10, D Loss Real: 0.2807736098766327, D Loss Fake: 1.2768698930740356, G Loss: [12.754332542419434, 0.8692502975463867, 0.11885082721710205]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 11, SSIM Loss: 0.12061011791229248\n",
      "Epoch: 5, Batch: 11, D Loss Real: 0.2785567343235016, D Loss Fake: 1.1767586469650269, G Loss: [13.2669677734375, 1.2107127904891968, 0.12056255340576172]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 5, Batch: 12, SSIM Loss: 0.12623953819274902\n",
      "Epoch: 5, Batch: 12, D Loss Real: 0.316893607378006, D Loss Fake: 1.1623315811157227, G Loss: [13.508123397827148, 0.8731970191001892, 0.12634927034378052]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 5, Batch: 13, SSIM Loss: 0.1350773572921753\n",
      "Epoch: 5, Batch: 13, D Loss Real: 0.2910650968551636, D Loss Fake: 1.2292803525924683, G Loss: [14.353413581848145, 0.8284162282943726, 0.13524997234344482]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 14, SSIM Loss: 0.13073134422302246\n",
      "Epoch: 5, Batch: 14, D Loss Real: 0.2901206612586975, D Loss Fake: 1.2478893995285034, G Loss: [13.812708854675293, 0.8232414126396179, 0.1298946738243103]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 15, SSIM Loss: 0.1280232071876526\n",
      "Epoch: 5, Batch: 15, D Loss Real: 0.29260146617889404, D Loss Fake: 1.250616192817688, G Loss: [13.68026065826416, 0.8160885572433472, 0.12864172458648682]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 16, SSIM Loss: 0.12415832281112671\n",
      "Epoch: 5, Batch: 16, D Loss Real: 0.2982415556907654, D Loss Fake: 1.2302073240280151, G Loss: [13.226644515991211, 0.8224999308586121, 0.12404143810272217]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 17, SSIM Loss: 0.12164533138275146\n",
      "Epoch: 5, Batch: 17, D Loss Real: 0.3152051568031311, D Loss Fake: 1.206303596496582, G Loss: [12.974489212036133, 0.8211793899536133, 0.1215330958366394]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 18, SSIM Loss: 0.12393689155578613\n",
      "Epoch: 5, Batch: 18, D Loss Real: 0.3053577244281769, D Loss Fake: 1.2135796546936035, G Loss: [13.110610961914062, 0.810692310333252, 0.12299919128417969]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 19, SSIM Loss: 0.12773555517196655\n",
      "Epoch: 5, Batch: 19, D Loss Real: 0.31314730644226074, D Loss Fake: 1.2369955778121948, G Loss: [13.571709632873535, 0.7904469966888428, 0.12781262397766113]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 20, SSIM Loss: 0.13040679693222046\n",
      "Epoch: 5, Batch: 20, D Loss Real: 0.3020099401473999, D Loss Fake: 1.2314703464508057, G Loss: [13.633590698242188, 0.7949520945549011, 0.12838637828826904]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 21, SSIM Loss: 0.16504567861557007\n",
      "Epoch: 5, Batch: 21, D Loss Real: 0.3132359981536865, D Loss Fake: 1.2335662841796875, G Loss: [15.677407264709473, 0.7857588529586792, 0.14891648292541504]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 22, SSIM Loss: 0.1352391242980957\n",
      "Epoch: 5, Batch: 22, D Loss Real: 0.31212812662124634, D Loss Fake: 1.205631971359253, G Loss: [14.284281730651855, 0.7896110415458679, 0.13494670391082764]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 23, SSIM Loss: 0.13571584224700928\n",
      "Epoch: 5, Batch: 23, D Loss Real: 0.3117002844810486, D Loss Fake: 1.1982797384262085, G Loss: [14.385860443115234, 0.784366250038147, 0.1360149383544922]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 24, SSIM Loss: 0.13525253534317017\n",
      "Epoch: 5, Batch: 24, D Loss Real: 0.30810853838920593, D Loss Fake: 1.2143745422363281, G Loss: [14.30368709564209, 0.774635910987854, 0.1352905035018921]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 25, SSIM Loss: 0.1290125846862793\n",
      "Epoch: 5, Batch: 25, D Loss Real: 0.30331894755363464, D Loss Fake: 1.1425554752349854, G Loss: [13.785578727722168, 0.8652997612953186, 0.12920278310775757]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 26, SSIM Loss: 0.13177204132080078\n",
      "Epoch: 5, Batch: 26, D Loss Real: 0.30483049154281616, D Loss Fake: 1.1756045818328857, G Loss: [13.922986030578613, 0.7830347418785095, 0.1313995122909546]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 27, SSIM Loss: 0.12770938873291016\n",
      "Epoch: 5, Batch: 27, D Loss Real: 0.2916383743286133, D Loss Fake: 1.1650586128234863, G Loss: [13.598336219787598, 0.8178069591522217, 0.12780529260635376]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 28, SSIM Loss: 0.1248587965965271\n",
      "Epoch: 5, Batch: 28, D Loss Real: 0.2703772485256195, D Loss Fake: 1.195151686668396, G Loss: [13.297979354858398, 0.8138400912284851, 0.12484139204025269]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 29, SSIM Loss: 0.13612961769104004\n",
      "Epoch: 5, Batch: 29, D Loss Real: 0.2763698697090149, D Loss Fake: 1.224932312965393, G Loss: [14.39652156829834, 0.7860396504402161, 0.13610482215881348]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 30, SSIM Loss: 0.13683903217315674\n",
      "Epoch: 5, Batch: 30, D Loss Real: 0.28197038173675537, D Loss Fake: 1.255455732345581, G Loss: [14.428565979003906, 0.7589324712753296, 0.13669633865356445]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 31, SSIM Loss: 0.12668782472610474\n",
      "Epoch: 5, Batch: 31, D Loss Real: 0.3021922707557678, D Loss Fake: 1.2569440603256226, G Loss: [13.393614768981934, 0.7415333390235901, 0.1265208125114441]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 5, Batch: 32, SSIM Loss: 0.13316333293914795\n",
      "Epoch: 5, Batch: 32, D Loss Real: 0.3065924048423767, D Loss Fake: 1.2412927150726318, G Loss: [14.057014465332031, 0.7425109148025513, 0.1331450343132019]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 33, SSIM Loss: 0.13221639394760132\n",
      "Epoch: 5, Batch: 33, D Loss Real: 0.31185486912727356, D Loss Fake: 1.2151813507080078, G Loss: [13.963235855102539, 0.7471274733543396, 0.13216108083724976]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 34, SSIM Loss: 0.13539117574691772\n",
      "Epoch: 5, Batch: 34, D Loss Real: 0.30994558334350586, D Loss Fake: 1.2250573635101318, G Loss: [14.250388145446777, 0.7313283085823059, 0.13519060611724854]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 35, SSIM Loss: 0.11373239755630493\n",
      "Epoch: 5, Batch: 35, D Loss Real: 0.3317864239215851, D Loss Fake: 1.1910855770111084, G Loss: [12.125072479248047, 0.740985095500946, 0.11384087800979614]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 36, SSIM Loss: 0.13196420669555664\n",
      "Epoch: 5, Batch: 36, D Loss Real: 0.3072257936000824, D Loss Fake: 1.2542238235473633, G Loss: [13.94067668914795, 0.7044163346290588, 0.13236260414123535]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 37, SSIM Loss: 0.1255629062652588\n",
      "Epoch: 5, Batch: 37, D Loss Real: 0.3197767436504364, D Loss Fake: 1.2265429496765137, G Loss: [13.287970542907715, 0.7098880410194397, 0.12578082084655762]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 5, Batch: 38, SSIM Loss: 0.14291566610336304\n",
      "Epoch: 5, Batch: 38, D Loss Real: 0.327669233083725, D Loss Fake: 1.2044739723205566, G Loss: [14.988765716552734, 0.7152060866355896, 0.14273560047149658]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 39, SSIM Loss: 0.1267288327217102\n",
      "Epoch: 5, Batch: 39, D Loss Real: 0.33346351981163025, D Loss Fake: 1.220367193222046, G Loss: [13.38642692565918, 0.701819121837616, 0.1268460750579834]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 5, Batch: 40, SSIM Loss: 0.12646090984344482\n",
      "Epoch: 5, Batch: 40, D Loss Real: 0.32812920212745667, D Loss Fake: 1.2084200382232666, G Loss: [13.333062171936035, 0.7015926837921143, 0.1263146996498108]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 41, SSIM Loss: 0.11692291498184204\n",
      "Epoch: 5, Batch: 41, D Loss Real: 0.3307502567768097, D Loss Fake: 1.2168612480163574, G Loss: [12.421197891235352, 0.6960583329200745, 0.11725139617919922]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 42, SSIM Loss: 0.1232110857963562\n",
      "Epoch: 5, Batch: 42, D Loss Real: 0.34616783261299133, D Loss Fake: 1.2018402814865112, G Loss: [13.021825790405273, 0.6964964866638184, 0.12325328588485718]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 43, SSIM Loss: 0.12231653928756714\n",
      "Epoch: 5, Batch: 43, D Loss Real: 0.3380683362483978, D Loss Fake: 1.2055586576461792, G Loss: [12.92578125, 0.6911175847053528, 0.12234663963317871]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 44, SSIM Loss: 0.11676770448684692\n",
      "Epoch: 5, Batch: 44, D Loss Real: 0.32878902554512024, D Loss Fake: 1.2016351222991943, G Loss: [12.375659942626953, 0.694460928440094, 0.11681199073791504]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 5, Batch: 45, SSIM Loss: 0.13650894165039062\n",
      "Epoch: 5, Batch: 45, D Loss Real: 0.35020846128463745, D Loss Fake: 1.2377831935882568, G Loss: [14.319196701049805, 0.6701200604438782, 0.13649076223373413]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 46, SSIM Loss: 0.11869561672210693\n",
      "Epoch: 5, Batch: 46, D Loss Real: 0.3263348937034607, D Loss Fake: 1.2307785749435425, G Loss: [12.541356086730957, 0.6738273501396179, 0.11867529153823853]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 47, SSIM Loss: 0.1375133991241455\n",
      "Epoch: 5, Batch: 47, D Loss Real: 0.34104734659194946, D Loss Fake: 1.2124302387237549, G Loss: [14.408998489379883, 0.6764878630638123, 0.13732510805130005]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 48, SSIM Loss: 0.13175547122955322\n",
      "Epoch: 5, Batch: 48, D Loss Real: 0.3370009660720825, D Loss Fake: 1.2043142318725586, G Loss: [13.906486511230469, 0.6750771999359131, 0.13231408596038818]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 49, SSIM Loss: 0.12588560581207275\n",
      "Epoch: 5, Batch: 49, D Loss Real: 0.3389562666416168, D Loss Fake: 1.120124340057373, G Loss: [13.378310203552246, 0.7434368133544922, 0.12634873390197754]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 50, SSIM Loss: 0.1230994462966919\n",
      "Epoch: 5, Batch: 50, D Loss Real: 0.3254324197769165, D Loss Fake: 1.2535209655761719, G Loss: [12.96634578704834, 0.6439253687858582, 0.12322419881820679]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 51, SSIM Loss: 0.12506085634231567\n",
      "Epoch: 5, Batch: 51, D Loss Real: 0.32470208406448364, D Loss Fake: 1.2093483209609985, G Loss: [13.15186595916748, 0.6673872470855713, 0.12484478950500488]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 52, SSIM Loss: 0.12676095962524414\n",
      "Epoch: 5, Batch: 52, D Loss Real: 0.3259095549583435, D Loss Fake: 1.2003782987594604, G Loss: [13.30378532409668, 0.6682801246643066, 0.12635505199432373]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 53, SSIM Loss: 0.12407076358795166\n",
      "Epoch: 5, Batch: 53, D Loss Real: 0.3231632709503174, D Loss Fake: 1.230316162109375, G Loss: [13.034539222717285, 0.652079701423645, 0.1238245964050293]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 5, Batch: 54, SSIM Loss: 0.1267101764678955\n",
      "Epoch: 5, Batch: 54, D Loss Real: 0.33670011162757874, D Loss Fake: 1.2081125974655151, G Loss: [13.333955764770508, 0.6590937972068787, 0.12674862146377563]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 55, SSIM Loss: 0.10881906747817993\n",
      "Epoch: 5, Batch: 55, D Loss Real: 0.3307274281978607, D Loss Fake: 1.2163465023040771, G Loss: [11.513097763061523, 0.6537872552871704, 0.10859310626983643]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 56, SSIM Loss: 0.12322127819061279\n",
      "Epoch: 5, Batch: 56, D Loss Real: 0.3451204001903534, D Loss Fake: 1.1922663450241089, G Loss: [12.964713096618652, 0.6593941450119019, 0.12305319309234619]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 57, SSIM Loss: 0.14088553190231323\n",
      "Epoch: 5, Batch: 57, D Loss Real: 0.34168490767478943, D Loss Fake: 1.2052538394927979, G Loss: [14.627785682678223, 0.6521945595741272, 0.13975590467453003]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 58, SSIM Loss: 0.13530248403549194\n",
      "Epoch: 5, Batch: 58, D Loss Real: 0.3481682240962982, D Loss Fake: 1.1173886060714722, G Loss: [14.258001327514648, 0.7173284292221069, 0.1354067325592041]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 59, SSIM Loss: 0.12678146362304688\n",
      "Epoch: 5, Batch: 59, D Loss Real: 0.3292354941368103, D Loss Fake: 1.2533529996871948, G Loss: [13.290228843688965, 0.6218342185020447, 0.12668395042419434]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 60, SSIM Loss: 0.12787550687789917\n",
      "Epoch: 5, Batch: 60, D Loss Real: 0.3316779136657715, D Loss Fake: 1.2216216325759888, G Loss: [13.410490036010742, 0.6400395631790161, 0.12770450115203857]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 61, SSIM Loss: 0.12092089653015137\n",
      "Epoch: 5, Batch: 61, D Loss Real: 0.33498039841651917, D Loss Fake: 1.1796212196350098, G Loss: [12.767380714416504, 0.6574993133544922, 0.12109881639480591]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 5, Batch: 62, SSIM Loss: 0.12053406238555908\n",
      "Epoch: 5, Batch: 62, D Loss Real: 0.33943259716033936, D Loss Fake: 1.2112082242965698, G Loss: [12.732002258300781, 0.6345424056053162, 0.120974600315094]\n",
      "1/1 [==============================] - 0s 148ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:19:13.375203: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:19:14.836591: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch: 1, SSIM Loss: 0.11767178773880005\n",
      "Epoch: 6, Batch: 1, D Loss Real: 0.33167392015457153, D Loss Fake: 1.1989006996154785, G Loss: [12.438102722167969, 0.6423913836479187, 0.11795711517333984]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 2, SSIM Loss: 0.11200588941574097\n",
      "Epoch: 6, Batch: 2, D Loss Real: 0.3281358778476715, D Loss Fake: 1.21466863155365, G Loss: [11.82908821105957, 0.631770670413971, 0.11197316646575928]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 6, Batch: 3, SSIM Loss: 0.12671244144439697\n",
      "Epoch: 6, Batch: 3, D Loss Real: 0.3367662727832794, D Loss Fake: 1.2095433473587036, G Loss: [13.334346771240234, 0.6343133449554443, 0.1270003318786621]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 4, SSIM Loss: 0.1293204426765442\n",
      "Epoch: 6, Batch: 4, D Loss Real: 0.3432648777961731, D Loss Fake: 1.196915626525879, G Loss: [13.58316707611084, 0.6361088156700134, 0.1294705867767334]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 5, SSIM Loss: 0.12000656127929688\n",
      "Epoch: 6, Batch: 5, D Loss Real: 0.34572091698646545, D Loss Fake: 1.1951042413711548, G Loss: [12.624608039855957, 0.6342338919639587, 0.11990374326705933]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 6, Batch: 6, SSIM Loss: 0.1179734468460083\n",
      "Epoch: 6, Batch: 6, D Loss Real: 0.3432580232620239, D Loss Fake: 1.2112228870391846, G Loss: [12.425610542297363, 0.6259890794754028, 0.1179962158203125]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 7, SSIM Loss: 0.12307071685791016\n",
      "Epoch: 6, Batch: 7, D Loss Real: 0.34042471647262573, D Loss Fake: 1.2095319032669067, G Loss: [12.943140029907227, 0.6272885203361511, 0.1231585144996643]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 8, SSIM Loss: 0.11740577220916748\n",
      "Epoch: 6, Batch: 8, D Loss Real: 0.34670040011405945, D Loss Fake: 1.1957420110702515, G Loss: [12.391529083251953, 0.6285996437072754, 0.1176292896270752]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 9, SSIM Loss: 0.12514019012451172\n",
      "Epoch: 6, Batch: 9, D Loss Real: 0.3505018353462219, D Loss Fake: 1.203476071357727, G Loss: [13.130071640014648, 0.6258330345153809, 0.1250423789024353]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 10, SSIM Loss: 0.11511993408203125\n",
      "Epoch: 6, Batch: 10, D Loss Real: 0.3525468707084656, D Loss Fake: 1.1992961168289185, G Loss: [12.151619911193848, 0.624177098274231, 0.11527442932128906]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 11, SSIM Loss: 0.11676430702209473\n",
      "Epoch: 6, Batch: 11, D Loss Real: 0.3438546359539032, D Loss Fake: 1.206490397453308, G Loss: [12.299769401550293, 0.6195474863052368, 0.11680221557617188]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 12, SSIM Loss: 0.11924588680267334\n",
      "Epoch: 6, Batch: 12, D Loss Real: 0.3531613051891327, D Loss Fake: 1.1958736181259155, G Loss: [12.59701156616211, 0.6226534247398376, 0.11974358558654785]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 13, SSIM Loss: 0.13099777698516846\n",
      "Epoch: 6, Batch: 13, D Loss Real: 0.3493724763393402, D Loss Fake: 1.2064324617385864, G Loss: [13.732677459716797, 0.6170697212219238, 0.1311560869216919]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 14, SSIM Loss: 0.12576830387115479\n",
      "Epoch: 6, Batch: 14, D Loss Real: 0.3516812324523926, D Loss Fake: 1.2062495946884155, G Loss: [13.185445785522461, 0.6150407195091248, 0.12570405006408691]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 15, SSIM Loss: 0.12279248237609863\n",
      "Epoch: 6, Batch: 15, D Loss Real: 0.35357150435447693, D Loss Fake: 1.2046728134155273, G Loss: [12.889116287231445, 0.6115076541900635, 0.1227760910987854]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 16, SSIM Loss: 0.11984825134277344\n",
      "Epoch: 6, Batch: 16, D Loss Real: 0.34955376386642456, D Loss Fake: 1.2044378519058228, G Loss: [12.607749938964844, 0.6128271818161011, 0.11994922161102295]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 17, SSIM Loss: 0.12080460786819458\n",
      "Epoch: 6, Batch: 17, D Loss Real: 0.3524227440357208, D Loss Fake: 1.195496916770935, G Loss: [12.740424156188965, 0.6147654056549072, 0.12125658988952637]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 18, SSIM Loss: 0.12474244832992554\n",
      "Epoch: 6, Batch: 18, D Loss Real: 0.35102105140686035, D Loss Fake: 1.205364465713501, G Loss: [13.068411827087402, 0.6088772416114807, 0.12459534406661987]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 19, SSIM Loss: 0.12912267446517944\n",
      "Epoch: 6, Batch: 19, D Loss Real: 0.3533884286880493, D Loss Fake: 1.206257939338684, G Loss: [13.498186111450195, 0.6037698984146118, 0.12894415855407715]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 20, SSIM Loss: 0.12767291069030762\n",
      "Epoch: 6, Batch: 20, D Loss Real: 0.34805071353912354, D Loss Fake: 1.2087448835372925, G Loss: [13.387304306030273, 0.6022034287452698, 0.12785100936889648]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 21, SSIM Loss: 0.11762845516204834\n",
      "Epoch: 6, Batch: 21, D Loss Real: 0.352068692445755, D Loss Fake: 1.206863284111023, G Loss: [12.347005844116211, 0.6016594171524048, 0.11745345592498779]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 22, SSIM Loss: 0.12059807777404785\n",
      "Epoch: 6, Batch: 22, D Loss Real: 0.3492093086242676, D Loss Fake: 1.2020448446273804, G Loss: [12.639842987060547, 0.6027202606201172, 0.12037122249603271]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 23, SSIM Loss: 0.12604540586471558\n",
      "Epoch: 6, Batch: 23, D Loss Real: 0.3513023257255554, D Loss Fake: 1.2025026082992554, G Loss: [13.171859741210938, 0.6035292744636536, 0.12568330764770508]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 24, SSIM Loss: 0.1267620325088501\n",
      "Epoch: 6, Batch: 24, D Loss Real: 0.34973880648612976, D Loss Fake: 1.2036876678466797, G Loss: [13.246306419372559, 0.5992023348808289, 0.12647104263305664]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 25, SSIM Loss: 0.11787581443786621\n",
      "Epoch: 6, Batch: 25, D Loss Real: 0.3517013490200043, D Loss Fake: 1.206788182258606, G Loss: [12.374055862426758, 0.5979423522949219, 0.11776113510131836]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 26, SSIM Loss: 0.12057638168334961\n",
      "Epoch: 6, Batch: 26, D Loss Real: 0.3532429039478302, D Loss Fake: 1.2032395601272583, G Loss: [12.689275741577148, 0.5980210304260254, 0.12091255187988281]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 27, SSIM Loss: 0.11721503734588623\n",
      "Epoch: 6, Batch: 27, D Loss Real: 0.3556452989578247, D Loss Fake: 1.1976776123046875, G Loss: [12.289377212524414, 0.60343337059021, 0.11685943603515625]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 28, SSIM Loss: 0.11237192153930664\n",
      "Epoch: 6, Batch: 28, D Loss Real: 0.3505903482437134, D Loss Fake: 1.2132240533828735, G Loss: [11.823290824890137, 0.5921542644500732, 0.11231136322021484]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 29, SSIM Loss: 0.12835991382598877\n",
      "Epoch: 6, Batch: 29, D Loss Real: 0.3512171804904938, D Loss Fake: 1.206892728805542, G Loss: [13.434008598327637, 0.5936657190322876, 0.1284034252166748]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 30, SSIM Loss: 0.12807434797286987\n",
      "Epoch: 6, Batch: 30, D Loss Real: 0.3520835041999817, D Loss Fake: 1.2140820026397705, G Loss: [13.351780891418457, 0.5892229080200195, 0.12762558460235596]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 31, SSIM Loss: 0.11720389127731323\n",
      "Epoch: 6, Batch: 31, D Loss Real: 0.35479259490966797, D Loss Fake: 1.2015796899795532, G Loss: [12.275355339050293, 0.5939655900001526, 0.11681389808654785]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 6, Batch: 32, SSIM Loss: 0.12346917390823364\n",
      "Epoch: 6, Batch: 32, D Loss Real: 0.3476766347885132, D Loss Fake: 1.2064242362976074, G Loss: [12.946006774902344, 0.5880452394485474, 0.12357962131500244]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 33, SSIM Loss: 0.12575048208236694\n",
      "Epoch: 6, Batch: 33, D Loss Real: 0.34721723198890686, D Loss Fake: 1.2126060724258423, G Loss: [13.149206161499023, 0.5869367122650146, 0.1256226897239685]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 34, SSIM Loss: 0.1266944408416748\n",
      "Epoch: 6, Batch: 34, D Loss Real: 0.3459147810935974, D Loss Fake: 1.2007876634597778, G Loss: [13.267876625061035, 0.588007926940918, 0.12679868936538696]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 35, SSIM Loss: 0.10787594318389893\n",
      "Epoch: 6, Batch: 35, D Loss Real: 0.3511834442615509, D Loss Fake: 1.2009947299957275, G Loss: [11.382826805114746, 0.585856556892395, 0.10796970129013062]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 36, SSIM Loss: 0.13223785161972046\n",
      "Epoch: 6, Batch: 36, D Loss Real: 0.3438340425491333, D Loss Fake: 1.2067761421203613, G Loss: [13.801819801330566, 0.5821767449378967, 0.13219642639160156]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 37, SSIM Loss: 0.12327098846435547\n",
      "Epoch: 6, Batch: 37, D Loss Real: 0.34378159046173096, D Loss Fake: 1.2045575380325317, G Loss: [12.889381408691406, 0.582304060459137, 0.12307077646255493]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 38, SSIM Loss: 0.13764530420303345\n",
      "Epoch: 6, Batch: 38, D Loss Real: 0.3431955575942993, D Loss Fake: 1.2015764713287354, G Loss: [14.34305191040039, 0.5831952095031738, 0.13759857416152954]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 39, SSIM Loss: 0.12543761730194092\n",
      "Epoch: 6, Batch: 39, D Loss Real: 0.3428451120853424, D Loss Fake: 1.1988298892974854, G Loss: [13.110180854797363, 0.5836024880409241, 0.12526577711105347]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 6, Batch: 40, SSIM Loss: 0.12379705905914307\n",
      "Epoch: 6, Batch: 40, D Loss Real: 0.3404105603694916, D Loss Fake: 1.2039051055908203, G Loss: [12.967313766479492, 0.5797877311706543, 0.12387526035308838]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 41, SSIM Loss: 0.11300456523895264\n",
      "Epoch: 6, Batch: 41, D Loss Real: 0.34072577953338623, D Loss Fake: 1.2046822309494019, G Loss: [11.887091636657715, 0.5776582956314087, 0.11309432983398438]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 6, Batch: 42, SSIM Loss: 0.12414062023162842\n",
      "Epoch: 6, Batch: 42, D Loss Real: 0.3446885049343109, D Loss Fake: 1.1992363929748535, G Loss: [12.968738555908203, 0.579418420791626, 0.12389320135116577]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 43, SSIM Loss: 0.12032210826873779\n",
      "Epoch: 6, Batch: 43, D Loss Real: 0.3428175151348114, D Loss Fake: 1.1737029552459717, G Loss: [12.617539405822754, 0.6010048389434814, 0.12016534805297852]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 44, SSIM Loss: 0.11575484275817871\n",
      "Epoch: 6, Batch: 44, D Loss Real: 0.3370210826396942, D Loss Fake: 1.2108913660049438, G Loss: [12.12891960144043, 0.5708401203155518, 0.11558079719543457]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 45, SSIM Loss: 0.1342083215713501\n",
      "Epoch: 6, Batch: 45, D Loss Real: 0.3492797315120697, D Loss Fake: 1.2102327346801758, G Loss: [14.00428581237793, 0.5717883110046387, 0.13432496786117554]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 46, SSIM Loss: 0.11637109518051147\n",
      "Epoch: 6, Batch: 46, D Loss Real: 0.33530300855636597, D Loss Fake: 1.2115345001220703, G Loss: [12.207763671875, 0.5706779360771179, 0.11637085676193237]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 47, SSIM Loss: 0.13731122016906738\n",
      "Epoch: 6, Batch: 47, D Loss Real: 0.3379412591457367, D Loss Fake: 1.20149564743042, G Loss: [14.348967552185059, 0.5725103616714478, 0.137764573097229]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 48, SSIM Loss: 0.12527263164520264\n",
      "Epoch: 6, Batch: 48, D Loss Real: 0.3374454379081726, D Loss Fake: 1.199406623840332, G Loss: [13.080305099487305, 0.5726870894432068, 0.12507617473602295]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 6, Batch: 49, SSIM Loss: 0.11835384368896484\n",
      "Epoch: 6, Batch: 49, D Loss Real: 0.33784109354019165, D Loss Fake: 1.2006731033325195, G Loss: [12.409201622009277, 0.5718620419502258, 0.11837339401245117]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 50, SSIM Loss: 0.12071752548217773\n",
      "Epoch: 6, Batch: 50, D Loss Real: 0.34088727831840515, D Loss Fake: 1.1994545459747314, G Loss: [12.639235496520996, 0.5712977647781372, 0.12067937850952148]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 51, SSIM Loss: 0.12146264314651489\n",
      "Epoch: 6, Batch: 51, D Loss Real: 0.338005930185318, D Loss Fake: 1.1958049535751343, G Loss: [12.734456062316895, 0.5705311298370361, 0.12163925170898438]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 52, SSIM Loss: 0.12499523162841797\n",
      "Epoch: 6, Batch: 52, D Loss Real: 0.3368152678012848, D Loss Fake: 1.1994484663009644, G Loss: [13.088207244873047, 0.5727217197418213, 0.12515485286712646]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 53, SSIM Loss: 0.12234151363372803\n",
      "Epoch: 6, Batch: 53, D Loss Real: 0.33616313338279724, D Loss Fake: 1.203615427017212, G Loss: [12.776890754699707, 0.5666938424110413, 0.12210196256637573]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 54, SSIM Loss: 0.12821108102798462\n",
      "Epoch: 6, Batch: 54, D Loss Real: 0.34017202258110046, D Loss Fake: 1.1994287967681885, G Loss: [13.39501667022705, 0.5675787329673767, 0.12827438116073608]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 55, SSIM Loss: 0.1088111400604248\n",
      "Epoch: 6, Batch: 55, D Loss Real: 0.33640792965888977, D Loss Fake: 1.2035895586013794, G Loss: [11.43980884552002, 0.5669738054275513, 0.10872834920883179]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 56, SSIM Loss: 0.12443172931671143\n",
      "Epoch: 6, Batch: 56, D Loss Real: 0.33678704500198364, D Loss Fake: 1.203887701034546, G Loss: [13.012356758117676, 0.5715264081954956, 0.1244083046913147]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 57, SSIM Loss: 0.13409364223480225\n",
      "Epoch: 6, Batch: 57, D Loss Real: 0.3372456431388855, D Loss Fake: 1.2040797472000122, G Loss: [13.975882530212402, 0.567578911781311, 0.13408303260803223]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 58, SSIM Loss: 0.13181579113006592\n",
      "Epoch: 6, Batch: 58, D Loss Real: 0.3390369415283203, D Loss Fake: 1.1951704025268555, G Loss: [13.753300666809082, 0.5693849325180054, 0.13183915615081787]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 59, SSIM Loss: 0.12268149852752686\n",
      "Epoch: 6, Batch: 59, D Loss Real: 0.33716049790382385, D Loss Fake: 1.1996980905532837, G Loss: [12.844651222229004, 0.5668515563011169, 0.12277799844741821]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 60, SSIM Loss: 0.12691712379455566\n",
      "Epoch: 6, Batch: 60, D Loss Real: 0.33686089515686035, D Loss Fake: 1.2026036977767944, G Loss: [13.224194526672363, 0.5645732879638672, 0.12659621238708496]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 6, Batch: 61, SSIM Loss: 0.11926054954528809\n",
      "Epoch: 6, Batch: 61, D Loss Real: 0.3385729193687439, D Loss Fake: 1.1952669620513916, G Loss: [12.489239692687988, 0.5699912309646606, 0.11919248104095459]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 6, Batch: 62, SSIM Loss: 0.12177109718322754\n",
      "Epoch: 6, Batch: 62, D Loss Real: 0.33534201979637146, D Loss Fake: 1.20164155960083, G Loss: [12.775412559509277, 0.5669805407524109, 0.12208431959152222]\n",
      "1/1 [==============================] - 0s 144ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:20:36.558280: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:20:38.023325: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch: 1, SSIM Loss: 0.11659562587738037\n",
      "Epoch: 7, Batch: 1, D Loss Real: 0.3340562582015991, D Loss Fake: 1.2097463607788086, G Loss: [12.20875072479248, 0.565579354763031, 0.11643171310424805]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 2, SSIM Loss: 0.1120384931564331\n",
      "Epoch: 7, Batch: 2, D Loss Real: 0.3354739546775818, D Loss Fake: 1.19855797290802, G Loss: [11.74510669708252, 0.5659988522529602, 0.11179107427597046]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 7, Batch: 3, SSIM Loss: 0.12238883972167969\n",
      "Epoch: 7, Batch: 3, D Loss Real: 0.33429813385009766, D Loss Fake: 1.2035802602767944, G Loss: [12.813108444213867, 0.5638059973716736, 0.12249302864074707]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 4, SSIM Loss: 0.12225723266601562\n",
      "Epoch: 7, Batch: 4, D Loss Real: 0.33645474910736084, D Loss Fake: 1.2030041217803955, G Loss: [12.77067756652832, 0.5637301802635193, 0.12206947803497314]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 5, SSIM Loss: 0.11553853750228882\n",
      "Epoch: 7, Batch: 5, D Loss Real: 0.34072306752204895, D Loss Fake: 1.1973752975463867, G Loss: [12.130562782287598, 0.5638583898544312, 0.11566704511642456]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 6, SSIM Loss: 0.1145932674407959\n",
      "Epoch: 7, Batch: 6, D Loss Real: 0.33489367365837097, D Loss Fake: 1.2006632089614868, G Loss: [12.031285285949707, 0.5630289912223816, 0.11468255519866943]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 7, Batch: 7, SSIM Loss: 0.11809569597244263\n",
      "Epoch: 7, Batch: 7, D Loss Real: 0.335968017578125, D Loss Fake: 1.2001097202301025, G Loss: [12.397403717041016, 0.563270628452301, 0.11834132671356201]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 8, SSIM Loss: 0.11422169208526611\n",
      "Epoch: 7, Batch: 8, D Loss Real: 0.34097447991371155, D Loss Fake: 1.2001510858535767, G Loss: [11.974832534790039, 0.5629745125770569, 0.11411857604980469]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 9, SSIM Loss: 0.12456119060516357\n",
      "Epoch: 7, Batch: 9, D Loss Real: 0.33439764380455017, D Loss Fake: 1.1999953985214233, G Loss: [13.0021390914917, 0.5652958154678345, 0.12436842918395996]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 10, SSIM Loss: 0.11789202690124512\n",
      "Epoch: 7, Batch: 10, D Loss Real: 0.3384461998939514, D Loss Fake: 1.2044577598571777, G Loss: [12.321840286254883, 0.5640432238578796, 0.11757797002792358]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 11, SSIM Loss: 0.11704391241073608\n",
      "Epoch: 7, Batch: 11, D Loss Real: 0.3346518576145172, D Loss Fake: 1.2095259428024292, G Loss: [12.269757270812988, 0.5675358176231384, 0.11702221632003784]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 12, SSIM Loss: 0.1185142993927002\n",
      "Epoch: 7, Batch: 12, D Loss Real: 0.3386536240577698, D Loss Fake: 1.1970453262329102, G Loss: [12.449101448059082, 0.5658664107322693, 0.11883234977722168]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 13, SSIM Loss: 0.12803006172180176\n",
      "Epoch: 7, Batch: 13, D Loss Real: 0.3338063657283783, D Loss Fake: 1.1924490928649902, G Loss: [13.364047050476074, 0.5669661164283752, 0.12797081470489502]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 14, SSIM Loss: 0.12752491235733032\n",
      "Epoch: 7, Batch: 14, D Loss Real: 0.330544114112854, D Loss Fake: 1.1909778118133545, G Loss: [13.328376770019531, 0.5679641962051392, 0.12760412693023682]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 15, SSIM Loss: 0.12325823307037354\n",
      "Epoch: 7, Batch: 15, D Loss Real: 0.33359476923942566, D Loss Fake: 1.207618236541748, G Loss: [12.893454551696777, 0.5646451115608215, 0.123288094997406]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 16, SSIM Loss: 0.11798584461212158\n",
      "Epoch: 7, Batch: 16, D Loss Real: 0.3301616311073303, D Loss Fake: 1.2211934328079224, G Loss: [12.336421012878418, 0.5735046863555908, 0.11762917041778564]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 7, Batch: 17, SSIM Loss: 0.11864519119262695\n",
      "Epoch: 7, Batch: 17, D Loss Real: 0.3330226242542267, D Loss Fake: 1.1872049570083618, G Loss: [12.45571231842041, 0.5692221522331238, 0.11886489391326904]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 18, SSIM Loss: 0.11599242687225342\n",
      "Epoch: 7, Batch: 18, D Loss Real: 0.3329881429672241, D Loss Fake: 1.1863056421279907, G Loss: [12.10871410369873, 0.564873993396759, 0.11543840169906616]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 19, SSIM Loss: 0.12209439277648926\n",
      "Epoch: 7, Batch: 19, D Loss Real: 0.32234036922454834, D Loss Fake: 1.1852731704711914, G Loss: [12.790771484375, 0.5670093894004822, 0.12223762273788452]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 20, SSIM Loss: 0.12492144107818604\n",
      "Epoch: 7, Batch: 20, D Loss Real: 0.32025662064552307, D Loss Fake: 1.1930058002471924, G Loss: [13.072669982910156, 0.5658807754516602, 0.12506788969039917]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 21, SSIM Loss: 0.11698496341705322\n",
      "Epoch: 7, Batch: 21, D Loss Real: 0.3282531499862671, D Loss Fake: 1.1882898807525635, G Loss: [12.21845817565918, 0.5699939131736755, 0.1164846420288086]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 22, SSIM Loss: 0.11621308326721191\n",
      "Epoch: 7, Batch: 22, D Loss Real: 0.3142344653606415, D Loss Fake: 1.174131989479065, G Loss: [12.198019027709961, 0.5727765560150146, 0.11625242233276367]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 23, SSIM Loss: 0.123069167137146\n",
      "Epoch: 7, Batch: 23, D Loss Real: 0.31369709968566895, D Loss Fake: 1.175154685974121, G Loss: [12.881049156188965, 0.5716410875320435, 0.12309408187866211]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 24, SSIM Loss: 0.12479311227798462\n",
      "Epoch: 7, Batch: 24, D Loss Real: 0.3129594027996063, D Loss Fake: 1.1813005208969116, G Loss: [13.049500465393066, 0.574194610118866, 0.12475305795669556]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 25, SSIM Loss: 0.1154470443725586\n",
      "Epoch: 7, Batch: 25, D Loss Real: 0.31262627243995667, D Loss Fake: 1.196053147315979, G Loss: [12.0994291305542, 0.5763490200042725, 0.11523079872131348]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 7, Batch: 26, SSIM Loss: 0.1203150749206543\n",
      "Epoch: 7, Batch: 26, D Loss Real: 0.3202597200870514, D Loss Fake: 1.1767423152923584, G Loss: [12.589637756347656, 0.5722499489784241, 0.1201738715171814]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 27, SSIM Loss: 0.11348676681518555\n",
      "Epoch: 7, Batch: 27, D Loss Real: 0.31021738052368164, D Loss Fake: 1.1714712381362915, G Loss: [11.932655334472656, 0.5757296085357666, 0.11356925964355469]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 28, SSIM Loss: 0.11143684387207031\n",
      "Epoch: 7, Batch: 28, D Loss Real: 0.30957335233688354, D Loss Fake: 1.166303038597107, G Loss: [11.731090545654297, 0.5766294002532959, 0.11154460906982422]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 29, SSIM Loss: 0.12606173753738403\n",
      "Epoch: 7, Batch: 29, D Loss Real: 0.31081685423851013, D Loss Fake: 1.1693835258483887, G Loss: [13.18055534362793, 0.5732616186141968, 0.1260729432106018]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 30, SSIM Loss: 0.12429463863372803\n",
      "Epoch: 7, Batch: 30, D Loss Real: 0.29606249928474426, D Loss Fake: 1.1739604473114014, G Loss: [13.025716781616211, 0.579849362373352, 0.1244586706161499]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 31, SSIM Loss: 0.11557334661483765\n",
      "Epoch: 7, Batch: 31, D Loss Real: 0.30701184272766113, D Loss Fake: 1.1722731590270996, G Loss: [12.126631736755371, 0.5811106562614441, 0.11545521020889282]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 32, SSIM Loss: 0.12189829349517822\n",
      "Epoch: 7, Batch: 32, D Loss Real: 0.2948923110961914, D Loss Fake: 1.1699193716049194, G Loss: [12.769887924194336, 0.5884267687797546, 0.12181460857391357]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 7, Batch: 33, SSIM Loss: 0.12067586183547974\n",
      "Epoch: 7, Batch: 33, D Loss Real: 0.3092420995235443, D Loss Fake: 1.1796833276748657, G Loss: [12.646409034729004, 0.5798651576042175, 0.12066543102264404]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 34, SSIM Loss: 0.12125706672668457\n",
      "Epoch: 7, Batch: 34, D Loss Real: 0.30736804008483887, D Loss Fake: 1.1775602102279663, G Loss: [12.749947547912598, 0.5820644497871399, 0.12167882919311523]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 35, SSIM Loss: 0.10548675060272217\n",
      "Epoch: 7, Batch: 35, D Loss Real: 0.3211733102798462, D Loss Fake: 1.1909765005111694, G Loss: [11.139815330505371, 0.5739984512329102, 0.10565817356109619]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 36, SSIM Loss: 0.12360793352127075\n",
      "Epoch: 7, Batch: 36, D Loss Real: 0.3061048090457916, D Loss Fake: 1.1939640045166016, G Loss: [12.956050872802734, 0.5818765759468079, 0.1237417459487915]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 37, SSIM Loss: 0.11671686172485352\n",
      "Epoch: 7, Batch: 37, D Loss Real: 0.3016757071018219, D Loss Fake: 1.1771737337112427, G Loss: [12.25874137878418, 0.5837054252624512, 0.11675035953521729]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 38, SSIM Loss: 0.13286161422729492\n",
      "Epoch: 7, Batch: 38, D Loss Real: 0.2885226309299469, D Loss Fake: 1.1518847942352295, G Loss: [13.826016426086426, 0.5910851359367371, 0.13234931230545044]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 39, SSIM Loss: 0.1234438419342041\n",
      "Epoch: 7, Batch: 39, D Loss Real: 0.30416247248649597, D Loss Fake: 1.1724827289581299, G Loss: [12.847259521484375, 0.5849809646606445, 0.1226227879524231]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 40, SSIM Loss: 0.12002313137054443\n",
      "Epoch: 7, Batch: 40, D Loss Real: 0.293705016374588, D Loss Fake: 1.1697636842727661, G Loss: [12.6014986038208, 0.5826154947280884, 0.12018883228302002]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 41, SSIM Loss: 0.10856115818023682\n",
      "Epoch: 7, Batch: 41, D Loss Real: 0.29627859592437744, D Loss Fake: 1.1679413318634033, G Loss: [11.442853927612305, 0.5836501717567444, 0.10859203338623047]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 42, SSIM Loss: 0.11933040618896484\n",
      "Epoch: 7, Batch: 42, D Loss Real: 0.2935566008090973, D Loss Fake: 1.1639045476913452, G Loss: [12.549488067626953, 0.5842075347900391, 0.11965280771255493]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 43, SSIM Loss: 0.11587405204772949\n",
      "Epoch: 7, Batch: 43, D Loss Real: 0.2840556800365448, D Loss Fake: 1.1635122299194336, G Loss: [12.160964965820312, 0.5919892191886902, 0.11568975448608398]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 44, SSIM Loss: 0.11170434951782227\n",
      "Epoch: 7, Batch: 44, D Loss Real: 0.2887660562992096, D Loss Fake: 1.1798654794692993, G Loss: [11.763410568237305, 0.5904067158699036, 0.11173003911972046]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 45, SSIM Loss: 0.13078999519348145\n",
      "Epoch: 7, Batch: 45, D Loss Real: 0.28377825021743774, D Loss Fake: 1.1492881774902344, G Loss: [13.656371116638184, 0.5967129468917847, 0.1305965781211853]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 7, Batch: 46, SSIM Loss: 0.11481678485870361\n",
      "Epoch: 7, Batch: 46, D Loss Real: 0.3005527853965759, D Loss Fake: 1.149868130683899, G Loss: [12.060853004455566, 0.5855759382247925, 0.11475276947021484]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 47, SSIM Loss: 0.13428843021392822\n",
      "Epoch: 7, Batch: 47, D Loss Real: 0.2682569622993469, D Loss Fake: 1.1476268768310547, G Loss: [13.978135108947754, 0.5889350771903992, 0.1338919997215271]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 48, SSIM Loss: 0.12245404720306396\n",
      "Epoch: 7, Batch: 48, D Loss Real: 0.26494696736335754, D Loss Fake: 1.1373586654663086, G Loss: [12.856841087341309, 0.5964882373809814, 0.12260353565216064]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 49, SSIM Loss: 0.11611044406890869\n",
      "Epoch: 7, Batch: 49, D Loss Real: 0.2594805359840393, D Loss Fake: 1.1497814655303955, G Loss: [12.21146011352539, 0.5975373983383179, 0.1161392331123352]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 7, Batch: 50, SSIM Loss: 0.11761093139648438\n",
      "Epoch: 7, Batch: 50, D Loss Real: 0.27179819345474243, D Loss Fake: 1.1904487609863281, G Loss: [12.365221977233887, 0.6125389933586121, 0.1175268292427063]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 51, SSIM Loss: 0.11930131912231445\n",
      "Epoch: 7, Batch: 51, D Loss Real: 0.2713015377521515, D Loss Fake: 1.11745023727417, G Loss: [12.511343955993652, 0.608284592628479, 0.11903059482574463]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 52, SSIM Loss: 0.12112736701965332\n",
      "Epoch: 7, Batch: 52, D Loss Real: 0.2683640718460083, D Loss Fake: 1.1342167854309082, G Loss: [12.709877014160156, 0.6007163524627686, 0.12109160423278809]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 53, SSIM Loss: 0.11900556087493896\n",
      "Epoch: 7, Batch: 53, D Loss Real: 0.26992952823638916, D Loss Fake: 1.1297893524169922, G Loss: [12.500590324401855, 0.5980081558227539, 0.1190258264541626]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 54, SSIM Loss: 0.12339860200881958\n",
      "Epoch: 7, Batch: 54, D Loss Real: 0.2601671516895294, D Loss Fake: 1.1436058282852173, G Loss: [12.916815757751465, 0.6023418307304382, 0.12314474582672119]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 55, SSIM Loss: 0.10701674222946167\n",
      "Epoch: 7, Batch: 55, D Loss Real: 0.26940423250198364, D Loss Fake: 1.14423406124115, G Loss: [11.306146621704102, 0.6024040579795837, 0.10703742504119873]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 56, SSIM Loss: 0.1220136284828186\n",
      "Epoch: 7, Batch: 56, D Loss Real: 0.25658535957336426, D Loss Fake: 1.1396572589874268, G Loss: [12.731523513793945, 0.6051676273345947, 0.12126356363296509]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 57, SSIM Loss: 0.13162744045257568\n",
      "Epoch: 7, Batch: 57, D Loss Real: 0.26276370882987976, D Loss Fake: 1.1567434072494507, G Loss: [13.77099323272705, 0.5841333866119385, 0.13186860084533691]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 7, Batch: 58, SSIM Loss: 0.13334232568740845\n",
      "Epoch: 7, Batch: 58, D Loss Real: 0.25693023204803467, D Loss Fake: 1.1633188724517822, G Loss: [13.937578201293945, 0.5859470367431641, 0.1335163116455078]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 59, SSIM Loss: 0.12257742881774902\n",
      "Epoch: 7, Batch: 59, D Loss Real: 0.2534903287887573, D Loss Fake: 1.1362488269805908, G Loss: [12.855510711669922, 0.608461856842041, 0.12247049808502197]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 7, Batch: 60, SSIM Loss: 0.12480932474136353\n",
      "Epoch: 7, Batch: 60, D Loss Real: 0.25412604212760925, D Loss Fake: 1.1338527202606201, G Loss: [13.077751159667969, 0.6137635707855225, 0.12463986873626709]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 61, SSIM Loss: 0.12267625331878662\n",
      "Epoch: 7, Batch: 61, D Loss Real: 0.2650717496871948, D Loss Fake: 1.1316826343536377, G Loss: [12.812200546264648, 0.602748692035675, 0.12209451198577881]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 7, Batch: 62, SSIM Loss: 0.11858510971069336\n",
      "Epoch: 7, Batch: 62, D Loss Real: 0.24685491621494293, D Loss Fake: 1.1358433961868286, G Loss: [12.499439239501953, 0.6179449558258057, 0.11881494522094727]\n",
      "1/1 [==============================] - 0s 151ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:21:59.808546: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:22:01.279186: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch: 1, SSIM Loss: 0.11390018463134766\n",
      "Epoch: 8, Batch: 1, D Loss Real: 0.25789034366607666, D Loss Fake: 1.111487865447998, G Loss: [12.023845672607422, 0.6228833794593811, 0.11400961875915527]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 2, SSIM Loss: 0.1093524694442749\n",
      "Epoch: 8, Batch: 2, D Loss Real: 0.25477135181427, D Loss Fake: 1.0904929637908936, G Loss: [11.551129341125488, 0.621925950050354, 0.10929203033447266]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 8, Batch: 3, SSIM Loss: 0.1235191822052002\n",
      "Epoch: 8, Batch: 3, D Loss Real: 0.24156802892684937, D Loss Fake: 1.1208544969558716, G Loss: [12.995530128479004, 0.6219335794448853, 0.12373596429824829]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 4, SSIM Loss: 0.12465393543243408\n",
      "Epoch: 8, Batch: 4, D Loss Real: 0.2457338571548462, D Loss Fake: 1.128105878829956, G Loss: [13.07502555847168, 0.618489146232605, 0.12456536293029785]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 5, SSIM Loss: 0.11710256338119507\n",
      "Epoch: 8, Batch: 5, D Loss Real: 0.2690333425998688, D Loss Fake: 1.1312711238861084, G Loss: [12.296395301818848, 0.6082825064659119, 0.11688113212585449]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 8, Batch: 6, SSIM Loss: 0.1157534122467041\n",
      "Epoch: 8, Batch: 6, D Loss Real: 0.24002009630203247, D Loss Fake: 1.121273159980774, G Loss: [12.191730499267578, 0.6138625144958496, 0.11577868461608887]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 7, SSIM Loss: 0.11862808465957642\n",
      "Epoch: 8, Batch: 7, D Loss Real: 0.24277611076831818, D Loss Fake: 1.1420676708221436, G Loss: [12.486994743347168, 0.6135767698287964, 0.11873418092727661]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 8, SSIM Loss: 0.11362320184707642\n",
      "Epoch: 8, Batch: 8, D Loss Real: 0.2645488977432251, D Loss Fake: 1.1452711820602417, G Loss: [11.975647926330566, 0.6105090379714966, 0.11365139484405518]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 8, Batch: 9, SSIM Loss: 0.12146282196044922\n",
      "Epoch: 8, Batch: 9, D Loss Real: 0.23644205927848816, D Loss Fake: 1.1126255989074707, G Loss: [12.744794845581055, 0.6234622001647949, 0.12121331691741943]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 10, SSIM Loss: 0.11179971694946289\n",
      "Epoch: 8, Batch: 10, D Loss Real: 0.2485385537147522, D Loss Fake: 1.1266049146652222, G Loss: [11.802224159240723, 0.6160356402397156, 0.11186188459396362]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 8, Batch: 11, SSIM Loss: 0.11381006240844727\n",
      "Epoch: 8, Batch: 11, D Loss Real: 0.2431652545928955, D Loss Fake: 1.1176784038543701, G Loss: [12.019736289978027, 0.626218855381012, 0.11393517255783081]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 12, SSIM Loss: 0.11576002836227417\n",
      "Epoch: 8, Batch: 12, D Loss Real: 0.23926252126693726, D Loss Fake: 1.133573293685913, G Loss: [12.177940368652344, 0.6148778200149536, 0.1156306266784668]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 13, SSIM Loss: 0.12560784816741943\n",
      "Epoch: 8, Batch: 13, D Loss Real: 0.22261103987693787, D Loss Fake: 1.111100673675537, G Loss: [13.232872009277344, 0.6285510659217834, 0.1260432004928589]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 14, SSIM Loss: 0.12300807237625122\n",
      "Epoch: 8, Batch: 14, D Loss Real: 0.23076854646205902, D Loss Fake: 1.1180222034454346, G Loss: [12.920784950256348, 0.6359338760375977, 0.1228485107421875]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 15, SSIM Loss: 0.11999613046646118\n",
      "Epoch: 8, Batch: 15, D Loss Real: 0.25915008783340454, D Loss Fake: 1.1023313999176025, G Loss: [12.623550415039062, 0.6291468739509583, 0.11994403600692749]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 8, Batch: 16, SSIM Loss: 0.11634588241577148\n",
      "Epoch: 8, Batch: 16, D Loss Real: 0.23846423625946045, D Loss Fake: 1.1180753707885742, G Loss: [12.267101287841797, 0.6143988966941833, 0.1165270209312439]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 17, SSIM Loss: 0.1166570782661438\n",
      "Epoch: 8, Batch: 17, D Loss Real: 0.22328118979930878, D Loss Fake: 1.1218736171722412, G Loss: [12.297489166259766, 0.6289505958557129, 0.11668539047241211]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 18, SSIM Loss: 0.11869585514068604\n",
      "Epoch: 8, Batch: 18, D Loss Real: 0.23263487219810486, D Loss Fake: 1.0952110290527344, G Loss: [12.513419151306152, 0.6328544020652771, 0.1188056468963623]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 19, SSIM Loss: 0.12242162227630615\n",
      "Epoch: 8, Batch: 19, D Loss Real: 0.2194238007068634, D Loss Fake: 1.1545157432556152, G Loss: [12.873123168945312, 0.63620525598526, 0.12236917018890381]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 20, SSIM Loss: 0.12264466285705566\n",
      "Epoch: 8, Batch: 20, D Loss Real: 0.250018835067749, D Loss Fake: 1.1045811176300049, G Loss: [12.876376152038574, 0.6251057386398315, 0.12251269817352295]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 21, SSIM Loss: 0.1149519681930542\n",
      "Epoch: 8, Batch: 21, D Loss Real: 0.24373647570610046, D Loss Fake: 1.1053361892700195, G Loss: [12.094887733459473, 0.6291531920433044, 0.11465734243392944]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 22, SSIM Loss: 0.1140434741973877\n",
      "Epoch: 8, Batch: 22, D Loss Real: 0.20729497075080872, D Loss Fake: 1.0924980640411377, G Loss: [12.02392864227295, 0.6382255554199219, 0.11385703086853027]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 23, SSIM Loss: 0.12123358249664307\n",
      "Epoch: 8, Batch: 23, D Loss Real: 0.20480352640151978, D Loss Fake: 1.1375571489334106, G Loss: [12.749786376953125, 0.6502343416213989, 0.12099552154541016]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 24, SSIM Loss: 0.12383878231048584\n",
      "Epoch: 8, Batch: 24, D Loss Real: 0.242980495095253, D Loss Fake: 1.0934116840362549, G Loss: [12.997943878173828, 0.6344031095504761, 0.12363541126251221]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 25, SSIM Loss: 0.11343085765838623\n",
      "Epoch: 8, Batch: 25, D Loss Real: 0.23063704371452332, D Loss Fake: 1.105142593383789, G Loss: [11.96165657043457, 0.6294897198677063, 0.11332166194915771]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 8, Batch: 26, SSIM Loss: 0.11900889873504639\n",
      "Epoch: 8, Batch: 26, D Loss Real: 0.22733627259731293, D Loss Fake: 1.137829065322876, G Loss: [12.531296730041504, 0.6350315809249878, 0.11896264553070068]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 27, SSIM Loss: 0.11288511753082275\n",
      "Epoch: 8, Batch: 27, D Loss Real: 0.217683345079422, D Loss Fake: 1.0971027612686157, G Loss: [11.941771507263184, 0.6352711319923401, 0.11306500434875488]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 28, SSIM Loss: 0.1097036600112915\n",
      "Epoch: 8, Batch: 28, D Loss Real: 0.23686042428016663, D Loss Fake: 1.1064258813858032, G Loss: [11.605158805847168, 0.6466894149780273, 0.10958468914031982]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 29, SSIM Loss: 0.12530970573425293\n",
      "Epoch: 8, Batch: 29, D Loss Real: 0.2324436753988266, D Loss Fake: 1.1152633428573608, G Loss: [13.181346893310547, 0.6313854455947876, 0.12549960613250732]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 30, SSIM Loss: 0.12519580125808716\n",
      "Epoch: 8, Batch: 30, D Loss Real: 0.19859082996845245, D Loss Fake: 1.1245777606964111, G Loss: [13.160273551940918, 0.6608639359474182, 0.12499409914016724]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 31, SSIM Loss: 0.11566871404647827\n",
      "Epoch: 8, Batch: 31, D Loss Real: 0.2450411021709442, D Loss Fake: 1.0811619758605957, G Loss: [12.197468757629395, 0.6471134424209595, 0.11550354957580566]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 32, SSIM Loss: 0.11977708339691162\n",
      "Epoch: 8, Batch: 32, D Loss Real: 0.21578386425971985, D Loss Fake: 1.0811229944229126, G Loss: [12.62303352355957, 0.6520543098449707, 0.1197097897529602]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 33, SSIM Loss: 0.12241041660308838\n",
      "Epoch: 8, Batch: 33, D Loss Real: 0.22020600736141205, D Loss Fake: 1.1278598308563232, G Loss: [12.795310020446777, 0.6505538821220398, 0.12144756317138672]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 34, SSIM Loss: 0.11994302272796631\n",
      "Epoch: 8, Batch: 34, D Loss Real: 0.21795746684074402, D Loss Fake: 1.1062626838684082, G Loss: [12.64805793762207, 0.6504533290863037, 0.11997604370117188]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 35, SSIM Loss: 0.10518538951873779\n",
      "Epoch: 8, Batch: 35, D Loss Real: 0.2522282302379608, D Loss Fake: 1.1098097562789917, G Loss: [11.109330177307129, 0.6320732831954956, 0.10477256774902344]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 36, SSIM Loss: 0.12203490734100342\n",
      "Epoch: 8, Batch: 36, D Loss Real: 0.2224465012550354, D Loss Fake: 1.122829556465149, G Loss: [12.808881759643555, 0.6243809461593628, 0.12184500694274902]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 8, Batch: 37, SSIM Loss: 0.11572921276092529\n",
      "Epoch: 8, Batch: 37, D Loss Real: 0.2021835893392563, D Loss Fake: 1.192028284072876, G Loss: [12.25631332397461, 0.645864725112915, 0.11610448360443115]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 38, SSIM Loss: 0.14451920986175537\n",
      "Epoch: 8, Batch: 38, D Loss Real: 0.21999621391296387, D Loss Fake: 1.1185376644134521, G Loss: [15.049381256103516, 0.6490184664726257, 0.14400362968444824]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 39, SSIM Loss: 0.12835407257080078\n",
      "Epoch: 8, Batch: 39, D Loss Real: 0.26796185970306396, D Loss Fake: 1.0985360145568848, G Loss: [13.431598663330078, 0.6370447874069214, 0.12794554233551025]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 40, SSIM Loss: 0.12525665760040283\n",
      "Epoch: 8, Batch: 40, D Loss Real: 0.22704331576824188, D Loss Fake: 1.1043381690979004, G Loss: [13.204605102539062, 0.6459423899650574, 0.1255866289138794]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 41, SSIM Loss: 0.11289125680923462\n",
      "Epoch: 8, Batch: 41, D Loss Real: 0.21836653351783752, D Loss Fake: 1.0647392272949219, G Loss: [11.962945938110352, 0.6555876731872559, 0.11307358741760254]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 42, SSIM Loss: 0.12202584743499756\n",
      "Epoch: 8, Batch: 42, D Loss Real: 0.1972523033618927, D Loss Fake: 1.1375267505645752, G Loss: [12.844196319580078, 0.6466423273086548, 0.12197554111480713]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 43, SSIM Loss: 0.11857378482818604\n",
      "Epoch: 8, Batch: 43, D Loss Real: 0.2035781294107437, D Loss Fake: 1.0743528604507446, G Loss: [12.543872833251953, 0.6648693084716797, 0.11879003047943115]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 44, SSIM Loss: 0.11350375413894653\n",
      "Epoch: 8, Batch: 44, D Loss Real: 0.22466379404067993, D Loss Fake: 1.0761351585388184, G Loss: [12.021429061889648, 0.6511150598526001, 0.11370313167572021]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 45, SSIM Loss: 0.13255274295806885\n",
      "Epoch: 8, Batch: 45, D Loss Real: 0.19201527535915375, D Loss Fake: 1.0551981925964355, G Loss: [13.938438415527344, 0.6720062494277954, 0.13266432285308838]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 46, SSIM Loss: 0.11554360389709473\n",
      "Epoch: 8, Batch: 46, D Loss Real: 0.25070255994796753, D Loss Fake: 1.084007740020752, G Loss: [12.234383583068848, 0.6419713497161865, 0.11592411994934082]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 47, SSIM Loss: 0.13481497764587402\n",
      "Epoch: 8, Batch: 47, D Loss Real: 0.17580820620059967, D Loss Fake: 1.0959287881851196, G Loss: [14.169726371765137, 0.6698583960533142, 0.13499867916107178]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 8, Batch: 48, SSIM Loss: 0.12277829647064209\n",
      "Epoch: 8, Batch: 48, D Loss Real: 0.18485280871391296, D Loss Fake: 1.1354210376739502, G Loss: [12.964147567749023, 0.682110071182251, 0.12282037734985352]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 8, Batch: 49, SSIM Loss: 0.11731672286987305\n",
      "Epoch: 8, Batch: 49, D Loss Real: 0.2143929898738861, D Loss Fake: 1.0925147533416748, G Loss: [12.426918983459473, 0.6738255023956299, 0.1175309419631958]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 50, SSIM Loss: 0.11857378482818604\n",
      "Epoch: 8, Batch: 50, D Loss Real: 0.21960538625717163, D Loss Fake: 1.081298589706421, G Loss: [12.534562110900879, 0.6584316492080688, 0.11876130104064941]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 8, Batch: 51, SSIM Loss: 0.12135154008865356\n",
      "Epoch: 8, Batch: 51, D Loss Real: 0.19667166471481323, D Loss Fake: 1.0951370000839233, G Loss: [12.775354385375977, 0.6492063403129578, 0.12126147747039795]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 52, SSIM Loss: 0.12455499172210693\n",
      "Epoch: 8, Batch: 52, D Loss Real: 0.18425068259239197, D Loss Fake: 1.0936986207962036, G Loss: [13.12502670288086, 0.6526833176612854, 0.12472343444824219]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 53, SSIM Loss: 0.12080681324005127\n",
      "Epoch: 8, Batch: 53, D Loss Real: 0.19580350816249847, D Loss Fake: 1.0825490951538086, G Loss: [12.720160484313965, 0.6673325300216675, 0.12052828073501587]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 54, SSIM Loss: 0.12681424617767334\n",
      "Epoch: 8, Batch: 54, D Loss Real: 0.19180747866630554, D Loss Fake: 1.0808690786361694, G Loss: [13.438146591186523, 0.6762086153030396, 0.12761938571929932]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 55, SSIM Loss: 0.10847914218902588\n",
      "Epoch: 8, Batch: 55, D Loss Real: 0.22191645205020905, D Loss Fake: 1.0746431350708008, G Loss: [11.508902549743652, 0.6728017330169678, 0.10836100578308105]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 56, SSIM Loss: 0.12320184707641602\n",
      "Epoch: 8, Batch: 56, D Loss Real: 0.19171130657196045, D Loss Fake: 1.0736889839172363, G Loss: [12.985349655151367, 0.6660115122795105, 0.12319338321685791]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 57, SSIM Loss: 0.13164448738098145\n",
      "Epoch: 8, Batch: 57, D Loss Real: 0.18141022324562073, D Loss Fake: 1.0517075061798096, G Loss: [13.841012001037598, 0.676217257976532, 0.13164794445037842]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 58, SSIM Loss: 0.1300029158592224\n",
      "Epoch: 8, Batch: 58, D Loss Real: 0.18883875012397766, D Loss Fake: 1.104554533958435, G Loss: [13.650589942932129, 0.6554304361343384, 0.1299515962600708]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 59, SSIM Loss: 0.11998945474624634\n",
      "Epoch: 8, Batch: 59, D Loss Real: 0.18426381051540375, D Loss Fake: 1.085447072982788, G Loss: [12.661626815795898, 0.672057032585144, 0.11989569664001465]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 60, SSIM Loss: 0.12517976760864258\n",
      "Epoch: 8, Batch: 60, D Loss Real: 0.18256250023841858, D Loss Fake: 1.0397695302963257, G Loss: [13.205418586730957, 0.6922813653945923, 0.12513136863708496]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 8, Batch: 61, SSIM Loss: 0.1168355941772461\n",
      "Epoch: 8, Batch: 61, D Loss Real: 0.2057810127735138, D Loss Fake: 1.0728623867034912, G Loss: [12.363184928894043, 0.6786832213401794, 0.1168450117111206]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 8, Batch: 62, SSIM Loss: 0.12142288684844971\n",
      "Epoch: 8, Batch: 62, D Loss Real: 0.18581418693065643, D Loss Fake: 1.1083052158355713, G Loss: [12.809941291809082, 0.6891515851020813, 0.12120789289474487]\n",
      "1/1 [==============================] - 0s 145ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:23:23.113587: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:23:24.591352: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch: 1, SSIM Loss: 0.1147652268409729\n",
      "Epoch: 9, Batch: 1, D Loss Real: 0.2079876810312271, D Loss Fake: 1.1094917058944702, G Loss: [12.155896186828613, 0.6668274998664856, 0.1148906946182251]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 2, SSIM Loss: 0.11087048053741455\n",
      "Epoch: 9, Batch: 2, D Loss Real: 0.20460660755634308, D Loss Fake: 1.0245245695114136, G Loss: [11.769877433776855, 0.6878299713134766, 0.110820472240448]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 9, Batch: 3, SSIM Loss: 0.12301099300384521\n",
      "Epoch: 9, Batch: 3, D Loss Real: 0.18213392794132233, D Loss Fake: 1.0796570777893066, G Loss: [12.955352783203125, 0.6804015040397644, 0.12274950742721558]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 4, SSIM Loss: 0.1218881607055664\n",
      "Epoch: 9, Batch: 4, D Loss Real: 0.1962992548942566, D Loss Fake: 1.0974000692367554, G Loss: [12.844762802124023, 0.6667417883872986, 0.12178021669387817]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 5, SSIM Loss: 0.11426901817321777\n",
      "Epoch: 9, Batch: 5, D Loss Real: 0.22566421329975128, D Loss Fake: 1.1044281721115112, G Loss: [12.126117706298828, 0.6512340903282166, 0.11474883556365967]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 6, SSIM Loss: 0.11473560333251953\n",
      "Epoch: 9, Batch: 6, D Loss Real: 0.1815611720085144, D Loss Fake: 1.0505402088165283, G Loss: [12.14242172241211, 0.6805858612060547, 0.11461836099624634]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 7, SSIM Loss: 0.11796194314956665\n",
      "Epoch: 9, Batch: 7, D Loss Real: 0.19065754115581512, D Loss Fake: 1.0928869247436523, G Loss: [12.454740524291992, 0.6611857414245605, 0.11793553829193115]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 8, SSIM Loss: 0.11312234401702881\n",
      "Epoch: 9, Batch: 8, D Loss Real: 0.21795101463794708, D Loss Fake: 1.0885593891143799, G Loss: [11.955416679382324, 0.6655518412590027, 0.11289864778518677]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 9, SSIM Loss: 0.12414109706878662\n",
      "Epoch: 9, Batch: 9, D Loss Real: 0.17554019391536713, D Loss Fake: 1.0678479671478271, G Loss: [13.1561918258667, 0.6832765936851501, 0.12472915649414062]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 10, SSIM Loss: 0.11585241556167603\n",
      "Epoch: 9, Batch: 10, D Loss Real: 0.19670936465263367, D Loss Fake: 1.051659107208252, G Loss: [12.246459007263184, 0.6687459945678711, 0.11577713489532471]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 11, SSIM Loss: 0.11549526453018188\n",
      "Epoch: 9, Batch: 11, D Loss Real: 0.18780618906021118, D Loss Fake: 1.0985703468322754, G Loss: [12.242963790893555, 0.6882097721099854, 0.1155475378036499]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 12, SSIM Loss: 0.11641037464141846\n",
      "Epoch: 9, Batch: 12, D Loss Real: 0.19871556758880615, D Loss Fake: 1.1120374202728271, G Loss: [12.300061225891113, 0.6502026915550232, 0.11649858951568604]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 13, SSIM Loss: 0.12615323066711426\n",
      "Epoch: 9, Batch: 13, D Loss Real: 0.18077468872070312, D Loss Fake: 1.0713307857513428, G Loss: [13.279955863952637, 0.6849581003189087, 0.12594997882843018]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 14, SSIM Loss: 0.12559783458709717\n",
      "Epoch: 9, Batch: 14, D Loss Real: 0.194073885679245, D Loss Fake: 1.087581992149353, G Loss: [13.276554107666016, 0.6921722888946533, 0.1258438229560852]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 15, SSIM Loss: 0.12071263790130615\n",
      "Epoch: 9, Batch: 15, D Loss Real: 0.21839384734630585, D Loss Fake: 1.0883004665374756, G Loss: [12.763757705688477, 0.6933820843696594, 0.12070375680923462]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 16, SSIM Loss: 0.11813640594482422\n",
      "Epoch: 9, Batch: 16, D Loss Real: 0.23036035895347595, D Loss Fake: 1.084540843963623, G Loss: [12.49665641784668, 0.6707558035850525, 0.1182590126991272]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 17, SSIM Loss: 0.1170647144317627\n",
      "Epoch: 9, Batch: 17, D Loss Real: 0.18827009201049805, D Loss Fake: 1.1041195392608643, G Loss: [12.356980323791504, 0.6522490382194519, 0.11704730987548828]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 18, SSIM Loss: 0.11361324787139893\n",
      "Epoch: 9, Batch: 18, D Loss Real: 0.1871480643749237, D Loss Fake: 1.0734995603561401, G Loss: [12.061059951782227, 0.6790890693664551, 0.11381971836090088]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 19, SSIM Loss: 0.12121999263763428\n",
      "Epoch: 9, Batch: 19, D Loss Real: 0.16628438234329224, D Loss Fake: 1.087735891342163, G Loss: [12.805713653564453, 0.6802577376365662, 0.121254563331604]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 20, SSIM Loss: 0.1223939061164856\n",
      "Epoch: 9, Batch: 20, D Loss Real: 0.1916218101978302, D Loss Fake: 1.0436463356018066, G Loss: [12.954215049743652, 0.6996962428092957, 0.12254518270492554]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 21, SSIM Loss: 0.11517161130905151\n",
      "Epoch: 9, Batch: 21, D Loss Real: 0.20120200514793396, D Loss Fake: 1.0297906398773193, G Loss: [12.206501960754395, 0.6903067827224731, 0.1151619553565979]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 22, SSIM Loss: 0.11259722709655762\n",
      "Epoch: 9, Batch: 22, D Loss Real: 0.1571885496377945, D Loss Fake: 1.0557026863098145, G Loss: [11.969870567321777, 0.6907644271850586, 0.11279106140136719]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 23, SSIM Loss: 0.1226499080657959\n",
      "Epoch: 9, Batch: 23, D Loss Real: 0.16015617549419403, D Loss Fake: 1.1115009784698486, G Loss: [12.968572616577148, 0.6858437657356262, 0.12282729148864746]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 24, SSIM Loss: 0.12457221746444702\n",
      "Epoch: 9, Batch: 24, D Loss Real: 0.19417572021484375, D Loss Fake: 1.0460741519927979, G Loss: [13.109180450439453, 0.6871911883354187, 0.12421989440917969]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 25, SSIM Loss: 0.11504781246185303\n",
      "Epoch: 9, Batch: 25, D Loss Real: 0.18094125390052795, D Loss Fake: 1.03340482711792, G Loss: [12.20189380645752, 0.6951571702957153, 0.11506736278533936]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 26, SSIM Loss: 0.11928039789199829\n",
      "Epoch: 9, Batch: 26, D Loss Real: 0.17435479164123535, D Loss Fake: 1.060119867324829, G Loss: [12.609747886657715, 0.6930738091468811, 0.11916673183441162]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 27, SSIM Loss: 0.11221307516098022\n",
      "Epoch: 9, Batch: 27, D Loss Real: 0.1674271523952484, D Loss Fake: 1.057386875152588, G Loss: [11.902044296264648, 0.6848022937774658, 0.11217242479324341]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 28, SSIM Loss: 0.11065202951431274\n",
      "Epoch: 9, Batch: 28, D Loss Real: 0.20092560350894928, D Loss Fake: 1.1006994247436523, G Loss: [11.796039581298828, 0.6916282176971436, 0.11104410886764526]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 9, Batch: 29, SSIM Loss: 0.1259806752204895\n",
      "Epoch: 9, Batch: 29, D Loss Real: 0.18974238634109497, D Loss Fake: 1.067426085472107, G Loss: [13.268296241760254, 0.6821797490119934, 0.12586116790771484]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 30, SSIM Loss: 0.12272793054580688\n",
      "Epoch: 9, Batch: 30, D Loss Real: 0.1533777117729187, D Loss Fake: 1.0560197830200195, G Loss: [12.992073059082031, 0.7173551917076111, 0.12274718284606934]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 31, SSIM Loss: 0.11429601907730103\n",
      "Epoch: 9, Batch: 31, D Loss Real: 0.20375467836856842, D Loss Fake: 1.127803087234497, G Loss: [12.083414077758789, 0.6540675163269043, 0.11429345607757568]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 32, SSIM Loss: 0.1194806694984436\n",
      "Epoch: 9, Batch: 32, D Loss Real: 0.17578673362731934, D Loss Fake: 1.1694014072418213, G Loss: [12.659516334533691, 0.6979013681411743, 0.11961615085601807]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 9, Batch: 33, SSIM Loss: 0.1204996109008789\n",
      "Epoch: 9, Batch: 33, D Loss Real: 0.2357829213142395, D Loss Fake: 1.106542944908142, G Loss: [12.671873092651367, 0.6609116196632385, 0.12010961771011353]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 34, SSIM Loss: 0.11907505989074707\n",
      "Epoch: 9, Batch: 34, D Loss Real: 0.20503024756908417, D Loss Fake: 1.0835813283920288, G Loss: [12.585073471069336, 0.6748499870300293, 0.11910223960876465]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 35, SSIM Loss: 0.1039348840713501\n",
      "Epoch: 9, Batch: 35, D Loss Real: 0.22106564044952393, D Loss Fake: 1.078181505203247, G Loss: [11.058112144470215, 0.6621083617210388, 0.10396003723144531]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 36, SSIM Loss: 0.12272107601165771\n",
      "Epoch: 9, Batch: 36, D Loss Real: 0.175872802734375, D Loss Fake: 1.205797791481018, G Loss: [12.95769214630127, 0.6834980845451355, 0.1227419376373291]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 37, SSIM Loss: 0.11407560110092163\n",
      "Epoch: 9, Batch: 37, D Loss Real: 0.18968482315540314, D Loss Fake: 1.0450230836868286, G Loss: [12.144235610961914, 0.7081066370010376, 0.11436128616333008]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 38, SSIM Loss: 0.13094019889831543\n",
      "Epoch: 9, Batch: 38, D Loss Real: 0.18136215209960938, D Loss Fake: 1.026448130607605, G Loss: [13.7918062210083, 0.7067506313323975, 0.13085055351257324]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 39, SSIM Loss: 0.12159740924835205\n",
      "Epoch: 9, Batch: 39, D Loss Real: 0.20863641798496246, D Loss Fake: 1.0423917770385742, G Loss: [12.831768035888672, 0.704809308052063, 0.1212695837020874]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 40, SSIM Loss: 0.11923801898956299\n",
      "Epoch: 9, Batch: 40, D Loss Real: 0.17798462510108948, D Loss Fake: 1.0676765441894531, G Loss: [12.609020233154297, 0.6827744841575623, 0.1192624568939209]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 41, SSIM Loss: 0.1080009937286377\n",
      "Epoch: 9, Batch: 41, D Loss Real: 0.19044822454452515, D Loss Fake: 1.0400282144546509, G Loss: [11.501832008361816, 0.6901101469993591, 0.10811722278594971]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 42, SSIM Loss: 0.1179690957069397\n",
      "Epoch: 9, Batch: 42, D Loss Real: 0.17746400833129883, D Loss Fake: 1.0781669616699219, G Loss: [12.475638389587402, 0.6672311425209045, 0.11808407306671143]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 43, SSIM Loss: 0.1141824722290039\n",
      "Epoch: 9, Batch: 43, D Loss Real: 0.1583629697561264, D Loss Fake: 1.0430874824523926, G Loss: [12.133438110351562, 0.7084382176399231, 0.11425000429153442]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 44, SSIM Loss: 0.10999077558517456\n",
      "Epoch: 9, Batch: 44, D Loss Real: 0.18362575769424438, D Loss Fake: 1.134992003440857, G Loss: [11.709820747375488, 0.6725603938102722, 0.11037260293960571]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 45, SSIM Loss: 0.12978249788284302\n",
      "Epoch: 9, Batch: 45, D Loss Real: 0.15160617232322693, D Loss Fake: 1.0193806886672974, G Loss: [13.701862335205078, 0.7221644520759583, 0.12979698181152344]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 9, Batch: 46, SSIM Loss: 0.11356163024902344\n",
      "Epoch: 9, Batch: 46, D Loss Real: 0.24298813939094543, D Loss Fake: 1.0591951608657837, G Loss: [12.040362358093262, 0.674126386642456, 0.11366236209869385]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 47, SSIM Loss: 0.13324308395385742\n",
      "Epoch: 9, Batch: 47, D Loss Real: 0.14508141577243805, D Loss Fake: 1.0658650398254395, G Loss: [14.053060531616211, 0.6976439952850342, 0.13355416059494019]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 48, SSIM Loss: 0.11874067783355713\n",
      "Epoch: 9, Batch: 48, D Loss Real: 0.13828423619270325, D Loss Fake: 1.0282025337219238, G Loss: [12.628951072692871, 0.7266305088996887, 0.11902320384979248]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 49, SSIM Loss: 0.11536884307861328\n",
      "Epoch: 9, Batch: 49, D Loss Real: 0.15934348106384277, D Loss Fake: 1.0633257627487183, G Loss: [12.271346092224121, 0.7395163774490356, 0.11531829833984375]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 50, SSIM Loss: 0.11505746841430664\n",
      "Epoch: 9, Batch: 50, D Loss Real: 0.18897360563278198, D Loss Fake: 1.0614882707595825, G Loss: [12.2274751663208, 0.7097839713096619, 0.11517691612243652]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 51, SSIM Loss: 0.11786192655563354\n",
      "Epoch: 9, Batch: 51, D Loss Real: 0.17311884462833405, D Loss Fake: 1.0490748882293701, G Loss: [12.485237121582031, 0.6999090909957886, 0.11785328388214111]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 52, SSIM Loss: 0.11964046955108643\n",
      "Epoch: 9, Batch: 52, D Loss Real: 0.15903888642787933, D Loss Fake: 1.044294834136963, G Loss: [12.649069786071777, 0.7072317600250244, 0.11941838264465332]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 53, SSIM Loss: 0.11748015880584717\n",
      "Epoch: 9, Batch: 53, D Loss Real: 0.1593497395515442, D Loss Fake: 1.0720292329788208, G Loss: [12.422364234924316, 0.7090615034103394, 0.11713302135467529]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 54, SSIM Loss: 0.1235889196395874\n",
      "Epoch: 9, Batch: 54, D Loss Real: 0.1545235812664032, D Loss Fake: 1.0864804983139038, G Loss: [13.081082344055176, 0.7007211446762085, 0.12380361557006836]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 55, SSIM Loss: 0.10566389560699463\n",
      "Epoch: 9, Batch: 55, D Loss Real: 0.2062300145626068, D Loss Fake: 0.9995502233505249, G Loss: [11.287223815917969, 0.7213703393936157, 0.10565853118896484]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 56, SSIM Loss: 0.11978375911712646\n",
      "Epoch: 9, Batch: 56, D Loss Real: 0.1572062075138092, D Loss Fake: 1.026236891746521, G Loss: [12.660521507263184, 0.7023403644561768, 0.11958181858062744]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 57, SSIM Loss: 0.12863564491271973\n",
      "Epoch: 9, Batch: 57, D Loss Real: 0.13044556975364685, D Loss Fake: 1.052748441696167, G Loss: [13.577392578125, 0.717846155166626, 0.1285954713821411]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 58, SSIM Loss: 0.12801527976989746\n",
      "Epoch: 9, Batch: 58, D Loss Real: 0.15504327416419983, D Loss Fake: 1.0897433757781982, G Loss: [13.48456859588623, 0.7025191783905029, 0.12782049179077148]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 59, SSIM Loss: 0.1174006462097168\n",
      "Epoch: 9, Batch: 59, D Loss Real: 0.1735616773366928, D Loss Fake: 1.0640982389450073, G Loss: [12.454164505004883, 0.723886251449585, 0.1173027753829956]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 60, SSIM Loss: 0.12401211261749268\n",
      "Epoch: 9, Batch: 60, D Loss Real: 0.16646112501621246, D Loss Fake: 1.0473532676696777, G Loss: [13.084325790405273, 0.705882728099823, 0.12378442287445068]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 61, SSIM Loss: 0.11268776655197144\n",
      "Epoch: 9, Batch: 61, D Loss Real: 0.19624364376068115, D Loss Fake: 1.0335272550582886, G Loss: [11.979771614074707, 0.718624472618103, 0.11261147260665894]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 9, Batch: 62, SSIM Loss: 0.11783576011657715\n",
      "Epoch: 9, Batch: 62, D Loss Real: 0.14556358754634857, D Loss Fake: 1.0650051832199097, G Loss: [12.517704963684082, 0.722125232219696, 0.11795580387115479]\n",
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:24:46.366122: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:24:47.829704: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch: 1, SSIM Loss: 0.1118844747543335\n",
      "Epoch: 10, Batch: 1, D Loss Real: 0.17029668390750885, D Loss Fake: 1.042243242263794, G Loss: [11.857121467590332, 0.70058673620224, 0.11156535148620605]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 2, SSIM Loss: 0.10927051305770874\n",
      "Epoch: 10, Batch: 2, D Loss Real: 0.16114889085292816, D Loss Fake: 1.0344970226287842, G Loss: [11.659098625183105, 0.7478134632110596, 0.10911285877227783]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 10, Batch: 3, SSIM Loss: 0.12110018730163574\n",
      "Epoch: 10, Batch: 3, D Loss Real: 0.15463390946388245, D Loss Fake: 1.0708955526351929, G Loss: [12.876134872436523, 0.7336193919181824, 0.12142515182495117]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 4, SSIM Loss: 0.12001055479049683\n",
      "Epoch: 10, Batch: 4, D Loss Real: 0.2050919234752655, D Loss Fake: 1.0735514163970947, G Loss: [12.697230339050293, 0.7068625688552856, 0.11990368366241455]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 5, SSIM Loss: 0.11218559741973877\n",
      "Epoch: 10, Batch: 5, D Loss Real: 0.23855601251125336, D Loss Fake: 1.146934986114502, G Loss: [11.896734237670898, 0.6774947643280029, 0.11219239234924316]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 10, Batch: 6, SSIM Loss: 0.1138007640838623\n",
      "Epoch: 10, Batch: 6, D Loss Real: 0.17630624771118164, D Loss Fake: 1.036649465560913, G Loss: [12.04968547821045, 0.7097938060760498, 0.11339890956878662]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 7, SSIM Loss: 0.11551535129547119\n",
      "Epoch: 10, Batch: 7, D Loss Real: 0.17520315945148468, D Loss Fake: 1.1194183826446533, G Loss: [12.252029418945312, 0.7054947018623352, 0.11546534299850464]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 10, Batch: 8, SSIM Loss: 0.11024868488311768\n",
      "Epoch: 10, Batch: 8, D Loss Real: 0.2192857563495636, D Loss Fake: 1.0575182437896729, G Loss: [11.718208312988281, 0.6970888376235962, 0.11021119356155396]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 9, SSIM Loss: 0.11945164203643799\n",
      "Epoch: 10, Batch: 9, D Loss Real: 0.1564984917640686, D Loss Fake: 1.0575119256973267, G Loss: [12.667487144470215, 0.7111656665802002, 0.11956322193145752]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 10, SSIM Loss: 0.11377906799316406\n",
      "Epoch: 10, Batch: 10, D Loss Real: 0.17647072672843933, D Loss Fake: 1.0834048986434937, G Loss: [12.092921257019043, 0.6886877417564392, 0.11404234170913696]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 11, SSIM Loss: 0.1137923002243042\n",
      "Epoch: 10, Batch: 11, D Loss Real: 0.1637650579214096, D Loss Fake: 1.1137079000473022, G Loss: [12.119089126586914, 0.7341910600662231, 0.1138489842414856]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 12, SSIM Loss: 0.11407411098480225\n",
      "Epoch: 10, Batch: 12, D Loss Real: 0.19218504428863525, D Loss Fake: 1.0772501230239868, G Loss: [12.085394859313965, 0.6786633729934692, 0.11406731605529785]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 13, SSIM Loss: 0.12227261066436768\n",
      "Epoch: 10, Batch: 13, D Loss Real: 0.1618042290210724, D Loss Fake: 1.052543044090271, G Loss: [12.965164184570312, 0.7158740162849426, 0.12249290943145752]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 14, SSIM Loss: 0.12463724613189697\n",
      "Epoch: 10, Batch: 14, D Loss Real: 0.1739887297153473, D Loss Fake: 1.0813161134719849, G Loss: [13.19540023803711, 0.7212089896202087, 0.12474191188812256]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 15, SSIM Loss: 0.12023615837097168\n",
      "Epoch: 10, Batch: 15, D Loss Real: 0.2088899165391922, D Loss Fake: 1.0521141290664673, G Loss: [12.711457252502441, 0.7178946137428284, 0.11993563175201416]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 16, SSIM Loss: 0.11607968807220459\n",
      "Epoch: 10, Batch: 16, D Loss Real: 0.2212660014629364, D Loss Fake: 1.0520833730697632, G Loss: [12.311046600341797, 0.6922891139984131, 0.11618757247924805]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 17, SSIM Loss: 0.11587381362915039\n",
      "Epoch: 10, Batch: 17, D Loss Real: 0.1589326560497284, D Loss Fake: 1.1000498533248901, G Loss: [12.258248329162598, 0.6789972186088562, 0.11579251289367676]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 18, SSIM Loss: 0.1118389368057251\n",
      "Epoch: 10, Batch: 18, D Loss Real: 0.17294204235076904, D Loss Fake: 1.0831042528152466, G Loss: [11.843716621398926, 0.6909067034721375, 0.11152809858322144]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 19, SSIM Loss: 0.1185828447341919\n",
      "Epoch: 10, Batch: 19, D Loss Real: 0.14322316646575928, D Loss Fake: 1.1162558794021606, G Loss: [12.620481491088867, 0.7254262566566467, 0.11895054578781128]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 20, SSIM Loss: 0.11987650394439697\n",
      "Epoch: 10, Batch: 20, D Loss Real: 0.1927618533372879, D Loss Fake: 1.0308403968811035, G Loss: [12.729219436645508, 0.7481024265289307, 0.11981117725372314]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 21, SSIM Loss: 0.11417889595031738\n",
      "Epoch: 10, Batch: 21, D Loss Real: 0.23071378469467163, D Loss Fake: 1.0224058628082275, G Loss: [12.06723690032959, 0.7167368531227112, 0.11350500583648682]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 22, SSIM Loss: 0.11092066764831543\n",
      "Epoch: 10, Batch: 22, D Loss Real: 0.17408017814159393, D Loss Fake: 1.0967415571212769, G Loss: [11.809038162231445, 0.696443498134613, 0.11112594604492188]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 23, SSIM Loss: 0.12266474962234497\n",
      "Epoch: 10, Batch: 23, D Loss Real: 0.15332314372062683, D Loss Fake: 1.1380107402801514, G Loss: [12.994832992553711, 0.7221889495849609, 0.1227264404296875]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 24, SSIM Loss: 0.12451756000518799\n",
      "Epoch: 10, Batch: 24, D Loss Real: 0.20535993576049805, D Loss Fake: 1.0379174947738647, G Loss: [13.236382484436035, 0.7250931262969971, 0.1251128911972046]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 10, Batch: 25, SSIM Loss: 0.11417579650878906\n",
      "Epoch: 10, Batch: 25, D Loss Real: 0.1783270239830017, D Loss Fake: 0.9967058300971985, G Loss: [12.174766540527344, 0.7418808341026306, 0.11432886123657227]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 26, SSIM Loss: 0.11831784248352051\n",
      "Epoch: 10, Batch: 26, D Loss Real: 0.16271129250526428, D Loss Fake: 1.0297671556472778, G Loss: [12.54601001739502, 0.7201802730560303, 0.11825829744338989]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 27, SSIM Loss: 0.1115119457244873\n",
      "Epoch: 10, Batch: 27, D Loss Real: 0.14627018570899963, D Loss Fake: 1.0574214458465576, G Loss: [11.851997375488281, 0.7189701795578003, 0.11133027076721191]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 28, SSIM Loss: 0.10929334163665771\n",
      "Epoch: 10, Batch: 28, D Loss Real: 0.16732369363307953, D Loss Fake: 1.1224342584609985, G Loss: [11.620595932006836, 0.7097219228744507, 0.10910874605178833]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 29, SSIM Loss: 0.1237558126449585\n",
      "Epoch: 10, Batch: 29, D Loss Real: 0.1577494740486145, D Loss Fake: 1.0470671653747559, G Loss: [13.082818031311035, 0.7197118401527405, 0.1236310601234436]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 30, SSIM Loss: 0.12036401033401489\n",
      "Epoch: 10, Batch: 30, D Loss Real: 0.13387933373451233, D Loss Fake: 0.9839745163917542, G Loss: [12.804474830627441, 0.7600269317626953, 0.12044447660446167]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 31, SSIM Loss: 0.11412763595581055\n",
      "Epoch: 10, Batch: 31, D Loss Real: 0.1767524927854538, D Loss Fake: 1.1536734104156494, G Loss: [12.102783203125, 0.6892325282096863, 0.1141355037689209]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 32, SSIM Loss: 0.1171637773513794\n",
      "Epoch: 10, Batch: 32, D Loss Real: 0.16728569567203522, D Loss Fake: 0.9933769702911377, G Loss: [12.439797401428223, 0.7394295930862427, 0.1170036792755127]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 33, SSIM Loss: 0.11870098114013672\n",
      "Epoch: 10, Batch: 33, D Loss Real: 0.16531530022621155, D Loss Fake: 1.0555979013442993, G Loss: [12.605439186096191, 0.7494024038314819, 0.11856037378311157]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 34, SSIM Loss: 0.11636495590209961\n",
      "Epoch: 10, Batch: 34, D Loss Real: 0.1646122932434082, D Loss Fake: 1.0640666484832764, G Loss: [12.393610000610352, 0.7498669624328613, 0.11643743515014648]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 35, SSIM Loss: 0.10270673036575317\n",
      "Epoch: 10, Batch: 35, D Loss Real: 0.23134249448776245, D Loss Fake: 1.0477622747421265, G Loss: [10.95906925201416, 0.7058363556861877, 0.10253232717514038]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 36, SSIM Loss: 0.12158167362213135\n",
      "Epoch: 10, Batch: 36, D Loss Real: 0.18438777327537537, D Loss Fake: 1.2345892190933228, G Loss: [12.851758003234863, 0.7004328370094299, 0.1215132474899292]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 37, SSIM Loss: 0.11239832639694214\n",
      "Epoch: 10, Batch: 37, D Loss Real: 0.1912737786769867, D Loss Fake: 1.0481401681900024, G Loss: [11.962127685546875, 0.7202267050743103, 0.1124190092086792]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 38, SSIM Loss: 0.13027679920196533\n",
      "Epoch: 10, Batch: 38, D Loss Real: 0.16521401703357697, D Loss Fake: 1.1182860136032104, G Loss: [13.733474731445312, 0.7248692512512207, 0.13008606433868408]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 39, SSIM Loss: 0.11968356370925903\n",
      "Epoch: 10, Batch: 39, D Loss Real: 0.21046182513237, D Loss Fake: 1.0344069004058838, G Loss: [12.692410469055176, 0.7497970461845398, 0.11942613124847412]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 40, SSIM Loss: 0.11802512407302856\n",
      "Epoch: 10, Batch: 40, D Loss Real: 0.17138533294200897, D Loss Fake: 1.0572214126586914, G Loss: [12.52302360534668, 0.7231879234313965, 0.11799836158752441]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 41, SSIM Loss: 0.10633218288421631\n",
      "Epoch: 10, Batch: 41, D Loss Real: 0.17998605966567993, D Loss Fake: 0.9986355900764465, G Loss: [11.385570526123047, 0.7366817593574524, 0.10648888349533081]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 42, SSIM Loss: 0.11694622039794922\n",
      "Epoch: 10, Batch: 42, D Loss Real: 0.1420142650604248, D Loss Fake: 1.1496442556381226, G Loss: [12.400307655334473, 0.6985213756561279, 0.11701786518096924]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 43, SSIM Loss: 0.11291366815567017\n",
      "Epoch: 10, Batch: 43, D Loss Real: 0.14545856416225433, D Loss Fake: 0.9910545349121094, G Loss: [12.036727905273438, 0.7555599808692932, 0.11281168460845947]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 44, SSIM Loss: 0.10872781276702881\n",
      "Epoch: 10, Batch: 44, D Loss Real: 0.18030968308448792, D Loss Fake: 1.153191089630127, G Loss: [11.561626434326172, 0.7006351351737976, 0.10860991477966309]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 45, SSIM Loss: 0.12764763832092285\n",
      "Epoch: 10, Batch: 45, D Loss Real: 0.13430552184581757, D Loss Fake: 0.9970337748527527, G Loss: [13.500537872314453, 0.7471224069595337, 0.1275341510772705]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 46, SSIM Loss: 0.11293184757232666\n",
      "Epoch: 10, Batch: 46, D Loss Real: 0.23268532752990723, D Loss Fake: 1.0660254955291748, G Loss: [11.981416702270508, 0.6904740333557129, 0.11290943622589111]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 47, SSIM Loss: 0.13244640827178955\n",
      "Epoch: 10, Batch: 47, D Loss Real: 0.12146607786417007, D Loss Fake: 1.0669567584991455, G Loss: [13.932682037353516, 0.7102373838424683, 0.132224440574646]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 48, SSIM Loss: 0.11553424596786499\n",
      "Epoch: 10, Batch: 48, D Loss Real: 0.1067257970571518, D Loss Fake: 1.0320212841033936, G Loss: [12.31508731842041, 0.7474293112754822, 0.11567658185958862]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 49, SSIM Loss: 0.1145404577255249\n",
      "Epoch: 10, Batch: 49, D Loss Real: 0.14028975367546082, D Loss Fake: 0.9968208074569702, G Loss: [12.22195816040039, 0.7686871886253357, 0.1145327091217041]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 50, SSIM Loss: 0.11440932750701904\n",
      "Epoch: 10, Batch: 50, D Loss Real: 0.1632465422153473, D Loss Fake: 1.1636549234390259, G Loss: [12.178632736206055, 0.7325920462608337, 0.11446040868759155]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 51, SSIM Loss: 0.11696290969848633\n",
      "Epoch: 10, Batch: 51, D Loss Real: 0.18814346194267273, D Loss Fake: 1.021532654762268, G Loss: [12.397209167480469, 0.7451205253601074, 0.11652088165283203]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 52, SSIM Loss: 0.11918473243713379\n",
      "Epoch: 10, Batch: 52, D Loss Real: 0.2030552178621292, D Loss Fake: 0.9966982007026672, G Loss: [12.64877700805664, 0.7312811017036438, 0.11917495727539062]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 53, SSIM Loss: 0.11662352085113525\n",
      "Epoch: 10, Batch: 53, D Loss Real: 0.17043694853782654, D Loss Fake: 1.0858025550842285, G Loss: [12.340328216552734, 0.697109043598175, 0.11643218994140625]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 54, SSIM Loss: 0.12156587839126587\n",
      "Epoch: 10, Batch: 54, D Loss Real: 0.1371263563632965, D Loss Fake: 1.1932368278503418, G Loss: [12.925923347473145, 0.717598557472229, 0.12208324670791626]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 55, SSIM Loss: 0.10440915822982788\n",
      "Epoch: 10, Batch: 55, D Loss Real: 0.22324204444885254, D Loss Fake: 0.937787652015686, G Loss: [11.22054386138916, 0.7852489352226257, 0.10435295104980469]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 56, SSIM Loss: 0.11848604679107666\n",
      "Epoch: 10, Batch: 56, D Loss Real: 0.16431492567062378, D Loss Fake: 1.0096051692962646, G Loss: [12.607476234436035, 0.7368897795677185, 0.1187058687210083]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 57, SSIM Loss: 0.12758862972259521\n",
      "Epoch: 10, Batch: 57, D Loss Real: 0.12176545709371567, D Loss Fake: 1.1777174472808838, G Loss: [13.489517211914062, 0.732132077217102, 0.12757384777069092]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 58, SSIM Loss: 0.12616604566574097\n",
      "Epoch: 10, Batch: 58, D Loss Real: 0.18781429529190063, D Loss Fake: 1.1249216794967651, G Loss: [13.318601608276367, 0.7176373600959778, 0.12600964307785034]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 59, SSIM Loss: 0.11507481336593628\n",
      "Epoch: 10, Batch: 59, D Loss Real: 0.22656981647014618, D Loss Fake: 1.0971566438674927, G Loss: [12.25564193725586, 0.7162538766860962, 0.11539387702941895]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 60, SSIM Loss: 0.12323331832885742\n",
      "Epoch: 10, Batch: 60, D Loss Real: 0.18279710412025452, D Loss Fake: 1.0743041038513184, G Loss: [13.08858871459961, 0.7123043537139893, 0.12376284599304199]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 61, SSIM Loss: 0.11106419563293457\n",
      "Epoch: 10, Batch: 61, D Loss Real: 0.19702845811843872, D Loss Fake: 1.0382680892944336, G Loss: [11.866846084594727, 0.7554795742034912, 0.11111366748809814]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 10, Batch: 62, SSIM Loss: 0.11743223667144775\n",
      "Epoch: 10, Batch: 62, D Loss Real: 0.14026670157909393, D Loss Fake: 1.0818060636520386, G Loss: [12.529014587402344, 0.7381615042686462, 0.1179085373878479]\n",
      "1/1 [==============================] - 0s 144ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:26:09.695426: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:26:11.151591: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Batch: 1, SSIM Loss: 0.10934948921203613\n",
      "Epoch: 11, Batch: 1, D Loss Real: 0.17011399567127228, D Loss Fake: 1.062370777130127, G Loss: [11.706815719604492, 0.7329754829406738, 0.10973840951919556]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 2, SSIM Loss: 0.10874533653259277\n",
      "Epoch: 11, Batch: 2, D Loss Real: 0.19940848648548126, D Loss Fake: 0.9984694123268127, G Loss: [11.614272117614746, 0.7293250560760498, 0.10884946584701538]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 11, Batch: 3, SSIM Loss: 0.12091827392578125\n",
      "Epoch: 11, Batch: 3, D Loss Real: 0.13897274434566498, D Loss Fake: 1.1506625413894653, G Loss: [12.871676445007324, 0.7627187371253967, 0.12108957767486572]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 4, SSIM Loss: 0.11906808614730835\n",
      "Epoch: 11, Batch: 4, D Loss Real: 0.21629825234413147, D Loss Fake: 1.0201364755630493, G Loss: [12.63399600982666, 0.7503791451454163, 0.1188361644744873]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 5, SSIM Loss: 0.11125338077545166\n",
      "Epoch: 11, Batch: 5, D Loss Real: 0.27107688784599304, D Loss Fake: 1.1467761993408203, G Loss: [11.787813186645508, 0.6716476082801819, 0.11116164922714233]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 11, Batch: 6, SSIM Loss: 0.11430901288986206\n",
      "Epoch: 11, Batch: 6, D Loss Real: 0.1925424337387085, D Loss Fake: 1.0633901357650757, G Loss: [12.135334014892578, 0.6985611915588379, 0.11436772346496582]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 7, SSIM Loss: 0.1154630184173584\n",
      "Epoch: 11, Batch: 7, D Loss Real: 0.17132993042469025, D Loss Fake: 1.2022247314453125, G Loss: [12.2641019821167, 0.7306394577026367, 0.11533463001251221]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 8, SSIM Loss: 0.10946798324584961\n",
      "Epoch: 11, Batch: 8, D Loss Real: 0.25315725803375244, D Loss Fake: 1.0384037494659424, G Loss: [11.647769927978516, 0.7144124507904053, 0.1093335747718811]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 9, SSIM Loss: 0.11765241622924805\n",
      "Epoch: 11, Batch: 9, D Loss Real: 0.17390455305576324, D Loss Fake: 1.0814417600631714, G Loss: [12.48885726928711, 0.7282591462135315, 0.11760598421096802]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 11, Batch: 10, SSIM Loss: 0.11127543449401855\n",
      "Epoch: 11, Batch: 10, D Loss Real: 0.17509686946868896, D Loss Fake: 1.1808233261108398, G Loss: [11.758374214172363, 0.7125728726387024, 0.11045801639556885]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 11, Batch: 11, SSIM Loss: 0.1139291524887085\n",
      "Epoch: 11, Batch: 11, D Loss Real: 0.23135557770729065, D Loss Fake: 1.088254451751709, G Loss: [12.069461822509766, 0.7315254807472229, 0.11337935924530029]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 12, SSIM Loss: 0.11285698413848877\n",
      "Epoch: 11, Batch: 12, D Loss Real: 0.223978653550148, D Loss Fake: 1.1597416400909424, G Loss: [11.9149169921875, 0.650402307510376, 0.11264514923095703]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 13, SSIM Loss: 0.1201295256614685\n",
      "Epoch: 11, Batch: 13, D Loss Real: 0.16052483022212982, D Loss Fake: 1.097618579864502, G Loss: [12.753171920776367, 0.7197389602661133, 0.12033432722091675]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 14, SSIM Loss: 0.12298691272735596\n",
      "Epoch: 11, Batch: 14, D Loss Real: 0.17667832970619202, D Loss Fake: 1.149062991142273, G Loss: [13.011725425720215, 0.7370070815086365, 0.12274718284606934]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 15, SSIM Loss: 0.11860287189483643\n",
      "Epoch: 11, Batch: 15, D Loss Real: 0.24372261762619019, D Loss Fake: 1.0448241233825684, G Loss: [12.660082817077637, 0.7169271111488342, 0.11943155527114868]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 16, SSIM Loss: 0.11519014835357666\n",
      "Epoch: 11, Batch: 16, D Loss Real: 0.2363145798444748, D Loss Fake: 1.0463051795959473, G Loss: [12.2213716506958, 0.7059565782546997, 0.11515414714813232]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 17, SSIM Loss: 0.11605751514434814\n",
      "Epoch: 11, Batch: 17, D Loss Real: 0.14553387463092804, D Loss Fake: 1.0768952369689941, G Loss: [12.31688117980957, 0.70375657081604, 0.1161312460899353]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 18, SSIM Loss: 0.11123478412628174\n",
      "Epoch: 11, Batch: 18, D Loss Real: 0.15087595582008362, D Loss Fake: 1.1043692827224731, G Loss: [11.85890007019043, 0.7247466444969177, 0.11134153604507446]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 11, Batch: 19, SSIM Loss: 0.11796361207962036\n",
      "Epoch: 11, Batch: 19, D Loss Real: 0.13314351439476013, D Loss Fake: 1.0623995065689087, G Loss: [12.523387908935547, 0.7433531284332275, 0.11780035495758057]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 20, SSIM Loss: 0.11774718761444092\n",
      "Epoch: 11, Batch: 20, D Loss Real: 0.1693856418132782, D Loss Fake: 1.0767568349838257, G Loss: [12.551424026489258, 0.7583109140396118, 0.11793112754821777]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 11, Batch: 21, SSIM Loss: 0.113311767578125\n",
      "Epoch: 11, Batch: 21, D Loss Real: 0.2003328651189804, D Loss Fake: 1.0137884616851807, G Loss: [12.067035675048828, 0.7428566217422485, 0.11324179172515869]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 22, SSIM Loss: 0.1094101071357727\n",
      "Epoch: 11, Batch: 22, D Loss Real: 0.1575929969549179, D Loss Fake: 1.0733660459518433, G Loss: [11.547107696533203, 0.6864143013954163, 0.10860693454742432]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 23, SSIM Loss: 0.12167620658874512\n",
      "Epoch: 11, Batch: 23, D Loss Real: 0.129319965839386, D Loss Fake: 1.2307803630828857, G Loss: [12.912481307983398, 0.7670809626579285, 0.12145400047302246]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 24, SSIM Loss: 0.12638211250305176\n",
      "Epoch: 11, Batch: 24, D Loss Real: 0.23757848143577576, D Loss Fake: 1.0479823350906372, G Loss: [13.320302963256836, 0.7324331402778625, 0.1258786916732788]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 25, SSIM Loss: 0.11384767293930054\n",
      "Epoch: 11, Batch: 25, D Loss Real: 0.23009507358074188, D Loss Fake: 0.9846997261047363, G Loss: [12.14541244506836, 0.7505776286125183, 0.11394834518432617]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 26, SSIM Loss: 0.11779046058654785\n",
      "Epoch: 11, Batch: 26, D Loss Real: 0.1678246110677719, D Loss Fake: 1.0166208744049072, G Loss: [12.486000061035156, 0.7281728982925415, 0.11757826805114746]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 27, SSIM Loss: 0.11184954643249512\n",
      "Epoch: 11, Batch: 27, D Loss Real: 0.14799350500106812, D Loss Fake: 1.049830675125122, G Loss: [11.868559837341309, 0.7144325375556946, 0.1115412712097168]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 28, SSIM Loss: 0.11008226871490479\n",
      "Epoch: 11, Batch: 28, D Loss Real: 0.1580992043018341, D Loss Fake: 1.1626129150390625, G Loss: [11.695663452148438, 0.7005793452262878, 0.10995084047317505]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 29, SSIM Loss: 0.12362432479858398\n",
      "Epoch: 11, Batch: 29, D Loss Real: 0.14484715461730957, D Loss Fake: 1.064643144607544, G Loss: [13.099452018737793, 0.7301586866378784, 0.12369292974472046]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 30, SSIM Loss: 0.12036097049713135\n",
      "Epoch: 11, Batch: 30, D Loss Real: 0.12080705165863037, D Loss Fake: 0.98099684715271, G Loss: [12.810591697692871, 0.7611785531044006, 0.12049412727355957]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 11, Batch: 31, SSIM Loss: 0.1137545108795166\n",
      "Epoch: 11, Batch: 31, D Loss Real: 0.1673998087644577, D Loss Fake: 1.224790096282959, G Loss: [12.09398365020752, 0.7273960113525391, 0.1136658787727356]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 32, SSIM Loss: 0.1166534423828125\n",
      "Epoch: 11, Batch: 32, D Loss Real: 0.1711055338382721, D Loss Fake: 1.024165391921997, G Loss: [12.42558765411377, 0.7697267532348633, 0.11655861139297485]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 33, SSIM Loss: 0.11787682771682739\n",
      "Epoch: 11, Batch: 33, D Loss Real: 0.2156488001346588, D Loss Fake: 1.0256904363632202, G Loss: [12.488466262817383, 0.7291483879089355, 0.11759316921234131]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 34, SSIM Loss: 0.1161801815032959\n",
      "Epoch: 11, Batch: 34, D Loss Real: 0.18142397701740265, D Loss Fake: 1.1224944591522217, G Loss: [12.299490928649902, 0.7096962332725525, 0.11589795351028442]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 35, SSIM Loss: 0.10210734605789185\n",
      "Epoch: 11, Batch: 35, D Loss Real: 0.20641322433948517, D Loss Fake: 1.0426677465438843, G Loss: [10.912071228027344, 0.7007099390029907, 0.10211360454559326]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 36, SSIM Loss: 0.12200331687927246\n",
      "Epoch: 11, Batch: 36, D Loss Real: 0.16703647375106812, D Loss Fake: 1.354941487312317, G Loss: [12.931976318359375, 0.7151938080787659, 0.12216782569885254]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 37, SSIM Loss: 0.11181974411010742\n",
      "Epoch: 11, Batch: 37, D Loss Real: 0.2068556696176529, D Loss Fake: 1.0125254392623901, G Loss: [11.920455932617188, 0.7445008754730225, 0.11175954341888428]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 38, SSIM Loss: 0.13054382801055908\n",
      "Epoch: 11, Batch: 38, D Loss Real: 0.20200632512569427, D Loss Fake: 1.0782933235168457, G Loss: [13.817633628845215, 0.7125991582870483, 0.13105034828186035]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 11, Batch: 39, SSIM Loss: 0.1192745566368103\n",
      "Epoch: 11, Batch: 39, D Loss Real: 0.22625231742858887, D Loss Fake: 1.0528388023376465, G Loss: [12.644377708435059, 0.7371286749839783, 0.11907249689102173]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 40, SSIM Loss: 0.11759358644485474\n",
      "Epoch: 11, Batch: 40, D Loss Real: 0.16729503870010376, D Loss Fake: 1.0393644571304321, G Loss: [12.505474090576172, 0.7363995313644409, 0.11769074201583862]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 41, SSIM Loss: 0.10628682374954224\n",
      "Epoch: 11, Batch: 41, D Loss Real: 0.16884003579616547, D Loss Fake: 0.9947948455810547, G Loss: [11.41042709350586, 0.7732981443405151, 0.10637128353118896]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 42, SSIM Loss: 0.11756634712219238\n",
      "Epoch: 11, Batch: 42, D Loss Real: 0.14137040078639984, D Loss Fake: 1.2083081007003784, G Loss: [12.504042625427246, 0.7298362851142883, 0.11774206161499023]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 43, SSIM Loss: 0.11257719993591309\n",
      "Epoch: 11, Batch: 43, D Loss Real: 0.1610405147075653, D Loss Fake: 0.9797617793083191, G Loss: [12.044035911560059, 0.7927348613739014, 0.11251300573348999]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 11, Batch: 44, SSIM Loss: 0.1077810525894165\n",
      "Epoch: 11, Batch: 44, D Loss Real: 0.2046491652727127, D Loss Fake: 1.2316820621490479, G Loss: [11.503290176391602, 0.6975644826889038, 0.10805726051330566]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 45, SSIM Loss: 0.12701231241226196\n",
      "Epoch: 11, Batch: 45, D Loss Real: 0.14456023275852203, D Loss Fake: 1.0121535062789917, G Loss: [13.460224151611328, 0.7734474539756775, 0.12686777114868164]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 46, SSIM Loss: 0.11292588710784912\n",
      "Epoch: 11, Batch: 46, D Loss Real: 0.2650136649608612, D Loss Fake: 1.0861539840698242, G Loss: [11.933300018310547, 0.6997557878494263, 0.1123354434967041]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 47, SSIM Loss: 0.13096970319747925\n",
      "Epoch: 11, Batch: 47, D Loss Real: 0.13060234487056732, D Loss Fake: 1.1279034614562988, G Loss: [13.784350395202637, 0.6911885142326355, 0.13093161582946777]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 48, SSIM Loss: 0.11459249258041382\n",
      "Epoch: 11, Batch: 48, D Loss Real: 0.11502479016780853, D Loss Fake: 1.1304020881652832, G Loss: [12.187904357910156, 0.7555316090583801, 0.11432373523712158]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 49, SSIM Loss: 0.11442720890045166\n",
      "Epoch: 11, Batch: 49, D Loss Real: 0.17387370765209198, D Loss Fake: 0.9953435063362122, G Loss: [12.182022094726562, 0.762225329875946, 0.11419796943664551]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 50, SSIM Loss: 0.11418676376342773\n",
      "Epoch: 11, Batch: 50, D Loss Real: 0.17844422161579132, D Loss Fake: 1.2226793766021729, G Loss: [12.137799263000488, 0.7103967666625977, 0.1142740249633789]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 51, SSIM Loss: 0.1164063811302185\n",
      "Epoch: 11, Batch: 51, D Loss Real: 0.1860024333000183, D Loss Fake: 1.0127906799316406, G Loss: [12.378216743469238, 0.750388503074646, 0.11627829074859619]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 52, SSIM Loss: 0.1195453405380249\n",
      "Epoch: 11, Batch: 52, D Loss Real: 0.20029911398887634, D Loss Fake: 0.9793725609779358, G Loss: [12.669740676879883, 0.7346256971359253, 0.11935114860534668]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 53, SSIM Loss: 0.11592131853103638\n",
      "Epoch: 11, Batch: 53, D Loss Real: 0.14914336800575256, D Loss Fake: 1.2283506393432617, G Loss: [12.326726913452148, 0.7341592311859131, 0.11592566967010498]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 54, SSIM Loss: 0.1230359673500061\n",
      "Epoch: 11, Batch: 54, D Loss Real: 0.15773414075374603, D Loss Fake: 1.1342920064926147, G Loss: [13.000686645507812, 0.732167661190033, 0.12268519401550293]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 55, SSIM Loss: 0.10367381572723389\n",
      "Epoch: 11, Batch: 55, D Loss Real: 0.2657429873943329, D Loss Fake: 0.9458766579627991, G Loss: [11.165205955505371, 0.7760741710662842, 0.10389131307601929]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 56, SSIM Loss: 0.11700582504272461\n",
      "Epoch: 11, Batch: 56, D Loss Real: 0.16694572567939758, D Loss Fake: 1.0433822870254517, G Loss: [12.431090354919434, 0.7199814319610596, 0.11711108684539795]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 57, SSIM Loss: 0.12677031755447388\n",
      "Epoch: 11, Batch: 57, D Loss Real: 0.11536139994859695, D Loss Fake: 1.2787675857543945, G Loss: [13.458333015441895, 0.7168684005737305, 0.12741464376449585]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 58, SSIM Loss: 0.1255030632019043\n",
      "Epoch: 11, Batch: 58, D Loss Real: 0.18076995015144348, D Loss Fake: 1.1296265125274658, G Loss: [13.27003002166748, 0.7301777601242065, 0.12539851665496826]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 59, SSIM Loss: 0.11450886726379395\n",
      "Epoch: 11, Batch: 59, D Loss Real: 0.25248682498931885, D Loss Fake: 1.0927400588989258, G Loss: [12.147628784179688, 0.7126627564430237, 0.11434966325759888]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 11, Batch: 60, SSIM Loss: 0.12443691492080688\n",
      "Epoch: 11, Batch: 60, D Loss Real: 0.20208650827407837, D Loss Fake: 1.1111520528793335, G Loss: [13.159808158874512, 0.6981935501098633, 0.12461614608764648]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 11, Batch: 61, SSIM Loss: 0.11097729206085205\n",
      "Epoch: 11, Batch: 61, D Loss Real: 0.21229936182498932, D Loss Fake: 1.050920009613037, G Loss: [11.8524751663208, 0.7307729721069336, 0.11121702194213867]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 11, Batch: 62, SSIM Loss: 0.1164391040802002\n",
      "Epoch: 11, Batch: 62, D Loss Real: 0.14245976507663727, D Loss Fake: 1.0804567337036133, G Loss: [12.393839836120605, 0.7379843592643738, 0.11655855178833008]\n",
      "1/1 [==============================] - 0s 155ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:27:33.552531: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:27:35.052299: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Batch: 1, SSIM Loss: 0.10939955711364746\n",
      "Epoch: 12, Batch: 1, D Loss Real: 0.16300491988658905, D Loss Fake: 1.054828405380249, G Loss: [11.678756713867188, 0.7451304197311401, 0.109336256980896]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 2, SSIM Loss: 0.10827791690826416\n",
      "Epoch: 12, Batch: 2, D Loss Real: 0.17881788313388824, D Loss Fake: 1.007718801498413, G Loss: [11.592035293579102, 0.7627534866333008, 0.10829281806945801]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 12, Batch: 3, SSIM Loss: 0.12049055099487305\n",
      "Epoch: 12, Batch: 3, D Loss Real: 0.1370103657245636, D Loss Fake: 1.137981653213501, G Loss: [12.821815490722656, 0.7505818009376526, 0.12071233987808228]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 12, Batch: 4, SSIM Loss: 0.11867493391036987\n",
      "Epoch: 12, Batch: 4, D Loss Real: 0.19040946662425995, D Loss Fake: 1.0255522727966309, G Loss: [12.670145988464355, 0.7589811682701111, 0.11911165714263916]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 12, Batch: 5, SSIM Loss: 0.11086124181747437\n",
      "Epoch: 12, Batch: 5, D Loss Real: 0.23390059173107147, D Loss Fake: 1.1622159481048584, G Loss: [11.780385971069336, 0.6996020078659058, 0.11080783605575562]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 12, Batch: 6, SSIM Loss: 0.1142035722732544\n",
      "Epoch: 12, Batch: 6, D Loss Real: 0.1849520206451416, D Loss Fake: 1.0536308288574219, G Loss: [12.187601089477539, 0.7253661155700684, 0.11462235450744629]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 7, SSIM Loss: 0.11466598510742188\n",
      "Epoch: 12, Batch: 7, D Loss Real: 0.1748722493648529, D Loss Fake: 1.1678941249847412, G Loss: [12.264168739318848, 0.7514484524726868, 0.11512720584869385]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 12, Batch: 8, SSIM Loss: 0.10907459259033203\n",
      "Epoch: 12, Batch: 8, D Loss Real: 0.2614668011665344, D Loss Fake: 1.0440704822540283, G Loss: [11.60510540008545, 0.7184123992919922, 0.10886693000793457]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 9, SSIM Loss: 0.11697763204574585\n",
      "Epoch: 12, Batch: 9, D Loss Real: 0.1733027547597885, D Loss Fake: 1.150482177734375, G Loss: [12.414375305175781, 0.7070107460021973, 0.117073655128479]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 10, SSIM Loss: 0.10964417457580566\n",
      "Epoch: 12, Batch: 10, D Loss Real: 0.172202929854393, D Loss Fake: 1.1559817790985107, G Loss: [11.658708572387695, 0.6915965676307678, 0.10967111587524414]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 11, SSIM Loss: 0.112498939037323\n",
      "Epoch: 12, Batch: 11, D Loss Real: 0.21062105894088745, D Loss Fake: 1.1688603162765503, G Loss: [11.974325180053711, 0.7140905857086182, 0.1126023530960083]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 12, Batch: 12, SSIM Loss: 0.11211240291595459\n",
      "Epoch: 12, Batch: 12, D Loss Real: 0.22163400053977966, D Loss Fake: 1.161102294921875, G Loss: [11.867833137512207, 0.6671663522720337, 0.11200666427612305]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 12, Batch: 13, SSIM Loss: 0.11989718675613403\n",
      "Epoch: 12, Batch: 13, D Loss Real: 0.172475665807724, D Loss Fake: 1.1178029775619507, G Loss: [12.689192771911621, 0.7193160653114319, 0.11969876289367676]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 12, Batch: 14, SSIM Loss: 0.12141716480255127\n",
      "Epoch: 12, Batch: 14, D Loss Real: 0.1767895370721817, D Loss Fake: 1.249389410018921, G Loss: [12.88111686706543, 0.7463852763175964, 0.12134730815887451]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 12, Batch: 15, SSIM Loss: 0.11908340454101562\n",
      "Epoch: 12, Batch: 15, D Loss Real: 0.2847917675971985, D Loss Fake: 1.0726804733276367, G Loss: [12.590364456176758, 0.7069739699363708, 0.11883389949798584]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 16, SSIM Loss: 0.11453449726104736\n",
      "Epoch: 12, Batch: 16, D Loss Real: 0.3009587526321411, D Loss Fake: 1.0857348442077637, G Loss: [12.10252571105957, 0.673359215259552, 0.11429166793823242]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 17, SSIM Loss: 0.11577492952346802\n",
      "Epoch: 12, Batch: 17, D Loss Real: 0.20633091032505035, D Loss Fake: 1.1276166439056396, G Loss: [12.263077735900879, 0.6682995557785034, 0.11594778299331665]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 18, SSIM Loss: 0.111186683177948\n",
      "Epoch: 12, Batch: 18, D Loss Real: 0.21513065695762634, D Loss Fake: 1.109809398651123, G Loss: [11.786413192749023, 0.6735624074935913, 0.11112850904464722]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 19, SSIM Loss: 0.1172667145729065\n",
      "Epoch: 12, Batch: 19, D Loss Real: 0.14734457433223724, D Loss Fake: 1.1384204626083374, G Loss: [12.415260314941406, 0.6892262697219849, 0.11726033687591553]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 20, SSIM Loss: 0.11731928586959839\n",
      "Epoch: 12, Batch: 20, D Loss Real: 0.17751283943653107, D Loss Fake: 1.14878511428833, G Loss: [12.47238826751709, 0.7277576923370361, 0.11744630336761475]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 12, Batch: 21, SSIM Loss: 0.11247074604034424\n",
      "Epoch: 12, Batch: 21, D Loss Real: 0.1989227533340454, D Loss Fake: 1.037459373474121, G Loss: [12.073877334594727, 0.7487330436706543, 0.1132514476776123]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 22, SSIM Loss: 0.10766017436981201\n",
      "Epoch: 12, Batch: 22, D Loss Real: 0.16173142194747925, D Loss Fake: 1.1678110361099243, G Loss: [11.515743255615234, 0.7435862421989441, 0.10772156715393066]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 23, SSIM Loss: 0.12095797061920166\n",
      "Epoch: 12, Batch: 23, D Loss Real: 0.20117174088954926, D Loss Fake: 1.059461236000061, G Loss: [12.912867546081543, 0.7317103743553162, 0.12181156873703003]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 24, SSIM Loss: 0.12318611145019531\n",
      "Epoch: 12, Batch: 24, D Loss Real: 0.2169661670923233, D Loss Fake: 1.081827163696289, G Loss: [13.053373336791992, 0.7166844010353088, 0.12336689233779907]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 25, SSIM Loss: 0.11260342597961426\n",
      "Epoch: 12, Batch: 25, D Loss Real: 0.16738241910934448, D Loss Fake: 0.9737874269485474, G Loss: [12.015095710754395, 0.7573996782302856, 0.11257696151733398]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 26, SSIM Loss: 0.1167682409286499\n",
      "Epoch: 12, Batch: 26, D Loss Real: 0.13150665163993835, D Loss Fake: 1.09373140335083, G Loss: [12.426756858825684, 0.7484844923019409, 0.11678272485733032]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 27, SSIM Loss: 0.10873878002166748\n",
      "Epoch: 12, Batch: 27, D Loss Real: 0.1536857783794403, D Loss Fake: 1.1051347255706787, G Loss: [11.657153129577637, 0.7540918588638306, 0.10903060436248779]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 28, SSIM Loss: 0.10832387208938599\n",
      "Epoch: 12, Batch: 28, D Loss Real: 0.2300330400466919, D Loss Fake: 1.1016026735305786, G Loss: [11.532487869262695, 0.7034260630607605, 0.10829061269760132]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 29, SSIM Loss: 0.1209058165550232\n",
      "Epoch: 12, Batch: 29, D Loss Real: 0.18364092707633972, D Loss Fake: 1.0452663898468018, G Loss: [12.800726890563965, 0.7191994190216064, 0.12081527709960938]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 30, SSIM Loss: 0.11853593587875366\n",
      "Epoch: 12, Batch: 30, D Loss Real: 0.11706328392028809, D Loss Fake: 1.1276824474334717, G Loss: [12.631889343261719, 0.774416446685791, 0.11857473850250244]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 31, SSIM Loss: 0.11275684833526611\n",
      "Epoch: 12, Batch: 31, D Loss Real: 0.22431164979934692, D Loss Fake: 1.1477481126785278, G Loss: [11.948868751525879, 0.6966678500175476, 0.11252200603485107]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 32, SSIM Loss: 0.11486029624938965\n",
      "Epoch: 12, Batch: 32, D Loss Real: 0.21333470940589905, D Loss Fake: 1.0305598974227905, G Loss: [12.201349258422852, 0.7187288999557495, 0.11482620239257812]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 12, Batch: 33, SSIM Loss: 0.11651712656021118\n",
      "Epoch: 12, Batch: 33, D Loss Real: 0.18166190385818481, D Loss Fake: 1.0927298069000244, G Loss: [12.36299991607666, 0.7001469135284424, 0.11662852764129639]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 34, SSIM Loss: 0.1140405535697937\n",
      "Epoch: 12, Batch: 34, D Loss Real: 0.15136413276195526, D Loss Fake: 1.1663461923599243, G Loss: [12.142958641052246, 0.7292529940605164, 0.11413705348968506]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 35, SSIM Loss: 0.1013643741607666\n",
      "Epoch: 12, Batch: 35, D Loss Real: 0.21605083346366882, D Loss Fake: 1.0099314451217651, G Loss: [10.878167152404785, 0.7350184321403503, 0.10143148899078369]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 36, SSIM Loss: 0.12093377113342285\n",
      "Epoch: 12, Batch: 36, D Loss Real: 0.18491347134113312, D Loss Fake: 1.4757651090621948, G Loss: [12.865334510803223, 0.720410943031311, 0.12144923210144043]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 37, SSIM Loss: 0.11073976755142212\n",
      "Epoch: 12, Batch: 37, D Loss Real: 0.2625376880168915, D Loss Fake: 1.0075793266296387, G Loss: [11.811029434204102, 0.7457849979400635, 0.11065244674682617]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 38, SSIM Loss: 0.12939602136611938\n",
      "Epoch: 12, Batch: 38, D Loss Real: 0.2622247338294983, D Loss Fake: 1.1112453937530518, G Loss: [13.598609924316406, 0.6638057231903076, 0.1293480396270752]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 39, SSIM Loss: 0.11736893653869629\n",
      "Epoch: 12, Batch: 39, D Loss Real: 0.2602806091308594, D Loss Fake: 1.0828677415847778, G Loss: [12.44069766998291, 0.6507322192192078, 0.11789965629577637]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 40, SSIM Loss: 0.11701822280883789\n",
      "Epoch: 12, Batch: 40, D Loss Real: 0.16989561915397644, D Loss Fake: 1.085589051246643, G Loss: [12.388867378234863, 0.6932553648948669, 0.11695611476898193]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 41, SSIM Loss: 0.10483354330062866\n",
      "Epoch: 12, Batch: 41, D Loss Real: 0.1557249128818512, D Loss Fake: 1.012926697731018, G Loss: [11.225747108459473, 0.7440080642700195, 0.10481739044189453]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 12, Batch: 42, SSIM Loss: 0.11685419082641602\n",
      "Epoch: 12, Batch: 42, D Loss Real: 0.125275120139122, D Loss Fake: 1.2498173713684082, G Loss: [12.430472373962402, 0.7296273708343506, 0.11700844764709473]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 43, SSIM Loss: 0.11150407791137695\n",
      "Epoch: 12, Batch: 43, D Loss Real: 0.15005013346672058, D Loss Fake: 0.9823663234710693, G Loss: [11.947821617126465, 0.7983676195144653, 0.11149454116821289]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 44, SSIM Loss: 0.10715138912200928\n",
      "Epoch: 12, Batch: 44, D Loss Real: 0.20722398161888123, D Loss Fake: 1.2439461946487427, G Loss: [11.454392433166504, 0.7166693806648254, 0.10737723112106323]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 45, SSIM Loss: 0.1268804669380188\n",
      "Epoch: 12, Batch: 45, D Loss Real: 0.161428764462471, D Loss Fake: 0.9912171363830566, G Loss: [13.427950859069824, 0.7772108912467957, 0.12650740146636963]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 46, SSIM Loss: 0.11174976825714111\n",
      "Epoch: 12, Batch: 46, D Loss Real: 0.26663172245025635, D Loss Fake: 1.0662763118743896, G Loss: [11.877165794372559, 0.6951860189437866, 0.1118198037147522]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 47, SSIM Loss: 0.12919634580612183\n",
      "Epoch: 12, Batch: 47, D Loss Real: 0.12820273637771606, D Loss Fake: 1.1305601596832275, G Loss: [13.637438774108887, 0.6959587335586548, 0.12941479682922363]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 48, SSIM Loss: 0.11251676082611084\n",
      "Epoch: 12, Batch: 48, D Loss Real: 0.11690323054790497, D Loss Fake: 1.1143897771835327, G Loss: [11.9931640625, 0.7528136372566223, 0.1124035120010376]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 49, SSIM Loss: 0.11397057771682739\n",
      "Epoch: 12, Batch: 49, D Loss Real: 0.1719086915254593, D Loss Fake: 1.0480858087539673, G Loss: [12.186878204345703, 0.7377323508262634, 0.11449146270751953]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 50, SSIM Loss: 0.11415457725524902\n",
      "Epoch: 12, Batch: 50, D Loss Real: 0.18127267062664032, D Loss Fake: 1.2963428497314453, G Loss: [12.172008514404297, 0.739909291267395, 0.11432099342346191]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 51, SSIM Loss: 0.11537718772888184\n",
      "Epoch: 12, Batch: 51, D Loss Real: 0.23392385244369507, D Loss Fake: 1.0727523565292358, G Loss: [12.253189086914062, 0.742798388004303, 0.11510390043258667]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 52, SSIM Loss: 0.11827075481414795\n",
      "Epoch: 12, Batch: 52, D Loss Real: 0.278698205947876, D Loss Fake: 1.050661325454712, G Loss: [12.544222831726074, 0.7143275141716003, 0.11829894781112671]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 53, SSIM Loss: 0.11498737335205078\n",
      "Epoch: 12, Batch: 53, D Loss Real: 0.24037182331085205, D Loss Fake: 1.1591633558273315, G Loss: [12.165288925170898, 0.6608718633651733, 0.11504417657852173]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 54, SSIM Loss: 0.12076592445373535\n",
      "Epoch: 12, Batch: 54, D Loss Real: 0.18295376002788544, D Loss Fake: 1.1982923746109009, G Loss: [12.770157814025879, 0.6516868472099304, 0.12118470668792725]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 55, SSIM Loss: 0.10338497161865234\n",
      "Epoch: 12, Batch: 55, D Loss Real: 0.2405105084180832, D Loss Fake: 1.0497068166732788, G Loss: [11.0374755859375, 0.7227613925933838, 0.10314714908599854]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 56, SSIM Loss: 0.11578238010406494\n",
      "Epoch: 12, Batch: 56, D Loss Real: 0.1672392636537552, D Loss Fake: 1.060501217842102, G Loss: [12.266702651977539, 0.7078949213027954, 0.11558806896209717]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 57, SSIM Loss: 0.12610769271850586\n",
      "Epoch: 12, Batch: 57, D Loss Real: 0.13246381282806396, D Loss Fake: 1.2751967906951904, G Loss: [13.389748573303223, 0.7266460657119751, 0.1266310214996338]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 58, SSIM Loss: 0.12357151508331299\n",
      "Epoch: 12, Batch: 58, D Loss Real: 0.2062365561723709, D Loss Fake: 1.0811880826950073, G Loss: [13.090985298156738, 0.7343224287033081, 0.1235666275024414]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 59, SSIM Loss: 0.1126062273979187\n",
      "Epoch: 12, Batch: 59, D Loss Real: 0.26956063508987427, D Loss Fake: 1.1207746267318726, G Loss: [11.944579124450684, 0.6950255036354065, 0.1124955415725708]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 12, Batch: 60, SSIM Loss: 0.12490850687026978\n",
      "Epoch: 12, Batch: 60, D Loss Real: 0.2061302363872528, D Loss Fake: 1.1402376890182495, G Loss: [13.06765079498291, 0.6837369203567505, 0.12383913993835449]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 61, SSIM Loss: 0.11092960834503174\n",
      "Epoch: 12, Batch: 61, D Loss Real: 0.22598481178283691, D Loss Fake: 1.05796217918396, G Loss: [11.80309009552002, 0.7202142477035522, 0.11082875728607178]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 12, Batch: 62, SSIM Loss: 0.11594665050506592\n",
      "Epoch: 12, Batch: 62, D Loss Real: 0.15620292723178864, D Loss Fake: 1.1079213619232178, G Loss: [12.326580047607422, 0.7178845405578613, 0.11608695983886719]\n",
      "1/1 [==============================] - 0s 157ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:28:56.846438: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:28:58.338930: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Batch: 1, SSIM Loss: 0.10880565643310547\n",
      "Epoch: 13, Batch: 1, D Loss Real: 0.17199040949344635, D Loss Fake: 1.0570346117019653, G Loss: [11.575780868530273, 0.7361036539077759, 0.10839676856994629]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 2, SSIM Loss: 0.10744667053222656\n",
      "Epoch: 13, Batch: 2, D Loss Real: 0.18354207277297974, D Loss Fake: 1.0159814357757568, G Loss: [11.515613555908203, 0.751772403717041, 0.107638418674469]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 13, Batch: 3, SSIM Loss: 0.12043213844299316\n",
      "Epoch: 13, Batch: 3, D Loss Real: 0.13824906945228577, D Loss Fake: 1.1594407558441162, G Loss: [12.761994361877441, 0.7644738554954529, 0.11997520923614502]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 4, SSIM Loss: 0.11775100231170654\n",
      "Epoch: 13, Batch: 4, D Loss Real: 0.220815047621727, D Loss Fake: 1.0345782041549683, G Loss: [12.498281478881836, 0.7485251426696777, 0.11749756336212158]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 13, Batch: 5, SSIM Loss: 0.11008822917938232\n",
      "Epoch: 13, Batch: 5, D Loss Real: 0.24259187281131744, D Loss Fake: 1.234986662864685, G Loss: [11.687803268432617, 0.6792071461677551, 0.11008596420288086]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 6, SSIM Loss: 0.114066481590271\n",
      "Epoch: 13, Batch: 6, D Loss Real: 0.19897039234638214, D Loss Fake: 1.0967682600021362, G Loss: [12.095771789550781, 0.7088527679443359, 0.11386919021606445]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 7, SSIM Loss: 0.11425185203552246\n",
      "Epoch: 13, Batch: 7, D Loss Real: 0.20473183691501617, D Loss Fake: 1.1487910747528076, G Loss: [12.112370491027832, 0.7103472948074341, 0.11402022838592529]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 13, Batch: 8, SSIM Loss: 0.10876184701919556\n",
      "Epoch: 13, Batch: 8, D Loss Real: 0.25524818897247314, D Loss Fake: 1.0728020668029785, G Loss: [11.560824394226074, 0.7054593563079834, 0.10855364799499512]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 13, Batch: 9, SSIM Loss: 0.11608248949050903\n",
      "Epoch: 13, Batch: 9, D Loss Real: 0.16689355671405792, D Loss Fake: 1.190263271331787, G Loss: [12.330023765563965, 0.7324973344802856, 0.1159752607345581]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 10, SSIM Loss: 0.10751199722290039\n",
      "Epoch: 13, Batch: 10, D Loss Real: 0.20332252979278564, D Loss Fake: 1.1122454404830933, G Loss: [11.469321250915527, 0.7050449252128601, 0.1076427698135376]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 11, SSIM Loss: 0.11193865537643433\n",
      "Epoch: 13, Batch: 11, D Loss Real: 0.26559069752693176, D Loss Fake: 1.1219537258148193, G Loss: [11.870077133178711, 0.6790313720703125, 0.11191046237945557]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 12, SSIM Loss: 0.11128097772598267\n",
      "Epoch: 13, Batch: 12, D Loss Real: 0.20827119052410126, D Loss Fake: 1.2977511882781982, G Loss: [11.771112442016602, 0.6535820960998535, 0.1111752986907959]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 13, SSIM Loss: 0.11962318420410156\n",
      "Epoch: 13, Batch: 13, D Loss Real: 0.23676061630249023, D Loss Fake: 1.1192359924316406, G Loss: [12.683680534362793, 0.7191267013549805, 0.11964553594589233]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 14, SSIM Loss: 0.11928999423980713\n",
      "Epoch: 13, Batch: 14, D Loss Real: 0.23939570784568787, D Loss Fake: 1.180229902267456, G Loss: [12.621769905090332, 0.6969313025474548, 0.1192483901977539]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 15, SSIM Loss: 0.1181986927986145\n",
      "Epoch: 13, Batch: 15, D Loss Real: 0.24570904672145844, D Loss Fake: 1.1953449249267578, G Loss: [12.637347221374512, 0.6725019812583923, 0.11964845657348633]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 16, SSIM Loss: 0.11495321989059448\n",
      "Epoch: 13, Batch: 16, D Loss Real: 0.26821810007095337, D Loss Fake: 1.0834593772888184, G Loss: [12.150604248046875, 0.7040030360221863, 0.11446601152420044]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 17, SSIM Loss: 0.11559689044952393\n",
      "Epoch: 13, Batch: 17, D Loss Real: 0.22309397161006927, D Loss Fake: 1.0859360694885254, G Loss: [12.244719505310059, 0.7029950618743896, 0.1154172420501709]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 18, SSIM Loss: 0.11042129993438721\n",
      "Epoch: 13, Batch: 18, D Loss Real: 0.20399333536624908, D Loss Fake: 1.1085028648376465, G Loss: [11.726730346679688, 0.695537805557251, 0.11031192541122437]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 19, SSIM Loss: 0.11621034145355225\n",
      "Epoch: 13, Batch: 19, D Loss Real: 0.14676639437675476, D Loss Fake: 1.2893531322479248, G Loss: [12.351532936096191, 0.712772011756897, 0.11638760566711426]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 20, SSIM Loss: 0.1168217658996582\n",
      "Epoch: 13, Batch: 20, D Loss Real: 0.21017511188983917, D Loss Fake: 1.0465199947357178, G Loss: [12.418733596801758, 0.7354306578636169, 0.11683303117752075]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 21, SSIM Loss: 0.11174696683883667\n",
      "Epoch: 13, Batch: 21, D Loss Real: 0.23557592928409576, D Loss Fake: 1.0199918746948242, G Loss: [11.862908363342285, 0.7175911068916321, 0.11145317554473877]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 22, SSIM Loss: 0.10671436786651611\n",
      "Epoch: 13, Batch: 22, D Loss Real: 0.15477502346038818, D Loss Fake: 1.2537269592285156, G Loss: [11.368753433227539, 0.6905574798583984, 0.1067819595336914]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 23, SSIM Loss: 0.11994338035583496\n",
      "Epoch: 13, Batch: 23, D Loss Real: 0.17893710732460022, D Loss Fake: 1.1155688762664795, G Loss: [12.775933265686035, 0.725012481212616, 0.12050920724868774]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 24, SSIM Loss: 0.12237131595611572\n",
      "Epoch: 13, Batch: 24, D Loss Real: 0.22310736775398254, D Loss Fake: 1.0613049268722534, G Loss: [13.017236709594727, 0.6924799084663391, 0.12324756383895874]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 25, SSIM Loss: 0.11218249797821045\n",
      "Epoch: 13, Batch: 25, D Loss Real: 0.16428114473819733, D Loss Fake: 1.0138672590255737, G Loss: [11.944426536560059, 0.7539885640144348, 0.11190438270568848]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 26, SSIM Loss: 0.11612117290496826\n",
      "Epoch: 13, Batch: 26, D Loss Real: 0.1345817595720291, D Loss Fake: 1.1091805696487427, G Loss: [12.414044380187988, 0.7464591264724731, 0.11667585372924805]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 27, SSIM Loss: 0.10889381170272827\n",
      "Epoch: 13, Batch: 27, D Loss Real: 0.163896381855011, D Loss Fake: 1.060746669769287, G Loss: [11.618114471435547, 0.736076831817627, 0.10882037878036499]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 28, SSIM Loss: 0.10774445533752441\n",
      "Epoch: 13, Batch: 28, D Loss Real: 0.21018163859844208, D Loss Fake: 1.1159530878067017, G Loss: [11.506458282470703, 0.7133327722549438, 0.10793125629425049]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 29, SSIM Loss: 0.11965686082839966\n",
      "Epoch: 13, Batch: 29, D Loss Real: 0.16539180278778076, D Loss Fake: 1.0442909002304077, G Loss: [12.719148635864258, 0.7441467642784119, 0.1197500228881836]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 30, SSIM Loss: 0.11859095096588135\n",
      "Epoch: 13, Batch: 30, D Loss Real: 0.11860008537769318, D Loss Fake: 1.0416991710662842, G Loss: [12.598963737487793, 0.7587997913360596, 0.11840164661407471]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 31, SSIM Loss: 0.11175048351287842\n",
      "Epoch: 13, Batch: 31, D Loss Real: 0.184003084897995, D Loss Fake: 1.2177717685699463, G Loss: [11.883870124816895, 0.7217742204666138, 0.1116209626197815]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 32, SSIM Loss: 0.11464571952819824\n",
      "Epoch: 13, Batch: 32, D Loss Real: 0.2054859846830368, D Loss Fake: 1.0212594270706177, G Loss: [12.208121299743652, 0.7561728358268738, 0.11451947689056396]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 33, SSIM Loss: 0.11445033550262451\n",
      "Epoch: 13, Batch: 33, D Loss Real: 0.22649994492530823, D Loss Fake: 1.0822840929031372, G Loss: [12.17165470123291, 0.7078812718391418, 0.11463773250579834]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 34, SSIM Loss: 0.1135486364364624\n",
      "Epoch: 13, Batch: 34, D Loss Real: 0.17339622974395752, D Loss Fake: 1.1971312761306763, G Loss: [12.058496475219727, 0.7160552740097046, 0.11342442035675049]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 35, SSIM Loss: 0.1009681224822998\n",
      "Epoch: 13, Batch: 35, D Loss Real: 0.24142611026763916, D Loss Fake: 1.0769271850585938, G Loss: [10.781326293945312, 0.7226136326789856, 0.10058712959289551]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 36, SSIM Loss: 0.12024706602096558\n",
      "Epoch: 13, Batch: 36, D Loss Real: 0.22996200621128082, D Loss Fake: 1.3570353984832764, G Loss: [12.72937297821045, 0.6947003602981567, 0.12034672498703003]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 13, Batch: 37, SSIM Loss: 0.10999923944473267\n",
      "Epoch: 13, Batch: 37, D Loss Real: 0.2624165415763855, D Loss Fake: 1.0592155456542969, G Loss: [11.729042053222656, 0.7061038017272949, 0.11022937297821045]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 38, SSIM Loss: 0.12853795289993286\n",
      "Epoch: 13, Batch: 38, D Loss Real: 0.24746760725975037, D Loss Fake: 1.1434756517410278, G Loss: [13.520703315734863, 0.6530203223228455, 0.12867683172225952]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 39, SSIM Loss: 0.1158902645111084\n",
      "Epoch: 13, Batch: 39, D Loss Real: 0.26606491208076477, D Loss Fake: 1.1102111339569092, G Loss: [12.2951021194458, 0.671266496181488, 0.11623835563659668]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 40, SSIM Loss: 0.1160576343536377\n",
      "Epoch: 13, Batch: 40, D Loss Real: 0.1856195330619812, D Loss Fake: 1.0618078708648682, G Loss: [12.3162202835083, 0.7002044320106506, 0.11616015434265137]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 41, SSIM Loss: 0.10387849807739258\n",
      "Epoch: 13, Batch: 41, D Loss Real: 0.15404367446899414, D Loss Fake: 1.056961178779602, G Loss: [11.121014595031738, 0.7455917596817017, 0.10375422239303589]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 42, SSIM Loss: 0.11647939682006836\n",
      "Epoch: 13, Batch: 42, D Loss Real: 0.12953241169452667, D Loss Fake: 1.1510286331176758, G Loss: [12.40743637084961, 0.74541175365448, 0.11662024259567261]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 43, SSIM Loss: 0.11044484376907349\n",
      "Epoch: 13, Batch: 43, D Loss Real: 0.16189917922019958, D Loss Fake: 0.980976939201355, G Loss: [11.826634407043457, 0.7823111414909363, 0.11044323444366455]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 44, SSIM Loss: 0.10554301738739014\n",
      "Epoch: 13, Batch: 44, D Loss Real: 0.20934155583381653, D Loss Fake: 1.1963493824005127, G Loss: [11.252370834350586, 0.6994757652282715, 0.10552895069122314]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 45, SSIM Loss: 0.12673139572143555\n",
      "Epoch: 13, Batch: 45, D Loss Real: 0.1436317414045334, D Loss Fake: 1.0249000787734985, G Loss: [13.398448944091797, 0.7532638311386108, 0.12645184993743896]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 46, SSIM Loss: 0.11170923709869385\n",
      "Epoch: 13, Batch: 46, D Loss Real: 0.2271956503391266, D Loss Fake: 1.0909550189971924, G Loss: [11.89640998840332, 0.7122661471366882, 0.11184144020080566]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 47, SSIM Loss: 0.1285896897315979\n",
      "Epoch: 13, Batch: 47, D Loss Real: 0.1159447580575943, D Loss Fake: 1.1767915487289429, G Loss: [13.516923904418945, 0.7124454379081726, 0.12804478406906128]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 13, Batch: 48, SSIM Loss: 0.11098122596740723\n",
      "Epoch: 13, Batch: 48, D Loss Real: 0.1371535360813141, D Loss Fake: 1.0598647594451904, G Loss: [11.870318412780762, 0.7683334946632385, 0.11101984977722168]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 13, Batch: 49, SSIM Loss: 0.11412060260772705\n",
      "Epoch: 13, Batch: 49, D Loss Real: 0.19418570399284363, D Loss Fake: 1.081288456916809, G Loss: [12.176470756530762, 0.7457069754600525, 0.11430764198303223]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 50, SSIM Loss: 0.11400675773620605\n",
      "Epoch: 13, Batch: 50, D Loss Real: 0.21453087031841278, D Loss Fake: 1.1861790418624878, G Loss: [12.052350997924805, 0.7244220972061157, 0.11327928304672241]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 51, SSIM Loss: 0.11420595645904541\n",
      "Epoch: 13, Batch: 51, D Loss Real: 0.22486595809459686, D Loss Fake: 1.066124677658081, G Loss: [12.14558219909668, 0.73507159948349, 0.11410510540008545]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 52, SSIM Loss: 0.11778450012207031\n",
      "Epoch: 13, Batch: 52, D Loss Real: 0.23796197772026062, D Loss Fake: 1.0645909309387207, G Loss: [12.48576545715332, 0.711320698261261, 0.11774444580078125]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 53, SSIM Loss: 0.11441099643707275\n",
      "Epoch: 13, Batch: 53, D Loss Real: 0.1657685786485672, D Loss Fake: 1.2244166135787964, G Loss: [12.140435218811035, 0.6886301040649414, 0.11451804637908936]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 54, SSIM Loss: 0.11968928575515747\n",
      "Epoch: 13, Batch: 54, D Loss Real: 0.14405886828899384, D Loss Fake: 1.1472545862197876, G Loss: [12.728199005126953, 0.721224308013916, 0.12006974220275879]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 55, SSIM Loss: 0.10335636138916016\n",
      "Epoch: 13, Batch: 55, D Loss Real: 0.23782497644424438, D Loss Fake: 1.026832103729248, G Loss: [11.086087226867676, 0.7564828991889954, 0.10329604148864746]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 56, SSIM Loss: 0.11445748805999756\n",
      "Epoch: 13, Batch: 56, D Loss Real: 0.15932589769363403, D Loss Fake: 1.0436068773269653, G Loss: [12.159029006958008, 0.7299991846084595, 0.11429029703140259]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 57, SSIM Loss: 0.126004159450531\n",
      "Epoch: 13, Batch: 57, D Loss Real: 0.12229740619659424, D Loss Fake: 1.389876127243042, G Loss: [13.36509895324707, 0.7558668851852417, 0.1260923147201538]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 58, SSIM Loss: 0.12266111373901367\n",
      "Epoch: 13, Batch: 58, D Loss Real: 0.24124443531036377, D Loss Fake: 1.0344643592834473, G Loss: [13.023720741271973, 0.7502070069313049, 0.12273514270782471]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 59, SSIM Loss: 0.11207139492034912\n",
      "Epoch: 13, Batch: 59, D Loss Real: 0.3042480945587158, D Loss Fake: 1.1024954319000244, G Loss: [11.887494087219238, 0.6766597032546997, 0.11210834980010986]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 60, SSIM Loss: 0.12406188249588013\n",
      "Epoch: 13, Batch: 60, D Loss Real: 0.22161635756492615, D Loss Fake: 1.1870548725128174, G Loss: [13.034490585327148, 0.6416890025138855, 0.1239280104637146]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 61, SSIM Loss: 0.11028826236724854\n",
      "Epoch: 13, Batch: 61, D Loss Real: 0.22970768809318542, D Loss Fake: 1.0909671783447266, G Loss: [11.73531723022461, 0.703510046005249, 0.11031806468963623]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 13, Batch: 62, SSIM Loss: 0.1161453127861023\n",
      "Epoch: 13, Batch: 62, D Loss Real: 0.1681586354970932, D Loss Fake: 1.1381428241729736, G Loss: [12.357612609863281, 0.7016141414642334, 0.11655998229980469]\n",
      "1/1 [==============================] - 0s 153ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:30:20.072885: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:30:21.558999: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Batch: 1, SSIM Loss: 0.10740309953689575\n",
      "Epoch: 14, Batch: 1, D Loss Real: 0.19346055388450623, D Loss Fake: 1.0731728076934814, G Loss: [11.469250679016113, 0.7307407855987549, 0.10738509893417358]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 14, Batch: 2, SSIM Loss: 0.10740888118743896\n",
      "Epoch: 14, Batch: 2, D Loss Real: 0.2153315395116806, D Loss Fake: 1.0497795343399048, G Loss: [11.452024459838867, 0.7315863370895386, 0.1072043776512146]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 14, Batch: 3, SSIM Loss: 0.11983352899551392\n",
      "Epoch: 14, Batch: 3, D Loss Real: 0.160287007689476, D Loss Fake: 1.1537977457046509, G Loss: [12.735713958740234, 0.7396889925003052, 0.1199602484703064]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 4, SSIM Loss: 0.11790013313293457\n",
      "Epoch: 14, Batch: 4, D Loss Real: 0.21252752840518951, D Loss Fake: 1.073736310005188, G Loss: [12.505719184875488, 0.7345466017723083, 0.11771172285079956]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 14, Batch: 5, SSIM Loss: 0.11001211404800415\n",
      "Epoch: 14, Batch: 5, D Loss Real: 0.2377244085073471, D Loss Fake: 1.2028064727783203, G Loss: [11.720775604248047, 0.6968196630477905, 0.11023956537246704]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 14, Batch: 6, SSIM Loss: 0.11281371116638184\n",
      "Epoch: 14, Batch: 6, D Loss Real: 0.203505739569664, D Loss Fake: 1.131131887435913, G Loss: [11.993562698364258, 0.7110710144042969, 0.11282491683959961]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 7, SSIM Loss: 0.11353170871734619\n",
      "Epoch: 14, Batch: 7, D Loss Real: 0.18736207485198975, D Loss Fake: 1.2054848670959473, G Loss: [12.083452224731445, 0.7264549732208252, 0.11356997489929199]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 8, SSIM Loss: 0.10837972164154053\n",
      "Epoch: 14, Batch: 8, D Loss Real: 0.2699376940727234, D Loss Fake: 1.1098464727401733, G Loss: [11.528864860534668, 0.6829535961151123, 0.10845911502838135]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 9, SSIM Loss: 0.11602246761322021\n",
      "Epoch: 14, Batch: 9, D Loss Real: 0.18670772016048431, D Loss Fake: 1.1284162998199463, G Loss: [12.278182029724121, 0.67463618516922, 0.11603546142578125]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 10, SSIM Loss: 0.10772120952606201\n",
      "Epoch: 14, Batch: 10, D Loss Real: 0.14302153885364532, D Loss Fake: 1.264148235321045, G Loss: [11.51669979095459, 0.7159087061882019, 0.10800790786743164]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 11, SSIM Loss: 0.11127161979675293\n",
      "Epoch: 14, Batch: 11, D Loss Real: 0.2496887743473053, D Loss Fake: 1.0950772762298584, G Loss: [11.868728637695312, 0.6967856884002686, 0.11171942949295044]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 12, SSIM Loss: 0.11088615655899048\n",
      "Epoch: 14, Batch: 12, D Loss Real: 0.22020313143730164, D Loss Fake: 1.1846351623535156, G Loss: [11.753682136535645, 0.6627782583236694, 0.11090904474258423]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 14, Batch: 13, SSIM Loss: 0.11885243654251099\n",
      "Epoch: 14, Batch: 13, D Loss Real: 0.17730525135993958, D Loss Fake: 1.1286420822143555, G Loss: [12.569334030151367, 0.7028481364250183, 0.11866486072540283]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 14, Batch: 14, SSIM Loss: 0.11881685256958008\n",
      "Epoch: 14, Batch: 14, D Loss Real: 0.19267067313194275, D Loss Fake: 1.1844817399978638, G Loss: [12.619216918945312, 0.6998858451843262, 0.11919331550598145]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 15, SSIM Loss: 0.1179322600364685\n",
      "Epoch: 14, Batch: 15, D Loss Real: 0.2473440021276474, D Loss Fake: 1.1676201820373535, G Loss: [12.488937377929688, 0.670242428779602, 0.11818695068359375]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 16, SSIM Loss: 0.11283868551254272\n",
      "Epoch: 14, Batch: 16, D Loss Real: 0.2734684944152832, D Loss Fake: 1.0910656452178955, G Loss: [12.006109237670898, 0.6943633556365967, 0.11311745643615723]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 17, SSIM Loss: 0.11575525999069214\n",
      "Epoch: 14, Batch: 17, D Loss Real: 0.18609736859798431, D Loss Fake: 1.097690224647522, G Loss: [12.260894775390625, 0.6969143152236938, 0.11563980579376221]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 18, SSIM Loss: 0.1102563738822937\n",
      "Epoch: 14, Batch: 18, D Loss Real: 0.14378610253334045, D Loss Fake: 1.1674240827560425, G Loss: [11.745363235473633, 0.7287265658378601, 0.11016637086868286]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 19, SSIM Loss: 0.11572182178497314\n",
      "Epoch: 14, Batch: 19, D Loss Real: 0.13606451451778412, D Loss Fake: 1.1027790307998657, G Loss: [12.309673309326172, 0.754871129989624, 0.1155480146408081]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 20, SSIM Loss: 0.1160573959350586\n",
      "Epoch: 14, Batch: 20, D Loss Real: 0.1868617981672287, D Loss Fake: 1.068756103515625, G Loss: [12.345425605773926, 0.7414445877075195, 0.11603981256484985]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 21, SSIM Loss: 0.11088532209396362\n",
      "Epoch: 14, Batch: 21, D Loss Real: 0.18856994807720184, D Loss Fake: 1.0500950813293457, G Loss: [11.843514442443848, 0.7543804049491882, 0.11089134216308594]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 14, Batch: 22, SSIM Loss: 0.10654312372207642\n",
      "Epoch: 14, Batch: 22, D Loss Real: 0.1512884497642517, D Loss Fake: 1.1727662086486816, G Loss: [11.378447532653809, 0.7414138913154602, 0.10637032985687256]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 23, SSIM Loss: 0.12092262506484985\n",
      "Epoch: 14, Batch: 23, D Loss Real: 0.1980419158935547, D Loss Fake: 1.100610375404358, G Loss: [12.931546211242676, 0.7251108884811401, 0.12206435203552246]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 24, SSIM Loss: 0.12165182828903198\n",
      "Epoch: 14, Batch: 24, D Loss Real: 0.22821617126464844, D Loss Fake: 1.0817219018936157, G Loss: [12.896719932556152, 0.7195861339569092, 0.12177133560180664]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 25, SSIM Loss: 0.11131668090820312\n",
      "Epoch: 14, Batch: 25, D Loss Real: 0.16233110427856445, D Loss Fake: 1.016879677772522, G Loss: [11.892827987670898, 0.7537684440612793, 0.11139059066772461]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 26, SSIM Loss: 0.115273118019104\n",
      "Epoch: 14, Batch: 26, D Loss Real: 0.1282707154750824, D Loss Fake: 1.120671272277832, G Loss: [12.26673698425293, 0.739628255367279, 0.11527109146118164]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 27, SSIM Loss: 0.10810476541519165\n",
      "Epoch: 14, Batch: 27, D Loss Real: 0.14120621979236603, D Loss Fake: 1.0743701457977295, G Loss: [11.571359634399414, 0.7490270137786865, 0.1082233190536499]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 28, SSIM Loss: 0.10689955949783325\n",
      "Epoch: 14, Batch: 28, D Loss Real: 0.186629056930542, D Loss Fake: 1.1598529815673828, G Loss: [11.433145523071289, 0.751915693283081, 0.10681229829788208]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 29, SSIM Loss: 0.11909180879592896\n",
      "Epoch: 14, Batch: 29, D Loss Real: 0.19806723296642303, D Loss Fake: 1.041276454925537, G Loss: [12.647870063781738, 0.7424020767211914, 0.11905467510223389]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 30, SSIM Loss: 0.11759233474731445\n",
      "Epoch: 14, Batch: 30, D Loss Real: 0.13387484848499298, D Loss Fake: 1.0560214519500732, G Loss: [12.496561050415039, 0.7523365616798401, 0.11744225025177002]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 14, Batch: 31, SSIM Loss: 0.1115460991859436\n",
      "Epoch: 14, Batch: 31, D Loss Real: 0.18701575696468353, D Loss Fake: 1.1955798864364624, G Loss: [11.884197235107422, 0.7041419148445129, 0.11180055141448975]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 32, SSIM Loss: 0.11390495300292969\n",
      "Epoch: 14, Batch: 32, D Loss Real: 0.18805289268493652, D Loss Fake: 1.0426727533340454, G Loss: [12.105390548706055, 0.7352026700973511, 0.11370187997817993]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 33, SSIM Loss: 0.11423373222351074\n",
      "Epoch: 14, Batch: 33, D Loss Real: 0.20931179821491241, D Loss Fake: 1.1015483140945435, G Loss: [12.127974510192871, 0.7099291086196899, 0.11418044567108154]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 34, SSIM Loss: 0.11280941963195801\n",
      "Epoch: 14, Batch: 34, D Loss Real: 0.17804014682769775, D Loss Fake: 1.1718846559524536, G Loss: [12.006561279296875, 0.742581844329834, 0.11263978481292725]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 35, SSIM Loss: 0.10000789165496826\n",
      "Epoch: 14, Batch: 35, D Loss Real: 0.2706981301307678, D Loss Fake: 1.1001938581466675, G Loss: [10.764467239379883, 0.7116067409515381, 0.10052859783172607]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 36, SSIM Loss: 0.1195753812789917\n",
      "Epoch: 14, Batch: 36, D Loss Real: 0.243061825633049, D Loss Fake: 1.3296395540237427, G Loss: [12.626822471618652, 0.6737310290336609, 0.11953091621398926]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 37, SSIM Loss: 0.10998356342315674\n",
      "Epoch: 14, Batch: 37, D Loss Real: 0.2629954516887665, D Loss Fake: 1.0902752876281738, G Loss: [11.690248489379883, 0.6924765706062317, 0.10997772216796875]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 38, SSIM Loss: 0.12783092260360718\n",
      "Epoch: 14, Batch: 38, D Loss Real: 0.22685649991035461, D Loss Fake: 1.1544544696807861, G Loss: [13.468343734741211, 0.6633949279785156, 0.12804949283599854]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 39, SSIM Loss: 0.11470258235931396\n",
      "Epoch: 14, Batch: 39, D Loss Real: 0.25001782178878784, D Loss Fake: 1.1095012426376343, G Loss: [12.191041946411133, 0.6719434261322021, 0.11519098281860352]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 40, SSIM Loss: 0.11580908298492432\n",
      "Epoch: 14, Batch: 40, D Loss Real: 0.1720854640007019, D Loss Fake: 1.070664644241333, G Loss: [12.278135299682617, 0.7044207453727722, 0.11573714017868042]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 41, SSIM Loss: 0.1034015417098999\n",
      "Epoch: 14, Batch: 41, D Loss Real: 0.14438915252685547, D Loss Fake: 1.0895192623138428, G Loss: [11.111555099487305, 0.7696427702903748, 0.10341912508010864]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 42, SSIM Loss: 0.11611270904541016\n",
      "Epoch: 14, Batch: 42, D Loss Real: 0.13368116319179535, D Loss Fake: 1.052045226097107, G Loss: [12.436558723449707, 0.7545667290687561, 0.11681991815567017]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 43, SSIM Loss: 0.11061877012252808\n",
      "Epoch: 14, Batch: 43, D Loss Real: 0.13756825029850006, D Loss Fake: 0.9706094861030579, G Loss: [11.837878227233887, 0.7982161045074463, 0.1103966236114502]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 44, SSIM Loss: 0.10514843463897705\n",
      "Epoch: 14, Batch: 44, D Loss Real: 0.1661382019519806, D Loss Fake: 1.3658173084259033, G Loss: [11.267078399658203, 0.7492427825927734, 0.1051783561706543]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 45, SSIM Loss: 0.12508082389831543\n",
      "Epoch: 14, Batch: 45, D Loss Real: 0.21625061333179474, D Loss Fake: 1.1006391048431396, G Loss: [13.307839393615723, 0.777667224407196, 0.12530171871185303]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 46, SSIM Loss: 0.11097383499145508\n",
      "Epoch: 14, Batch: 46, D Loss Real: 0.3199930787086487, D Loss Fake: 1.0871360301971436, G Loss: [11.779388427734375, 0.6974306106567383, 0.11081957817077637]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 47, SSIM Loss: 0.12724697589874268\n",
      "Epoch: 14, Batch: 47, D Loss Real: 0.18891310691833496, D Loss Fake: 1.1875394582748413, G Loss: [13.322067260742188, 0.6434918642044067, 0.1267857551574707]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 48, SSIM Loss: 0.11064267158508301\n",
      "Epoch: 14, Batch: 48, D Loss Real: 0.1598123013973236, D Loss Fake: 1.1234943866729736, G Loss: [11.792886734008789, 0.6956346035003662, 0.11097252368927002]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 49, SSIM Loss: 0.11377853155136108\n",
      "Epoch: 14, Batch: 49, D Loss Real: 0.1683483123779297, D Loss Fake: 1.1572139263153076, G Loss: [12.077775001525879, 0.7074609994888306, 0.11370313167572021]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 50, SSIM Loss: 0.11359179019927979\n",
      "Epoch: 14, Batch: 50, D Loss Real: 0.2020396590232849, D Loss Fake: 1.1603331565856934, G Loss: [12.112507820129395, 0.7101396322250366, 0.11402368545532227]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 51, SSIM Loss: 0.11353003978729248\n",
      "Epoch: 14, Batch: 51, D Loss Real: 0.19862377643585205, D Loss Fake: 1.0401673316955566, G Loss: [12.088798522949219, 0.7263650894165039, 0.11362433433532715]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 52, SSIM Loss: 0.11765038967132568\n",
      "Epoch: 14, Batch: 52, D Loss Real: 0.2055826336145401, D Loss Fake: 1.048567533493042, G Loss: [12.497206687927246, 0.7218564748764038, 0.11775350570678711]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 53, SSIM Loss: 0.11439251899719238\n",
      "Epoch: 14, Batch: 53, D Loss Real: 0.16749736666679382, D Loss Fake: 1.1675604581832886, G Loss: [12.109485626220703, 0.7063124775886536, 0.11403173208236694]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 54, SSIM Loss: 0.1199834942817688\n",
      "Epoch: 14, Batch: 54, D Loss Real: 0.14096838235855103, D Loss Fake: 1.1669596433639526, G Loss: [12.730335235595703, 0.7293925285339355, 0.1200094223022461]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 55, SSIM Loss: 0.10287761688232422\n",
      "Epoch: 14, Batch: 55, D Loss Real: 0.23552775382995605, D Loss Fake: 1.0190962553024292, G Loss: [11.037599563598633, 0.7523226737976074, 0.10285276174545288]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 56, SSIM Loss: 0.11318713426589966\n",
      "Epoch: 14, Batch: 56, D Loss Real: 0.16262827813625336, D Loss Fake: 1.0500380992889404, G Loss: [12.019915580749512, 0.732666552066803, 0.11287248134613037]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 57, SSIM Loss: 0.12442731857299805\n",
      "Epoch: 14, Batch: 57, D Loss Real: 0.11745444685220718, D Loss Fake: 1.2675395011901855, G Loss: [13.231231689453125, 0.7489341497421265, 0.12482297420501709]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 58, SSIM Loss: 0.12243551015853882\n",
      "Epoch: 14, Batch: 58, D Loss Real: 0.19274646043777466, D Loss Fake: 1.0186222791671753, G Loss: [12.98328971862793, 0.7583292126655579, 0.12224960327148438]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 59, SSIM Loss: 0.11126136779785156\n",
      "Epoch: 14, Batch: 59, D Loss Real: 0.2488798052072525, D Loss Fake: 1.1670879125595093, G Loss: [11.852660179138184, 0.7049461603164673, 0.11147713661193848]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 60, SSIM Loss: 0.12304508686065674\n",
      "Epoch: 14, Batch: 60, D Loss Real: 0.2033257782459259, D Loss Fake: 1.1423721313476562, G Loss: [12.87876033782959, 0.6740896701812744, 0.12204670906066895]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 61, SSIM Loss: 0.10975492000579834\n",
      "Epoch: 14, Batch: 61, D Loss Real: 0.2260303795337677, D Loss Fake: 1.059617280960083, G Loss: [11.667757034301758, 0.7104322910308838, 0.10957324504852295]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 14, Batch: 62, SSIM Loss: 0.11517715454101562\n",
      "Epoch: 14, Batch: 62, D Loss Real: 0.14356689155101776, D Loss Fake: 1.1578483581542969, G Loss: [12.237594604492188, 0.7033810615539551, 0.1153421401977539]\n",
      "1/1 [==============================] - 0s 153ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:31:43.411314: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:31:44.896200: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Batch: 1, SSIM Loss: 0.10671329498291016\n",
      "Epoch: 15, Batch: 1, D Loss Real: 0.17176350951194763, D Loss Fake: 1.04249906539917, G Loss: [11.389480590820312, 0.7433464527130127, 0.10646134614944458]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 2, SSIM Loss: 0.10658496618270874\n",
      "Epoch: 15, Batch: 2, D Loss Real: 0.1788613200187683, D Loss Fake: 1.0214276313781738, G Loss: [11.44377613067627, 0.7498027086257935, 0.10693973302841187]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 15, Batch: 3, SSIM Loss: 0.11953425407409668\n",
      "Epoch: 15, Batch: 3, D Loss Real: 0.13188743591308594, D Loss Fake: 1.2003543376922607, G Loss: [12.717103004455566, 0.7646786570549011, 0.11952424049377441]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 4, SSIM Loss: 0.11633431911468506\n",
      "Epoch: 15, Batch: 4, D Loss Real: 0.22174647450447083, D Loss Fake: 1.0328562259674072, G Loss: [12.39992904663086, 0.7499279975891113, 0.11650002002716064]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 5, SSIM Loss: 0.1097249984741211\n",
      "Epoch: 15, Batch: 5, D Loss Real: 0.24564290046691895, D Loss Fake: 1.1420211791992188, G Loss: [11.647705078125, 0.6917404532432556, 0.10955965518951416]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 6, SSIM Loss: 0.1128532886505127\n",
      "Epoch: 15, Batch: 6, D Loss Real: 0.1894240379333496, D Loss Fake: 1.095827579498291, G Loss: [12.00002384185791, 0.7168113589286804, 0.11283212900161743]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 15, Batch: 7, SSIM Loss: 0.11304306983947754\n",
      "Epoch: 15, Batch: 7, D Loss Real: 0.16920918226242065, D Loss Fake: 1.1766066551208496, G Loss: [12.043632507324219, 0.7490881681442261, 0.11294543743133545]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 8, SSIM Loss: 0.10815870761871338\n",
      "Epoch: 15, Batch: 8, D Loss Real: 0.3256836533546448, D Loss Fake: 1.1175087690353394, G Loss: [11.508474349975586, 0.7021285891532898, 0.1080634593963623]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 15, Batch: 9, SSIM Loss: 0.11522817611694336\n",
      "Epoch: 15, Batch: 9, D Loss Real: 0.22714507579803467, D Loss Fake: 1.115773320198059, G Loss: [12.1716890335083, 0.683739423751831, 0.11487948894500732]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 10, SSIM Loss: 0.1068008542060852\n",
      "Epoch: 15, Batch: 10, D Loss Real: 0.15769898891448975, D Loss Fake: 1.221596598625183, G Loss: [11.38724422454834, 0.6887239217758179, 0.10698521137237549]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 11, SSIM Loss: 0.1119840145111084\n",
      "Epoch: 15, Batch: 11, D Loss Real: 0.20947006344795227, D Loss Fake: 1.1566030979156494, G Loss: [11.9119291305542, 0.7216689586639404, 0.11190259456634521]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 12, SSIM Loss: 0.11004596948623657\n",
      "Epoch: 15, Batch: 12, D Loss Real: 0.29231297969818115, D Loss Fake: 1.2190070152282715, G Loss: [11.707008361816406, 0.6646760106086731, 0.11042332649230957]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 13, SSIM Loss: 0.11881345510482788\n",
      "Epoch: 15, Batch: 13, D Loss Real: 0.2799922227859497, D Loss Fake: 1.0999078750610352, G Loss: [12.517876625061035, 0.6712804436683655, 0.11846596002578735]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 15, Batch: 14, SSIM Loss: 0.11800265312194824\n",
      "Epoch: 15, Batch: 14, D Loss Real: 0.20617420971393585, D Loss Fake: 1.2798819541931152, G Loss: [12.472824096679688, 0.6691678762435913, 0.11803656816482544]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 15, SSIM Loss: 0.11696648597717285\n",
      "Epoch: 15, Batch: 15, D Loss Real: 0.2472991645336151, D Loss Fake: 1.12751305103302, G Loss: [12.418855667114258, 0.6691769361495972, 0.1174967885017395]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 16, SSIM Loss: 0.11360442638397217\n",
      "Epoch: 15, Batch: 16, D Loss Real: 0.25627371668815613, D Loss Fake: 1.0707298517227173, G Loss: [12.01248836517334, 0.6918553709983826, 0.11320632696151733]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 17, SSIM Loss: 0.1149148941040039\n",
      "Epoch: 15, Batch: 17, D Loss Real: 0.189487487077713, D Loss Fake: 1.10791015625, G Loss: [12.247270584106445, 0.6864544153213501, 0.11560815572738647]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 18, SSIM Loss: 0.10869401693344116\n",
      "Epoch: 15, Batch: 18, D Loss Real: 0.15353921055793762, D Loss Fake: 1.194584608078003, G Loss: [11.579703330993652, 0.7203811407089233, 0.10859322547912598]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 19, SSIM Loss: 0.11492478847503662\n",
      "Epoch: 15, Batch: 19, D Loss Real: 0.13605722784996033, D Loss Fake: 1.081805944442749, G Loss: [12.20414924621582, 0.7367876172065735, 0.11467361450195312]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 20, SSIM Loss: 0.11571526527404785\n",
      "Epoch: 15, Batch: 20, D Loss Real: 0.1693899929523468, D Loss Fake: 1.0583266019821167, G Loss: [12.325325012207031, 0.7462226152420044, 0.11579102277755737]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 21, SSIM Loss: 0.110420823097229\n",
      "Epoch: 15, Batch: 21, D Loss Real: 0.16782842576503754, D Loss Fake: 1.0439245700836182, G Loss: [11.801880836486816, 0.7556256055831909, 0.11046254634857178]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 22, SSIM Loss: 0.10551559925079346\n",
      "Epoch: 15, Batch: 22, D Loss Real: 0.13930580019950867, D Loss Fake: 1.1446716785430908, G Loss: [11.30233097076416, 0.746390700340271, 0.10555940866470337]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 23, SSIM Loss: 0.12063688039779663\n",
      "Epoch: 15, Batch: 23, D Loss Real: 0.18455329537391663, D Loss Fake: 1.1038577556610107, G Loss: [12.781982421875, 0.7393527626991272, 0.12042629718780518]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 24, SSIM Loss: 0.12151527404785156\n",
      "Epoch: 15, Batch: 24, D Loss Real: 0.22505643963813782, D Loss Fake: 1.056692123413086, G Loss: [12.873376846313477, 0.7155071496963501, 0.12157869338989258]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 25, SSIM Loss: 0.11064642667770386\n",
      "Epoch: 15, Batch: 25, D Loss Real: 0.16502556204795837, D Loss Fake: 1.0410563945770264, G Loss: [11.808684349060059, 0.7394454479217529, 0.11069238185882568]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 26, SSIM Loss: 0.1143791675567627\n",
      "Epoch: 15, Batch: 26, D Loss Real: 0.134464293718338, D Loss Fake: 1.0975323915481567, G Loss: [12.186399459838867, 0.7276445031166077, 0.11458754539489746]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 27, SSIM Loss: 0.10740995407104492\n",
      "Epoch: 15, Batch: 27, D Loss Real: 0.12596015632152557, D Loss Fake: 1.140630841255188, G Loss: [11.488627433776855, 0.7522150874137878, 0.10736411809921265]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 28, SSIM Loss: 0.10641860961914062\n",
      "Epoch: 15, Batch: 28, D Loss Real: 0.2034720778465271, D Loss Fake: 1.051696538925171, G Loss: [11.431191444396973, 0.7366514205932617, 0.10694539546966553]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 29, SSIM Loss: 0.11895906925201416\n",
      "Epoch: 15, Batch: 29, D Loss Real: 0.1619437336921692, D Loss Fake: 1.0589382648468018, G Loss: [12.645590782165527, 0.7436344623565674, 0.11901956796646118]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 30, SSIM Loss: 0.11760079860687256\n",
      "Epoch: 15, Batch: 30, D Loss Real: 0.11114579439163208, D Loss Fake: 1.0814491510391235, G Loss: [12.534811019897461, 0.7689605355262756, 0.11765849590301514]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 31, SSIM Loss: 0.11063826084136963\n",
      "Epoch: 15, Batch: 31, D Loss Real: 0.19885167479515076, D Loss Fake: 1.1333369016647339, G Loss: [11.794882774353027, 0.7365883588790894, 0.11058294773101807]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 32, SSIM Loss: 0.11314290761947632\n",
      "Epoch: 15, Batch: 32, D Loss Real: 0.182795912027359, D Loss Fake: 1.0306365489959717, G Loss: [12.043289184570312, 0.7441563010215759, 0.1129913330078125]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 33, SSIM Loss: 0.11339473724365234\n",
      "Epoch: 15, Batch: 33, D Loss Real: 0.1984413117170334, D Loss Fake: 1.106109380722046, G Loss: [12.036026954650879, 0.7229816913604736, 0.11313045024871826]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 34, SSIM Loss: 0.11185872554779053\n",
      "Epoch: 15, Batch: 34, D Loss Real: 0.175409734249115, D Loss Fake: 1.164154291152954, G Loss: [11.913164138793945, 0.7392721176147461, 0.11173892021179199]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 35, SSIM Loss: 0.0995895266532898\n",
      "Epoch: 15, Batch: 35, D Loss Real: 0.29968708753585815, D Loss Fake: 1.1626555919647217, G Loss: [10.702606201171875, 0.7246088981628418, 0.09977996349334717]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 36, SSIM Loss: 0.11825627088546753\n",
      "Epoch: 15, Batch: 36, D Loss Real: 0.26973024010658264, D Loss Fake: 1.244399070739746, G Loss: [12.476261138916016, 0.6570528149604797, 0.11819207668304443]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 15, Batch: 37, SSIM Loss: 0.10995185375213623\n",
      "Epoch: 15, Batch: 37, D Loss Real: 0.24224650859832764, D Loss Fake: 1.1110011339187622, G Loss: [11.666885375976562, 0.6714440584182739, 0.10995441675186157]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 38, SSIM Loss: 0.12664413452148438\n",
      "Epoch: 15, Batch: 38, D Loss Real: 0.17514535784721375, D Loss Fake: 1.2134144306182861, G Loss: [13.318462371826172, 0.6871358752250671, 0.12631326913833618]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 39, SSIM Loss: 0.11441624164581299\n",
      "Epoch: 15, Batch: 39, D Loss Real: 0.26267147064208984, D Loss Fake: 1.0867068767547607, G Loss: [12.103792190551758, 0.692804753780365, 0.11410987377166748]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 15, Batch: 40, SSIM Loss: 0.11530452966690063\n",
      "Epoch: 15, Batch: 40, D Loss Real: 0.21536403894424438, D Loss Fake: 1.0793904066085815, G Loss: [12.219233512878418, 0.6847449541091919, 0.11534488201141357]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 41, SSIM Loss: 0.1031121015548706\n",
      "Epoch: 15, Batch: 41, D Loss Real: 0.16931843757629395, D Loss Fake: 1.0675485134124756, G Loss: [11.0210542678833, 0.7243810296058655, 0.10296672582626343]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 42, SSIM Loss: 0.11661076545715332\n",
      "Epoch: 15, Batch: 42, D Loss Real: 0.11384639143943787, D Loss Fake: 1.1918370723724365, G Loss: [12.450163841247559, 0.7448126673698425, 0.11705350875854492]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 43, SSIM Loss: 0.11022520065307617\n",
      "Epoch: 15, Batch: 43, D Loss Real: 0.14875119924545288, D Loss Fake: 0.965232789516449, G Loss: [11.758234977722168, 0.7820520401000977, 0.10976183414459229]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 44, SSIM Loss: 0.10455608367919922\n",
      "Epoch: 15, Batch: 44, D Loss Real: 0.2033519297838211, D Loss Fake: 1.1332870721817017, G Loss: [11.189031600952148, 0.7216565608978271, 0.10467374324798584]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 15, Batch: 45, SSIM Loss: 0.1242828369140625\n",
      "Epoch: 15, Batch: 45, D Loss Real: 0.13314186036586761, D Loss Fake: 1.0320980548858643, G Loss: [13.174222946166992, 0.757610559463501, 0.12416613101959229]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 46, SSIM Loss: 0.11039280891418457\n",
      "Epoch: 15, Batch: 46, D Loss Real: 0.2061021625995636, D Loss Fake: 1.0802010297775269, G Loss: [11.805611610412598, 0.7106598019599915, 0.11094951629638672]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 15, Batch: 47, SSIM Loss: 0.12604856491088867\n",
      "Epoch: 15, Batch: 47, D Loss Real: 0.10145506262779236, D Loss Fake: 1.1747663021087646, G Loss: [13.35729694366455, 0.7262381315231323, 0.1263105869293213]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 15, Batch: 48, SSIM Loss: 0.109405517578125\n",
      "Epoch: 15, Batch: 48, D Loss Real: 0.13030211627483368, D Loss Fake: 1.0442683696746826, G Loss: [11.724615097045898, 0.7870620489120483, 0.10937553644180298]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 49, SSIM Loss: 0.11436474323272705\n",
      "Epoch: 15, Batch: 49, D Loss Real: 0.20938795804977417, D Loss Fake: 1.0566515922546387, G Loss: [12.13863754272461, 0.744554340839386, 0.11394083499908447]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 50, SSIM Loss: 0.11288511753082275\n",
      "Epoch: 15, Batch: 50, D Loss Real: 0.20331062376499176, D Loss Fake: 1.125723123550415, G Loss: [12.005857467651367, 0.7117604613304138, 0.1129409670829773]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 51, SSIM Loss: 0.11296498775482178\n",
      "Epoch: 15, Batch: 51, D Loss Real: 0.16670124232769012, D Loss Fake: 1.0282480716705322, G Loss: [12.037341117858887, 0.7326472401618958, 0.11304694414138794]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 52, SSIM Loss: 0.1180734634399414\n",
      "Epoch: 15, Batch: 52, D Loss Real: 0.16546256840229034, D Loss Fake: 1.0163238048553467, G Loss: [12.553048133850098, 0.7556494474411011, 0.11797398328781128]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 53, SSIM Loss: 0.11403191089630127\n",
      "Epoch: 15, Batch: 53, D Loss Real: 0.14297640323638916, D Loss Fake: 1.162101149559021, G Loss: [12.12842845916748, 0.7427308559417725, 0.1138569712638855]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 54, SSIM Loss: 0.11963927745819092\n",
      "Epoch: 15, Batch: 54, D Loss Real: 0.1311383992433548, D Loss Fake: 1.0973281860351562, G Loss: [12.716757774353027, 0.7663184404373169, 0.11950439214706421]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 55, SSIM Loss: 0.10221683979034424\n",
      "Epoch: 15, Batch: 55, D Loss Real: 0.2223634123802185, D Loss Fake: 1.0195118188858032, G Loss: [11.043535232543945, 0.7684275507926941, 0.10275107622146606]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 15, Batch: 56, SSIM Loss: 0.11231565475463867\n",
      "Epoch: 15, Batch: 56, D Loss Real: 0.15293985605239868, D Loss Fake: 1.0360465049743652, G Loss: [11.97745132446289, 0.7465649247169495, 0.11230885982513428]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 15, Batch: 57, SSIM Loss: 0.12376248836517334\n",
      "Epoch: 15, Batch: 57, D Loss Real: 0.11916894465684891, D Loss Fake: 1.2465791702270508, G Loss: [13.158160209655762, 0.7659016847610474, 0.12392258644104004]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 58, SSIM Loss: 0.1221160888671875\n",
      "Epoch: 15, Batch: 58, D Loss Real: 0.22334671020507812, D Loss Fake: 1.031514286994934, G Loss: [12.925043106079102, 0.7394453287124634, 0.1218559741973877]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 15, Batch: 59, SSIM Loss: 0.11064207553863525\n",
      "Epoch: 15, Batch: 59, D Loss Real: 0.2795979380607605, D Loss Fake: 1.1050646305084229, G Loss: [11.744562149047852, 0.6685645580291748, 0.11075997352600098]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 60, SSIM Loss: 0.12149220705032349\n",
      "Epoch: 15, Batch: 60, D Loss Real: 0.18148714303970337, D Loss Fake: 1.2058075666427612, G Loss: [12.813401222229004, 0.6514670848846436, 0.1216193437576294]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 61, SSIM Loss: 0.1090536117553711\n",
      "Epoch: 15, Batch: 61, D Loss Real: 0.18431441485881805, D Loss Fake: 1.1126022338867188, G Loss: [11.64775562286377, 0.7335612177848816, 0.10914194583892822]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 15, Batch: 62, SSIM Loss: 0.11406606435775757\n",
      "Epoch: 15, Batch: 62, D Loss Real: 0.1532966047525406, D Loss Fake: 1.0949152708053589, G Loss: [12.146467208862305, 0.7216637134552002, 0.11424803733825684]\n",
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:33:06.671937: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:33:08.159093: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Batch: 1, SSIM Loss: 0.10642015933990479\n",
      "Epoch: 16, Batch: 1, D Loss Real: 0.17623627185821533, D Loss Fake: 1.0455102920532227, G Loss: [11.434744834899902, 0.7585278749465942, 0.10676217079162598]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 2, SSIM Loss: 0.10608959197998047\n",
      "Epoch: 16, Batch: 2, D Loss Real: 0.16343890130519867, D Loss Fake: 1.0084450244903564, G Loss: [11.386945724487305, 0.758425235748291, 0.1062852144241333]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 3, SSIM Loss: 0.11928707361221313\n",
      "Epoch: 16, Batch: 3, D Loss Real: 0.12028750777244568, D Loss Fake: 1.1581889390945435, G Loss: [12.706001281738281, 0.7598952651023865, 0.1194610595703125]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 4, SSIM Loss: 0.11576831340789795\n",
      "Epoch: 16, Batch: 4, D Loss Real: 0.2044743448495865, D Loss Fake: 1.0502779483795166, G Loss: [12.318136215209961, 0.7478493452072144, 0.11570286750793457]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 5, SSIM Loss: 0.10886514186859131\n",
      "Epoch: 16, Batch: 5, D Loss Real: 0.2343927025794983, D Loss Fake: 1.1201765537261963, G Loss: [11.601994514465332, 0.7058842182159424, 0.10896110534667969]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 6, SSIM Loss: 0.11219823360443115\n",
      "Epoch: 16, Batch: 6, D Loss Real: 0.18508024513721466, D Loss Fake: 1.0618743896484375, G Loss: [12.00052547454834, 0.7135812044143677, 0.11286944150924683]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 7, SSIM Loss: 0.11256307363510132\n",
      "Epoch: 16, Batch: 7, D Loss Real: 0.1464288979768753, D Loss Fake: 1.2097276449203491, G Loss: [12.00867748260498, 0.7504328489303589, 0.11258244514465332]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 8, SSIM Loss: 0.10839462280273438\n",
      "Epoch: 16, Batch: 8, D Loss Real: 0.3001943826675415, D Loss Fake: 1.0667105913162231, G Loss: [11.511600494384766, 0.7011777758598328, 0.10810422897338867]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 9, SSIM Loss: 0.115104079246521\n",
      "Epoch: 16, Batch: 9, D Loss Real: 0.22727461159229279, D Loss Fake: 1.1032493114471436, G Loss: [12.235600471496582, 0.6843999624252319, 0.11551201343536377]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 10, SSIM Loss: 0.10682648420333862\n",
      "Epoch: 16, Batch: 10, D Loss Real: 0.15047962963581085, D Loss Fake: 1.2024304866790771, G Loss: [11.366242408752441, 0.6964627504348755, 0.10669779777526855]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 11, SSIM Loss: 0.11064708232879639\n",
      "Epoch: 16, Batch: 11, D Loss Real: 0.20023289322853088, D Loss Fake: 1.093956708908081, G Loss: [11.787137985229492, 0.7261136174201965, 0.1106102466583252]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 12, SSIM Loss: 0.10984373092651367\n",
      "Epoch: 16, Batch: 12, D Loss Real: 0.19758331775665283, D Loss Fake: 1.1514173746109009, G Loss: [11.691812515258789, 0.6732136011123657, 0.11018598079681396]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 13, SSIM Loss: 0.11866974830627441\n",
      "Epoch: 16, Batch: 13, D Loss Real: 0.13734698295593262, D Loss Fake: 1.0827672481536865, G Loss: [12.636909484863281, 0.7564939260482788, 0.11880415678024292]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 14, SSIM Loss: 0.11730659008026123\n",
      "Epoch: 16, Batch: 14, D Loss Real: 0.15290626883506775, D Loss Fake: 1.1206624507904053, G Loss: [12.468021392822266, 0.7598452568054199, 0.11708176136016846]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 15, SSIM Loss: 0.11628448963165283\n",
      "Epoch: 16, Batch: 15, D Loss Real: 0.2848149836063385, D Loss Fake: 1.1027100086212158, G Loss: [12.341205596923828, 0.7160115242004395, 0.11625194549560547]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 16, SSIM Loss: 0.11450344324111938\n",
      "Epoch: 16, Batch: 16, D Loss Real: 0.2610480785369873, D Loss Fake: 1.1023286581039429, G Loss: [12.137316703796387, 0.6805413961410522, 0.11456775665283203]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 17, SSIM Loss: 0.11491501331329346\n",
      "Epoch: 16, Batch: 17, D Loss Real: 0.18590456247329712, D Loss Fake: 1.1362282037734985, G Loss: [12.226300239562988, 0.6989637017250061, 0.1152733564376831]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 18, SSIM Loss: 0.10935896635055542\n",
      "Epoch: 16, Batch: 18, D Loss Real: 0.15772216022014618, D Loss Fake: 1.1562871932983398, G Loss: [11.63428783416748, 0.725111722946167, 0.10909175872802734]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 19, SSIM Loss: 0.11524701118469238\n",
      "Epoch: 16, Batch: 19, D Loss Real: 0.1328531801700592, D Loss Fake: 1.0479092597961426, G Loss: [12.275028228759766, 0.7490274310112, 0.11526000499725342]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 20, SSIM Loss: 0.11568021774291992\n",
      "Epoch: 16, Batch: 20, D Loss Real: 0.16081179678440094, D Loss Fake: 1.0240836143493652, G Loss: [12.326674461364746, 0.7541224956512451, 0.11572551727294922]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 21, SSIM Loss: 0.11083972454071045\n",
      "Epoch: 16, Batch: 21, D Loss Real: 0.1383732706308365, D Loss Fake: 1.0335261821746826, G Loss: [11.835371017456055, 0.7742385268211365, 0.11061131954193115]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 22, SSIM Loss: 0.10467344522476196\n",
      "Epoch: 16, Batch: 22, D Loss Real: 0.1274530440568924, D Loss Fake: 1.1069718599319458, G Loss: [11.249652862548828, 0.7627642750740051, 0.10486888885498047]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 23, SSIM Loss: 0.12126213312149048\n",
      "Epoch: 16, Batch: 23, D Loss Real: 0.18514758348464966, D Loss Fake: 1.0666098594665527, G Loss: [12.80054759979248, 0.7479164004325867, 0.12052631378173828]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 24, SSIM Loss: 0.1229180097579956\n",
      "Epoch: 16, Batch: 24, D Loss Real: 0.2169555127620697, D Loss Fake: 1.0790399312973022, G Loss: [12.995993614196777, 0.7190760970115662, 0.12276917695999146]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 25, SSIM Loss: 0.1113629937171936\n",
      "Epoch: 16, Batch: 25, D Loss Real: 0.1398504674434662, D Loss Fake: 1.028555154800415, G Loss: [11.873143196105957, 0.7588979005813599, 0.11114245653152466]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 26, SSIM Loss: 0.113991379737854\n",
      "Epoch: 16, Batch: 26, D Loss Real: 0.1098862886428833, D Loss Fake: 1.0486148595809937, G Loss: [12.147272109985352, 0.7434964776039124, 0.11403775215148926]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 27, SSIM Loss: 0.1080101728439331\n",
      "Epoch: 16, Batch: 27, D Loss Real: 0.08811559528112411, D Loss Fake: 1.0662184953689575, G Loss: [11.588162422180176, 0.7802370190620422, 0.10807925462722778]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 28, SSIM Loss: 0.10683023929595947\n",
      "Epoch: 16, Batch: 28, D Loss Real: 0.1393415331840515, D Loss Fake: 1.0272016525268555, G Loss: [11.474296569824219, 0.7842334508895874, 0.10690063238143921]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 29, SSIM Loss: 0.11981403827667236\n",
      "Epoch: 16, Batch: 29, D Loss Real: 0.15915155410766602, D Loss Fake: 1.023087501525879, G Loss: [12.779645919799805, 0.7673844695091248, 0.12012261152267456]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 30, SSIM Loss: 0.11704325675964355\n",
      "Epoch: 16, Batch: 30, D Loss Real: 0.09977304190397263, D Loss Fake: 1.0429056882858276, G Loss: [12.531725883483887, 0.7813979983329773, 0.11750328540802002]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 31, SSIM Loss: 0.11073583364486694\n",
      "Epoch: 16, Batch: 31, D Loss Real: 0.1614699810743332, D Loss Fake: 1.1284343004226685, G Loss: [11.830409049987793, 0.7637812495231628, 0.11066627502441406]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 32, SSIM Loss: 0.11234939098358154\n",
      "Epoch: 16, Batch: 32, D Loss Real: 0.1717447191476822, D Loss Fake: 0.9916062355041504, G Loss: [12.034704208374023, 0.7686695456504822, 0.11266034841537476]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 33, SSIM Loss: 0.11384779214859009\n",
      "Epoch: 16, Batch: 33, D Loss Real: 0.20955654978752136, D Loss Fake: 1.080580472946167, G Loss: [12.146349906921387, 0.735100507736206, 0.1141124963760376]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 34, SSIM Loss: 0.11099022626876831\n",
      "Epoch: 16, Batch: 34, D Loss Real: 0.14890816807746887, D Loss Fake: 1.112170934677124, G Loss: [11.844832420349121, 0.7464767694473267, 0.11098355054855347]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 35, SSIM Loss: 0.10023683309555054\n",
      "Epoch: 16, Batch: 35, D Loss Real: 0.23669324815273285, D Loss Fake: 1.077910304069519, G Loss: [10.751020431518555, 0.7152190208435059, 0.1003580093383789]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 36, SSIM Loss: 0.11720156669616699\n",
      "Epoch: 16, Batch: 36, D Loss Real: 0.1548963040113449, D Loss Fake: 1.5640844106674194, G Loss: [12.479329109191895, 0.7686141133308411, 0.11710715293884277]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 37, SSIM Loss: 0.10978102684020996\n",
      "Epoch: 16, Batch: 37, D Loss Real: 0.3537030816078186, D Loss Fake: 1.0607856512069702, G Loss: [11.711994171142578, 0.7253558039665222, 0.10986638069152832]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 38, SSIM Loss: 0.12594270706176758\n",
      "Epoch: 16, Batch: 38, D Loss Real: 0.3343809247016907, D Loss Fake: 1.1341629028320312, G Loss: [13.269269943237305, 0.6487676501274109, 0.12620502710342407]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 16, Batch: 39, SSIM Loss: 0.1152578592300415\n",
      "Epoch: 16, Batch: 39, D Loss Real: 0.33653104305267334, D Loss Fake: 1.196447730064392, G Loss: [12.123516082763672, 0.6157665848731995, 0.11507749557495117]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 40, SSIM Loss: 0.11584901809692383\n",
      "Epoch: 16, Batch: 40, D Loss Real: 0.29855436086654663, D Loss Fake: 1.2128252983093262, G Loss: [12.241087913513184, 0.6117509603500366, 0.11629337072372437]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 41, SSIM Loss: 0.10298651456832886\n",
      "Epoch: 16, Batch: 41, D Loss Real: 0.31311658024787903, D Loss Fake: 1.2003631591796875, G Loss: [10.907724380493164, 0.6210231781005859, 0.1028670072555542]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 42, SSIM Loss: 0.11704683303833008\n",
      "Epoch: 16, Batch: 42, D Loss Real: 0.27289605140686035, D Loss Fake: 1.208917260169983, G Loss: [12.396040916442871, 0.6338391900062561, 0.1176220178604126]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 43, SSIM Loss: 0.11207574605941772\n",
      "Epoch: 16, Batch: 43, D Loss Real: 0.2328280508518219, D Loss Fake: 1.1333575248718262, G Loss: [11.886310577392578, 0.6865137219429016, 0.11199796199798584]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 44, SSIM Loss: 0.10712158679962158\n",
      "Epoch: 16, Batch: 44, D Loss Real: 0.24469110369682312, D Loss Fake: 1.157417893409729, G Loss: [11.394648551940918, 0.6740257143974304, 0.10720622539520264]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 45, SSIM Loss: 0.12459564208984375\n",
      "Epoch: 16, Batch: 45, D Loss Real: 0.1527285873889923, D Loss Fake: 1.078623652458191, G Loss: [13.193599700927734, 0.7311984300613403, 0.12462401390075684]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 46, SSIM Loss: 0.11114418506622314\n",
      "Epoch: 16, Batch: 46, D Loss Real: 0.2136003077030182, D Loss Fake: 1.1081957817077637, G Loss: [11.788406372070312, 0.7123852372169495, 0.11076021194458008]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 47, SSIM Loss: 0.12557125091552734\n",
      "Epoch: 16, Batch: 47, D Loss Real: 0.11583554744720459, D Loss Fake: 1.1562153100967407, G Loss: [13.314398765563965, 0.7280322313308716, 0.1258636713027954]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 48, SSIM Loss: 0.10898691415786743\n",
      "Epoch: 16, Batch: 48, D Loss Real: 0.1472286581993103, D Loss Fake: 1.0152885913848877, G Loss: [11.713024139404297, 0.7794456481933594, 0.10933578014373779]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 49, SSIM Loss: 0.11376392841339111\n",
      "Epoch: 16, Batch: 49, D Loss Real: 0.15785789489746094, D Loss Fake: 1.1472896337509155, G Loss: [12.0792875289917, 0.77003413438797, 0.11309254169464111]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 50, SSIM Loss: 0.11329567432403564\n",
      "Epoch: 16, Batch: 50, D Loss Real: 0.21341858804225922, D Loss Fake: 1.0700675249099731, G Loss: [12.028772354125977, 0.7341446876525879, 0.1129462718963623]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 51, SSIM Loss: 0.11219984292984009\n",
      "Epoch: 16, Batch: 51, D Loss Real: 0.1712765246629715, D Loss Fake: 1.0384058952331543, G Loss: [11.935982704162598, 0.71458500623703, 0.11221396923065186]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 52, SSIM Loss: 0.11766338348388672\n",
      "Epoch: 16, Batch: 52, D Loss Real: 0.1491241753101349, D Loss Fake: 1.026995062828064, G Loss: [12.53212833404541, 0.7389918565750122, 0.11793136596679688]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 53, SSIM Loss: 0.1138567328453064\n",
      "Epoch: 16, Batch: 53, D Loss Real: 0.13474439084529877, D Loss Fake: 1.1784238815307617, G Loss: [12.105347633361816, 0.7398684024810791, 0.11365479230880737]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 54, SSIM Loss: 0.11945676803588867\n",
      "Epoch: 16, Batch: 54, D Loss Real: 0.1212015151977539, D Loss Fake: 1.0936702489852905, G Loss: [12.734833717346191, 0.7541812658309937, 0.11980652809143066]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 55, SSIM Loss: 0.10244405269622803\n",
      "Epoch: 16, Batch: 55, D Loss Real: 0.1920473277568817, D Loss Fake: 0.9896304607391357, G Loss: [11.016361236572266, 0.7737975120544434, 0.10242563486099243]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 56, SSIM Loss: 0.11184197664260864\n",
      "Epoch: 16, Batch: 56, D Loss Real: 0.12089065462350845, D Loss Fake: 0.9971086382865906, G Loss: [11.933491706848145, 0.7629255056381226, 0.11170566082000732]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 57, SSIM Loss: 0.12313687801361084\n",
      "Epoch: 16, Batch: 57, D Loss Real: 0.08455350995063782, D Loss Fake: 1.3067257404327393, G Loss: [13.156906127929688, 0.8157044053077698, 0.12341201305389404]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 58, SSIM Loss: 0.12158763408660889\n",
      "Epoch: 16, Batch: 58, D Loss Real: 0.20302268862724304, D Loss Fake: 0.9748677015304565, G Loss: [12.953255653381348, 0.7737014889717102, 0.12179553508758545]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 59, SSIM Loss: 0.11039614677429199\n",
      "Epoch: 16, Batch: 59, D Loss Real: 0.2920534014701843, D Loss Fake: 1.0691301822662354, G Loss: [11.712736129760742, 0.6839805841445923, 0.11028754711151123]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 16, Batch: 60, SSIM Loss: 0.12128502130508423\n",
      "Epoch: 16, Batch: 60, D Loss Real: 0.19543242454528809, D Loss Fake: 1.1675889492034912, G Loss: [12.72939682006836, 0.655582070350647, 0.12073814868927002]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 16, Batch: 61, SSIM Loss: 0.10871577262878418\n",
      "Epoch: 16, Batch: 61, D Loss Real: 0.17542675137519836, D Loss Fake: 1.1441545486450195, G Loss: [11.602593421936035, 0.7127290964126587, 0.10889863967895508]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 16, Batch: 62, SSIM Loss: 0.11403524875640869\n",
      "Epoch: 16, Batch: 62, D Loss Real: 0.12401440739631653, D Loss Fake: 1.124335765838623, G Loss: [12.13548469543457, 0.7307556867599487, 0.11404728889465332]\n",
      "1/1 [==============================] - 0s 149ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:34:29.948903: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:34:31.432085: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Batch: 1, SSIM Loss: 0.10558813810348511\n",
      "Epoch: 17, Batch: 1, D Loss Real: 0.17054101824760437, D Loss Fake: 1.0287705659866333, G Loss: [11.34964370727539, 0.7621843814849854, 0.10587459802627563]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 17, Batch: 2, SSIM Loss: 0.10567879676818848\n",
      "Epoch: 17, Batch: 2, D Loss Real: 0.18571987748146057, D Loss Fake: 1.0181714296340942, G Loss: [11.313528060913086, 0.7465423345565796, 0.10566985607147217]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 17, Batch: 3, SSIM Loss: 0.11920541524887085\n",
      "Epoch: 17, Batch: 3, D Loss Real: 0.11434668302536011, D Loss Fake: 1.2398849725723267, G Loss: [12.689292907714844, 0.7751647233963013, 0.11914128065109253]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 4, SSIM Loss: 0.11603105068206787\n",
      "Epoch: 17, Batch: 4, D Loss Real: 0.2065524309873581, D Loss Fake: 1.0016860961914062, G Loss: [12.37209701538086, 0.7630912661552429, 0.11609005928039551]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 5, SSIM Loss: 0.109169602394104\n",
      "Epoch: 17, Batch: 5, D Loss Real: 0.21948324143886566, D Loss Fake: 1.1048020124435425, G Loss: [11.644163131713867, 0.7195795178413391, 0.10924583673477173]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 6, SSIM Loss: 0.1110076904296875\n",
      "Epoch: 17, Batch: 6, D Loss Real: 0.15218274295330048, D Loss Fake: 1.0268036127090454, G Loss: [11.903255462646484, 0.7352408766746521, 0.11168015003204346]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 7, SSIM Loss: 0.11202090978622437\n",
      "Epoch: 17, Batch: 7, D Loss Real: 0.11761689931154251, D Loss Fake: 1.3179320096969604, G Loss: [11.990545272827148, 0.7843361496925354, 0.11206209659576416]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 8, SSIM Loss: 0.10775351524353027\n",
      "Epoch: 17, Batch: 8, D Loss Real: 0.34669801592826843, D Loss Fake: 1.0490320920944214, G Loss: [11.491930961608887, 0.722086489200592, 0.10769844055175781]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 9, SSIM Loss: 0.11432969570159912\n",
      "Epoch: 17, Batch: 9, D Loss Real: 0.2936176061630249, D Loss Fake: 1.1334227323532104, G Loss: [12.107640266418457, 0.6615216135978699, 0.11446118354797363]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 17, Batch: 10, SSIM Loss: 0.10626906156539917\n",
      "Epoch: 17, Batch: 10, D Loss Real: 0.2497890144586563, D Loss Fake: 1.1910442113876343, G Loss: [11.246580123901367, 0.6227378249168396, 0.10623842477798462]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 17, Batch: 11, SSIM Loss: 0.11008048057556152\n",
      "Epoch: 17, Batch: 11, D Loss Real: 0.22030887007713318, D Loss Fake: 1.2567315101623535, G Loss: [11.614808082580566, 0.6431902647018433, 0.10971617698669434]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 12, SSIM Loss: 0.10898458957672119\n",
      "Epoch: 17, Batch: 12, D Loss Real: 0.18711933493614197, D Loss Fake: 1.1714653968811035, G Loss: [11.530936241149902, 0.6466572284698486, 0.10884279012680054]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 13, SSIM Loss: 0.11756062507629395\n",
      "Epoch: 17, Batch: 13, D Loss Real: 0.15231482684612274, D Loss Fake: 1.1086180210113525, G Loss: [12.408032417297363, 0.7145786285400391, 0.11693453788757324]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 14, SSIM Loss: 0.11556100845336914\n",
      "Epoch: 17, Batch: 14, D Loss Real: 0.1509035974740982, D Loss Fake: 1.129990816116333, G Loss: [12.333647727966309, 0.7486270070075989, 0.11585021018981934]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 15, SSIM Loss: 0.11683523654937744\n",
      "Epoch: 17, Batch: 15, D Loss Real: 0.2395484447479248, D Loss Fake: 1.0881882905960083, G Loss: [12.478386878967285, 0.7252625226974487, 0.11753123998641968]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 16, SSIM Loss: 0.11177104711532593\n",
      "Epoch: 17, Batch: 16, D Loss Real: 0.22603526711463928, D Loss Fake: 1.0433578491210938, G Loss: [12.017739295959473, 0.7119661569595337, 0.11305773258209229]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 17, SSIM Loss: 0.1142282485961914\n",
      "Epoch: 17, Batch: 17, D Loss Real: 0.16815418004989624, D Loss Fake: 1.096047043800354, G Loss: [12.130019187927246, 0.7316085696220398, 0.1139841079711914]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 18, SSIM Loss: 0.11044728755950928\n",
      "Epoch: 17, Batch: 18, D Loss Real: 0.12572342157363892, D Loss Fake: 1.1813496351242065, G Loss: [11.812932014465332, 0.7600796818733215, 0.11052852869033813]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 19, SSIM Loss: 0.1146288514137268\n",
      "Epoch: 17, Batch: 19, D Loss Real: 0.11201229691505432, D Loss Fake: 1.0077435970306396, G Loss: [12.282715797424316, 0.7955897450447083, 0.11487126350402832]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 17, Batch: 20, SSIM Loss: 0.11482161283493042\n",
      "Epoch: 17, Batch: 20, D Loss Real: 0.1480935961008072, D Loss Fake: 0.982182502746582, G Loss: [12.24553108215332, 0.7859177589416504, 0.11459612846374512]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 17, Batch: 21, SSIM Loss: 0.10915184020996094\n",
      "Epoch: 17, Batch: 21, D Loss Real: 0.12271276116371155, D Loss Fake: 1.000890851020813, G Loss: [11.742612838745117, 0.7805190682411194, 0.10962092876434326]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 17, Batch: 22, SSIM Loss: 0.10582756996154785\n",
      "Epoch: 17, Batch: 22, D Loss Real: 0.09490542858839035, D Loss Fake: 1.3157156705856323, G Loss: [11.361544609069824, 0.8027369976043701, 0.10558807849884033]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 23, SSIM Loss: 0.11763185262680054\n",
      "Epoch: 17, Batch: 23, D Loss Real: 0.2610419988632202, D Loss Fake: 1.0052342414855957, G Loss: [12.620833396911621, 0.7526723742485046, 0.11868160963058472]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 17, Batch: 24, SSIM Loss: 0.12419641017913818\n",
      "Epoch: 17, Batch: 24, D Loss Real: 0.2586963474750519, D Loss Fake: 1.1043566465377808, G Loss: [13.011744499206543, 0.6978423595428467, 0.12313902378082275]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 25, SSIM Loss: 0.11097055673599243\n",
      "Epoch: 17, Batch: 25, D Loss Real: 0.1847073882818222, D Loss Fake: 1.0673381090164185, G Loss: [11.87027359008789, 0.7502168416976929, 0.11120057106018066]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 26, SSIM Loss: 0.11359190940856934\n",
      "Epoch: 17, Batch: 26, D Loss Real: 0.17280125617980957, D Loss Fake: 1.0850417613983154, G Loss: [12.074101448059082, 0.7092481851577759, 0.11364853382110596]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 27, SSIM Loss: 0.10738217830657959\n",
      "Epoch: 17, Batch: 27, D Loss Real: 0.13753633201122284, D Loss Fake: 1.139615535736084, G Loss: [11.459529876708984, 0.7333274483680725, 0.1072620153427124]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 28, SSIM Loss: 0.10465383529663086\n",
      "Epoch: 17, Batch: 28, D Loss Real: 0.1475066989660263, D Loss Fake: 1.0890233516693115, G Loss: [11.250824928283691, 0.7761319279670715, 0.10474693775177002]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 29, SSIM Loss: 0.11823916435241699\n",
      "Epoch: 17, Batch: 29, D Loss Real: 0.16160035133361816, D Loss Fake: 1.0542199611663818, G Loss: [12.563653945922852, 0.7532796263694763, 0.1181037425994873]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 30, SSIM Loss: 0.11616700887680054\n",
      "Epoch: 17, Batch: 30, D Loss Real: 0.09663551300764084, D Loss Fake: 1.0796431303024292, G Loss: [12.386820793151855, 0.7855397462844849, 0.1160128116607666]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 31, SSIM Loss: 0.10997331142425537\n",
      "Epoch: 17, Batch: 31, D Loss Real: 0.16545629501342773, D Loss Fake: 1.0863789319992065, G Loss: [11.819231986999512, 0.7622424364089966, 0.11056989431381226]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 32, SSIM Loss: 0.11158478260040283\n",
      "Epoch: 17, Batch: 32, D Loss Real: 0.14444200694561005, D Loss Fake: 1.0358266830444336, G Loss: [11.93164348602295, 0.7863744497299194, 0.11145269870758057]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 33, SSIM Loss: 0.11169815063476562\n",
      "Epoch: 17, Batch: 33, D Loss Real: 0.2102413773536682, D Loss Fake: 1.084389328956604, G Loss: [11.923919677734375, 0.745307445526123, 0.1117861270904541]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 34, SSIM Loss: 0.11083465814590454\n",
      "Epoch: 17, Batch: 34, D Loss Real: 0.18452154099941254, D Loss Fake: 1.094099521636963, G Loss: [11.821168899536133, 0.7394675612449646, 0.11081701517105103]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 35, SSIM Loss: 0.09978395700454712\n",
      "Epoch: 17, Batch: 35, D Loss Real: 0.2237616330385208, D Loss Fake: 1.130464792251587, G Loss: [10.659980773925781, 0.7179203629493713, 0.09942060708999634]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 36, SSIM Loss: 0.11680138111114502\n",
      "Epoch: 17, Batch: 36, D Loss Real: 0.1867447793483734, D Loss Fake: 1.359554409980774, G Loss: [12.408757209777832, 0.7285474538803101, 0.11680209636688232]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 37, SSIM Loss: 0.10963201522827148\n",
      "Epoch: 17, Batch: 37, D Loss Real: 0.3164793848991394, D Loss Fake: 1.1576285362243652, G Loss: [11.698237419128418, 0.7176070809364319, 0.10980629920959473]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 38, SSIM Loss: 0.12609553337097168\n",
      "Epoch: 17, Batch: 38, D Loss Real: 0.304411917924881, D Loss Fake: 1.1403990983963013, G Loss: [13.231752395629883, 0.6565554738044739, 0.12575197219848633]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 39, SSIM Loss: 0.11307311058044434\n",
      "Epoch: 17, Batch: 39, D Loss Real: 0.321468710899353, D Loss Fake: 1.1778556108474731, G Loss: [11.920143127441406, 0.6443273425102234, 0.11275815963745117]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 17, Batch: 40, SSIM Loss: 0.11622262001037598\n",
      "Epoch: 17, Batch: 40, D Loss Real: 0.2525476813316345, D Loss Fake: 1.1847801208496094, G Loss: [12.2722806930542, 0.6476221680641174, 0.11624658107757568]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 41, SSIM Loss: 0.10239589214324951\n",
      "Epoch: 17, Batch: 41, D Loss Real: 0.23998011648654938, D Loss Fake: 1.1338573694229126, G Loss: [10.934041976928711, 0.6676363945007324, 0.102664053440094]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 42, SSIM Loss: 0.11758524179458618\n",
      "Epoch: 17, Batch: 42, D Loss Real: 0.15640893578529358, D Loss Fake: 1.1932233572006226, G Loss: [12.418766021728516, 0.6775456666946411, 0.11741220951080322]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 43, SSIM Loss: 0.10898160934448242\n",
      "Epoch: 17, Batch: 43, D Loss Real: 0.13366079330444336, D Loss Fake: 1.0396924018859863, G Loss: [11.67213249206543, 0.7418217658996582, 0.10930311679840088]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 44, SSIM Loss: 0.10362100601196289\n",
      "Epoch: 17, Batch: 44, D Loss Real: 0.16066467761993408, D Loss Fake: 1.1126198768615723, G Loss: [11.120466232299805, 0.745455265045166, 0.10375010967254639]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 45, SSIM Loss: 0.12274563312530518\n",
      "Epoch: 17, Batch: 45, D Loss Real: 0.11952383816242218, D Loss Fake: 1.0071511268615723, G Loss: [13.086990356445312, 0.7730157971382141, 0.12313973903656006]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 46, SSIM Loss: 0.11037576198577881\n",
      "Epoch: 17, Batch: 46, D Loss Real: 0.17779846489429474, D Loss Fake: 1.0496246814727783, G Loss: [11.8027925491333, 0.7392053604125977, 0.11063587665557861]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 47, SSIM Loss: 0.1250683069229126\n",
      "Epoch: 17, Batch: 47, D Loss Real: 0.08767040073871613, D Loss Fake: 1.145378828048706, G Loss: [13.204985618591309, 0.7425124645233154, 0.12462472915649414]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 48, SSIM Loss: 0.10777807235717773\n",
      "Epoch: 17, Batch: 48, D Loss Real: 0.10994338244199753, D Loss Fake: 1.045762300491333, G Loss: [11.584650039672852, 0.8152823448181152, 0.10769367218017578]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 49, SSIM Loss: 0.11378586292266846\n",
      "Epoch: 17, Batch: 49, D Loss Real: 0.17227831482887268, D Loss Fake: 1.041348934173584, G Loss: [12.095437049865723, 0.7883043885231018, 0.11307132244110107]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 50, SSIM Loss: 0.11250817775726318\n",
      "Epoch: 17, Batch: 50, D Loss Real: 0.19663050770759583, D Loss Fake: 1.050238013267517, G Loss: [11.993158340454102, 0.754143238067627, 0.11239016056060791]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 51, SSIM Loss: 0.11177098751068115\n",
      "Epoch: 17, Batch: 51, D Loss Real: 0.15263155102729797, D Loss Fake: 1.0344105958938599, G Loss: [11.923429489135742, 0.7251946926116943, 0.11198234558105469]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 52, SSIM Loss: 0.11708581447601318\n",
      "Epoch: 17, Batch: 52, D Loss Real: 0.1375858634710312, D Loss Fake: 1.0302873849868774, G Loss: [12.465314865112305, 0.7729758024215698, 0.11692339181900024]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 53, SSIM Loss: 0.11365354061126709\n",
      "Epoch: 17, Batch: 53, D Loss Real: 0.1355549395084381, D Loss Fake: 1.2256861925125122, G Loss: [12.13134479522705, 0.7919428944587708, 0.11339402198791504]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 54, SSIM Loss: 0.1191137433052063\n",
      "Epoch: 17, Batch: 54, D Loss Real: 0.167279452085495, D Loss Fake: 1.025946021080017, G Loss: [12.670111656188965, 0.7548811435699463, 0.11915230751037598]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 55, SSIM Loss: 0.10158658027648926\n",
      "Epoch: 17, Batch: 55, D Loss Real: 0.22018826007843018, D Loss Fake: 1.0571873188018799, G Loss: [10.909639358520508, 0.7673969268798828, 0.10142242908477783]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 56, SSIM Loss: 0.11098259687423706\n",
      "Epoch: 17, Batch: 56, D Loss Real: 0.14578594267368317, D Loss Fake: 1.0037858486175537, G Loss: [11.852042198181152, 0.7552904486656189, 0.11096751689910889]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 57, SSIM Loss: 0.12284880876541138\n",
      "Epoch: 17, Batch: 57, D Loss Real: 0.10622987896203995, D Loss Fake: 1.3057326078414917, G Loss: [13.046918869018555, 0.775525689125061, 0.12271392345428467]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 58, SSIM Loss: 0.12158280611038208\n",
      "Epoch: 17, Batch: 58, D Loss Real: 0.22521346807479858, D Loss Fake: 1.0191974639892578, G Loss: [12.862913131713867, 0.7462478876113892, 0.1211666464805603]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 59, SSIM Loss: 0.10957515239715576\n",
      "Epoch: 17, Batch: 59, D Loss Real: 0.3099111318588257, D Loss Fake: 1.0758264064788818, G Loss: [11.606954574584961, 0.679969310760498, 0.10926985740661621]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 60, SSIM Loss: 0.12044632434844971\n",
      "Epoch: 17, Batch: 60, D Loss Real: 0.22051696479320526, D Loss Fake: 1.1642906665802002, G Loss: [12.638413429260254, 0.6572544574737549, 0.11981159448623657]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 61, SSIM Loss: 0.10879772901535034\n",
      "Epoch: 17, Batch: 61, D Loss Real: 0.18325138092041016, D Loss Fake: 1.116374135017395, G Loss: [11.536993980407715, 0.6970787644386292, 0.1083991527557373]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 17, Batch: 62, SSIM Loss: 0.11309373378753662\n",
      "Epoch: 17, Batch: 62, D Loss Real: 0.11524102836847305, D Loss Fake: 1.1406617164611816, G Loss: [12.019535064697266, 0.719913125038147, 0.11299622058868408]\n",
      "1/1 [==============================] - 0s 151ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:35:53.230231: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:35:54.720583: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Batch: 1, SSIM Loss: 0.10474908351898193\n",
      "Epoch: 18, Batch: 1, D Loss Real: 0.1637725979089737, D Loss Fake: 1.0454379320144653, G Loss: [11.305139541625977, 0.7637003660202026, 0.10541439056396484]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 2, SSIM Loss: 0.10558903217315674\n",
      "Epoch: 18, Batch: 2, D Loss Real: 0.20387524366378784, D Loss Fake: 1.0210989713668823, G Loss: [11.246674537658691, 0.7441093325614929, 0.10502564907073975]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 18, Batch: 3, SSIM Loss: 0.1187136173248291\n",
      "Epoch: 18, Batch: 3, D Loss Real: 0.1213320940732956, D Loss Fake: 1.1368179321289062, G Loss: [12.66616153717041, 0.7537025809288025, 0.11912459135055542]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 18, Batch: 4, SSIM Loss: 0.11496293544769287\n",
      "Epoch: 18, Batch: 4, D Loss Real: 0.1857985556125641, D Loss Fake: 1.0355470180511475, G Loss: [12.311799049377441, 0.7629220485687256, 0.11548876762390137]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 5, SSIM Loss: 0.10922223329544067\n",
      "Epoch: 18, Batch: 5, D Loss Real: 0.19802400469779968, D Loss Fake: 1.091353416442871, G Loss: [11.626835823059082, 0.7205507159233093, 0.10906285047531128]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 18, Batch: 6, SSIM Loss: 0.11009073257446289\n",
      "Epoch: 18, Batch: 6, D Loss Real: 0.13622969388961792, D Loss Fake: 1.090982437133789, G Loss: [11.772933959960938, 0.7638367414474487, 0.11009097099304199]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 7, SSIM Loss: 0.11102664470672607\n",
      "Epoch: 18, Batch: 7, D Loss Real: 0.1572410762310028, D Loss Fake: 1.0545921325683594, G Loss: [11.896465301513672, 0.776223361492157, 0.1112024188041687]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 8, SSIM Loss: 0.1070488691329956\n",
      "Epoch: 18, Batch: 8, D Loss Real: 0.27275580167770386, D Loss Fake: 1.1128060817718506, G Loss: [11.393653869628906, 0.7037099003791809, 0.1068994402885437]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 9, SSIM Loss: 0.11342036724090576\n",
      "Epoch: 18, Batch: 9, D Loss Real: 0.1442265510559082, D Loss Fake: 1.1539511680603027, G Loss: [12.045791625976562, 0.7131308913230896, 0.11332660913467407]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 10, SSIM Loss: 0.10637122392654419\n",
      "Epoch: 18, Batch: 10, D Loss Real: 0.1296999752521515, D Loss Fake: 1.2265386581420898, G Loss: [11.356340408325195, 0.7198255658149719, 0.1063651442527771]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 11, SSIM Loss: 0.10950493812561035\n",
      "Epoch: 18, Batch: 11, D Loss Real: 0.2743987739086151, D Loss Fake: 1.060065746307373, G Loss: [11.694794654846191, 0.7090497612953186, 0.10985743999481201]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 18, Batch: 12, SSIM Loss: 0.10869204998016357\n",
      "Epoch: 18, Batch: 12, D Loss Real: 0.22696083784103394, D Loss Fake: 1.1560567617416382, G Loss: [11.553144454956055, 0.655722439289093, 0.10897421836853027]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 13, SSIM Loss: 0.11824464797973633\n",
      "Epoch: 18, Batch: 13, D Loss Real: 0.12814581394195557, D Loss Fake: 1.1453393697738647, G Loss: [12.539983749389648, 0.7296042442321777, 0.11810380220413208]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 14, SSIM Loss: 0.11521279811859131\n",
      "Epoch: 18, Batch: 14, D Loss Real: 0.1413772702217102, D Loss Fake: 1.1108040809631348, G Loss: [12.285459518432617, 0.7622781991958618, 0.11523181200027466]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 15, SSIM Loss: 0.11760294437408447\n",
      "Epoch: 18, Batch: 15, D Loss Real: 0.27586600184440613, D Loss Fake: 1.0842543840408325, G Loss: [12.35733699798584, 0.7311829924583435, 0.1162615418434143]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 16, SSIM Loss: 0.1117517352104187\n",
      "Epoch: 18, Batch: 16, D Loss Real: 0.2675987184047699, D Loss Fake: 1.0649733543395996, G Loss: [11.904083251953125, 0.6939935684204102, 0.11210089921951294]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 17, SSIM Loss: 0.11282205581665039\n",
      "Epoch: 18, Batch: 17, D Loss Real: 0.2108500748872757, D Loss Fake: 1.166067361831665, G Loss: [11.959425926208496, 0.672171950340271, 0.11287254095077515]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 18, SSIM Loss: 0.10890185832977295\n",
      "Epoch: 18, Batch: 18, D Loss Real: 0.14803989231586456, D Loss Fake: 1.226339340209961, G Loss: [11.595948219299316, 0.7023288011550903, 0.10893619060516357]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 19, SSIM Loss: 0.11308294534683228\n",
      "Epoch: 18, Batch: 19, D Loss Real: 0.1212608814239502, D Loss Fake: 1.0243480205535889, G Loss: [12.050543785095215, 0.7572754621505737, 0.11293268203735352]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 20, SSIM Loss: 0.11291998624801636\n",
      "Epoch: 18, Batch: 20, D Loss Real: 0.15315459668636322, D Loss Fake: 1.0579196214675903, G Loss: [12.101397514343262, 0.782057523727417, 0.11319339275360107]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 21, SSIM Loss: 0.10781335830688477\n",
      "Epoch: 18, Batch: 21, D Loss Real: 0.15328510105609894, D Loss Fake: 0.9914631843566895, G Loss: [11.558941841125488, 0.75736403465271, 0.10801577568054199]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 22, SSIM Loss: 0.1058419942855835\n",
      "Epoch: 18, Batch: 22, D Loss Real: 0.1167798563838005, D Loss Fake: 1.38031005859375, G Loss: [11.42083740234375, 0.7935735583305359, 0.1062726378440857]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 23, SSIM Loss: 0.11668848991394043\n",
      "Epoch: 18, Batch: 23, D Loss Real: 0.2922056317329407, D Loss Fake: 1.0240920782089233, G Loss: [12.42698860168457, 0.744854211807251, 0.11682134866714478]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 18, Batch: 24, SSIM Loss: 0.12065494060516357\n",
      "Epoch: 18, Batch: 24, D Loss Real: 0.3016234338283539, D Loss Fake: 1.1029706001281738, G Loss: [12.790546417236328, 0.6899455785751343, 0.12100601196289062]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 25, SSIM Loss: 0.10998326539993286\n",
      "Epoch: 18, Batch: 25, D Loss Real: 0.21517175436019897, D Loss Fake: 1.1027361154556274, G Loss: [11.696240425109863, 0.7027122378349304, 0.10993528366088867]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 26, SSIM Loss: 0.11236238479614258\n",
      "Epoch: 18, Batch: 26, D Loss Real: 0.168754443526268, D Loss Fake: 1.1229995489120483, G Loss: [11.937766075134277, 0.6967118382453918, 0.1124105453491211]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 27, SSIM Loss: 0.10653722286224365\n",
      "Epoch: 18, Batch: 27, D Loss Real: 0.15986894071102142, D Loss Fake: 1.1489235162734985, G Loss: [11.384175300598145, 0.7019973993301392, 0.10682177543640137]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 28, SSIM Loss: 0.10410290956497192\n",
      "Epoch: 18, Batch: 28, D Loss Real: 0.15357622504234314, D Loss Fake: 1.1635786294937134, G Loss: [11.185328483581543, 0.7473214864730835, 0.10438007116317749]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 29, SSIM Loss: 0.11803889274597168\n",
      "Epoch: 18, Batch: 29, D Loss Real: 0.18605877459049225, D Loss Fake: 1.0630199909210205, G Loss: [12.550680160522461, 0.7321164608001709, 0.11818563938140869]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 30, SSIM Loss: 0.1149907112121582\n",
      "Epoch: 18, Batch: 30, D Loss Real: 0.10192999243736267, D Loss Fake: 1.1251262426376343, G Loss: [12.284162521362305, 0.7831006050109863, 0.11501061916351318]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 31, SSIM Loss: 0.10919749736785889\n",
      "Epoch: 18, Batch: 31, D Loss Real: 0.18870419263839722, D Loss Fake: 1.0296220779418945, G Loss: [11.684881210327148, 0.7533783316612244, 0.10931503772735596]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 32, SSIM Loss: 0.11051511764526367\n",
      "Epoch: 18, Batch: 32, D Loss Real: 0.1398065835237503, D Loss Fake: 1.044255256652832, G Loss: [11.800307273864746, 0.7604005336761475, 0.11039906740188599]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 33, SSIM Loss: 0.11104834079742432\n",
      "Epoch: 18, Batch: 33, D Loss Real: 0.18738321959972382, D Loss Fake: 1.0848214626312256, G Loss: [11.809789657592773, 0.7336971163749695, 0.11076092720031738]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 34, SSIM Loss: 0.11013692617416382\n",
      "Epoch: 18, Batch: 34, D Loss Real: 0.17095239460468292, D Loss Fake: 1.146818995475769, G Loss: [11.785995483398438, 0.7379054427146912, 0.1104809045791626]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 35, SSIM Loss: 0.09830069541931152\n",
      "Epoch: 18, Batch: 35, D Loss Real: 0.2785617411136627, D Loss Fake: 1.1523116827011108, G Loss: [10.528193473815918, 0.71668541431427, 0.09811508655548096]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 36, SSIM Loss: 0.11581599712371826\n",
      "Epoch: 18, Batch: 36, D Loss Real: 0.2798859179019928, D Loss Fake: 1.222235918045044, G Loss: [12.22849178314209, 0.662198007106781, 0.11566293239593506]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 37, SSIM Loss: 0.10897916555404663\n",
      "Epoch: 18, Batch: 37, D Loss Real: 0.21873150765895844, D Loss Fake: 1.0981156826019287, G Loss: [11.585247039794922, 0.6771260499954224, 0.1090812087059021]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 38, SSIM Loss: 0.12373292446136475\n",
      "Epoch: 18, Batch: 38, D Loss Real: 0.1473953127861023, D Loss Fake: 1.1567684412002563, G Loss: [13.093985557556152, 0.6960816979408264, 0.12397903203964233]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 39, SSIM Loss: 0.11187928915023804\n",
      "Epoch: 18, Batch: 39, D Loss Real: 0.2085607796907425, D Loss Fake: 1.0609281063079834, G Loss: [11.900259971618652, 0.713362991809845, 0.1118689775466919]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 40, SSIM Loss: 0.11616003513336182\n",
      "Epoch: 18, Batch: 40, D Loss Real: 0.1663217395544052, D Loss Fake: 1.0811657905578613, G Loss: [12.339024543762207, 0.7186883091926575, 0.11620336771011353]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 41, SSIM Loss: 0.10207593441009521\n",
      "Epoch: 18, Batch: 41, D Loss Real: 0.1590779423713684, D Loss Fake: 1.0440161228179932, G Loss: [11.00150203704834, 0.7563931345939636, 0.10245108604431152]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 42, SSIM Loss: 0.11868178844451904\n",
      "Epoch: 18, Batch: 42, D Loss Real: 0.10489124059677124, D Loss Fake: 1.181765079498291, G Loss: [12.568909645080566, 0.7720655202865601, 0.11796844005584717]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 43, SSIM Loss: 0.10927146673202515\n",
      "Epoch: 18, Batch: 43, D Loss Real: 0.1844497174024582, D Loss Fake: 0.9822044372558594, G Loss: [11.708456039428711, 0.7816962003707886, 0.10926759243011475]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 44, SSIM Loss: 0.1032571792602539\n",
      "Epoch: 18, Batch: 44, D Loss Real: 0.22336000204086304, D Loss Fake: 1.0401824712753296, G Loss: [11.040771484375, 0.7256926894187927, 0.10315078496932983]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 18, Batch: 45, SSIM Loss: 0.1217186450958252\n",
      "Epoch: 18, Batch: 45, D Loss Real: 0.11812253296375275, D Loss Fake: 1.0330488681793213, G Loss: [12.879920959472656, 0.7239355444908142, 0.12155985832214355]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 46, SSIM Loss: 0.10992264747619629\n",
      "Epoch: 18, Batch: 46, D Loss Real: 0.11884036660194397, D Loss Fake: 1.2483433485031128, G Loss: [11.795353889465332, 0.7903759479522705, 0.1100497841835022]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 47, SSIM Loss: 0.12272286415100098\n",
      "Epoch: 18, Batch: 47, D Loss Real: 0.11594343185424805, D Loss Fake: 0.9747546911239624, G Loss: [13.045588493347168, 0.8001125454902649, 0.12245476245880127]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 48, SSIM Loss: 0.1072530746459961\n",
      "Epoch: 18, Batch: 48, D Loss Real: 0.19959621131420135, D Loss Fake: 1.0166501998901367, G Loss: [11.393349647521973, 0.7436506152153015, 0.10649698972702026]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 49, SSIM Loss: 0.11311465501785278\n",
      "Epoch: 18, Batch: 49, D Loss Real: 0.15329855680465698, D Loss Fake: 1.3138484954833984, G Loss: [12.0469388961792, 0.7471970319747925, 0.11299741268157959]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 50, SSIM Loss: 0.11260175704956055\n",
      "Epoch: 18, Batch: 50, D Loss Real: 0.28724205493927, D Loss Fake: 1.059417486190796, G Loss: [12.040332794189453, 0.7350118160247803, 0.11305320262908936]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 51, SSIM Loss: 0.11144310235977173\n",
      "Epoch: 18, Batch: 51, D Loss Real: 0.28262418508529663, D Loss Fake: 1.0792310237884521, G Loss: [11.811409950256348, 0.6836282014846802, 0.11127781867980957]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 18, Batch: 52, SSIM Loss: 0.11594200134277344\n",
      "Epoch: 18, Batch: 52, D Loss Real: 0.23115991055965424, D Loss Fake: 1.108365535736084, G Loss: [12.281332015991211, 0.6910060048103333, 0.11590325832366943]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 53, SSIM Loss: 0.11292994022369385\n",
      "Epoch: 18, Batch: 53, D Loss Real: 0.21533392369747162, D Loss Fake: 1.1389410495758057, G Loss: [11.972942352294922, 0.6772241592407227, 0.1129571795463562]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 54, SSIM Loss: 0.11762851476669312\n",
      "Epoch: 18, Batch: 54, D Loss Real: 0.15797139704227448, D Loss Fake: 1.2140132188796997, G Loss: [12.467971801757812, 0.6957444548606873, 0.1177222728729248]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 55, SSIM Loss: 0.10068023204803467\n",
      "Epoch: 18, Batch: 55, D Loss Real: 0.18916046619415283, D Loss Fake: 1.0553913116455078, G Loss: [10.827754020690918, 0.7441022396087646, 0.10083651542663574]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 56, SSIM Loss: 0.11000573635101318\n",
      "Epoch: 18, Batch: 56, D Loss Real: 0.13486510515213013, D Loss Fake: 1.0240936279296875, G Loss: [11.725057601928711, 0.7509481906890869, 0.10974109172821045]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 57, SSIM Loss: 0.12050527334213257\n",
      "Epoch: 18, Batch: 57, D Loss Real: 0.09218890964984894, D Loss Fake: 1.2733837366104126, G Loss: [12.835055351257324, 0.7923843860626221, 0.1204267144203186]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 58, SSIM Loss: 0.12052595615386963\n",
      "Epoch: 18, Batch: 58, D Loss Real: 0.17956161499023438, D Loss Fake: 1.0095282793045044, G Loss: [12.816084861755371, 0.7991321086883545, 0.12016952037811279]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 59, SSIM Loss: 0.10693109035491943\n",
      "Epoch: 18, Batch: 59, D Loss Real: 0.290447473526001, D Loss Fake: 1.0581153631210327, G Loss: [11.397798538208008, 0.7133083343505859, 0.10684490203857422]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 60, SSIM Loss: 0.12280142307281494\n",
      "Epoch: 18, Batch: 60, D Loss Real: 0.20762647688388824, D Loss Fake: 1.1673588752746582, G Loss: [13.055386543273926, 0.6529591679573059, 0.12402427196502686]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 18, Batch: 61, SSIM Loss: 0.11259031295776367\n",
      "Epoch: 18, Batch: 61, D Loss Real: 0.16703802347183228, D Loss Fake: 1.073248267173767, G Loss: [11.98399829864502, 0.718576967716217, 0.11265420913696289]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 18, Batch: 62, SSIM Loss: 0.11424130201339722\n",
      "Epoch: 18, Batch: 62, D Loss Real: 0.10128480941057205, D Loss Fake: 1.0732200145721436, G Loss: [12.179245948791504, 0.7444109320640564, 0.11434835195541382]\n",
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:37:16.460496: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:37:17.934725: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Batch: 1, SSIM Loss: 0.10510939359664917\n",
      "Epoch: 19, Batch: 1, D Loss Real: 0.12578187882900238, D Loss Fake: 0.9836208820343018, G Loss: [11.30621337890625, 0.7809978127479553, 0.10525214672088623]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 2, SSIM Loss: 0.10627532005310059\n",
      "Epoch: 19, Batch: 2, D Loss Real: 0.14940336346626282, D Loss Fake: 0.9668965935707092, G Loss: [11.41472053527832, 0.7914201021194458, 0.10623300075531006]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 19, Batch: 3, SSIM Loss: 0.11940497159957886\n",
      "Epoch: 19, Batch: 3, D Loss Real: 0.08674256503582001, D Loss Fake: 1.0529993772506714, G Loss: [12.72104263305664, 0.7868869304656982, 0.11934155225753784]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 19, Batch: 4, SSIM Loss: 0.11741417646408081\n",
      "Epoch: 19, Batch: 4, D Loss Real: 0.15405260026454926, D Loss Fake: 1.0279278755187988, G Loss: [12.544203758239746, 0.7937206029891968, 0.11750483512878418]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 5, SSIM Loss: 0.10912388563156128\n",
      "Epoch: 19, Batch: 5, D Loss Real: 0.15452273190021515, D Loss Fake: 1.1288237571716309, G Loss: [11.713713645935059, 0.7627613544464111, 0.10950952768325806]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 19, Batch: 6, SSIM Loss: 0.11049675941467285\n",
      "Epoch: 19, Batch: 6, D Loss Real: 0.17378829419612885, D Loss Fake: 1.0306808948516846, G Loss: [11.842007637023926, 0.7706301212310791, 0.11071377992630005]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 19, Batch: 7, SSIM Loss: 0.11180293560028076\n",
      "Epoch: 19, Batch: 7, D Loss Real: 0.1633371114730835, D Loss Fake: 1.025641679763794, G Loss: [11.92203140258789, 0.739067018032074, 0.11182963848114014]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 8, SSIM Loss: 0.1079249382019043\n",
      "Epoch: 19, Batch: 8, D Loss Real: 0.15568745136260986, D Loss Fake: 1.1968258619308472, G Loss: [11.567458152770996, 0.7696478366851807, 0.10797810554504395]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 9, SSIM Loss: 0.11521804332733154\n",
      "Epoch: 19, Batch: 9, D Loss Real: 0.1458698958158493, D Loss Fake: 1.008709192276001, G Loss: [12.303202629089355, 0.7824471592903137, 0.11520755290985107]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 10, SSIM Loss: 0.10837620496749878\n",
      "Epoch: 19, Batch: 10, D Loss Real: 0.14852119982242584, D Loss Fake: 1.1058341264724731, G Loss: [11.599388122558594, 0.7659639716148376, 0.1083342432975769]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 11, SSIM Loss: 0.11039400100708008\n",
      "Epoch: 19, Batch: 11, D Loss Real: 0.2022910863161087, D Loss Fake: 1.0707035064697266, G Loss: [11.744429588317871, 0.7386225461959839, 0.11005806922912598]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 12, SSIM Loss: 0.10794854164123535\n",
      "Epoch: 19, Batch: 12, D Loss Real: 0.18418921530246735, D Loss Fake: 1.1447422504425049, G Loss: [11.50606918334961, 0.7027875185012817, 0.10803282260894775]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 19, Batch: 13, SSIM Loss: 0.11867910623550415\n",
      "Epoch: 19, Batch: 13, D Loss Real: 0.13375800848007202, D Loss Fake: 1.0852807760238647, G Loss: [12.650402069091797, 0.7484988570213318, 0.1190190315246582]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 14, SSIM Loss: 0.11603748798370361\n",
      "Epoch: 19, Batch: 14, D Loss Real: 0.12012958526611328, D Loss Fake: 1.1717191934585571, G Loss: [12.389120101928711, 0.7922078371047974, 0.11596912145614624]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 15, SSIM Loss: 0.11831843852996826\n",
      "Epoch: 19, Batch: 15, D Loss Real: 0.3193868398666382, D Loss Fake: 1.1657549142837524, G Loss: [12.529369354248047, 0.7348384857177734, 0.11794531345367432]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 16, SSIM Loss: 0.11253893375396729\n",
      "Epoch: 19, Batch: 16, D Loss Real: 0.31660568714141846, D Loss Fake: 1.1089732646942139, G Loss: [11.983732223510742, 0.6881221532821655, 0.11295610666275024]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 19, Batch: 17, SSIM Loss: 0.11174309253692627\n",
      "Epoch: 19, Batch: 17, D Loss Real: 0.29158470034599304, D Loss Fake: 1.1673696041107178, G Loss: [11.858729362487793, 0.6392164826393127, 0.11219513416290283]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 18, SSIM Loss: 0.10882425308227539\n",
      "Epoch: 19, Batch: 18, D Loss Real: 0.22926700115203857, D Loss Fake: 1.200154423713684, G Loss: [11.54285717010498, 0.6373710036277771, 0.10905486345291138]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 19, SSIM Loss: 0.11295980215072632\n",
      "Epoch: 19, Batch: 19, D Loss Real: 0.1650058478116989, D Loss Fake: 1.1363614797592163, G Loss: [11.992599487304688, 0.6931324005126953, 0.11299467086791992]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 20, SSIM Loss: 0.11287331581115723\n",
      "Epoch: 19, Batch: 20, D Loss Real: 0.16041910648345947, D Loss Fake: 1.0705468654632568, G Loss: [12.025233268737793, 0.750079333782196, 0.1127515435218811]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 21, SSIM Loss: 0.10772466659545898\n",
      "Epoch: 19, Batch: 21, D Loss Real: 0.1410183161497116, D Loss Fake: 1.0301932096481323, G Loss: [11.497335433959961, 0.763027548789978, 0.10734307765960693]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 19, Batch: 22, SSIM Loss: 0.10441505908966064\n",
      "Epoch: 19, Batch: 22, D Loss Real: 0.13929079473018646, D Loss Fake: 1.180784821510315, G Loss: [11.213924407958984, 0.7627804279327393, 0.10451143980026245]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 23, SSIM Loss: 0.1162787675857544\n",
      "Epoch: 19, Batch: 23, D Loss Real: 0.18782275915145874, D Loss Fake: 0.9993637800216675, G Loss: [12.446235656738281, 0.7647149562835693, 0.11681520938873291]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 24, SSIM Loss: 0.11956632137298584\n",
      "Epoch: 19, Batch: 24, D Loss Real: 0.1666172295808792, D Loss Fake: 1.0025112628936768, G Loss: [12.721982955932617, 0.762466549873352, 0.11959517002105713]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 19, Batch: 25, SSIM Loss: 0.1088712215423584\n",
      "Epoch: 19, Batch: 25, D Loss Real: 0.09839440882205963, D Loss Fake: 1.0431444644927979, G Loss: [11.653413772583008, 0.7621849775314331, 0.10891228914260864]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 26, SSIM Loss: 0.11127352714538574\n",
      "Epoch: 19, Batch: 26, D Loss Real: 0.09747301787137985, D Loss Fake: 1.1660349369049072, G Loss: [11.958556175231934, 0.7981643676757812, 0.11160391569137573]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 27, SSIM Loss: 0.10695677995681763\n",
      "Epoch: 19, Batch: 27, D Loss Real: 0.13466854393482208, D Loss Fake: 1.020254135131836, G Loss: [11.47531509399414, 0.7955273985862732, 0.10679787397384644]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 28, SSIM Loss: 0.10417968034744263\n",
      "Epoch: 19, Batch: 28, D Loss Real: 0.15833424031734467, D Loss Fake: 1.0943645238876343, G Loss: [11.198453903198242, 0.7822204828262329, 0.10416233539581299]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 29, SSIM Loss: 0.11835825443267822\n",
      "Epoch: 19, Batch: 29, D Loss Real: 0.21839183568954468, D Loss Fake: 1.113145112991333, G Loss: [12.588534355163574, 0.718197762966156, 0.11870336532592773]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 30, SSIM Loss: 0.11513149738311768\n",
      "Epoch: 19, Batch: 30, D Loss Real: 0.11005407571792603, D Loss Fake: 1.050255537033081, G Loss: [12.240750312805176, 0.7623624205589294, 0.1147838830947876]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 31, SSIM Loss: 0.10896694660186768\n",
      "Epoch: 19, Batch: 31, D Loss Real: 0.14746247231960297, D Loss Fake: 1.169442892074585, G Loss: [11.633066177368164, 0.7741602659225464, 0.1085890531539917]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 32, SSIM Loss: 0.10843551158905029\n",
      "Epoch: 19, Batch: 32, D Loss Real: 0.16419555246829987, D Loss Fake: 0.9912737607955933, G Loss: [11.624549865722656, 0.7857970595359802, 0.1083875298500061]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 33, SSIM Loss: 0.11063694953918457\n",
      "Epoch: 19, Batch: 33, D Loss Real: 0.2667231559753418, D Loss Fake: 1.07499098777771, G Loss: [11.809233665466309, 0.6883602738380432, 0.11120873689651489]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 34, SSIM Loss: 0.10911095142364502\n",
      "Epoch: 19, Batch: 34, D Loss Real: 0.15792909264564514, D Loss Fake: 1.2012101411819458, G Loss: [11.609110832214355, 0.7175776958465576, 0.10891532897949219]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 35, SSIM Loss: 0.0979498028755188\n",
      "Epoch: 19, Batch: 35, D Loss Real: 0.30222779512405396, D Loss Fake: 1.2133862972259521, G Loss: [10.521430015563965, 0.7041815519332886, 0.09817248582839966]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 36, SSIM Loss: 0.11402702331542969\n",
      "Epoch: 19, Batch: 36, D Loss Real: 0.3027956187725067, D Loss Fake: 1.1873031854629517, G Loss: [12.103096008300781, 0.6541991233825684, 0.11448895931243896]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 37, SSIM Loss: 0.11016064882278442\n",
      "Epoch: 19, Batch: 37, D Loss Real: 0.20408838987350464, D Loss Fake: 1.1023716926574707, G Loss: [11.619719505310059, 0.6854257583618164, 0.10934293270111084]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 38, SSIM Loss: 0.12192273139953613\n",
      "Epoch: 19, Batch: 38, D Loss Real: 0.11116615682840347, D Loss Fake: 1.1770107746124268, G Loss: [12.901537895202637, 0.7437583208084106, 0.12157779932022095]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 39, SSIM Loss: 0.11003434658050537\n",
      "Epoch: 19, Batch: 39, D Loss Real: 0.25709885358810425, D Loss Fake: 1.0379854440689087, G Loss: [11.745275497436523, 0.7398858070373535, 0.1100538969039917]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 40, SSIM Loss: 0.11599516868591309\n",
      "Epoch: 19, Batch: 40, D Loss Real: 0.22842557728290558, D Loss Fake: 1.0878206491470337, G Loss: [12.26820182800293, 0.696007251739502, 0.1157219409942627]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 41, SSIM Loss: 0.10220968723297119\n",
      "Epoch: 19, Batch: 41, D Loss Real: 0.16511480510234833, D Loss Fake: 1.105565071105957, G Loss: [10.937554359436035, 0.715435266494751, 0.10222119092941284]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 19, Batch: 42, SSIM Loss: 0.11840939521789551\n",
      "Epoch: 19, Batch: 42, D Loss Real: 0.11076322197914124, D Loss Fake: 1.1199681758880615, G Loss: [12.668599128723145, 0.7429491877555847, 0.11925649642944336]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 43, SSIM Loss: 0.10811114311218262\n",
      "Epoch: 19, Batch: 43, D Loss Real: 0.13533012568950653, D Loss Fake: 0.9874874949455261, G Loss: [11.62042236328125, 0.7836125493049622, 0.10836809873580933]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 44, SSIM Loss: 0.10238015651702881\n",
      "Epoch: 19, Batch: 44, D Loss Real: 0.14721979200839996, D Loss Fake: 1.007691502571106, G Loss: [10.981359481811523, 0.7752081155776978, 0.10206151008605957]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 45, SSIM Loss: 0.12147402763366699\n",
      "Epoch: 19, Batch: 45, D Loss Real: 0.10440873354673386, D Loss Fake: 1.0078998804092407, G Loss: [12.899603843688965, 0.7747975587844849, 0.12124806642532349]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 46, SSIM Loss: 0.10930424928665161\n",
      "Epoch: 19, Batch: 46, D Loss Real: 0.13709045946598053, D Loss Fake: 1.0482897758483887, G Loss: [11.753185272216797, 0.7861932516098022, 0.10966992378234863]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 47, SSIM Loss: 0.12225711345672607\n",
      "Epoch: 19, Batch: 47, D Loss Real: 0.07459255307912827, D Loss Fake: 1.0963557958602905, G Loss: [13.12542724609375, 0.800152063369751, 0.1232527494430542]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 48, SSIM Loss: 0.1060328483581543\n",
      "Epoch: 19, Batch: 48, D Loss Real: 0.16692030429840088, D Loss Fake: 0.9807495474815369, G Loss: [11.349540710449219, 0.7804450392723083, 0.10569095611572266]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 49, SSIM Loss: 0.10943138599395752\n",
      "Epoch: 19, Batch: 49, D Loss Real: 0.1613318920135498, D Loss Fake: 1.0195770263671875, G Loss: [11.739643096923828, 0.726600706577301, 0.1101304292678833]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 50, SSIM Loss: 0.11124807596206665\n",
      "Epoch: 19, Batch: 50, D Loss Real: 0.11605296283960342, D Loss Fake: 1.3469398021697998, G Loss: [11.990174293518066, 0.7997123003005981, 0.11190462112426758]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 51, SSIM Loss: 0.11066478490829468\n",
      "Epoch: 19, Batch: 51, D Loss Real: 0.2638302743434906, D Loss Fake: 1.0016741752624512, G Loss: [11.8655424118042, 0.7736243605613708, 0.11091917753219604]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 52, SSIM Loss: 0.1149410605430603\n",
      "Epoch: 19, Batch: 52, D Loss Real: 0.2782861590385437, D Loss Fake: 1.0517970323562622, G Loss: [12.217379570007324, 0.7047780752182007, 0.11512601375579834]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 53, SSIM Loss: 0.11181354522705078\n",
      "Epoch: 19, Batch: 53, D Loss Real: 0.25538718700408936, D Loss Fake: 1.1341803073883057, G Loss: [11.842893600463867, 0.6617413759231567, 0.11181151866912842]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 54, SSIM Loss: 0.11723172664642334\n",
      "Epoch: 19, Batch: 54, D Loss Real: 0.2184121161699295, D Loss Fake: 1.2134264707565308, G Loss: [12.374626159667969, 0.6389248371124268, 0.11735701560974121]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 55, SSIM Loss: 0.10118895769119263\n",
      "Epoch: 19, Batch: 55, D Loss Real: 0.18113578855991364, D Loss Fake: 1.1147323846817017, G Loss: [10.850950241088867, 0.7137205600738525, 0.10137230157852173]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 56, SSIM Loss: 0.10892277956008911\n",
      "Epoch: 19, Batch: 56, D Loss Real: 0.15986576676368713, D Loss Fake: 1.0383856296539307, G Loss: [11.629779815673828, 0.729812502861023, 0.10899966955184937]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 57, SSIM Loss: 0.1188669204711914\n",
      "Epoch: 19, Batch: 57, D Loss Real: 0.11715438961982727, D Loss Fake: 1.0726120471954346, G Loss: [12.6240873336792, 0.7536612749099731, 0.11870425939559937]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 58, SSIM Loss: 0.11808925867080688\n",
      "Epoch: 19, Batch: 58, D Loss Real: 0.11714261770248413, D Loss Fake: 1.0481547117233276, G Loss: [12.561910629272461, 0.7723739147186279, 0.11789536476135254]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 19, Batch: 59, SSIM Loss: 0.103695809841156\n",
      "Epoch: 19, Batch: 59, D Loss Real: 0.19369177520275116, D Loss Fake: 1.0414108037948608, G Loss: [11.112101554870605, 0.7542684078216553, 0.10357832908630371]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 60, SSIM Loss: 0.11465972661972046\n",
      "Epoch: 19, Batch: 60, D Loss Real: 0.14908155798912048, D Loss Fake: 1.029856562614441, G Loss: [12.266011238098145, 0.7496839761734009, 0.11516326665878296]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 61, SSIM Loss: 0.11188220977783203\n",
      "Epoch: 19, Batch: 61, D Loss Real: 0.12963517010211945, D Loss Fake: 1.7680537700653076, G Loss: [12.1939058303833, 0.7890462875366211, 0.11404860019683838]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 19, Batch: 62, SSIM Loss: 0.11708921194076538\n",
      "Epoch: 19, Batch: 62, D Loss Real: 0.38726598024368286, D Loss Fake: 1.3747798204421997, G Loss: [12.596299171447754, 0.902159571647644, 0.11694139242172241]\n",
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:38:39.668567: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:38:41.137460: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Batch: 1, SSIM Loss: 0.10655862092971802\n",
      "Epoch: 20, Batch: 1, D Loss Real: 0.38505473732948303, D Loss Fake: 1.156968593597412, G Loss: [11.324234962463379, 0.6973171234130859, 0.10626918077468872]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 20, Batch: 2, SSIM Loss: 0.10571295022964478\n",
      "Epoch: 20, Batch: 2, D Loss Real: 0.34459391236305237, D Loss Fake: 1.1901508569717407, G Loss: [11.209808349609375, 0.6374699473381042, 0.10572338104248047]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 3, SSIM Loss: 0.11640548706054688\n",
      "Epoch: 20, Batch: 3, D Loss Real: 0.3035048842430115, D Loss Fake: 1.2293671369552612, G Loss: [12.256245613098145, 0.6142005324363708, 0.1164204478263855]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 4, SSIM Loss: 0.11735564470291138\n",
      "Epoch: 20, Batch: 4, D Loss Real: 0.30163508653640747, D Loss Fake: 1.239013671875, G Loss: [12.33883285522461, 0.619510293006897, 0.11719322204589844]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 20, Batch: 5, SSIM Loss: 0.1084449291229248\n",
      "Epoch: 20, Batch: 5, D Loss Real: 0.31350600719451904, D Loss Fake: 1.2391997575759888, G Loss: [11.484637260437012, 0.6181745529174805, 0.1086646318435669]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 6, SSIM Loss: 0.10916751623153687\n",
      "Epoch: 20, Batch: 6, D Loss Real: 0.29918399453163147, D Loss Fake: 1.2002050876617432, G Loss: [11.517204284667969, 0.6322037577629089, 0.10885000228881836]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 7, SSIM Loss: 0.11201304197311401\n",
      "Epoch: 20, Batch: 7, D Loss Real: 0.315865159034729, D Loss Fake: 1.2165240049362183, G Loss: [11.824980735778809, 0.6272286772727966, 0.11197751760482788]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 8, SSIM Loss: 0.10693448781967163\n",
      "Epoch: 20, Batch: 8, D Loss Real: 0.3320823609828949, D Loss Fake: 1.2026344537734985, G Loss: [11.366589546203613, 0.6255467534065247, 0.10741043090820312]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 20, Batch: 9, SSIM Loss: 0.11447298526763916\n",
      "Epoch: 20, Batch: 9, D Loss Real: 0.30164557695388794, D Loss Fake: 1.222529649734497, G Loss: [12.078760147094727, 0.6150942444801331, 0.11463665962219238]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 10, SSIM Loss: 0.10623270273208618\n",
      "Epoch: 20, Batch: 10, D Loss Real: 0.3008480966091156, D Loss Fake: 1.2137831449508667, G Loss: [11.266593933105469, 0.626234769821167, 0.10640358924865723]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 11, SSIM Loss: 0.10718846321105957\n",
      "Epoch: 20, Batch: 11, D Loss Real: 0.2985125184059143, D Loss Fake: 1.2107096910476685, G Loss: [11.342582702636719, 0.6266325116157532, 0.10715949535369873]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 12, SSIM Loss: 0.108623206615448\n",
      "Epoch: 20, Batch: 12, D Loss Real: 0.29251161217689514, D Loss Fake: 1.2098655700683594, G Loss: [11.446367263793945, 0.6212461590766907, 0.10825121402740479]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 13, SSIM Loss: 0.11679613590240479\n",
      "Epoch: 20, Batch: 13, D Loss Real: 0.2721286416053772, D Loss Fake: 1.2160941362380981, G Loss: [12.304288864135742, 0.6302720308303833, 0.1167401671409607]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 20, Batch: 14, SSIM Loss: 0.11400401592254639\n",
      "Epoch: 20, Batch: 14, D Loss Real: 0.27989763021469116, D Loss Fake: 1.2103252410888672, G Loss: [12.065999984741211, 0.6328034400939941, 0.11433196067810059]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 15, SSIM Loss: 0.11559462547302246\n",
      "Epoch: 20, Batch: 15, D Loss Real: 0.29677218198776245, D Loss Fake: 1.2138108015060425, G Loss: [12.231119155883789, 0.6285508871078491, 0.11602568626403809]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 16, SSIM Loss: 0.11039459705352783\n",
      "Epoch: 20, Batch: 16, D Loss Real: 0.2773888409137726, D Loss Fake: 1.1449859142303467, G Loss: [11.70428466796875, 0.6567122936248779, 0.11047571897506714]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 20, Batch: 17, SSIM Loss: 0.110176682472229\n",
      "Epoch: 20, Batch: 17, D Loss Real: 0.2533518075942993, D Loss Fake: 1.1443331241607666, G Loss: [11.67214298248291, 0.662211537361145, 0.11009931564331055]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 20, Batch: 18, SSIM Loss: 0.10652554035186768\n",
      "Epoch: 20, Batch: 18, D Loss Real: 0.23806801438331604, D Loss Fake: 1.214303970336914, G Loss: [11.29503345489502, 0.6512649655342102, 0.10643768310546875]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 20, Batch: 19, SSIM Loss: 0.11155253648757935\n",
      "Epoch: 20, Batch: 19, D Loss Real: 0.19578315317630768, D Loss Fake: 1.202100157737732, G Loss: [11.801410675048828, 0.6687301993370056, 0.11132681369781494]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 20, SSIM Loss: 0.11191397905349731\n",
      "Epoch: 20, Batch: 20, D Loss Real: 0.22020331025123596, D Loss Fake: 1.1246494054794312, G Loss: [11.882536888122559, 0.695722758769989, 0.11186814308166504]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 21, SSIM Loss: 0.10549521446228027\n",
      "Epoch: 20, Batch: 21, D Loss Real: 0.19667424261569977, D Loss Fake: 1.0726302862167358, G Loss: [11.305623054504395, 0.7097653746604919, 0.10595858097076416]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 22, SSIM Loss: 0.10385501384735107\n",
      "Epoch: 20, Batch: 22, D Loss Real: 0.18358749151229858, D Loss Fake: 1.2428812980651855, G Loss: [11.120807647705078, 0.7131099700927734, 0.10407698154449463]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 23, SSIM Loss: 0.11480104923248291\n",
      "Epoch: 20, Batch: 23, D Loss Real: 0.20059555768966675, D Loss Fake: 1.0929738283157349, G Loss: [12.23859977722168, 0.7226430773735046, 0.11515957117080688]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 24, SSIM Loss: 0.11687660217285156\n",
      "Epoch: 20, Batch: 24, D Loss Real: 0.19282953441143036, D Loss Fake: 1.0394434928894043, G Loss: [12.407400131225586, 0.7353916764259338, 0.11672008037567139]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 25, SSIM Loss: 0.10578358173370361\n",
      "Epoch: 20, Batch: 25, D Loss Real: 0.14817562699317932, D Loss Fake: 1.0987701416015625, G Loss: [11.291142463684082, 0.7140777707099915, 0.10577064752578735]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 26, SSIM Loss: 0.10959857702255249\n",
      "Epoch: 20, Batch: 26, D Loss Real: 0.14008484780788422, D Loss Fake: 1.1854701042175293, G Loss: [11.684622764587402, 0.6999750733375549, 0.10984647274017334]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 20, Batch: 27, SSIM Loss: 0.10805195569992065\n",
      "Epoch: 20, Batch: 27, D Loss Real: 0.1624201238155365, D Loss Fake: 1.1770650148391724, G Loss: [11.503899574279785, 0.7353426218032837, 0.10768556594848633]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 28, SSIM Loss: 0.10325509309768677\n",
      "Epoch: 20, Batch: 28, D Loss Real: 0.16580572724342346, D Loss Fake: 1.0481160879135132, G Loss: [11.10086727142334, 0.7546157240867615, 0.10346251726150513]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 29, SSIM Loss: 0.11630368232727051\n",
      "Epoch: 20, Batch: 29, D Loss Real: 0.2075791358947754, D Loss Fake: 1.1603474617004395, G Loss: [12.323528289794922, 0.7096532583236694, 0.116138756275177]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 30, SSIM Loss: 0.112282395362854\n",
      "Epoch: 20, Batch: 30, D Loss Real: 0.11839351058006287, D Loss Fake: 1.1310213804244995, G Loss: [11.984675407409668, 0.7583664655685425, 0.11226308345794678]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 31, SSIM Loss: 0.10666310787200928\n",
      "Epoch: 20, Batch: 31, D Loss Real: 0.19665974378585815, D Loss Fake: 1.0838470458984375, G Loss: [11.39582633972168, 0.7231616377830505, 0.10672664642333984]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 32, SSIM Loss: 0.10895919799804688\n",
      "Epoch: 20, Batch: 32, D Loss Real: 0.15375569462776184, D Loss Fake: 1.1120576858520508, G Loss: [11.61806583404541, 0.7505175471305847, 0.10867547988891602]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 33, SSIM Loss: 0.11056983470916748\n",
      "Epoch: 20, Batch: 33, D Loss Real: 0.2358667552471161, D Loss Fake: 1.1564313173294067, G Loss: [11.745102882385254, 0.6912187337875366, 0.11053884029388428]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 34, SSIM Loss: 0.10945916175842285\n",
      "Epoch: 20, Batch: 34, D Loss Real: 0.19591926038265228, D Loss Fake: 1.150336742401123, G Loss: [11.64010238647461, 0.706822395324707, 0.10933279991149902]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 35, SSIM Loss: 0.09700191020965576\n",
      "Epoch: 20, Batch: 35, D Loss Real: 0.27154797315597534, D Loss Fake: 1.1202905178070068, G Loss: [10.404025077819824, 0.6869477033615112, 0.09717077016830444]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 36, SSIM Loss: 0.11406552791595459\n",
      "Epoch: 20, Batch: 36, D Loss Real: 0.2128697782754898, D Loss Fake: 1.5333709716796875, G Loss: [12.080131530761719, 0.6995963454246521, 0.11380535364151001]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 37, SSIM Loss: 0.1050558090209961\n",
      "Epoch: 20, Batch: 37, D Loss Real: 0.28859055042266846, D Loss Fake: 1.1782920360565186, G Loss: [11.196479797363281, 0.7160643935203552, 0.1048041582107544]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 38, SSIM Loss: 0.12094390392303467\n",
      "Epoch: 20, Batch: 38, D Loss Real: 0.3188357651233673, D Loss Fake: 1.1780537366867065, G Loss: [12.7626953125, 0.6744858622550964, 0.12088209390640259]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 39, SSIM Loss: 0.10707753896713257\n",
      "Epoch: 20, Batch: 39, D Loss Real: 0.3367013931274414, D Loss Fake: 1.177321195602417, G Loss: [11.334609031677246, 0.6384841799736023, 0.10696125030517578]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 40, SSIM Loss: 0.11338496208190918\n",
      "Epoch: 20, Batch: 40, D Loss Real: 0.292462021112442, D Loss Fake: 1.1979286670684814, G Loss: [12.016242027282715, 0.622302234172821, 0.11393940448760986]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 41, SSIM Loss: 0.10251957178115845\n",
      "Epoch: 20, Batch: 41, D Loss Real: 0.3106691837310791, D Loss Fake: 1.2087033987045288, G Loss: [10.866445541381836, 0.6065422892570496, 0.10259902477264404]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 42, SSIM Loss: 0.11636233329772949\n",
      "Epoch: 20, Batch: 42, D Loss Real: 0.2469848394393921, D Loss Fake: 1.2101746797561646, G Loss: [12.197999954223633, 0.6191897392272949, 0.11578810214996338]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 43, SSIM Loss: 0.10721403360366821\n",
      "Epoch: 20, Batch: 43, D Loss Real: 0.24408172070980072, D Loss Fake: 1.1482880115509033, G Loss: [11.37822151184082, 0.6557990908622742, 0.1072242259979248]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 20, Batch: 44, SSIM Loss: 0.10055804252624512\n",
      "Epoch: 20, Batch: 44, D Loss Real: 0.24406053125858307, D Loss Fake: 1.128199577331543, G Loss: [10.732074737548828, 0.6661013960838318, 0.10065972805023193]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 45, SSIM Loss: 0.11955839395523071\n",
      "Epoch: 20, Batch: 45, D Loss Real: 0.18243280053138733, D Loss Fake: 1.1193645000457764, G Loss: [12.643014907836914, 0.6850780248641968, 0.11957937479019165]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 46, SSIM Loss: 0.10968172550201416\n",
      "Epoch: 20, Batch: 46, D Loss Real: 0.19223392009735107, D Loss Fake: 1.105341911315918, G Loss: [11.669479370117188, 0.6980822682380676, 0.10971397161483765]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 47, SSIM Loss: 0.1212759017944336\n",
      "Epoch: 20, Batch: 47, D Loss Real: 0.11929395794868469, D Loss Fake: 1.0931135416030884, G Loss: [12.865036964416504, 0.7277909517288208, 0.12137246131896973]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 48, SSIM Loss: 0.10456681251525879\n",
      "Epoch: 20, Batch: 48, D Loss Real: 0.1545506864786148, D Loss Fake: 1.2816241979599, G Loss: [11.18450927734375, 0.7693904638290405, 0.10415118932723999]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 49, SSIM Loss: 0.10702890157699585\n",
      "Epoch: 20, Batch: 49, D Loss Real: 0.2672707438468933, D Loss Fake: 1.0503355264663696, G Loss: [11.484795570373535, 0.7417739629745483, 0.10743021965026855]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 50, SSIM Loss: 0.11110353469848633\n",
      "Epoch: 20, Batch: 50, D Loss Real: 0.2831330895423889, D Loss Fake: 1.0972944498062134, G Loss: [11.763476371765137, 0.6847080588340759, 0.11078768968582153]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 51, SSIM Loss: 0.11081719398498535\n",
      "Epoch: 20, Batch: 51, D Loss Real: 0.226891428232193, D Loss Fake: 1.1386674642562866, G Loss: [11.747016906738281, 0.6703393459320068, 0.11076676845550537]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 52, SSIM Loss: 0.11354583501815796\n",
      "Epoch: 20, Batch: 52, D Loss Real: 0.144331157207489, D Loss Fake: 1.076528549194336, G Loss: [12.074302673339844, 0.707660973072052, 0.11366641521453857]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 53, SSIM Loss: 0.11133182048797607\n",
      "Epoch: 20, Batch: 53, D Loss Real: 0.16622000932693481, D Loss Fake: 1.1037728786468506, G Loss: [11.798648834228516, 0.7096939086914062, 0.11088955402374268]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 54, SSIM Loss: 0.11414980888366699\n",
      "Epoch: 20, Batch: 54, D Loss Real: 0.14353574812412262, D Loss Fake: 1.3931106328964233, G Loss: [12.10048770904541, 0.7641251087188721, 0.11336362361907959]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 55, SSIM Loss: 0.10099029541015625\n",
      "Epoch: 20, Batch: 55, D Loss Real: 0.2432587444782257, D Loss Fake: 0.9941831231117249, G Loss: [10.827973365783691, 0.7702143788337708, 0.10057759284973145]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 56, SSIM Loss: 0.10769999027252197\n",
      "Epoch: 20, Batch: 56, D Loss Real: 0.2474341094493866, D Loss Fake: 1.0291351079940796, G Loss: [11.51447868347168, 0.7205838561058044, 0.10793894529342651]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 20, Batch: 57, SSIM Loss: 0.11703944206237793\n",
      "Epoch: 20, Batch: 57, D Loss Real: 0.17886397242546082, D Loss Fake: 1.0947257280349731, G Loss: [12.375911712646484, 0.6758055686950684, 0.11700105667114258]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 58, SSIM Loss: 0.11716580390930176\n",
      "Epoch: 20, Batch: 58, D Loss Real: 0.126928448677063, D Loss Fake: 1.2104299068450928, G Loss: [12.372875213623047, 0.7022619247436523, 0.11670613288879395]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 59, SSIM Loss: 0.10265177488327026\n",
      "Epoch: 20, Batch: 59, D Loss Real: 0.17337331175804138, D Loss Fake: 1.0743924379348755, G Loss: [10.96004581451416, 0.7378495931625366, 0.10222196578979492]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 60, SSIM Loss: 0.11034446954727173\n",
      "Epoch: 20, Batch: 60, D Loss Real: 0.14691057801246643, D Loss Fake: 1.0346640348434448, G Loss: [11.791593551635742, 0.7617244720458984, 0.11029869318008423]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 20, Batch: 61, SSIM Loss: 0.10291785001754761\n",
      "Epoch: 20, Batch: 61, D Loss Real: 0.1361701637506485, D Loss Fake: 1.4009552001953125, G Loss: [11.121699333190918, 0.7700594067573547, 0.10351639986038208]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 20, Batch: 62, SSIM Loss: 0.11961537599563599\n",
      "Epoch: 20, Batch: 62, D Loss Real: 0.277833491563797, D Loss Fake: 1.2606922388076782, G Loss: [12.626847267150879, 0.7830228209495544, 0.1184382438659668]\n",
      "\n",
      "Epoch 20: val_loss improved from inf to 12.62685, saving model to checkpoints/model_checkpoint_{epoch:02d}_{val_loss:.2f}\n",
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:40:07.028263: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:40:08.594656: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Batch: 1, SSIM Loss: 0.1052544116973877\n",
      "Epoch: 21, Batch: 1, D Loss Real: 0.331993043422699, D Loss Fake: 1.071453332901001, G Loss: [11.26407241821289, 0.7264714241027832, 0.10537600517272949]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 2, SSIM Loss: 0.10612493753433228\n",
      "Epoch: 21, Batch: 2, D Loss Real: 0.29897770285606384, D Loss Fake: 1.1079790592193604, G Loss: [11.243836402893066, 0.6677071452140808, 0.10576128959655762]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 21, Batch: 3, SSIM Loss: 0.11592650413513184\n",
      "Epoch: 21, Batch: 3, D Loss Real: 0.17666186392307281, D Loss Fake: 1.120688796043396, G Loss: [12.277188301086426, 0.6781006455421448, 0.11599087715148926]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 4, SSIM Loss: 0.11555075645446777\n",
      "Epoch: 21, Batch: 4, D Loss Real: 0.22451478242874146, D Loss Fake: 1.1021591424942017, G Loss: [12.225625038146973, 0.6769267916679382, 0.1154869794845581]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 5, SSIM Loss: 0.10869598388671875\n",
      "Epoch: 21, Batch: 5, D Loss Real: 0.18177294731140137, D Loss Fake: 1.1535184383392334, G Loss: [11.551721572875977, 0.6737896800041199, 0.10877931118011475]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 6, SSIM Loss: 0.10693323612213135\n",
      "Epoch: 21, Batch: 6, D Loss Real: 0.11709743738174438, D Loss Fake: 1.058093547821045, G Loss: [11.474185943603516, 0.7449981570243835, 0.10729187726974487]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 7, SSIM Loss: 0.1098739504814148\n",
      "Epoch: 21, Batch: 7, D Loss Real: 0.12218961119651794, D Loss Fake: 1.0413769483566284, G Loss: [11.76059341430664, 0.7544653415679932, 0.11006128787994385]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 8, SSIM Loss: 0.10589545965194702\n",
      "Epoch: 21, Batch: 8, D Loss Real: 0.18180282413959503, D Loss Fake: 1.1079535484313965, G Loss: [11.34382152557373, 0.7414662837982178, 0.10602355003356934]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 21, Batch: 9, SSIM Loss: 0.11146438121795654\n",
      "Epoch: 21, Batch: 9, D Loss Real: 0.1487147957086563, D Loss Fake: 1.074892520904541, G Loss: [11.908677101135254, 0.751534640789032, 0.11157143115997314]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 10, SSIM Loss: 0.10607165098190308\n",
      "Epoch: 21, Batch: 10, D Loss Real: 0.11896413564682007, D Loss Fake: 1.1625727415084839, G Loss: [11.393451690673828, 0.7675167918205261, 0.10625934600830078]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 11, SSIM Loss: 0.10648304224014282\n",
      "Epoch: 21, Batch: 11, D Loss Real: 0.183000847697258, D Loss Fake: 1.0248664617538452, G Loss: [11.361873626708984, 0.7539455890655518, 0.10607928037643433]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 12, SSIM Loss: 0.10744422674179077\n",
      "Epoch: 21, Batch: 12, D Loss Real: 0.1716173142194748, D Loss Fake: 1.0940091609954834, G Loss: [11.469083786010742, 0.7229390144348145, 0.10746145248413086]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 13, SSIM Loss: 0.1130172610282898\n",
      "Epoch: 21, Batch: 13, D Loss Real: 0.12042352557182312, D Loss Fake: 1.1032822132110596, G Loss: [12.049927711486816, 0.7428675293922424, 0.11307060718536377]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 14, SSIM Loss: 0.11139297485351562\n",
      "Epoch: 21, Batch: 14, D Loss Real: 0.12063499540090561, D Loss Fake: 1.0569361448287964, G Loss: [11.917745590209961, 0.7772378921508789, 0.11140507459640503]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 15, SSIM Loss: 0.11506903171539307\n",
      "Epoch: 21, Batch: 15, D Loss Real: 0.19879764318466187, D Loss Fake: 1.0625077486038208, G Loss: [12.265278816223145, 0.7692958116531372, 0.11495983600616455]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 16, SSIM Loss: 0.11149615049362183\n",
      "Epoch: 21, Batch: 16, D Loss Real: 0.1554935723543167, D Loss Fake: 1.0587785243988037, G Loss: [11.7833890914917, 0.7652921080589294, 0.11018097400665283]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 17, SSIM Loss: 0.10826849937438965\n",
      "Epoch: 21, Batch: 17, D Loss Real: 0.18429937958717346, D Loss Fake: 1.0467931032180786, G Loss: [11.619321823120117, 0.7371404767036438, 0.1088218092918396]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 18, SSIM Loss: 0.10646617412567139\n",
      "Epoch: 21, Batch: 18, D Loss Real: 0.1313374638557434, D Loss Fake: 1.108948826789856, G Loss: [11.380940437316895, 0.7512505054473877, 0.10629689693450928]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 19, SSIM Loss: 0.11088520288467407\n",
      "Epoch: 21, Batch: 19, D Loss Real: 0.08267535269260406, D Loss Fake: 1.0622035264968872, G Loss: [11.847171783447266, 0.7843226790428162, 0.11062848567962646]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 21, Batch: 20, SSIM Loss: 0.11023736000061035\n",
      "Epoch: 21, Batch: 20, D Loss Real: 0.1565280705690384, D Loss Fake: 0.9875932931900024, G Loss: [11.860723495483398, 0.7873136401176453, 0.11073410511016846]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 21, SSIM Loss: 0.105110764503479\n",
      "Epoch: 21, Batch: 21, D Loss Real: 0.10630033165216446, D Loss Fake: 1.0343244075775146, G Loss: [11.286660194396973, 0.7938819527626038, 0.10492777824401855]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 22, SSIM Loss: 0.10485023260116577\n",
      "Epoch: 21, Batch: 22, D Loss Real: 0.12097858637571335, D Loss Fake: 1.1362468004226685, G Loss: [11.274147987365723, 0.7836647629737854, 0.10490483045578003]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 23, SSIM Loss: 0.11391520500183105\n",
      "Epoch: 21, Batch: 23, D Loss Real: 0.1503061205148697, D Loss Fake: 0.9724393486976624, G Loss: [12.263936996459961, 0.8026678562164307, 0.11461269855499268]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 24, SSIM Loss: 0.1149061918258667\n",
      "Epoch: 21, Batch: 24, D Loss Real: 0.10001164674758911, D Loss Fake: 0.9673076868057251, G Loss: [12.30497932434082, 0.7971585988998413, 0.11507821083068848]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 25, SSIM Loss: 0.10439407825469971\n",
      "Epoch: 21, Batch: 25, D Loss Real: 0.078265480697155, D Loss Fake: 0.9929543733596802, G Loss: [11.220829963684082, 0.7992377877235413, 0.10421591997146606]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 26, SSIM Loss: 0.10535776615142822\n",
      "Epoch: 21, Batch: 26, D Loss Real: 0.07772424072027206, D Loss Fake: 1.096862554550171, G Loss: [11.344884872436523, 0.7763195037841797, 0.10568565130233765]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 21, Batch: 27, SSIM Loss: 0.10566145181655884\n",
      "Epoch: 21, Batch: 27, D Loss Real: 0.11494040489196777, D Loss Fake: 1.079996109008789, G Loss: [11.331114768981934, 0.7869466543197632, 0.10544168949127197]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 28, SSIM Loss: 0.10163336992263794\n",
      "Epoch: 21, Batch: 28, D Loss Real: 0.09928788244724274, D Loss Fake: 1.0142440795898438, G Loss: [11.022931098937988, 0.8231346011161804, 0.101997971534729]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 29, SSIM Loss: 0.11575484275817871\n",
      "Epoch: 21, Batch: 29, D Loss Real: 0.19637924432754517, D Loss Fake: 1.0630604028701782, G Loss: [12.384510040283203, 0.8018496632575989, 0.11582660675048828]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 21, Batch: 30, SSIM Loss: 0.11162543296813965\n",
      "Epoch: 21, Batch: 30, D Loss Real: 0.09014604985713959, D Loss Fake: 1.1069164276123047, G Loss: [12.01903247833252, 0.8512385487556458, 0.11167794466018677]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 31, SSIM Loss: 0.10554993152618408\n",
      "Epoch: 21, Batch: 31, D Loss Real: 0.22387701272964478, D Loss Fake: 1.0145138502120972, G Loss: [11.298657417297363, 0.7595659494400024, 0.10539090633392334]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 32, SSIM Loss: 0.10686171054840088\n",
      "Epoch: 21, Batch: 32, D Loss Real: 0.14971612393856049, D Loss Fake: 1.088937520980835, G Loss: [11.473871231079102, 0.7587679028511047, 0.10715103149414062]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 33, SSIM Loss: 0.10991394519805908\n",
      "Epoch: 21, Batch: 33, D Loss Real: 0.23638586699962616, D Loss Fake: 1.1184347867965698, G Loss: [11.66976547241211, 0.7190457582473755, 0.10950720310211182]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 34, SSIM Loss: 0.10702908039093018\n",
      "Epoch: 21, Batch: 34, D Loss Real: 0.1635795384645462, D Loss Fake: 1.0581045150756836, G Loss: [11.478464126586914, 0.7341786623001099, 0.10744285583496094]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 35, SSIM Loss: 0.09715509414672852\n",
      "Epoch: 21, Batch: 35, D Loss Real: 0.19958597421646118, D Loss Fake: 1.1307213306427002, G Loss: [10.390615463256836, 0.709366500377655, 0.09681248664855957]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 36, SSIM Loss: 0.11062109470367432\n",
      "Epoch: 21, Batch: 36, D Loss Real: 0.13159716129302979, D Loss Fake: 1.381542682647705, G Loss: [11.802159309387207, 0.7401039600372314, 0.11062055826187134]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 37, SSIM Loss: 0.10372436046600342\n",
      "Epoch: 21, Batch: 37, D Loss Real: 0.2615623474121094, D Loss Fake: 1.4666467905044556, G Loss: [11.163987159729004, 0.8173603415489197, 0.10346627235412598]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 38, SSIM Loss: 0.11868268251419067\n",
      "Epoch: 21, Batch: 38, D Loss Real: 0.3083966076374054, D Loss Fake: 1.1198548078536987, G Loss: [12.581146240234375, 0.7766129374504089, 0.11804533004760742]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 21, Batch: 39, SSIM Loss: 0.1052703857421875\n",
      "Epoch: 21, Batch: 39, D Loss Real: 0.3666638135910034, D Loss Fake: 1.1145427227020264, G Loss: [11.180046081542969, 0.6600115299224854, 0.10520035028457642]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 40, SSIM Loss: 0.10966938734054565\n",
      "Epoch: 21, Batch: 40, D Loss Real: 0.298114538192749, D Loss Fake: 1.1834686994552612, G Loss: [11.612918853759766, 0.616398274898529, 0.10996520519256592]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 41, SSIM Loss: 0.09903895854949951\n",
      "Epoch: 21, Batch: 41, D Loss Real: 0.31001633405685425, D Loss Fake: 1.2287380695343018, G Loss: [10.51641845703125, 0.5871425867080688, 0.09929275512695312]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 42, SSIM Loss: 0.11182951927185059\n",
      "Epoch: 21, Batch: 42, D Loss Real: 0.24362704157829285, D Loss Fake: 1.216825008392334, G Loss: [11.789335250854492, 0.6054768562316895, 0.11183857917785645]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 43, SSIM Loss: 0.10795056819915771\n",
      "Epoch: 21, Batch: 43, D Loss Real: 0.25335532426834106, D Loss Fake: 1.1876325607299805, G Loss: [11.354415893554688, 0.6256809234619141, 0.10728734731674194]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 44, SSIM Loss: 0.09991800785064697\n",
      "Epoch: 21, Batch: 44, D Loss Real: 0.25194159150123596, D Loss Fake: 1.142984390258789, G Loss: [10.644001007080078, 0.6504536867141724, 0.09993547201156616]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 45, SSIM Loss: 0.11961734294891357\n",
      "Epoch: 21, Batch: 45, D Loss Real: 0.24509157240390778, D Loss Fake: 1.1326624155044556, G Loss: [12.538969039916992, 0.6666184067726135, 0.11872351169586182]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 46, SSIM Loss: 0.1102287769317627\n",
      "Epoch: 21, Batch: 46, D Loss Real: 0.21319490671157837, D Loss Fake: 1.1118297576904297, G Loss: [11.6817045211792, 0.6817029118537903, 0.11000001430511475]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 47, SSIM Loss: 0.12049245834350586\n",
      "Epoch: 21, Batch: 47, D Loss Real: 0.16603463888168335, D Loss Fake: 1.0971726179122925, G Loss: [12.769272804260254, 0.7044817805290222, 0.12064790725708008]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 21, Batch: 48, SSIM Loss: 0.10319674015045166\n",
      "Epoch: 21, Batch: 48, D Loss Real: 0.22546400129795074, D Loss Fake: 1.0840061902999878, G Loss: [11.004261016845703, 0.6950117945671082, 0.1030924916267395]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 49, SSIM Loss: 0.10713851451873779\n",
      "Epoch: 21, Batch: 49, D Loss Real: 0.14503754675388336, D Loss Fake: 1.08951735496521, G Loss: [11.42979907989502, 0.7207279801368713, 0.10709071159362793]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 50, SSIM Loss: 0.10935473442077637\n",
      "Epoch: 21, Batch: 50, D Loss Real: 0.13922542333602905, D Loss Fake: 1.0610721111297607, G Loss: [11.639623641967773, 0.7431371212005615, 0.10896486043930054]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 51, SSIM Loss: 0.10851222276687622\n",
      "Epoch: 21, Batch: 51, D Loss Real: 0.1562226116657257, D Loss Fake: 1.0600159168243408, G Loss: [11.611027717590332, 0.7553529739379883, 0.10855674743652344]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 52, SSIM Loss: 0.11071646213531494\n",
      "Epoch: 21, Batch: 52, D Loss Real: 0.0920007973909378, D Loss Fake: 1.0038456916809082, G Loss: [11.822444915771484, 0.7796826362609863, 0.1104276180267334]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 53, SSIM Loss: 0.10873502492904663\n",
      "Epoch: 21, Batch: 53, D Loss Real: 0.12336281687021255, D Loss Fake: 1.010960578918457, G Loss: [11.664580345153809, 0.7660858631134033, 0.10898494720458984]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 54, SSIM Loss: 0.11106133460998535\n",
      "Epoch: 21, Batch: 54, D Loss Real: 0.1317271739244461, D Loss Fake: 1.190105676651001, G Loss: [11.871665954589844, 0.79838627576828, 0.1107327938079834]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 55, SSIM Loss: 0.10100317001342773\n",
      "Epoch: 21, Batch: 55, D Loss Real: 0.14511819183826447, D Loss Fake: 0.9790640473365784, G Loss: [10.907442092895508, 0.7969024777412415, 0.10110539197921753]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 56, SSIM Loss: 0.10723960399627686\n",
      "Epoch: 21, Batch: 56, D Loss Real: 0.17907947301864624, D Loss Fake: 0.9907815456390381, G Loss: [11.511008262634277, 0.7730527520179749, 0.10737955570220947]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 21, Batch: 57, SSIM Loss: 0.11492884159088135\n",
      "Epoch: 21, Batch: 57, D Loss Real: 0.10750028491020203, D Loss Fake: 1.0418373346328735, G Loss: [12.266840934753418, 0.7544236779212952, 0.1151241660118103]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 58, SSIM Loss: 0.11330467462539673\n",
      "Epoch: 21, Batch: 58, D Loss Real: 0.07952408492565155, D Loss Fake: 1.058948278427124, G Loss: [12.12435245513916, 0.7769745588302612, 0.11347377300262451]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 59, SSIM Loss: 0.10041040182113647\n",
      "Epoch: 21, Batch: 59, D Loss Real: 0.13640543818473816, D Loss Fake: 1.0065698623657227, G Loss: [10.908853530883789, 0.7889743447303772, 0.10119879245758057]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 60, SSIM Loss: 0.10973823070526123\n",
      "Epoch: 21, Batch: 60, D Loss Real: 0.12282838672399521, D Loss Fake: 1.0631626844406128, G Loss: [11.672117233276367, 0.7740515470504761, 0.10898065567016602]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 61, SSIM Loss: 0.10369044542312622\n",
      "Epoch: 21, Batch: 61, D Loss Real: 0.1134779304265976, D Loss Fake: 1.0171557664871216, G Loss: [10.994969367980957, 0.7906244397163391, 0.10204344987869263]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21, Batch: 62, SSIM Loss: 0.11255687475204468\n",
      "Epoch: 21, Batch: 62, D Loss Real: 0.08511002361774445, D Loss Fake: 0.99586021900177, G Loss: [11.842473983764648, 0.7944192886352539, 0.11048054695129395]\n",
      "1/1 [==============================] - 0s 145ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:41:30.215576: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:41:31.690633: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Batch: 1, SSIM Loss: 0.10568487644195557\n",
      "Epoch: 22, Batch: 1, D Loss Real: 0.09884092211723328, D Loss Fake: 0.9534288048744202, G Loss: [11.372262001037598, 0.8004781007766724, 0.10571783781051636]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 2, SSIM Loss: 0.10454928874969482\n",
      "Epoch: 22, Batch: 2, D Loss Real: 0.09197692573070526, D Loss Fake: 0.9411097168922424, G Loss: [11.23289966583252, 0.8048885464668274, 0.10428011417388916]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 22, Batch: 3, SSIM Loss: 0.11495906114578247\n",
      "Epoch: 22, Batch: 3, D Loss Real: 0.05105990171432495, D Loss Fake: 0.9402074813842773, G Loss: [12.327275276184082, 0.8260586261749268, 0.11501216888427734]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 4, SSIM Loss: 0.11531585454940796\n",
      "Epoch: 22, Batch: 4, D Loss Real: 0.08870123326778412, D Loss Fake: 0.9928039312362671, G Loss: [12.355313301086426, 0.8365434408187866, 0.11518770456314087]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 5, SSIM Loss: 0.10791754722595215\n",
      "Epoch: 22, Batch: 5, D Loss Real: 0.10965459793806076, D Loss Fake: 0.9913523197174072, G Loss: [11.60848331451416, 0.825120747089386, 0.1078336238861084]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 22, Batch: 6, SSIM Loss: 0.10496580600738525\n",
      "Epoch: 22, Batch: 6, D Loss Real: 0.08400136977434158, D Loss Fake: 0.9390005469322205, G Loss: [11.32420825958252, 0.8309180736541748, 0.10493290424346924]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 22, Batch: 7, SSIM Loss: 0.10997378826141357\n",
      "Epoch: 22, Batch: 7, D Loss Real: 0.0982436090707779, D Loss Fake: 0.9793274402618408, G Loss: [11.774303436279297, 0.7984423041343689, 0.10975861549377441]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 22, Batch: 8, SSIM Loss: 0.10497748851776123\n",
      "Epoch: 22, Batch: 8, D Loss Real: 0.12688156962394714, D Loss Fake: 1.0332587957382202, G Loss: [11.276619911193848, 0.7931525111198425, 0.1048346757888794]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 9, SSIM Loss: 0.1110239028930664\n",
      "Epoch: 22, Batch: 9, D Loss Real: 0.08939655870199203, D Loss Fake: 1.0291019678115845, G Loss: [11.885514259338379, 0.7995569705963135, 0.11085957288742065]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 10, SSIM Loss: 0.10465061664581299\n",
      "Epoch: 22, Batch: 10, D Loss Real: 0.08745958656072617, D Loss Fake: 1.0653718709945679, G Loss: [11.256208419799805, 0.8028596043586731, 0.10453349351882935]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 11, SSIM Loss: 0.10312986373901367\n",
      "Epoch: 22, Batch: 11, D Loss Real: 0.07227569073438644, D Loss Fake: 1.628919005393982, G Loss: [11.247454643249512, 0.9315115213394165, 0.10315942764282227]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 12, SSIM Loss: 0.10560959577560425\n",
      "Epoch: 22, Batch: 12, D Loss Real: 0.24795211851596832, D Loss Fake: 1.0989892482757568, G Loss: [11.460951805114746, 0.9074124693870544, 0.10553538799285889]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 13, SSIM Loss: 0.1102222204208374\n",
      "Epoch: 22, Batch: 13, D Loss Real: 0.34768861532211304, D Loss Fake: 1.095381259918213, G Loss: [11.744060516357422, 0.7578639984130859, 0.10986196994781494]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 14, SSIM Loss: 0.1099247932434082\n",
      "Epoch: 22, Batch: 14, D Loss Real: 0.2577844262123108, D Loss Fake: 1.0961428880691528, G Loss: [11.658343315124512, 0.678327202796936, 0.10980015993118286]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 15, SSIM Loss: 0.11200451850891113\n",
      "Epoch: 22, Batch: 15, D Loss Real: 0.2546263337135315, D Loss Fake: 1.1492788791656494, G Loss: [11.818655014038086, 0.6341717839241028, 0.11184483766555786]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 16, SSIM Loss: 0.10605710744857788\n",
      "Epoch: 22, Batch: 16, D Loss Real: 0.17429731786251068, D Loss Fake: 1.1644394397735596, G Loss: [11.288597106933594, 0.641215980052948, 0.10647380352020264]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 17, SSIM Loss: 0.10281848907470703\n",
      "Epoch: 22, Batch: 17, D Loss Real: 0.16921207308769226, D Loss Fake: 1.0595532655715942, G Loss: [11.035541534423828, 0.706378698348999, 0.10329163074493408]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 18, SSIM Loss: 0.11865544319152832\n",
      "Epoch: 22, Batch: 18, D Loss Real: 0.14442910254001617, D Loss Fake: 1.1834805011749268, G Loss: [12.027612686157227, 0.6959481239318848, 0.11331665515899658]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 19, SSIM Loss: 0.13015490770339966\n",
      "Epoch: 22, Batch: 19, D Loss Real: 0.11226553469896317, D Loss Fake: 0.9495420455932617, G Loss: [13.799911499023438, 0.8138715028762817, 0.12986040115356445]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 20, SSIM Loss: 0.12832772731781006\n",
      "Epoch: 22, Batch: 20, D Loss Real: 0.15279389917850494, D Loss Fake: 1.0286508798599243, G Loss: [13.58916187286377, 0.8173884749412537, 0.1277177333831787]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 21, SSIM Loss: 0.11676561832427979\n",
      "Epoch: 22, Batch: 21, D Loss Real: 0.11281447857618332, D Loss Fake: 0.9814572930335999, G Loss: [12.468777656555176, 0.7958334684371948, 0.11672943830490112]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 22, SSIM Loss: 0.11226969957351685\n",
      "Epoch: 22, Batch: 22, D Loss Real: 0.13947737216949463, D Loss Fake: 0.9699066877365112, G Loss: [11.96581745147705, 0.7749683260917664, 0.11190849542617798]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 23, SSIM Loss: 0.12854892015457153\n",
      "Epoch: 22, Batch: 23, D Loss Real: 0.0875902846455574, D Loss Fake: 1.0113195180892944, G Loss: [13.638608932495117, 0.7668076753616333, 0.12871801853179932]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 24, SSIM Loss: 0.12578535079956055\n",
      "Epoch: 22, Batch: 24, D Loss Real: 0.055374156683683395, D Loss Fake: 0.9602187871932983, G Loss: [13.450407981872559, 0.8223768472671509, 0.1262803077697754]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 25, SSIM Loss: 0.11807847023010254\n",
      "Epoch: 22, Batch: 25, D Loss Real: 0.053348179906606674, D Loss Fake: 0.9755527973175049, G Loss: [12.57762336730957, 0.8095449805259705, 0.11768078804016113]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 26, SSIM Loss: 0.11932599544525146\n",
      "Epoch: 22, Batch: 26, D Loss Real: 0.0615232028067112, D Loss Fake: 0.9689244031906128, G Loss: [12.762922286987305, 0.8473580479621887, 0.1191556453704834]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 27, SSIM Loss: 0.11053967475891113\n",
      "Epoch: 22, Batch: 27, D Loss Real: 0.05653024837374687, D Loss Fake: 0.8863425254821777, G Loss: [11.932732582092285, 0.8674821853637695, 0.11065250635147095]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 28, SSIM Loss: 0.11039161682128906\n",
      "Epoch: 22, Batch: 28, D Loss Real: 0.04865448176860809, D Loss Fake: 0.8896986842155457, G Loss: [11.858652114868164, 0.8573039174079895, 0.11001348495483398]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 29, SSIM Loss: 0.12183129787445068\n",
      "Epoch: 22, Batch: 29, D Loss Real: 0.08433473110198975, D Loss Fake: 0.9431160688400269, G Loss: [13.008671760559082, 0.8156353235244751, 0.12193036079406738]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 30, SSIM Loss: 0.12327682971954346\n",
      "Epoch: 22, Batch: 30, D Loss Real: 0.04278366640210152, D Loss Fake: 0.9410820603370667, G Loss: [13.168672561645508, 0.8478916883468628, 0.12320780754089355]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 31, SSIM Loss: 0.11237627267837524\n",
      "Epoch: 22, Batch: 31, D Loss Real: 0.06688708066940308, D Loss Fake: 0.9261801838874817, G Loss: [12.0714111328125, 0.8385521173477173, 0.11232858896255493]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 22, Batch: 32, SSIM Loss: 0.11599278450012207\n",
      "Epoch: 22, Batch: 32, D Loss Real: 0.04625295475125313, D Loss Fake: 0.9888713955879211, G Loss: [12.436323165893555, 0.8497767448425293, 0.11586546897888184]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 33, SSIM Loss: 0.11931687593460083\n",
      "Epoch: 22, Batch: 33, D Loss Real: 0.07655112445354462, D Loss Fake: 1.0382267236709595, G Loss: [12.786874771118164, 0.82450270652771, 0.11962372064590454]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 34, SSIM Loss: 0.11314797401428223\n",
      "Epoch: 22, Batch: 34, D Loss Real: 0.08681465685367584, D Loss Fake: 0.9272921085357666, G Loss: [12.163448333740234, 0.8562682271003723, 0.11307179927825928]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 35, SSIM Loss: 0.10125571489334106\n",
      "Epoch: 22, Batch: 35, D Loss Real: 0.12068444490432739, D Loss Fake: 0.9122835993766785, G Loss: [10.917064666748047, 0.8033306002616882, 0.10113734006881714]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 36, SSIM Loss: 0.11854124069213867\n",
      "Epoch: 22, Batch: 36, D Loss Real: 0.061308201402425766, D Loss Fake: 1.0329387187957764, G Loss: [12.651459693908691, 0.8179463148117065, 0.11833512783050537]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 37, SSIM Loss: 0.11017626523971558\n",
      "Epoch: 22, Batch: 37, D Loss Real: 0.06950484961271286, D Loss Fake: 1.0000405311584473, G Loss: [11.90322494506836, 0.8413836359977722, 0.11061841249465942]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 38, SSIM Loss: 0.1265655755996704\n",
      "Epoch: 22, Batch: 38, D Loss Real: 0.07421943545341492, D Loss Fake: 0.915543258190155, G Loss: [13.500324249267578, 0.8438795208930969, 0.12656444311141968]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 39, SSIM Loss: 0.1165459156036377\n",
      "Epoch: 22, Batch: 39, D Loss Real: 0.07655814290046692, D Loss Fake: 1.030141830444336, G Loss: [12.496729850769043, 0.8425323367118835, 0.11654198169708252]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 40, SSIM Loss: 0.12106192111968994\n",
      "Epoch: 22, Batch: 40, D Loss Real: 0.11661889404058456, D Loss Fake: 0.9248049855232239, G Loss: [12.944150924682617, 0.8276230692863464, 0.12116527557373047]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 41, SSIM Loss: 0.10496068000793457\n",
      "Epoch: 22, Batch: 41, D Loss Real: 0.10573222488164902, D Loss Fake: 1.0500494241714478, G Loss: [11.265674591064453, 0.8096009492874146, 0.1045607328414917]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 42, SSIM Loss: 0.11992943286895752\n",
      "Epoch: 22, Batch: 42, D Loss Real: 0.06455095112323761, D Loss Fake: 1.010195255279541, G Loss: [12.797456741333008, 0.8119692802429199, 0.1198548674583435]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 43, SSIM Loss: 0.11452549695968628\n",
      "Epoch: 22, Batch: 43, D Loss Real: 0.1097172275185585, D Loss Fake: 1.041151523590088, G Loss: [12.258403778076172, 0.8151939511299133, 0.11443209648132324]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 44, SSIM Loss: 0.10563218593597412\n",
      "Epoch: 22, Batch: 44, D Loss Real: 0.07144684344530106, D Loss Fake: 0.9449257850646973, G Loss: [11.412666320800781, 0.8602660894393921, 0.10552400350570679]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 45, SSIM Loss: 0.1239386796951294\n",
      "Epoch: 22, Batch: 45, D Loss Real: 0.0826040580868721, D Loss Fake: 0.8987588882446289, G Loss: [13.256351470947266, 0.8809542655944824, 0.12375396490097046]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 46, SSIM Loss: 0.11186540126800537\n",
      "Epoch: 22, Batch: 46, D Loss Real: 0.06826139241456985, D Loss Fake: 0.9327974915504456, G Loss: [12.029206275939941, 0.8429162502288818, 0.1118628978729248]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 47, SSIM Loss: 0.12572413682937622\n",
      "Epoch: 22, Batch: 47, D Loss Real: 0.05669759213924408, D Loss Fake: 0.9812343716621399, G Loss: [13.345040321350098, 0.8156675696372986, 0.12529373168945312]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 48, SSIM Loss: 0.10952949523925781\n",
      "Epoch: 22, Batch: 48, D Loss Real: 0.06675934791564941, D Loss Fake: 1.019186019897461, G Loss: [11.77394962310791, 0.834458589553833, 0.10939490795135498]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 49, SSIM Loss: 0.11337119340896606\n",
      "Epoch: 22, Batch: 49, D Loss Real: 0.0825679823756218, D Loss Fake: 0.9301673173904419, G Loss: [12.15212345123291, 0.8439537286758423, 0.11308169364929199]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 50, SSIM Loss: 0.11365276575088501\n",
      "Epoch: 22, Batch: 50, D Loss Real: 0.08423970639705658, D Loss Fake: 0.9503716230392456, G Loss: [12.194732666015625, 0.8384985327720642, 0.11356234550476074]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 51, SSIM Loss: 0.11326086521148682\n",
      "Epoch: 22, Batch: 51, D Loss Real: 0.09332232177257538, D Loss Fake: 1.2121371030807495, G Loss: [12.131991386413574, 0.8327386379241943, 0.11299252510070801]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 52, SSIM Loss: 0.12192177772521973\n",
      "Epoch: 22, Batch: 52, D Loss Real: 0.07383304834365845, D Loss Fake: 1.064134120941162, G Loss: [13.14533805847168, 0.952248752117157, 0.12193089723587036]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 53, SSIM Loss: 0.11558568477630615\n",
      "Epoch: 22, Batch: 53, D Loss Real: 0.16529633104801178, D Loss Fake: 0.955017626285553, G Loss: [12.375316619873047, 0.8199610114097595, 0.11555355787277222]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 54, SSIM Loss: 0.1235281229019165\n",
      "Epoch: 22, Batch: 54, D Loss Real: 0.17435875535011292, D Loss Fake: 1.0338029861450195, G Loss: [13.109350204467773, 0.7796171307563782, 0.12329733371734619]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 22, Batch: 55, SSIM Loss: 0.10237741470336914\n",
      "Epoch: 22, Batch: 55, D Loss Real: 0.11244948208332062, D Loss Fake: 1.0118741989135742, G Loss: [11.03514575958252, 0.777461051940918, 0.1025768518447876]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 56, SSIM Loss: 0.11158508062362671\n",
      "Epoch: 22, Batch: 56, D Loss Real: 0.10461243987083435, D Loss Fake: 1.0022380352020264, G Loss: [11.989221572875977, 0.7833817005157471, 0.11205840110778809]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 57, SSIM Loss: 0.12307083606719971\n",
      "Epoch: 22, Batch: 57, D Loss Real: 0.06996075809001923, D Loss Fake: 0.9857579469680786, G Loss: [13.09750747680664, 0.8012118339538574, 0.12296295166015625]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 58, SSIM Loss: 0.11969208717346191\n",
      "Epoch: 22, Batch: 58, D Loss Real: 0.07834827899932861, D Loss Fake: 0.9354064464569092, G Loss: [12.739864349365234, 0.8227440118789673, 0.11917120218276978]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 59, SSIM Loss: 0.10591757297515869\n",
      "Epoch: 22, Batch: 59, D Loss Real: 0.11061270534992218, D Loss Fake: 1.0466852188110352, G Loss: [11.381494522094727, 0.8074763417243958, 0.10574018955230713]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 60, SSIM Loss: 0.11930227279663086\n",
      "Epoch: 22, Batch: 60, D Loss Real: 0.11146994680166245, D Loss Fake: 0.983322024345398, G Loss: [12.840765953063965, 0.8138118386268616, 0.1202695369720459]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 61, SSIM Loss: 0.11113423109054565\n",
      "Epoch: 22, Batch: 61, D Loss Real: 0.09552842378616333, D Loss Fake: 1.1346957683563232, G Loss: [11.970914840698242, 0.809515655040741, 0.11161398887634277]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 22, Batch: 62, SSIM Loss: 0.13211506605148315\n",
      "Epoch: 22, Batch: 62, D Loss Real: 0.07999500632286072, D Loss Fake: 0.9408264756202698, G Loss: [14.011062622070312, 0.8682748675346375, 0.13142788410186768]\n",
      "1/1 [==============================] - 0s 148ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:42:53.785638: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:42:55.243797: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Batch: 1, SSIM Loss: 0.10928905010223389\n",
      "Epoch: 23, Batch: 1, D Loss Real: 0.1912250518798828, D Loss Fake: 1.0304839611053467, G Loss: [11.7991361618042, 0.8295396566390991, 0.10969597101211548]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 2, SSIM Loss: 0.10765546560287476\n",
      "Epoch: 23, Batch: 2, D Loss Real: 0.1835951805114746, D Loss Fake: 0.9250417947769165, G Loss: [11.567219734191895, 0.8248650431632996, 0.10742354393005371]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 23, Batch: 3, SSIM Loss: 0.12053430080413818\n",
      "Epoch: 23, Batch: 3, D Loss Real: 0.08589641749858856, D Loss Fake: 0.9848783016204834, G Loss: [12.87109088897705, 0.7914224863052368, 0.12079668045043945]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 4, SSIM Loss: 0.11835819482803345\n",
      "Epoch: 23, Batch: 4, D Loss Real: 0.12730062007904053, D Loss Fake: 0.981480062007904, G Loss: [12.674408912658691, 0.8083584308624268, 0.11866050958633423]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 23, Batch: 5, SSIM Loss: 0.10987544059753418\n",
      "Epoch: 23, Batch: 5, D Loss Real: 0.10619497299194336, D Loss Fake: 0.9835537672042847, G Loss: [11.766172409057617, 0.8096578121185303, 0.1095651388168335]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 23, Batch: 6, SSIM Loss: 0.10976052284240723\n",
      "Epoch: 23, Batch: 6, D Loss Real: 0.05539005994796753, D Loss Fake: 0.9621396660804749, G Loss: [11.788846969604492, 0.8239403963088989, 0.10964906215667725]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 7, SSIM Loss: 0.11124873161315918\n",
      "Epoch: 23, Batch: 7, D Loss Real: 0.05842885747551918, D Loss Fake: 0.9828485250473022, G Loss: [11.972160339355469, 0.8110241889953613, 0.11161136627197266]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 8, SSIM Loss: 0.10773438215255737\n",
      "Epoch: 23, Batch: 8, D Loss Real: 0.126986563205719, D Loss Fake: 0.9363089799880981, G Loss: [11.611478805541992, 0.8188415765762329, 0.1079263687133789]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 9, SSIM Loss: 0.1169465184211731\n",
      "Epoch: 23, Batch: 9, D Loss Real: 0.07383265346288681, D Loss Fake: 1.2466490268707275, G Loss: [12.578227996826172, 0.846197783946991, 0.11732029914855957]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 10, SSIM Loss: 0.10982322692871094\n",
      "Epoch: 23, Batch: 10, D Loss Real: 0.17751654982566833, D Loss Fake: 0.9507685899734497, G Loss: [11.819762229919434, 0.8231232762336731, 0.10996639728546143]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 23, Batch: 11, SSIM Loss: 0.10733306407928467\n",
      "Epoch: 23, Batch: 11, D Loss Real: 0.1809493601322174, D Loss Fake: 1.0329560041427612, G Loss: [11.5149564743042, 0.7568788528442383, 0.10758078098297119]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 12, SSIM Loss: 0.10828006267547607\n",
      "Epoch: 23, Batch: 12, D Loss Real: 0.11558730900287628, D Loss Fake: 1.055903673171997, G Loss: [11.625800132751465, 0.7627109289169312, 0.10863089561462402]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 13, SSIM Loss: 0.11546039581298828\n",
      "Epoch: 23, Batch: 13, D Loss Real: 0.09115254878997803, D Loss Fake: 0.9896862506866455, G Loss: [12.352066040039062, 0.7853556871414185, 0.11566710472106934]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 14, SSIM Loss: 0.11409211158752441\n",
      "Epoch: 23, Batch: 14, D Loss Real: 0.08810851722955704, D Loss Fake: 1.1163530349731445, G Loss: [12.245489120483398, 0.8064635992050171, 0.11439025402069092]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 15, SSIM Loss: 0.11392843723297119\n",
      "Epoch: 23, Batch: 15, D Loss Real: 0.16594810783863068, D Loss Fake: 1.4033321142196655, G Loss: [12.342345237731934, 0.8991004228591919, 0.1144324541091919]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 16, SSIM Loss: 0.10819590091705322\n",
      "Epoch: 23, Batch: 16, D Loss Real: 0.22915810346603394, D Loss Fake: 0.8951674103736877, G Loss: [11.705981254577637, 0.9028003811836243, 0.10803180932998657]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 17, SSIM Loss: 0.10875064134597778\n",
      "Epoch: 23, Batch: 17, D Loss Real: 0.2569432854652405, D Loss Fake: 1.014135718345642, G Loss: [11.651131629943848, 0.7481187582015991, 0.10903012752532959]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 18, SSIM Loss: 0.1066436767578125\n",
      "Epoch: 23, Batch: 18, D Loss Real: 0.18309055268764496, D Loss Fake: 1.087451457977295, G Loss: [11.360640525817871, 0.7283580899238586, 0.10632282495498657]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 19, SSIM Loss: 0.1153632402420044\n",
      "Epoch: 23, Batch: 19, D Loss Real: 0.07942303270101547, D Loss Fake: 1.0900607109069824, G Loss: [12.21721363067627, 0.7548828125, 0.1146233081817627]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 20, SSIM Loss: 0.11134880781173706\n",
      "Epoch: 23, Batch: 20, D Loss Real: 0.09939834475517273, D Loss Fake: 1.0323820114135742, G Loss: [11.880788803100586, 0.7774809002876282, 0.11103308200836182]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 21, SSIM Loss: 0.10805052518844604\n",
      "Epoch: 23, Batch: 21, D Loss Real: 0.06629818677902222, D Loss Fake: 1.071541666984558, G Loss: [11.58123779296875, 0.8109646439552307, 0.10770273208618164]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 22, SSIM Loss: 0.10438555479049683\n",
      "Epoch: 23, Batch: 22, D Loss Real: 0.10995243489742279, D Loss Fake: 0.9886854887008667, G Loss: [11.295309066772461, 0.8220939636230469, 0.10473215579986572]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 23, SSIM Loss: 0.11885654926300049\n",
      "Epoch: 23, Batch: 23, D Loss Real: 0.10105900466442108, D Loss Fake: 0.9853348731994629, G Loss: [12.685921669006348, 0.8476399779319763, 0.11838281154632568]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 24, SSIM Loss: 0.11807584762573242\n",
      "Epoch: 23, Batch: 24, D Loss Real: 0.08997900784015656, D Loss Fake: 0.9006465673446655, G Loss: [12.616410255432129, 0.8495836853981018, 0.1176682710647583]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 25, SSIM Loss: 0.10758858919143677\n",
      "Epoch: 23, Batch: 25, D Loss Real: 0.08061790466308594, D Loss Fake: 0.9979841709136963, G Loss: [11.592305183410645, 0.8233789205551147, 0.1076892614364624]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 26, SSIM Loss: 0.1082410216331482\n",
      "Epoch: 23, Batch: 26, D Loss Real: 0.07516279816627502, D Loss Fake: 1.007951021194458, G Loss: [11.634599685668945, 0.8285822868347168, 0.10806018114089966]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 27, SSIM Loss: 0.10733902454376221\n",
      "Epoch: 23, Batch: 27, D Loss Real: 0.08360157907009125, D Loss Fake: 0.9916067719459534, G Loss: [11.570756912231445, 0.8273236155509949, 0.10743433237075806]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 28, SSIM Loss: 0.10206586122512817\n",
      "Epoch: 23, Batch: 28, D Loss Real: 0.05798373371362686, D Loss Fake: 1.0682059526443481, G Loss: [11.106734275817871, 0.8839473128318787, 0.10222786664962769]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 29, SSIM Loss: 0.11714959144592285\n",
      "Epoch: 23, Batch: 29, D Loss Real: 0.19017936289310455, D Loss Fake: 0.9403913617134094, G Loss: [12.568183898925781, 0.8283098936080933, 0.11739873886108398]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 30, SSIM Loss: 0.11319971084594727\n",
      "Epoch: 23, Batch: 30, D Loss Real: 0.08593177050352097, D Loss Fake: 0.9829564094543457, G Loss: [12.150823593139648, 0.8153020143508911, 0.11335521936416626]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 31, SSIM Loss: 0.10713958740234375\n",
      "Epoch: 23, Batch: 31, D Loss Real: 0.10448233038187027, D Loss Fake: 1.0453286170959473, G Loss: [11.481966018676758, 0.8161198496818542, 0.1066584587097168]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 32, SSIM Loss: 0.1088489294052124\n",
      "Epoch: 23, Batch: 32, D Loss Real: 0.06389577686786652, D Loss Fake: 1.0604839324951172, G Loss: [11.759713172912598, 0.8521223664283752, 0.10907590389251709]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 33, SSIM Loss: 0.11229056119918823\n",
      "Epoch: 23, Batch: 33, D Loss Real: 0.1599840521812439, D Loss Fake: 0.9737618565559387, G Loss: [12.011421203613281, 0.8186938762664795, 0.11192727088928223]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 34, SSIM Loss: 0.10892325639724731\n",
      "Epoch: 23, Batch: 34, D Loss Real: 0.13374866545200348, D Loss Fake: 0.9725008010864258, G Loss: [11.678763389587402, 0.7963857054710388, 0.10882377624511719]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 35, SSIM Loss: 0.09843051433563232\n",
      "Epoch: 23, Batch: 35, D Loss Real: 0.13844290375709534, D Loss Fake: 1.0495131015777588, G Loss: [10.645014762878418, 0.7710885405540466, 0.09873926639556885]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 36, SSIM Loss: 0.11462640762329102\n",
      "Epoch: 23, Batch: 36, D Loss Real: 0.12380555272102356, D Loss Fake: 1.0438175201416016, G Loss: [12.26992416381836, 0.7892951965332031, 0.11480629444122314]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 37, SSIM Loss: 0.10552036762237549\n",
      "Epoch: 23, Batch: 37, D Loss Real: 0.0934375673532486, D Loss Fake: 0.9970051646232605, G Loss: [11.389220237731934, 0.7992026209831238, 0.10590016841888428]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 38, SSIM Loss: 0.11923325061798096\n",
      "Epoch: 23, Batch: 38, D Loss Real: 0.06311897188425064, D Loss Fake: 1.1413798332214355, G Loss: [12.720882415771484, 0.8451159000396729, 0.11875766515731812]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 39, SSIM Loss: 0.11031055450439453\n",
      "Epoch: 23, Batch: 39, D Loss Real: 0.15524378418922424, D Loss Fake: 0.9746781587600708, G Loss: [11.867530822753906, 0.8671363592147827, 0.11000394821166992]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 23, Batch: 40, SSIM Loss: 0.11583942174911499\n",
      "Epoch: 23, Batch: 40, D Loss Real: 0.17067211866378784, D Loss Fake: 1.1024024486541748, G Loss: [12.365021705627441, 0.8094815611839294, 0.11555540561676025]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 41, SSIM Loss: 0.09999942779541016\n",
      "Epoch: 23, Batch: 41, D Loss Real: 0.21728992462158203, D Loss Fake: 1.1313987970352173, G Loss: [10.795088768005371, 0.7536427974700928, 0.1004144549369812]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 42, SSIM Loss: 0.11348748207092285\n",
      "Epoch: 23, Batch: 42, D Loss Real: 0.11739610135555267, D Loss Fake: 0.9916077852249146, G Loss: [12.074414253234863, 0.7734272480010986, 0.11300987005233765]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 43, SSIM Loss: 0.111855149269104\n",
      "Epoch: 23, Batch: 43, D Loss Real: 0.16011174023151398, D Loss Fake: 1.017308235168457, G Loss: [11.894603729248047, 0.7251105904579163, 0.11169493198394775]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 44, SSIM Loss: 0.10693883895874023\n",
      "Epoch: 23, Batch: 44, D Loss Real: 0.08986753970384598, D Loss Fake: 1.0840786695480347, G Loss: [11.492218971252441, 0.7933756113052368, 0.10698843002319336]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 45, SSIM Loss: 0.11621755361557007\n",
      "Epoch: 23, Batch: 45, D Loss Real: 0.11795251071453094, D Loss Fake: 0.940760612487793, G Loss: [12.516267776489258, 0.8251265287399292, 0.11691141128540039]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 46, SSIM Loss: 0.1092231273651123\n",
      "Epoch: 23, Batch: 46, D Loss Real: 0.09944047778844833, D Loss Fake: 1.0182182788848877, G Loss: [11.769902229309082, 0.7965916991233826, 0.10973310470581055]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 47, SSIM Loss: 0.12340694665908813\n",
      "Epoch: 23, Batch: 47, D Loss Real: 0.09034517407417297, D Loss Fake: 1.2381997108459473, G Loss: [13.190081596374512, 0.8590837121009827, 0.12330996990203857]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 48, SSIM Loss: 0.103107750415802\n",
      "Epoch: 23, Batch: 48, D Loss Real: 0.2371445894241333, D Loss Fake: 0.9423481225967407, G Loss: [11.194581985473633, 0.858218789100647, 0.10336363315582275]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 49, SSIM Loss: 0.10906732082366943\n",
      "Epoch: 23, Batch: 49, D Loss Real: 0.1461399793624878, D Loss Fake: 0.9734790921211243, G Loss: [11.698163032531738, 0.8038641214370728, 0.10894298553466797]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 50, SSIM Loss: 0.10998761653900146\n",
      "Epoch: 23, Batch: 50, D Loss Real: 0.11879398673772812, D Loss Fake: 0.9899340867996216, G Loss: [11.794241905212402, 0.7770030498504639, 0.11017239093780518]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 51, SSIM Loss: 0.11009752750396729\n",
      "Epoch: 23, Batch: 51, D Loss Real: 0.11005408316850662, D Loss Fake: 1.1382834911346436, G Loss: [11.804481506347656, 0.7897336483001709, 0.11014747619628906]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 52, SSIM Loss: 0.11538118124008179\n",
      "Epoch: 23, Batch: 52, D Loss Real: 0.07549914717674255, D Loss Fake: 0.9241192936897278, G Loss: [12.317353248596191, 0.8333503007888794, 0.11484003067016602]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 53, SSIM Loss: 0.11000120639801025\n",
      "Epoch: 23, Batch: 53, D Loss Real: 0.08697409927845001, D Loss Fake: 1.0237075090408325, G Loss: [11.85446834564209, 0.8286764025688171, 0.11025792360305786]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 54, SSIM Loss: 0.11540752649307251\n",
      "Epoch: 23, Batch: 54, D Loss Real: 0.12629841268062592, D Loss Fake: 1.0507186651229858, G Loss: [12.45474624633789, 0.8519518375396729, 0.11602795124053955]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 55, SSIM Loss: 0.10151362419128418\n",
      "Epoch: 23, Batch: 55, D Loss Real: 0.1088242307305336, D Loss Fake: 1.0114531517028809, G Loss: [10.996467590332031, 0.836605429649353, 0.10159862041473389]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 56, SSIM Loss: 0.10578775405883789\n",
      "Epoch: 23, Batch: 56, D Loss Real: 0.12912297248840332, D Loss Fake: 0.9939568042755127, G Loss: [11.419561386108398, 0.8218495845794678, 0.1059771180152893]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 57, SSIM Loss: 0.11596435308456421\n",
      "Epoch: 23, Batch: 57, D Loss Real: 0.07045608758926392, D Loss Fake: 1.2090386152267456, G Loss: [12.372100830078125, 0.7766079306602478, 0.1159549355506897]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 58, SSIM Loss: 0.11421048641204834\n",
      "Epoch: 23, Batch: 58, D Loss Real: 0.07143685221672058, D Loss Fake: 1.0394525527954102, G Loss: [12.29460334777832, 0.8726956248283386, 0.114219069480896]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 23, Batch: 59, SSIM Loss: 0.10227221250534058\n",
      "Epoch: 23, Batch: 59, D Loss Real: 0.12653079628944397, D Loss Fake: 1.0142766237258911, G Loss: [11.099648475646973, 0.8761759996414185, 0.10223472118377686]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 23, Batch: 60, SSIM Loss: 0.10908520221710205\n",
      "Epoch: 23, Batch: 60, D Loss Real: 0.14936190843582153, D Loss Fake: 1.2490928173065186, G Loss: [11.74950122833252, 0.9253637790679932, 0.10824137926101685]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 61, SSIM Loss: 0.10256963968276978\n",
      "Epoch: 23, Batch: 61, D Loss Real: 0.17910170555114746, D Loss Fake: 1.124719500541687, G Loss: [11.133395195007324, 0.8603790402412415, 0.1027301549911499]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 23, Batch: 62, SSIM Loss: 0.11193215847015381\n",
      "Epoch: 23, Batch: 62, D Loss Real: 0.1601109504699707, D Loss Fake: 1.0476025342941284, G Loss: [11.994147300720215, 0.8101341724395752, 0.1118401288986206]\n",
      "1/1 [==============================] - 0s 145ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:44:17.090701: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:44:18.544611: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Batch: 1, SSIM Loss: 0.1077505350112915\n",
      "Epoch: 24, Batch: 1, D Loss Real: 0.15577323734760284, D Loss Fake: 1.0500881671905518, G Loss: [11.579460144042969, 0.7898030877113342, 0.10789656639099121]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 2, SSIM Loss: 0.10420083999633789\n",
      "Epoch: 24, Batch: 2, D Loss Real: 0.13619424402713776, D Loss Fake: 1.0665799379348755, G Loss: [11.218151092529297, 0.7987165451049805, 0.10419434309005737]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 24, Batch: 3, SSIM Loss: 0.11392664909362793\n",
      "Epoch: 24, Batch: 3, D Loss Real: 0.08840521425008774, D Loss Fake: 1.0130327939987183, G Loss: [12.168771743774414, 0.8035377264022827, 0.11365234851837158]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 4, SSIM Loss: 0.11639964580535889\n",
      "Epoch: 24, Batch: 4, D Loss Real: 0.15156272053718567, D Loss Fake: 1.2112789154052734, G Loss: [12.444367408752441, 0.8168478012084961, 0.11627519130706787]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 5, SSIM Loss: 0.10903209447860718\n",
      "Epoch: 24, Batch: 5, D Loss Real: 0.19192729890346527, D Loss Fake: 0.9850968718528748, G Loss: [11.68433666229248, 0.801720917224884, 0.1088261604309082]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 24, Batch: 6, SSIM Loss: 0.10536837577819824\n",
      "Epoch: 24, Batch: 6, D Loss Real: 0.12492084503173828, D Loss Fake: 0.9580679535865784, G Loss: [11.308411598205566, 0.7962982654571533, 0.10512113571166992]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 7, SSIM Loss: 0.109444260597229\n",
      "Epoch: 24, Batch: 7, D Loss Real: 0.141665980219841, D Loss Fake: 1.072569489479065, G Loss: [11.737043380737305, 0.7413874268531799, 0.10995656251907349]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 8, SSIM Loss: 0.10557246208190918\n",
      "Epoch: 24, Batch: 8, D Loss Real: 0.17360372841358185, D Loss Fake: 1.1397424936294556, G Loss: [11.315999984741211, 0.7735835909843445, 0.10542416572570801]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 9, SSIM Loss: 0.11127746105194092\n",
      "Epoch: 24, Batch: 9, D Loss Real: 0.138431116938591, D Loss Fake: 1.0545871257781982, G Loss: [11.995573043823242, 0.7969092130661011, 0.11198663711547852]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 10, SSIM Loss: 0.10624730587005615\n",
      "Epoch: 24, Batch: 10, D Loss Real: 0.14967969059944153, D Loss Fake: 1.0957103967666626, G Loss: [11.479724884033203, 0.7717154026031494, 0.10708010196685791]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 11, SSIM Loss: 0.10309410095214844\n",
      "Epoch: 24, Batch: 11, D Loss Real: 0.12953409552574158, D Loss Fake: 1.072795033454895, G Loss: [11.090675354003906, 0.7803892493247986, 0.10310286283493042]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 12, SSIM Loss: 0.10556548833847046\n",
      "Epoch: 24, Batch: 12, D Loss Real: 0.12047620862722397, D Loss Fake: 1.070214033126831, G Loss: [11.302865982055664, 0.7750405669212341, 0.10527825355529785]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 13, SSIM Loss: 0.11040937900543213\n",
      "Epoch: 24, Batch: 13, D Loss Real: 0.12177033722400665, D Loss Fake: 1.108665943145752, G Loss: [11.879230499267578, 0.8287917375564575, 0.1105043888092041]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 14, SSIM Loss: 0.1107933521270752\n",
      "Epoch: 24, Batch: 14, D Loss Real: 0.13046473264694214, D Loss Fake: 1.0061570405960083, G Loss: [12.00566577911377, 0.8650925159454346, 0.11140573024749756]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 15, SSIM Loss: 0.11230981349945068\n",
      "Epoch: 24, Batch: 15, D Loss Real: 0.12720108032226562, D Loss Fake: 1.7158228158950806, G Loss: [12.211564064025879, 0.9286543130874634, 0.11282908916473389]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 16, SSIM Loss: 0.10740154981613159\n",
      "Epoch: 24, Batch: 16, D Loss Real: 0.22394348680973053, D Loss Fake: 0.9889005422592163, G Loss: [11.598987579345703, 0.8689888119697571, 0.10729998350143433]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 24, Batch: 17, SSIM Loss: 0.10365760326385498\n",
      "Epoch: 24, Batch: 17, D Loss Real: 0.23843282461166382, D Loss Fake: 1.0722966194152832, G Loss: [11.110469818115234, 0.7728667855262756, 0.10337603092193604]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 24, Batch: 18, SSIM Loss: 0.10450500249862671\n",
      "Epoch: 24, Batch: 18, D Loss Real: 0.20582780241966248, D Loss Fake: 1.1240513324737549, G Loss: [11.186182975769043, 0.7295734286308289, 0.10456609725952148]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 19, SSIM Loss: 0.1156073808670044\n",
      "Epoch: 24, Batch: 19, D Loss Real: 0.13314534723758698, D Loss Fake: 1.224153757095337, G Loss: [12.311230659484863, 0.7311155200004578, 0.11580115556716919]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 20, SSIM Loss: 0.11191010475158691\n",
      "Epoch: 24, Batch: 20, D Loss Real: 0.20326335728168488, D Loss Fake: 1.0677828788757324, G Loss: [11.987020492553711, 0.7969037294387817, 0.1119011640548706]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 24, Batch: 21, SSIM Loss: 0.10653489828109741\n",
      "Epoch: 24, Batch: 21, D Loss Real: 0.12268435955047607, D Loss Fake: 0.9924903512001038, G Loss: [11.436357498168945, 0.7939663529396057, 0.10642391443252563]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 22, SSIM Loss: 0.10495740175247192\n",
      "Epoch: 24, Batch: 22, D Loss Real: 0.1383700966835022, D Loss Fake: 1.1088790893554688, G Loss: [11.218127250671387, 0.7383010387420654, 0.10479825735092163]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 23, SSIM Loss: 0.11504197120666504\n",
      "Epoch: 24, Batch: 23, D Loss Real: 0.10620066523551941, D Loss Fake: 1.248827338218689, G Loss: [12.277670860290527, 0.8252528309822083, 0.11452418565750122]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 24, SSIM Loss: 0.11668932437896729\n",
      "Epoch: 24, Batch: 24, D Loss Real: 0.14481401443481445, D Loss Fake: 0.9226349592208862, G Loss: [12.52786636352539, 0.8611871004104614, 0.11666679382324219]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 25, SSIM Loss: 0.10291540622711182\n",
      "Epoch: 24, Batch: 25, D Loss Real: 0.1780215948820114, D Loss Fake: 0.9539361000061035, G Loss: [11.090670585632324, 0.7881208658218384, 0.10302549600601196]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 26, SSIM Loss: 0.1049538254737854\n",
      "Epoch: 24, Batch: 26, D Loss Real: 0.10931751877069473, D Loss Fake: 1.1165308952331543, G Loss: [11.264663696289062, 0.7501775622367859, 0.10514485836029053]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 27, SSIM Loss: 0.10589009523391724\n",
      "Epoch: 24, Batch: 27, D Loss Real: 0.11607719212770462, D Loss Fake: 1.2028133869171143, G Loss: [11.402656555175781, 0.7933876514434814, 0.10609269142150879]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 28, SSIM Loss: 0.1017867922782898\n",
      "Epoch: 24, Batch: 28, D Loss Real: 0.13674171268939972, D Loss Fake: 1.0331512689590454, G Loss: [10.987977027893066, 0.8427951335906982, 0.1014518141746521]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 29, SSIM Loss: 0.11263716220855713\n",
      "Epoch: 24, Batch: 29, D Loss Real: 0.26040416955947876, D Loss Fake: 1.0433573722839355, G Loss: [12.027169227600098, 0.7514601945877075, 0.11275708675384521]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 30, SSIM Loss: 0.10700368881225586\n",
      "Epoch: 24, Batch: 30, D Loss Real: 0.18254965543746948, D Loss Fake: 1.0598293542861938, G Loss: [11.45113468170166, 0.743398904800415, 0.10707736015319824]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 31, SSIM Loss: 0.10161113739013672\n",
      "Epoch: 24, Batch: 31, D Loss Real: 0.14469388127326965, D Loss Fake: 1.2232619524002075, G Loss: [10.920487403869629, 0.7307046055793762, 0.10189783573150635]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 32, SSIM Loss: 0.10640782117843628\n",
      "Epoch: 24, Batch: 32, D Loss Real: 0.09202224016189575, D Loss Fake: 1.1590744256973267, G Loss: [11.461721420288086, 0.8077009916305542, 0.10654020309448242]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 33, SSIM Loss: 0.10783898830413818\n",
      "Epoch: 24, Batch: 33, D Loss Real: 0.19869890809059143, D Loss Fake: 1.0585061311721802, G Loss: [11.582630157470703, 0.7848317623138428, 0.1079779863357544]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 34, SSIM Loss: 0.10609805583953857\n",
      "Epoch: 24, Batch: 34, D Loss Real: 0.17617973685264587, D Loss Fake: 1.094792366027832, G Loss: [11.30465316772461, 0.778968095779419, 0.10525685548782349]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 35, SSIM Loss: 0.0990058183670044\n",
      "Epoch: 24, Batch: 35, D Loss Real: 0.20558536052703857, D Loss Fake: 1.1940455436706543, G Loss: [10.757308006286621, 0.8115221261978149, 0.09945785999298096]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 36, SSIM Loss: 0.11078536510467529\n",
      "Epoch: 24, Batch: 36, D Loss Real: 0.24524939060211182, D Loss Fake: 1.1012816429138184, G Loss: [11.847208023071289, 0.7485431432723999, 0.11098664999008179]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 37, SSIM Loss: 0.1052888035774231\n",
      "Epoch: 24, Batch: 37, D Loss Real: 0.14656740427017212, D Loss Fake: 1.0116064548492432, G Loss: [11.257613182067871, 0.7769472002983093, 0.10480666160583496]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 24, Batch: 38, SSIM Loss: 0.11531823873519897\n",
      "Epoch: 24, Batch: 38, D Loss Real: 0.10907820612192154, D Loss Fake: 1.0615081787109375, G Loss: [12.240625381469727, 0.7674465179443359, 0.1147317886352539]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 39, SSIM Loss: 0.10681033134460449\n",
      "Epoch: 24, Batch: 39, D Loss Real: 0.12418115884065628, D Loss Fake: 1.031487226486206, G Loss: [11.537178993225098, 0.7785410284996033, 0.10758638381958008]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 40, SSIM Loss: 0.11008423566818237\n",
      "Epoch: 24, Batch: 40, D Loss Real: 0.13426892459392548, D Loss Fake: 1.224939227104187, G Loss: [11.880393981933594, 0.8291319608688354, 0.1105126142501831]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 41, SSIM Loss: 0.09637093544006348\n",
      "Epoch: 24, Batch: 41, D Loss Real: 0.17217117547988892, D Loss Fake: 1.1306815147399902, G Loss: [10.411205291748047, 0.7950800061225891, 0.09616124629974365]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 42, SSIM Loss: 0.10884475708007812\n",
      "Epoch: 24, Batch: 42, D Loss Real: 0.09717356413602829, D Loss Fake: 1.0438895225524902, G Loss: [11.74321174621582, 0.8226983547210693, 0.10920512676239014]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 43, SSIM Loss: 0.10422813892364502\n",
      "Epoch: 24, Batch: 43, D Loss Real: 0.13805751502513885, D Loss Fake: 1.1610206365585327, G Loss: [11.205328941345215, 0.8002769947052002, 0.10405051708221436]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 44, SSIM Loss: 0.09767258167266846\n",
      "Epoch: 24, Batch: 44, D Loss Real: 0.12391737848520279, D Loss Fake: 1.0443344116210938, G Loss: [10.617197036743164, 0.8429773449897766, 0.09774219989776611]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 45, SSIM Loss: 0.11286807060241699\n",
      "Epoch: 24, Batch: 45, D Loss Real: 0.14052172005176544, D Loss Fake: 1.1044436693191528, G Loss: [12.150859832763672, 0.8567864298820496, 0.1129407286643982]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 46, SSIM Loss: 0.1066962480545044\n",
      "Epoch: 24, Batch: 46, D Loss Real: 0.1585383266210556, D Loss Fake: 1.3808674812316895, G Loss: [11.450325965881348, 0.8087992072105408, 0.1064152717590332]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 47, SSIM Loss: 0.11748045682907104\n",
      "Epoch: 24, Batch: 47, D Loss Real: 0.16124284267425537, D Loss Fake: 1.4331769943237305, G Loss: [12.587573051452637, 0.8253469467163086, 0.1176222562789917]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 48, SSIM Loss: 0.1028968095779419\n",
      "Epoch: 24, Batch: 48, D Loss Real: 0.3708480894565582, D Loss Fake: 1.102060079574585, G Loss: [11.067776679992676, 0.7321346402168274, 0.10335642099380493]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 49, SSIM Loss: 0.1070406436920166\n",
      "Epoch: 24, Batch: 49, D Loss Real: 0.26788949966430664, D Loss Fake: 1.1351667642593384, G Loss: [11.403031349182129, 0.6776643991470337, 0.10725367069244385]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 50, SSIM Loss: 0.10770773887634277\n",
      "Epoch: 24, Batch: 50, D Loss Real: 0.23802289366722107, D Loss Fake: 1.1578412055969238, G Loss: [11.431982040405273, 0.6568986177444458, 0.10775083303451538]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 51, SSIM Loss: 0.10883677005767822\n",
      "Epoch: 24, Batch: 51, D Loss Real: 0.2427140772342682, D Loss Fake: 1.1611900329589844, G Loss: [11.561881065368652, 0.6539214849472046, 0.10907959938049316]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 52, SSIM Loss: 0.11006075143814087\n",
      "Epoch: 24, Batch: 52, D Loss Real: 0.12086257338523865, D Loss Fake: 1.2755564451217651, G Loss: [11.739395141601562, 0.7302924394607544, 0.11009103059768677]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 24, Batch: 53, SSIM Loss: 0.10780388116836548\n",
      "Epoch: 24, Batch: 53, D Loss Real: 0.16203251481056213, D Loss Fake: 1.1548457145690918, G Loss: [11.54076099395752, 0.7899007201194763, 0.1075085997581482]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 54, SSIM Loss: 0.11031532287597656\n",
      "Epoch: 24, Batch: 54, D Loss Real: 0.27564144134521484, D Loss Fake: 1.2151024341583252, G Loss: [11.782097816467285, 0.7465485334396362, 0.11035549640655518]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 55, SSIM Loss: 0.10229909420013428\n",
      "Epoch: 24, Batch: 55, D Loss Real: 0.27175086736679077, D Loss Fake: 1.0918070077896118, G Loss: [10.906292915344238, 0.728860080242157, 0.10177433490753174]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 56, SSIM Loss: 0.10409033298492432\n",
      "Epoch: 24, Batch: 56, D Loss Real: 0.272926926612854, D Loss Fake: 1.04111909866333, G Loss: [11.115581512451172, 0.7205679416656494, 0.1039501428604126]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 57, SSIM Loss: 0.11274081468582153\n",
      "Epoch: 24, Batch: 57, D Loss Real: 0.1676718294620514, D Loss Fake: 1.187654972076416, G Loss: [11.936527252197266, 0.6704918742179871, 0.11266034841537476]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 58, SSIM Loss: 0.11092698574066162\n",
      "Epoch: 24, Batch: 58, D Loss Real: 0.13016846776008606, D Loss Fake: 1.326973557472229, G Loss: [11.810566902160645, 0.7012922763824463, 0.11109274625778198]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 59, SSIM Loss: 0.0993657112121582\n",
      "Epoch: 24, Batch: 59, D Loss Real: 0.20782434940338135, D Loss Fake: 1.275507926940918, G Loss: [10.715880393981934, 0.7755721211433411, 0.09940308332443237]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 60, SSIM Loss: 0.1070021390914917\n",
      "Epoch: 24, Batch: 60, D Loss Real: 0.24661262333393097, D Loss Fake: 1.0616035461425781, G Loss: [11.531201362609863, 0.837090253829956, 0.1069411039352417]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 61, SSIM Loss: 0.11440402269363403\n",
      "Epoch: 24, Batch: 61, D Loss Real: 0.26385757327079773, D Loss Fake: 1.130311369895935, G Loss: [12.249137878417969, 0.7251041531562805, 0.11524033546447754]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 24, Batch: 62, SSIM Loss: 0.11433374881744385\n",
      "Epoch: 24, Batch: 62, D Loss Real: 0.17794322967529297, D Loss Fake: 1.0645134449005127, G Loss: [12.235310554504395, 0.7420932650566101, 0.11493217945098877]\n",
      "1/1 [==============================] - 0s 144ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:45:40.638453: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:45:42.109487: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Batch: 1, SSIM Loss: 0.10950905084609985\n",
      "Epoch: 25, Batch: 1, D Loss Real: 0.16437548398971558, D Loss Fake: 1.0375008583068848, G Loss: [11.705811500549316, 0.7740035653114319, 0.1093180775642395]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 2, SSIM Loss: 0.1065477728843689\n",
      "Epoch: 25, Batch: 2, D Loss Real: 0.14664633572101593, D Loss Fake: 1.1122045516967773, G Loss: [11.421192169189453, 0.7879434823989868, 0.10633248090744019]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 25, Batch: 3, SSIM Loss: 0.11510217189788818\n",
      "Epoch: 25, Batch: 3, D Loss Real: 0.105946384370327, D Loss Fake: 1.0811829566955566, G Loss: [12.36102294921875, 0.8394932746887207, 0.11521530151367188]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 25, Batch: 4, SSIM Loss: 0.11575102806091309\n",
      "Epoch: 25, Batch: 4, D Loss Real: 0.15344753861427307, D Loss Fake: 1.0859777927398682, G Loss: [12.396524429321289, 0.8160868883132935, 0.11580437421798706]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 5, SSIM Loss: 0.1075742244720459\n",
      "Epoch: 25, Batch: 5, D Loss Real: 0.1488691121339798, D Loss Fake: 1.0506025552749634, G Loss: [11.549315452575684, 0.7954927086830139, 0.10753822326660156]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 6, SSIM Loss: 0.10547590255737305\n",
      "Epoch: 25, Batch: 6, D Loss Real: 0.10747301578521729, D Loss Fake: 1.010134220123291, G Loss: [11.389364242553711, 0.8047824501991272, 0.10584580898284912]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 7, SSIM Loss: 0.10667407512664795\n",
      "Epoch: 25, Batch: 7, D Loss Real: 0.1635180413722992, D Loss Fake: 1.1554150581359863, G Loss: [11.47719669342041, 0.765085756778717, 0.10712110996246338]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 8, SSIM Loss: 0.10509514808654785\n",
      "Epoch: 25, Batch: 8, D Loss Real: 0.22496297955513, D Loss Fake: 1.155631184577942, G Loss: [11.299155235290527, 0.7970434427261353, 0.10502111911773682]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 9, SSIM Loss: 0.10913622379302979\n",
      "Epoch: 25, Batch: 9, D Loss Real: 0.22496822476387024, D Loss Fake: 1.11539626121521, G Loss: [11.69616985321045, 0.7579549551010132, 0.10938215255737305]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 10, SSIM Loss: 0.10250735282897949\n",
      "Epoch: 25, Batch: 10, D Loss Real: 0.2160356491804123, D Loss Fake: 1.2416127920150757, G Loss: [10.980777740478516, 0.7308768033981323, 0.10249900817871094]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 11, SSIM Loss: 0.10019540786743164\n",
      "Epoch: 25, Batch: 11, D Loss Real: 0.21012958884239197, D Loss Fake: 1.1919426918029785, G Loss: [10.746343612670898, 0.7169319987297058, 0.10029411315917969]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 12, SSIM Loss: 0.10281121730804443\n",
      "Epoch: 25, Batch: 12, D Loss Real: 0.20198111236095428, D Loss Fake: 1.2179334163665771, G Loss: [11.025927543640137, 0.7225973010063171, 0.10303330421447754]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 13, SSIM Loss: 0.10547745227813721\n",
      "Epoch: 25, Batch: 13, D Loss Real: 0.22707855701446533, D Loss Fake: 1.1252191066741943, G Loss: [11.303881645202637, 0.7268227338790894, 0.10577058792114258]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 14, SSIM Loss: 0.11014449596405029\n",
      "Epoch: 25, Batch: 14, D Loss Real: 0.2304246723651886, D Loss Fake: 1.1372179985046387, G Loss: [11.63780403137207, 0.7157424688339233, 0.10922062397003174]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 15, SSIM Loss: 0.10936689376831055\n",
      "Epoch: 25, Batch: 15, D Loss Real: 0.20469039678573608, D Loss Fake: 1.1461029052734375, G Loss: [11.693965911865234, 0.7577292323112488, 0.10936236381530762]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 16, SSIM Loss: 0.10875612497329712\n",
      "Epoch: 25, Batch: 16, D Loss Real: 0.2009948194026947, D Loss Fake: 1.1922780275344849, G Loss: [11.537641525268555, 0.7175866365432739, 0.1082005500793457]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 17, SSIM Loss: 0.10251665115356445\n",
      "Epoch: 25, Batch: 17, D Loss Real: 0.17131537199020386, D Loss Fake: 1.2328215837478638, G Loss: [10.997387886047363, 0.7527435421943665, 0.10244643688201904]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 18, SSIM Loss: 0.10354804992675781\n",
      "Epoch: 25, Batch: 18, D Loss Real: 0.2501470446586609, D Loss Fake: 1.3306291103363037, G Loss: [11.107643127441406, 0.7532855868339539, 0.10354357957839966]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 19, SSIM Loss: 0.11124002933502197\n",
      "Epoch: 25, Batch: 19, D Loss Real: 0.15564703941345215, D Loss Fake: 1.3634659051895142, G Loss: [11.887733459472656, 0.7498078346252441, 0.11137926578521729]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 25, Batch: 20, SSIM Loss: 0.10623228549957275\n",
      "Epoch: 25, Batch: 20, D Loss Real: 0.21452464163303375, D Loss Fake: 1.2143346071243286, G Loss: [11.346635818481445, 0.7041437029838562, 0.10642492771148682]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 21, SSIM Loss: 0.10545879602432251\n",
      "Epoch: 25, Batch: 21, D Loss Real: 0.18194332718849182, D Loss Fake: 1.1489152908325195, G Loss: [11.287435531616211, 0.750324547290802, 0.10537111759185791]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 22, SSIM Loss: 0.10170149803161621\n",
      "Epoch: 25, Batch: 22, D Loss Real: 0.22172054648399353, D Loss Fake: 1.36921226978302, G Loss: [10.804186820983887, 0.6769757866859436, 0.1012721061706543]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 25, Batch: 23, SSIM Loss: 0.11315953731536865\n",
      "Epoch: 25, Batch: 23, D Loss Real: 0.24022924900054932, D Loss Fake: 1.3104472160339355, G Loss: [12.004688262939453, 0.6922622919082642, 0.11312425136566162]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 24, SSIM Loss: 0.11234164237976074\n",
      "Epoch: 25, Batch: 24, D Loss Real: 0.2761959433555603, D Loss Fake: 1.0754079818725586, G Loss: [12.101781845092773, 0.8321648836135864, 0.11269617080688477]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 25, SSIM Loss: 0.10284620523452759\n",
      "Epoch: 25, Batch: 25, D Loss Real: 0.2731425166130066, D Loss Fake: 1.0918275117874146, G Loss: [10.987410545349121, 0.7153485417366028, 0.10272061824798584]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 26, SSIM Loss: 0.10446727275848389\n",
      "Epoch: 25, Batch: 26, D Loss Real: 0.19300545752048492, D Loss Fake: 1.0875816345214844, G Loss: [11.13733196258545, 0.7261940240859985, 0.10411137342453003]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 27, SSIM Loss: 0.10351777076721191\n",
      "Epoch: 25, Batch: 27, D Loss Real: 0.15755844116210938, D Loss Fake: 1.1240020990371704, G Loss: [11.086227416992188, 0.7109904289245605, 0.10375237464904785]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 28, SSIM Loss: 0.10164487361907959\n",
      "Epoch: 25, Batch: 28, D Loss Real: 0.13718673586845398, D Loss Fake: 1.2277348041534424, G Loss: [10.951313972473145, 0.747368574142456, 0.10203945636749268]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 29, SSIM Loss: 0.112690269947052\n",
      "Epoch: 25, Batch: 29, D Loss Real: 0.2009373903274536, D Loss Fake: 1.0939792394638062, G Loss: [12.040850639343262, 0.7836793661117554, 0.11257171630859375]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 30, SSIM Loss: 0.10619384050369263\n",
      "Epoch: 25, Batch: 30, D Loss Real: 0.1863040328025818, D Loss Fake: 1.1078540086746216, G Loss: [11.344767570495605, 0.7313206195831299, 0.10613447427749634]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 31, SSIM Loss: 0.09962248802185059\n",
      "Epoch: 25, Batch: 31, D Loss Real: 0.18258534371852875, D Loss Fake: 1.1928880214691162, G Loss: [10.694574356079102, 0.7103673815727234, 0.09984207153320312]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 32, SSIM Loss: 0.10584795475006104\n",
      "Epoch: 25, Batch: 32, D Loss Real: 0.14864598214626312, D Loss Fake: 1.2900404930114746, G Loss: [11.270142555236816, 0.732745349407196, 0.10537397861480713]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 33, SSIM Loss: 0.10412776470184326\n",
      "Epoch: 25, Batch: 33, D Loss Real: 0.2195819616317749, D Loss Fake: 1.1596925258636475, G Loss: [11.19336223602295, 0.7530784606933594, 0.10440284013748169]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 34, SSIM Loss: 0.10515666007995605\n",
      "Epoch: 25, Batch: 34, D Loss Real: 0.2384812831878662, D Loss Fake: 1.3189215660095215, G Loss: [11.138731956481934, 0.7263963222503662, 0.10412335395812988]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 35, SSIM Loss: 0.09880638122558594\n",
      "Epoch: 25, Batch: 35, D Loss Real: 0.2871697247028351, D Loss Fake: 1.1738401651382446, G Loss: [10.621055603027344, 0.7366561889648438, 0.09884399175643921]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 36, SSIM Loss: 0.10949873924255371\n",
      "Epoch: 25, Batch: 36, D Loss Real: 0.2928670346736908, D Loss Fake: 1.2713088989257812, G Loss: [11.653411865234375, 0.6647054553031921, 0.10988706350326538]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 37, SSIM Loss: 0.1040811538696289\n",
      "Epoch: 25, Batch: 37, D Loss Real: 0.2502409815788269, D Loss Fake: 1.3021130561828613, G Loss: [11.077524185180664, 0.6679069995880127, 0.1040961742401123]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 38, SSIM Loss: 0.1108696460723877\n",
      "Epoch: 25, Batch: 38, D Loss Real: 0.2663905620574951, D Loss Fake: 1.3541290760040283, G Loss: [11.684000015258789, 0.6557523012161255, 0.11028248071670532]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 39, SSIM Loss: 0.1042792797088623\n",
      "Epoch: 25, Batch: 39, D Loss Real: 0.29878950119018555, D Loss Fake: 1.208620548248291, G Loss: [11.121037483215332, 0.6897592544555664, 0.10431277751922607]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 40, SSIM Loss: 0.10672509670257568\n",
      "Epoch: 25, Batch: 40, D Loss Real: 0.30183207988739014, D Loss Fake: 1.1947382688522339, G Loss: [11.333627700805664, 0.6628819108009338, 0.10670745372772217]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 41, SSIM Loss: 0.09770441055297852\n",
      "Epoch: 25, Batch: 41, D Loss Real: 0.3137620985507965, D Loss Fake: 1.294417142868042, G Loss: [10.434893608093262, 0.6354370713233948, 0.09799456596374512]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 25, Batch: 42, SSIM Loss: 0.10541391372680664\n",
      "Epoch: 25, Batch: 42, D Loss Real: 0.26509490609169006, D Loss Fake: 1.266828179359436, G Loss: [11.159256935119629, 0.6698592901229858, 0.10489398241043091]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 43, SSIM Loss: 0.10268306732177734\n",
      "Epoch: 25, Batch: 43, D Loss Real: 0.2995350658893585, D Loss Fake: 1.1831865310668945, G Loss: [10.952566146850586, 0.6978312730789185, 0.10254734754562378]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 25, Batch: 44, SSIM Loss: 0.09655368328094482\n",
      "Epoch: 25, Batch: 44, D Loss Real: 0.269439160823822, D Loss Fake: 1.1501384973526, G Loss: [10.357532501220703, 0.7019434571266174, 0.09655588865280151]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 45, SSIM Loss: 0.11106538772583008\n",
      "Epoch: 25, Batch: 45, D Loss Real: 0.24215269088745117, D Loss Fake: 1.2445883750915527, G Loss: [11.866561889648438, 0.740473210811615, 0.11126089096069336]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 46, SSIM Loss: 0.10313194990158081\n",
      "Epoch: 25, Batch: 46, D Loss Real: 0.3004736304283142, D Loss Fake: 1.3146882057189941, G Loss: [11.00206184387207, 0.6686668992042542, 0.10333395004272461]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 47, SSIM Loss: 0.11241209506988525\n",
      "Epoch: 25, Batch: 47, D Loss Real: 0.2657330632209778, D Loss Fake: 1.2571609020233154, G Loss: [11.93049430847168, 0.6702589988708496, 0.1126023530960083]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 48, SSIM Loss: 0.1005173921585083\n",
      "Epoch: 25, Batch: 48, D Loss Real: 0.29007840156555176, D Loss Fake: 1.2222537994384766, G Loss: [10.82857894897461, 0.7292041182518005, 0.10099375247955322]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 49, SSIM Loss: 0.10465848445892334\n",
      "Epoch: 25, Batch: 49, D Loss Real: 0.25239187479019165, D Loss Fake: 1.172996163368225, G Loss: [11.17367935180664, 0.7104296684265137, 0.10463249683380127]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 50, SSIM Loss: 0.10797119140625\n",
      "Epoch: 25, Batch: 50, D Loss Real: 0.25106343626976013, D Loss Fake: 1.107779622077942, G Loss: [11.519800186157227, 0.7223708629608154, 0.10797429084777832]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 51, SSIM Loss: 0.10590171813964844\n",
      "Epoch: 25, Batch: 51, D Loss Real: 0.21840567886829376, D Loss Fake: 1.0993577241897583, G Loss: [11.317941665649414, 0.7280672192573547, 0.10589873790740967]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 52, SSIM Loss: 0.10704708099365234\n",
      "Epoch: 25, Batch: 52, D Loss Real: 0.15173617005348206, D Loss Fake: 1.1242825984954834, G Loss: [11.417381286621094, 0.7264959216117859, 0.10690885782241821]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 53, SSIM Loss: 0.10619276762008667\n",
      "Epoch: 25, Batch: 53, D Loss Real: 0.14180555939674377, D Loss Fake: 1.222288966178894, G Loss: [11.364551544189453, 0.7168141603469849, 0.10647737979888916]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 54, SSIM Loss: 0.10818541049957275\n",
      "Epoch: 25, Batch: 54, D Loss Real: 0.19013604521751404, D Loss Fake: 1.1544955968856812, G Loss: [11.546914100646973, 0.7622168064117432, 0.10784697532653809]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 25, Batch: 55, SSIM Loss: 0.10066699981689453\n",
      "Epoch: 25, Batch: 55, D Loss Real: 0.18100765347480774, D Loss Fake: 1.1156537532806396, G Loss: [10.875299453735352, 0.7522136569023132, 0.10123085975646973]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 56, SSIM Loss: 0.10326629877090454\n",
      "Epoch: 25, Batch: 56, D Loss Real: 0.18948152661323547, D Loss Fake: 1.160243034362793, G Loss: [11.0610990524292, 0.7437371015548706, 0.10317361354827881]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 57, SSIM Loss: 0.11298877000808716\n",
      "Epoch: 25, Batch: 57, D Loss Real: 0.1493174284696579, D Loss Fake: 1.1892783641815186, G Loss: [12.076081275939941, 0.7487488389015198, 0.11327332258224487]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 58, SSIM Loss: 0.10814899206161499\n",
      "Epoch: 25, Batch: 58, D Loss Real: 0.1801420897245407, D Loss Fake: 1.2632944583892822, G Loss: [11.67912483215332, 0.7863885760307312, 0.10892736911773682]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 59, SSIM Loss: 0.09922319650650024\n",
      "Epoch: 25, Batch: 59, D Loss Real: 0.2520679235458374, D Loss Fake: 1.154999017715454, G Loss: [10.656754493713379, 0.7198023200035095, 0.09936952590942383]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 60, SSIM Loss: 0.10414975881576538\n",
      "Epoch: 25, Batch: 60, D Loss Real: 0.25863319635391235, D Loss Fake: 1.2180365324020386, G Loss: [11.221231460571289, 0.6898356080055237, 0.10531395673751831]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 61, SSIM Loss: 0.10088223218917847\n",
      "Epoch: 25, Batch: 61, D Loss Real: 0.25421077013015747, D Loss Fake: 1.221837043762207, G Loss: [10.723769187927246, 0.6800886392593384, 0.10043680667877197]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 25, Batch: 62, SSIM Loss: 0.10743016004562378\n",
      "Epoch: 25, Batch: 62, D Loss Real: 0.23984332382678986, D Loss Fake: 1.2263776063919067, G Loss: [11.390727996826172, 0.6779977083206177, 0.10712730884552002]\n",
      "1/1 [==============================] - 0s 140ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:47:03.939362: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:47:05.394418: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Batch: 1, SSIM Loss: 0.10466325283050537\n",
      "Epoch: 26, Batch: 1, D Loss Real: 0.2648946940898895, D Loss Fake: 1.178934097290039, G Loss: [11.153360366821289, 0.6854017376899719, 0.10467958450317383]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 2, SSIM Loss: 0.10257703065872192\n",
      "Epoch: 26, Batch: 2, D Loss Real: 0.2717536389827728, D Loss Fake: 1.0694029331207275, G Loss: [11.020670890808105, 0.723229169845581, 0.10297441482543945]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 26, Batch: 3, SSIM Loss: 0.11154896020889282\n",
      "Epoch: 26, Batch: 3, D Loss Real: 0.20540380477905273, D Loss Fake: 1.097765564918518, G Loss: [11.867568969726562, 0.7236645817756653, 0.111439049243927]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 4, SSIM Loss: 0.1119644045829773\n",
      "Epoch: 26, Batch: 4, D Loss Real: 0.19342933595180511, D Loss Fake: 1.1320735216140747, G Loss: [11.906383514404297, 0.7251720428466797, 0.11181211471557617]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 5, SSIM Loss: 0.10640490055084229\n",
      "Epoch: 26, Batch: 5, D Loss Real: 0.1705297976732254, D Loss Fake: 1.07371187210083, G Loss: [11.386343955993652, 0.7820939421653748, 0.10604250431060791]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 6, SSIM Loss: 0.10019159317016602\n",
      "Epoch: 26, Batch: 6, D Loss Real: 0.11477238684892654, D Loss Fake: 1.11105477809906, G Loss: [10.82973575592041, 0.8019033670425415, 0.10027831792831421]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 7, SSIM Loss: 0.10435819625854492\n",
      "Epoch: 26, Batch: 7, D Loss Real: 0.1695459634065628, D Loss Fake: 1.054231882095337, G Loss: [11.20073413848877, 0.7801555395126343, 0.10420578718185425]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 26, Batch: 8, SSIM Loss: 0.10516327619552612\n",
      "Epoch: 26, Batch: 8, D Loss Real: 0.1847943663597107, D Loss Fake: 1.150604248046875, G Loss: [11.259936332702637, 0.7268891930580139, 0.1053304672241211]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 9, SSIM Loss: 0.10557186603546143\n",
      "Epoch: 26, Batch: 9, D Loss Real: 0.16183900833129883, D Loss Fake: 1.184257984161377, G Loss: [11.24124526977539, 0.7360878586769104, 0.10505157709121704]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 10, SSIM Loss: 0.09985017776489258\n",
      "Epoch: 26, Batch: 10, D Loss Real: 0.1777917891740799, D Loss Fake: 1.1531739234924316, G Loss: [10.728195190429688, 0.7387791275978088, 0.09989416599273682]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 11, SSIM Loss: 0.09881782531738281\n",
      "Epoch: 26, Batch: 11, D Loss Real: 0.16924244165420532, D Loss Fake: 1.2636561393737793, G Loss: [10.678955078125, 0.7555630803108215, 0.09923392534255981]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 12, SSIM Loss: 0.10113179683685303\n",
      "Epoch: 26, Batch: 12, D Loss Real: 0.21905791759490967, D Loss Fake: 1.3351552486419678, G Loss: [10.884071350097656, 0.7624817490577698, 0.1012158989906311]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 13, SSIM Loss: 0.1029592752456665\n",
      "Epoch: 26, Batch: 13, D Loss Real: 0.24744388461112976, D Loss Fake: 1.2048624753952026, G Loss: [11.039531707763672, 0.6800777912139893, 0.10359454154968262]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 14, SSIM Loss: 0.10771059989929199\n",
      "Epoch: 26, Batch: 14, D Loss Real: 0.2634006440639496, D Loss Fake: 1.175801157951355, G Loss: [11.466794967651367, 0.6738301515579224, 0.10792964696884155]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 26, Batch: 15, SSIM Loss: 0.10897165536880493\n",
      "Epoch: 26, Batch: 15, D Loss Real: 0.23702819645404816, D Loss Fake: 1.272815465927124, G Loss: [11.656183242797852, 0.6372686624526978, 0.11018913984298706]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 16, SSIM Loss: 0.11904639005661011\n",
      "Epoch: 26, Batch: 16, D Loss Real: 0.2555040717124939, D Loss Fake: 1.2546025514602661, G Loss: [13.116276741027832, 0.7240530848503113, 0.12392222881317139]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 17, SSIM Loss: 0.10851073265075684\n",
      "Epoch: 26, Batch: 17, D Loss Real: 0.2851647734642029, D Loss Fake: 1.0793421268463135, G Loss: [11.56328010559082, 0.7183223366737366, 0.10844957828521729]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 26, Batch: 18, SSIM Loss: 0.13258397579193115\n",
      "Epoch: 26, Batch: 18, D Loss Real: 0.27861014008522034, D Loss Fake: 1.1085584163665771, G Loss: [14.011520385742188, 0.7362125515937805, 0.13275307416915894]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 19, SSIM Loss: 0.1317461133003235\n",
      "Epoch: 26, Batch: 19, D Loss Real: 0.21450921893119812, D Loss Fake: 1.0948516130447388, G Loss: [13.889474868774414, 0.7618858814239502, 0.13127589225769043]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 20, SSIM Loss: 0.12001287937164307\n",
      "Epoch: 26, Batch: 20, D Loss Real: 0.2315860092639923, D Loss Fake: 1.1920615434646606, G Loss: [12.720674514770508, 0.6897275447845459, 0.12030947208404541]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 21, SSIM Loss: 0.10905802249908447\n",
      "Epoch: 26, Batch: 21, D Loss Real: 0.17779357731342316, D Loss Fake: 1.165747880935669, G Loss: [11.560837745666504, 0.712935209274292, 0.10847902297973633]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 22, SSIM Loss: 0.10395610332489014\n",
      "Epoch: 26, Batch: 22, D Loss Real: 0.17925965785980225, D Loss Fake: 1.2381319999694824, G Loss: [11.126243591308594, 0.7034053802490234, 0.10422837734222412]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 23, SSIM Loss: 0.11308962106704712\n",
      "Epoch: 26, Batch: 23, D Loss Real: 0.21034292876720428, D Loss Fake: 1.1687991619110107, G Loss: [12.046233177185059, 0.7294933199882507, 0.113167405128479]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 24, SSIM Loss: 0.11199116706848145\n",
      "Epoch: 26, Batch: 24, D Loss Real: 0.21845413744449615, D Loss Fake: 1.1704723834991455, G Loss: [11.925265312194824, 0.7188173532485962, 0.11206448078155518]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 25, SSIM Loss: 0.10177850723266602\n",
      "Epoch: 26, Batch: 25, D Loss Real: 0.2468520849943161, D Loss Fake: 1.1120426654815674, G Loss: [10.871719360351562, 0.7031782865524292, 0.10168540477752686]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 26, SSIM Loss: 0.1034092903137207\n",
      "Epoch: 26, Batch: 26, D Loss Real: 0.19883042573928833, D Loss Fake: 1.2117700576782227, G Loss: [11.016286849975586, 0.6628173589706421, 0.10353469848632812]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 26, Batch: 27, SSIM Loss: 0.10300654172897339\n",
      "Epoch: 26, Batch: 27, D Loss Real: 0.18629135191440582, D Loss Fake: 1.1653459072113037, G Loss: [11.025395393371582, 0.7178332805633545, 0.10307562351226807]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 28, SSIM Loss: 0.10054439306259155\n",
      "Epoch: 26, Batch: 28, D Loss Real: 0.20721100270748138, D Loss Fake: 1.1527717113494873, G Loss: [10.814793586730957, 0.7430627942085266, 0.10071730613708496]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 29, SSIM Loss: 0.11326479911804199\n",
      "Epoch: 26, Batch: 29, D Loss Real: 0.2850537896156311, D Loss Fake: 1.0037637948989868, G Loss: [12.091086387634277, 0.7677187323570251, 0.11323368549346924]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 30, SSIM Loss: 0.10650604963302612\n",
      "Epoch: 26, Batch: 30, D Loss Real: 0.2162606418132782, D Loss Fake: 1.0066866874694824, G Loss: [11.427151679992676, 0.7535809874534607, 0.1067357063293457]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 31, SSIM Loss: 0.10114490985870361\n",
      "Epoch: 26, Batch: 31, D Loss Real: 0.16169282793998718, D Loss Fake: 1.0734138488769531, G Loss: [10.862730026245117, 0.7259467244148254, 0.10136783123016357]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 32, SSIM Loss: 0.10477203130722046\n",
      "Epoch: 26, Batch: 32, D Loss Real: 0.10553149878978729, D Loss Fake: 1.1484785079956055, G Loss: [11.290820121765137, 0.7466092705726624, 0.1054421067237854]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 33, SSIM Loss: 0.10336548089981079\n",
      "Epoch: 26, Batch: 33, D Loss Real: 0.1455344408750534, D Loss Fake: 1.0576245784759521, G Loss: [11.120705604553223, 0.7605715990066528, 0.10360133647918701]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 34, SSIM Loss: 0.10495352745056152\n",
      "Epoch: 26, Batch: 34, D Loss Real: 0.13020965456962585, D Loss Fake: 1.1063027381896973, G Loss: [11.324671745300293, 0.7710496783256531, 0.10553622245788574]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 35, SSIM Loss: 0.10048151016235352\n",
      "Epoch: 26, Batch: 35, D Loss Real: 0.148644357919693, D Loss Fake: 1.1468199491500854, G Loss: [10.815335273742676, 0.7881473898887634, 0.10027188062667847]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 36, SSIM Loss: 0.1041838526725769\n",
      "Epoch: 26, Batch: 36, D Loss Real: 0.20498760044574738, D Loss Fake: 1.0568686723709106, G Loss: [11.208094596862793, 0.7690563201904297, 0.10439038276672363]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 37, SSIM Loss: 0.1007845401763916\n",
      "Epoch: 26, Batch: 37, D Loss Real: 0.16651731729507446, D Loss Fake: 1.1402552127838135, G Loss: [10.850143432617188, 0.7568717002868652, 0.10093271732330322]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 38, SSIM Loss: 0.10933160781860352\n",
      "Epoch: 26, Batch: 38, D Loss Real: 0.12658949196338654, D Loss Fake: 1.2222487926483154, G Loss: [11.713105201721191, 0.760006844997406, 0.1095309853553772]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 39, SSIM Loss: 0.10474574565887451\n",
      "Epoch: 26, Batch: 39, D Loss Real: 0.1970110833644867, D Loss Fake: 1.051938533782959, G Loss: [11.284640312194824, 0.7844362854957581, 0.10500204563140869]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 40, SSIM Loss: 0.11235517263412476\n",
      "Epoch: 26, Batch: 40, D Loss Real: 0.23783892393112183, D Loss Fake: 1.158255934715271, G Loss: [12.093762397766113, 0.7269546985626221, 0.11366808414459229]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 41, SSIM Loss: 0.09998255968093872\n",
      "Epoch: 26, Batch: 41, D Loss Real: 0.2416127473115921, D Loss Fake: 1.2420742511749268, G Loss: [10.693604469299316, 0.6548949480056763, 0.1003870964050293]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 42, SSIM Loss: 0.10400450229644775\n",
      "Epoch: 26, Batch: 42, D Loss Real: 0.1834799349308014, D Loss Fake: 1.3009624481201172, G Loss: [11.072147369384766, 0.6821155548095703, 0.10390031337738037]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 26, Batch: 43, SSIM Loss: 0.09990441799163818\n",
      "Epoch: 26, Batch: 43, D Loss Real: 0.24006114900112152, D Loss Fake: 1.0836468935012817, G Loss: [10.878445625305176, 0.8706350326538086, 0.10007810592651367]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 44, SSIM Loss: 0.09986209869384766\n",
      "Epoch: 26, Batch: 44, D Loss Real: 0.25696995854377747, D Loss Fake: 1.1482599973678589, G Loss: [10.6924467086792, 0.7463147640228271, 0.09946131706237793]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 45, SSIM Loss: 0.11223554611206055\n",
      "Epoch: 26, Batch: 45, D Loss Real: 0.23185467720031738, D Loss Fake: 1.0744593143463135, G Loss: [11.949701309204102, 0.7224092483520508, 0.11227291822433472]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 46, SSIM Loss: 0.10182249546051025\n",
      "Epoch: 26, Batch: 46, D Loss Real: 0.17174509167671204, D Loss Fake: 1.0487830638885498, G Loss: [10.892057418823242, 0.750791072845459, 0.10141265392303467]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 47, SSIM Loss: 0.11256980895996094\n",
      "Epoch: 26, Batch: 47, D Loss Real: 0.14748266339302063, D Loss Fake: 1.0746421813964844, G Loss: [12.002302169799805, 0.7443199157714844, 0.1125798225402832]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 48, SSIM Loss: 0.10111141204833984\n",
      "Epoch: 26, Batch: 48, D Loss Real: 0.1282152533531189, D Loss Fake: 1.1431427001953125, G Loss: [10.855998039245605, 0.742085337638855, 0.1011391282081604]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 26, Batch: 49, SSIM Loss: 0.10389292240142822\n",
      "Epoch: 26, Batch: 49, D Loss Real: 0.10205961763858795, D Loss Fake: 1.0338332653045654, G Loss: [11.183000564575195, 0.7978152632713318, 0.10385185480117798]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 50, SSIM Loss: 0.10628050565719604\n",
      "Epoch: 26, Batch: 50, D Loss Real: 0.0854371041059494, D Loss Fake: 1.0676156282424927, G Loss: [11.419159889221191, 0.8093186020851135, 0.10609841346740723]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 51, SSIM Loss: 0.1074066162109375\n",
      "Epoch: 26, Batch: 51, D Loss Real: 0.11281175166368484, D Loss Fake: 1.0390747785568237, G Loss: [11.606861114501953, 0.8122397661209106, 0.10794621706008911]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 52, SSIM Loss: 0.10853993892669678\n",
      "Epoch: 26, Batch: 52, D Loss Real: 0.0870773047208786, D Loss Fake: 1.038658857345581, G Loss: [11.609292030334473, 0.8198314309120178, 0.10789459943771362]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 53, SSIM Loss: 0.11038589477539062\n",
      "Epoch: 26, Batch: 53, D Loss Real: 0.10576451569795609, D Loss Fake: 1.1868751049041748, G Loss: [11.817817687988281, 0.8402995467185974, 0.10977518558502197]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 54, SSIM Loss: 0.1083565354347229\n",
      "Epoch: 26, Batch: 54, D Loss Real: 0.20277553796768188, D Loss Fake: 1.097961187362671, G Loss: [11.665702819824219, 0.8235044479370117, 0.10842198133468628]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 55, SSIM Loss: 0.09985566139221191\n",
      "Epoch: 26, Batch: 55, D Loss Real: 0.17690764367580414, D Loss Fake: 1.113508701324463, G Loss: [10.714240074157715, 0.7582498788833618, 0.09955990314483643]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 56, SSIM Loss: 0.10255467891693115\n",
      "Epoch: 26, Batch: 56, D Loss Real: 0.17841778695583344, D Loss Fake: 1.1592884063720703, G Loss: [10.98546028137207, 0.7438085675239563, 0.1024165153503418]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 26, Batch: 57, SSIM Loss: 0.11097937822341919\n",
      "Epoch: 26, Batch: 57, D Loss Real: 0.15695874392986298, D Loss Fake: 1.191676139831543, G Loss: [11.810457229614258, 0.7399314641952515, 0.11070525646209717]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 58, SSIM Loss: 0.10505819320678711\n",
      "Epoch: 26, Batch: 58, D Loss Real: 0.16643497347831726, D Loss Fake: 1.2435238361358643, G Loss: [11.246777534484863, 0.7367032766342163, 0.10510075092315674]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 59, SSIM Loss: 0.09875011444091797\n",
      "Epoch: 26, Batch: 59, D Loss Real: 0.2465924322605133, D Loss Fake: 1.2899868488311768, G Loss: [10.58092975616455, 0.6909691095352173, 0.09889960289001465]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 60, SSIM Loss: 0.10496467351913452\n",
      "Epoch: 26, Batch: 60, D Loss Real: 0.28156381845474243, D Loss Fake: 1.1106209754943848, G Loss: [11.27564811706543, 0.7494863867759705, 0.10526162385940552]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 26, Batch: 61, SSIM Loss: 0.10005903244018555\n",
      "Epoch: 26, Batch: 61, D Loss Real: 0.2977880537509918, D Loss Fake: 1.134133219718933, G Loss: [10.623088836669922, 0.6915906071662903, 0.09931498765945435]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 26, Batch: 62, SSIM Loss: 0.10554498434066772\n",
      "Epoch: 26, Batch: 62, D Loss Real: 0.22140783071517944, D Loss Fake: 1.098104476928711, G Loss: [11.309073448181152, 0.7074941396713257, 0.10601580142974854]\n",
      "1/1 [==============================] - 0s 143ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:48:27.214075: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:48:28.681151: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Batch: 1, SSIM Loss: 0.10127103328704834\n",
      "Epoch: 27, Batch: 1, D Loss Real: 0.19145303964614868, D Loss Fake: 1.0715659856796265, G Loss: [10.858986854553223, 0.733898401260376, 0.10125088691711426]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 27, Batch: 2, SSIM Loss: 0.10271072387695312\n",
      "Epoch: 27, Batch: 2, D Loss Real: 0.18570083379745483, D Loss Fake: 1.070215106010437, G Loss: [10.995526313781738, 0.7448144555091858, 0.10250711441040039]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 27, Batch: 3, SSIM Loss: 0.1101410984992981\n",
      "Epoch: 27, Batch: 3, D Loss Real: 0.11478256434202194, D Loss Fake: 1.0522857904434204, G Loss: [11.75802230834961, 0.7663719654083252, 0.10991650819778442]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 27, Batch: 4, SSIM Loss: 0.10906857252120972\n",
      "Epoch: 27, Batch: 4, D Loss Real: 0.13025255501270294, D Loss Fake: 1.1666088104248047, G Loss: [11.709760665893555, 0.7607688903808594, 0.10948991775512695]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 5, SSIM Loss: 0.10302448272705078\n",
      "Epoch: 27, Batch: 5, D Loss Real: 0.14345429837703705, D Loss Fake: 1.1239734888076782, G Loss: [11.067562103271484, 0.7573888897895813, 0.10310173034667969]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 6, SSIM Loss: 0.09823429584503174\n",
      "Epoch: 27, Batch: 6, D Loss Real: 0.12799972295761108, D Loss Fake: 1.0658042430877686, G Loss: [10.631721496582031, 0.7887775301933289, 0.09842944145202637]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 7, SSIM Loss: 0.10244011878967285\n",
      "Epoch: 27, Batch: 7, D Loss Real: 0.18585491180419922, D Loss Fake: 1.1729419231414795, G Loss: [10.990851402282715, 0.7436503171920776, 0.10247200727462769]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 8, SSIM Loss: 0.10492932796478271\n",
      "Epoch: 27, Batch: 8, D Loss Real: 0.2288396656513214, D Loss Fake: 1.1744600534439087, G Loss: [11.168697357177734, 0.7036956548690796, 0.10465002059936523]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 9, SSIM Loss: 0.10412919521331787\n",
      "Epoch: 27, Batch: 9, D Loss Real: 0.2063315510749817, D Loss Fake: 1.1901057958602905, G Loss: [11.104528427124023, 0.7055265307426453, 0.10399001836776733]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 10, SSIM Loss: 0.10109901428222656\n",
      "Epoch: 27, Batch: 10, D Loss Real: 0.20288226008415222, D Loss Fake: 1.213416337966919, G Loss: [10.839253425598145, 0.7219251990318298, 0.1011732816696167]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 11, SSIM Loss: 0.09874451160430908\n",
      "Epoch: 27, Batch: 11, D Loss Real: 0.2313326895236969, D Loss Fake: 1.1006875038146973, G Loss: [10.663030624389648, 0.7427197694778442, 0.09920310974121094]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 27, Batch: 12, SSIM Loss: 0.09861600399017334\n",
      "Epoch: 27, Batch: 12, D Loss Real: 0.23121008276939392, D Loss Fake: 1.0845788717269897, G Loss: [10.552067756652832, 0.7172779440879822, 0.09834790229797363]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 13, SSIM Loss: 0.10313630104064941\n",
      "Epoch: 27, Batch: 13, D Loss Real: 0.17870259284973145, D Loss Fake: 1.0319652557373047, G Loss: [11.089285850524902, 0.7731998562812805, 0.10316085815429688]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 14, SSIM Loss: 0.10723364353179932\n",
      "Epoch: 27, Batch: 14, D Loss Real: 0.14736686646938324, D Loss Fake: 1.2311381101608276, G Loss: [11.466604232788086, 0.752729594707489, 0.1071387529373169]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 27, Batch: 15, SSIM Loss: 0.10854262113571167\n",
      "Epoch: 27, Batch: 15, D Loss Real: 0.1964745819568634, D Loss Fake: 1.2485617399215698, G Loss: [11.523895263671875, 0.7196347117424011, 0.10804259777069092]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 27, Batch: 16, SSIM Loss: 0.11481738090515137\n",
      "Epoch: 27, Batch: 16, D Loss Real: 0.27687332034111023, D Loss Fake: 1.1931548118591309, G Loss: [12.170449256896973, 0.6966924667358398, 0.11473757028579712]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 17, SSIM Loss: 0.09964275360107422\n",
      "Epoch: 27, Batch: 17, D Loss Real: 0.2460450977087021, D Loss Fake: 1.0704394578933716, G Loss: [10.741659164428711, 0.7357503175735474, 0.10005909204483032]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 18, SSIM Loss: 0.10031819343566895\n",
      "Epoch: 27, Batch: 18, D Loss Real: 0.2606569826602936, D Loss Fake: 1.151918649673462, G Loss: [10.71491527557373, 0.6705015897750854, 0.10044413805007935]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 19, SSIM Loss: 0.10729140043258667\n",
      "Epoch: 27, Batch: 19, D Loss Real: 0.18612609803676605, D Loss Fake: 1.0786089897155762, G Loss: [11.440176010131836, 0.7213295698165894, 0.10718846321105957]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 20, SSIM Loss: 0.10592401027679443\n",
      "Epoch: 27, Batch: 20, D Loss Real: 0.18715360760688782, D Loss Fake: 1.0981688499450684, G Loss: [11.306584358215332, 0.7405820488929749, 0.10566002130508423]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 21, SSIM Loss: 0.1023869514465332\n",
      "Epoch: 27, Batch: 21, D Loss Real: 0.13461600244045258, D Loss Fake: 1.1411268711090088, G Loss: [10.989153861999512, 0.7819413542747498, 0.10207211971282959]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 22, SSIM Loss: 0.09764409065246582\n",
      "Epoch: 27, Batch: 22, D Loss Real: 0.14963822066783905, D Loss Fake: 1.3145573139190674, G Loss: [10.481762886047363, 0.7393659353256226, 0.0974239706993103]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 23, SSIM Loss: 0.11056143045425415\n",
      "Epoch: 27, Batch: 23, D Loss Real: 0.22341865301132202, D Loss Fake: 1.1050550937652588, G Loss: [11.806644439697266, 0.7247692942619324, 0.11081874370574951]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 24, SSIM Loss: 0.10541200637817383\n",
      "Epoch: 27, Batch: 24, D Loss Real: 0.2417081892490387, D Loss Fake: 1.0887353420257568, G Loss: [11.217850685119629, 0.706839382648468, 0.10511010885238647]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 27, Batch: 25, SSIM Loss: 0.09727323055267334\n",
      "Epoch: 27, Batch: 25, D Loss Real: 0.19810348749160767, D Loss Fake: 1.130392074584961, G Loss: [10.451547622680664, 0.6998459100723267, 0.09751701354980469]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 26, SSIM Loss: 0.10025274753570557\n",
      "Epoch: 27, Batch: 26, D Loss Real: 0.15564335882663727, D Loss Fake: 1.2014367580413818, G Loss: [10.728669166564941, 0.7003180980682373, 0.10028350353240967]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 27, SSIM Loss: 0.09917938709259033\n",
      "Epoch: 27, Batch: 27, D Loss Real: 0.1726265549659729, D Loss Fake: 1.2572638988494873, G Loss: [10.692277908325195, 0.7152472138404846, 0.09977030754089355]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 28, SSIM Loss: 0.10023355484008789\n",
      "Epoch: 27, Batch: 28, D Loss Real: 0.22721202671527863, D Loss Fake: 1.0275951623916626, G Loss: [10.745549201965332, 0.7983741760253906, 0.09947174787521362]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 27, Batch: 29, SSIM Loss: 0.10696631669998169\n",
      "Epoch: 27, Batch: 29, D Loss Real: 0.3154796361923218, D Loss Fake: 1.0158162117004395, G Loss: [11.465234756469727, 0.7332518696784973, 0.10731983184814453]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 30, SSIM Loss: 0.10273319482803345\n",
      "Epoch: 27, Batch: 30, D Loss Real: 0.24169866740703583, D Loss Fake: 1.030131459236145, G Loss: [11.018710136413574, 0.7428691983222961, 0.10275840759277344]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 31, SSIM Loss: 0.09851032495498657\n",
      "Epoch: 27, Batch: 31, D Loss Real: 0.1820034682750702, D Loss Fake: 1.0797839164733887, G Loss: [10.563151359558105, 0.722907304763794, 0.09840244054794312]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 32, SSIM Loss: 0.10344243049621582\n",
      "Epoch: 27, Batch: 32, D Loss Real: 0.11630694568157196, D Loss Fake: 1.0760951042175293, G Loss: [11.118711471557617, 0.7528073787689209, 0.10365903377532959]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 33, SSIM Loss: 0.0998610258102417\n",
      "Epoch: 27, Batch: 33, D Loss Real: 0.13249096274375916, D Loss Fake: 1.0756300687789917, G Loss: [10.776741027832031, 0.7724224925041199, 0.10004317760467529]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 34, SSIM Loss: 0.1030535101890564\n",
      "Epoch: 27, Batch: 34, D Loss Real: 0.11384551227092743, D Loss Fake: 1.0690813064575195, G Loss: [11.03134822845459, 0.7685612440109253, 0.10262787342071533]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 27, Batch: 35, SSIM Loss: 0.09851408004760742\n",
      "Epoch: 27, Batch: 35, D Loss Real: 0.12817198038101196, D Loss Fake: 1.2490826845169067, G Loss: [10.626310348510742, 0.7739664316177368, 0.09852343797683716]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 36, SSIM Loss: 0.10250508785247803\n",
      "Epoch: 27, Batch: 36, D Loss Real: 0.18125545978546143, D Loss Fake: 1.1094906330108643, G Loss: [11.040221214294434, 0.7507009506225586, 0.10289520025253296]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 37, SSIM Loss: 0.09971082210540771\n",
      "Epoch: 27, Batch: 37, D Loss Real: 0.17945674061775208, D Loss Fake: 1.1558281183242798, G Loss: [10.674617767333984, 0.7272812128067017, 0.09947335720062256]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 27, Batch: 38, SSIM Loss: 0.10696142911911011\n",
      "Epoch: 27, Batch: 38, D Loss Real: 0.1799267828464508, D Loss Fake: 1.303727626800537, G Loss: [11.371724128723145, 0.7112302780151367, 0.1066049337387085]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 39, SSIM Loss: 0.1025623083114624\n",
      "Epoch: 27, Batch: 39, D Loss Real: 0.2822098135948181, D Loss Fake: 1.1465001106262207, G Loss: [10.939502716064453, 0.7237430214881897, 0.1021575927734375]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 40, SSIM Loss: 0.10831284523010254\n",
      "Epoch: 27, Batch: 40, D Loss Real: 0.28804418444633484, D Loss Fake: 1.1185365915298462, G Loss: [11.493388175964355, 0.682154655456543, 0.10811233520507812]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 41, SSIM Loss: 0.09710758924484253\n",
      "Epoch: 27, Batch: 41, D Loss Real: 0.2818581461906433, D Loss Fake: 1.2130591869354248, G Loss: [10.406403541564941, 0.6408444046974182, 0.09765559434890747]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 42, SSIM Loss: 0.10104930400848389\n",
      "Epoch: 27, Batch: 42, D Loss Real: 0.20271769165992737, D Loss Fake: 1.2602534294128418, G Loss: [10.750760078430176, 0.6827903985977173, 0.10067969560623169]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 43, SSIM Loss: 0.09871494770050049\n",
      "Epoch: 27, Batch: 43, D Loss Real: 0.3015119135379791, D Loss Fake: 1.2543624639511108, G Loss: [10.58657169342041, 0.6888512969017029, 0.09897720813751221]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 44, SSIM Loss: 0.0954439640045166\n",
      "Epoch: 27, Batch: 44, D Loss Real: 0.23257941007614136, D Loss Fake: 1.1722638607025146, G Loss: [10.225713729858398, 0.6898289918899536, 0.09535884857177734]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 45, SSIM Loss: 0.10918521881103516\n",
      "Epoch: 27, Batch: 45, D Loss Real: 0.22176718711853027, D Loss Fake: 1.1057240962982178, G Loss: [11.653246879577637, 0.7088915705680847, 0.1094435453414917]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 46, SSIM Loss: 0.09874451160430908\n",
      "Epoch: 27, Batch: 46, D Loss Real: 0.22034411132335663, D Loss Fake: 1.1750086545944214, G Loss: [10.542584419250488, 0.6774076223373413, 0.09865176677703857]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 47, SSIM Loss: 0.1082998514175415\n",
      "Epoch: 27, Batch: 47, D Loss Real: 0.19387872517108917, D Loss Fake: 1.246882438659668, G Loss: [11.536376953125, 0.7004795670509338, 0.10835897922515869]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 48, SSIM Loss: 0.09921413660049438\n",
      "Epoch: 27, Batch: 48, D Loss Real: 0.2545762062072754, D Loss Fake: 1.1908690929412842, G Loss: [10.60242748260498, 0.7036336064338684, 0.09898793697357178]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 49, SSIM Loss: 0.10146522521972656\n",
      "Epoch: 27, Batch: 49, D Loss Real: 0.23129236698150635, D Loss Fake: 1.0978193283081055, G Loss: [10.922080039978027, 0.7285833358764648, 0.10193496942520142]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 50, SSIM Loss: 0.10430818796157837\n",
      "Epoch: 27, Batch: 50, D Loss Real: 0.20625847578048706, D Loss Fake: 1.0658100843429565, G Loss: [11.188284873962402, 0.7336664795875549, 0.1045461893081665]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 27, Batch: 51, SSIM Loss: 0.10434162616729736\n",
      "Epoch: 27, Batch: 51, D Loss Real: 0.1877571940422058, D Loss Fake: 1.0741289854049683, G Loss: [11.170515060424805, 0.7326265573501587, 0.10437887907028198]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 52, SSIM Loss: 0.10536015033721924\n",
      "Epoch: 27, Batch: 52, D Loss Real: 0.12342934310436249, D Loss Fake: 1.1074435710906982, G Loss: [11.22300910949707, 0.7277169227600098, 0.10495293140411377]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 27, Batch: 53, SSIM Loss: 0.10076594352722168\n",
      "Epoch: 27, Batch: 53, D Loss Real: 0.11717391014099121, D Loss Fake: 1.2653117179870605, G Loss: [10.850700378417969, 0.776645839214325, 0.10074055194854736]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 54, SSIM Loss: 0.10661941766738892\n",
      "Epoch: 27, Batch: 54, D Loss Real: 0.22524748742580414, D Loss Fake: 1.169914722442627, G Loss: [11.387348175048828, 0.733161211013794, 0.10654187202453613]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 55, SSIM Loss: 0.09867578744888306\n",
      "Epoch: 27, Batch: 55, D Loss Real: 0.2596888244152069, D Loss Fake: 1.0576496124267578, G Loss: [10.653298377990723, 0.7653827667236328, 0.09887915849685669]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 56, SSIM Loss: 0.09983700513839722\n",
      "Epoch: 27, Batch: 56, D Loss Real: 0.24603202939033508, D Loss Fake: 1.162691354751587, G Loss: [10.708748817443848, 0.679653525352478, 0.10029095411300659]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 27, Batch: 57, SSIM Loss: 0.10963380336761475\n",
      "Epoch: 27, Batch: 57, D Loss Real: 0.1975705921649933, D Loss Fake: 1.127755880355835, G Loss: [11.708392143249512, 0.718762218952179, 0.10989630222320557]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 58, SSIM Loss: 0.10252118110656738\n",
      "Epoch: 27, Batch: 58, D Loss Real: 0.18185551464557648, D Loss Fake: 1.2147953510284424, G Loss: [10.973982810974121, 0.6927778720855713, 0.10281205177307129]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 59, SSIM Loss: 0.09800440073013306\n",
      "Epoch: 27, Batch: 59, D Loss Real: 0.23486414551734924, D Loss Fake: 1.1695666313171387, G Loss: [10.51449966430664, 0.7023472785949707, 0.0981215238571167]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 60, SSIM Loss: 0.10406416654586792\n",
      "Epoch: 27, Batch: 60, D Loss Real: 0.23148158192634583, D Loss Fake: 1.3756840229034424, G Loss: [11.06655216217041, 0.6791319251060486, 0.10387420654296875]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 61, SSIM Loss: 0.10106998682022095\n",
      "Epoch: 27, Batch: 61, D Loss Real: 0.2623317539691925, D Loss Fake: 1.1370563507080078, G Loss: [10.875349044799805, 0.6893685460090637, 0.10185980796813965]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 27, Batch: 62, SSIM Loss: 0.1017298698425293\n",
      "Epoch: 27, Batch: 62, D Loss Real: 0.25987404584884644, D Loss Fake: 1.0817906856536865, G Loss: [10.867716789245605, 0.72117018699646, 0.10146546363830566]\n",
      "1/1 [==============================] - 0s 144ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:49:50.425009: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:49:51.897820: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Batch: 1, SSIM Loss: 0.09869605302810669\n",
      "Epoch: 28, Batch: 1, D Loss Real: 0.22478725016117096, D Loss Fake: 1.1616427898406982, G Loss: [10.579137802124023, 0.6792594194412231, 0.0989987850189209]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 2, SSIM Loss: 0.09863698482513428\n",
      "Epoch: 28, Batch: 2, D Loss Real: 0.22302667796611786, D Loss Fake: 1.200201153755188, G Loss: [10.555685997009277, 0.6812352538108826, 0.09874451160430908]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 28, Batch: 3, SSIM Loss: 0.10544490814208984\n",
      "Epoch: 28, Batch: 3, D Loss Real: 0.14503704011440277, D Loss Fake: 1.1160093545913696, G Loss: [11.268072128295898, 0.741855800151825, 0.1052621603012085]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 4, SSIM Loss: 0.10524415969848633\n",
      "Epoch: 28, Batch: 4, D Loss Real: 0.18234433233737946, D Loss Fake: 1.1721552610397339, G Loss: [11.266117095947266, 0.7484184503555298, 0.10517698526382446]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 5, SSIM Loss: 0.10064935684204102\n",
      "Epoch: 28, Batch: 5, D Loss Real: 0.1854199469089508, D Loss Fake: 1.1339442729949951, G Loss: [10.79206657409668, 0.7433613538742065, 0.10048705339431763]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 6, SSIM Loss: 0.09603482484817505\n",
      "Epoch: 28, Batch: 6, D Loss Real: 0.14293114840984344, D Loss Fake: 1.2040680646896362, G Loss: [10.37646484375, 0.7530217170715332, 0.09623444080352783]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 7, SSIM Loss: 0.1008528470993042\n",
      "Epoch: 28, Batch: 7, D Loss Real: 0.26144319772720337, D Loss Fake: 1.065153956413269, G Loss: [10.870610237121582, 0.7748470902442932, 0.10095763206481934]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 8, SSIM Loss: 0.10317325592041016\n",
      "Epoch: 28, Batch: 8, D Loss Real: 0.2704843580722809, D Loss Fake: 1.1182996034622192, G Loss: [11.033345222473145, 0.7464596629142761, 0.10286885499954224]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 9, SSIM Loss: 0.10329562425613403\n",
      "Epoch: 28, Batch: 9, D Loss Real: 0.2233872264623642, D Loss Fake: 1.0989556312561035, G Loss: [11.070131301879883, 0.7485733032226562, 0.10321557521820068]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 28, Batch: 10, SSIM Loss: 0.09969770908355713\n",
      "Epoch: 28, Batch: 10, D Loss Real: 0.18008920550346375, D Loss Fake: 1.129666805267334, G Loss: [10.654276847839355, 0.7124074697494507, 0.09941869974136353]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 28, Batch: 11, SSIM Loss: 0.09812402725219727\n",
      "Epoch: 28, Batch: 11, D Loss Real: 0.1338033825159073, D Loss Fake: 1.1177401542663574, G Loss: [10.573472023010254, 0.7382234334945679, 0.09835249185562134]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 12, SSIM Loss: 0.09789341688156128\n",
      "Epoch: 28, Batch: 12, D Loss Real: 0.11886460334062576, D Loss Fake: 1.4266467094421387, G Loss: [10.559202194213867, 0.760187566280365, 0.09799015522003174]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 13, SSIM Loss: 0.10112261772155762\n",
      "Epoch: 28, Batch: 13, D Loss Real: 0.21888355910778046, D Loss Fake: 1.1074028015136719, G Loss: [10.871771812438965, 0.7430587410926819, 0.1012871265411377]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 14, SSIM Loss: 0.10473263263702393\n",
      "Epoch: 28, Batch: 14, D Loss Real: 0.24631601572036743, D Loss Fake: 1.1232573986053467, G Loss: [11.19053840637207, 0.697503924369812, 0.1049303412437439]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 15, SSIM Loss: 0.10691136121749878\n",
      "Epoch: 28, Batch: 15, D Loss Real: 0.22744089365005493, D Loss Fake: 1.1398301124572754, G Loss: [11.350793838500977, 0.6969528198242188, 0.10653841495513916]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 16, SSIM Loss: 0.10455065965652466\n",
      "Epoch: 28, Batch: 16, D Loss Real: 0.2292313277721405, D Loss Fake: 1.1507779359817505, G Loss: [11.18801212310791, 0.6748734712600708, 0.10513138771057129]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 17, SSIM Loss: 0.09918153285980225\n",
      "Epoch: 28, Batch: 17, D Loss Real: 0.20382924377918243, D Loss Fake: 1.0869135856628418, G Loss: [10.602996826171875, 0.7374803423881531, 0.09865516424179077]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 28, Batch: 18, SSIM Loss: 0.09890627861022949\n",
      "Epoch: 28, Batch: 18, D Loss Real: 0.15550129115581512, D Loss Fake: 1.1108139753341675, G Loss: [10.623221397399902, 0.7385665774345398, 0.09884655475616455]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 19, SSIM Loss: 0.1034349799156189\n",
      "Epoch: 28, Batch: 19, D Loss Real: 0.10512497276067734, D Loss Fake: 1.176684021949768, G Loss: [11.181661605834961, 0.7825472354888916, 0.10399115085601807]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 20, SSIM Loss: 0.10248219966888428\n",
      "Epoch: 28, Batch: 20, D Loss Real: 0.13914944231510162, D Loss Fake: 1.179356575012207, G Loss: [11.044090270996094, 0.7783219814300537, 0.10265767574310303]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 21, SSIM Loss: 0.1001274585723877\n",
      "Epoch: 28, Batch: 21, D Loss Real: 0.15969079732894897, D Loss Fake: 1.0901317596435547, G Loss: [10.752163887023926, 0.775007963180542, 0.09977155923843384]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 22, SSIM Loss: 0.09741604328155518\n",
      "Epoch: 28, Batch: 22, D Loss Real: 0.19687262177467346, D Loss Fake: 1.1139603853225708, G Loss: [10.520785331726074, 0.8134718537330627, 0.09707313776016235]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 23, SSIM Loss: 0.1084790825843811\n",
      "Epoch: 28, Batch: 23, D Loss Real: 0.21438908576965332, D Loss Fake: 1.03371262550354, G Loss: [11.639542579650879, 0.7668629884719849, 0.10872679948806763]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 24, SSIM Loss: 0.10335969924926758\n",
      "Epoch: 28, Batch: 24, D Loss Real: 0.20001664757728577, D Loss Fake: 1.0082600116729736, G Loss: [11.083575248718262, 0.7854188680648804, 0.1029815673828125]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 25, SSIM Loss: 0.09764611721038818\n",
      "Epoch: 28, Batch: 25, D Loss Real: 0.13602247834205627, D Loss Fake: 1.1004505157470703, G Loss: [10.584650039672852, 0.7895932197570801, 0.09795057773590088]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 26, SSIM Loss: 0.10070836544036865\n",
      "Epoch: 28, Batch: 26, D Loss Real: 0.12849017977714539, D Loss Fake: 1.0781382322311401, G Loss: [10.838932991027832, 0.7828075885772705, 0.10056126117706299]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 27, SSIM Loss: 0.09734344482421875\n",
      "Epoch: 28, Batch: 27, D Loss Real: 0.13799169659614563, D Loss Fake: 1.096495509147644, G Loss: [10.542394638061523, 0.7907885909080505, 0.09751605987548828]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 28, SSIM Loss: 0.09932571649551392\n",
      "Epoch: 28, Batch: 28, D Loss Real: 0.12342873215675354, D Loss Fake: 1.4373832941055298, G Loss: [10.712193489074707, 0.7950772047042847, 0.09917116165161133]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 29, SSIM Loss: 0.10685640573501587\n",
      "Epoch: 28, Batch: 29, D Loss Real: 0.2966393530368805, D Loss Fake: 1.118319034576416, G Loss: [11.409146308898926, 0.7346224188804626, 0.10674524307250977]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 30, SSIM Loss: 0.1006326675415039\n",
      "Epoch: 28, Batch: 30, D Loss Real: 0.28261277079582214, D Loss Fake: 1.119754433631897, G Loss: [10.745396614074707, 0.6861714124679565, 0.10059225559234619]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 28, Batch: 31, SSIM Loss: 0.09847044944763184\n",
      "Epoch: 28, Batch: 31, D Loss Real: 0.25509658455848694, D Loss Fake: 1.1684335470199585, G Loss: [10.414469718933105, 0.6624823212623596, 0.0975198745727539]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 28, Batch: 32, SSIM Loss: 0.10038816928863525\n",
      "Epoch: 28, Batch: 32, D Loss Real: 0.18216204643249512, D Loss Fake: 1.1713039875030518, G Loss: [10.720617294311523, 0.6707385182380676, 0.10049879550933838]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 33, SSIM Loss: 0.09845530986785889\n",
      "Epoch: 28, Batch: 33, D Loss Real: 0.20985525846481323, D Loss Fake: 1.1455775499343872, G Loss: [10.540030479431152, 0.6903625726699829, 0.09849667549133301]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 34, SSIM Loss: 0.10239005088806152\n",
      "Epoch: 28, Batch: 34, D Loss Real: 0.19384008646011353, D Loss Fake: 1.1894803047180176, G Loss: [10.866205215454102, 0.6917643547058105, 0.10174441337585449]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 35, SSIM Loss: 0.0959119200706482\n",
      "Epoch: 28, Batch: 35, D Loss Real: 0.21939058601856232, D Loss Fake: 1.0653421878814697, G Loss: [10.413885116577148, 0.8206002116203308, 0.09593284130096436]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 36, SSIM Loss: 0.10280996561050415\n",
      "Epoch: 28, Batch: 36, D Loss Real: 0.2228522151708603, D Loss Fake: 1.0688003301620483, G Loss: [10.976099014282227, 0.7411468029022217, 0.10234951972961426]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 37, SSIM Loss: 0.10011327266693115\n",
      "Epoch: 28, Batch: 37, D Loss Real: 0.1710357666015625, D Loss Fake: 1.003919005393982, G Loss: [10.781229019165039, 0.7895176410675049, 0.09991711378097534]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 38, SSIM Loss: 0.10339891910552979\n",
      "Epoch: 28, Batch: 38, D Loss Real: 0.11516273021697998, D Loss Fake: 1.0985684394836426, G Loss: [11.140547752380371, 0.777207612991333, 0.10363340377807617]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 39, SSIM Loss: 0.10200917720794678\n",
      "Epoch: 28, Batch: 39, D Loss Real: 0.13158263266086578, D Loss Fake: 1.0605310201644897, G Loss: [10.974555969238281, 0.8036785125732422, 0.10170876979827881]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 40, SSIM Loss: 0.10391426086425781\n",
      "Epoch: 28, Batch: 40, D Loss Real: 0.15283538401126862, D Loss Fake: 1.0664764642715454, G Loss: [11.183114051818848, 0.766319990158081, 0.10416793823242188]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 41, SSIM Loss: 0.09660637378692627\n",
      "Epoch: 28, Batch: 41, D Loss Real: 0.17259007692337036, D Loss Fake: 1.2245242595672607, G Loss: [10.480379104614258, 0.7273131012916565, 0.09753066301345825]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 42, SSIM Loss: 0.09954869747161865\n",
      "Epoch: 28, Batch: 42, D Loss Real: 0.13359330594539642, D Loss Fake: 1.1507649421691895, G Loss: [10.690834999084473, 0.7581858038902283, 0.099326491355896]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 43, SSIM Loss: 0.09853506088256836\n",
      "Epoch: 28, Batch: 43, D Loss Real: 0.18077445030212402, D Loss Fake: 1.2230727672576904, G Loss: [10.573163986206055, 0.7186088562011719, 0.09854555130004883]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 44, SSIM Loss: 0.09453821182250977\n",
      "Epoch: 28, Batch: 44, D Loss Real: 0.21241572499275208, D Loss Fake: 1.2293351888656616, G Loss: [10.146976470947266, 0.6815316081047058, 0.09465444087982178]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 45, SSIM Loss: 0.10810506343841553\n",
      "Epoch: 28, Batch: 45, D Loss Real: 0.23409532010555267, D Loss Fake: 1.121455430984497, G Loss: [11.538320541381836, 0.7060468792915344, 0.10832273960113525]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 46, SSIM Loss: 0.097481369972229\n",
      "Epoch: 28, Batch: 46, D Loss Real: 0.23070895671844482, D Loss Fake: 1.2480695247650146, G Loss: [10.393953323364258, 0.6592454314231873, 0.09734708070755005]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 47, SSIM Loss: 0.10658419132232666\n",
      "Epoch: 28, Batch: 47, D Loss Real: 0.21681879460811615, D Loss Fake: 1.2083152532577515, G Loss: [11.32814884185791, 0.6639774441719055, 0.10664170980453491]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 48, SSIM Loss: 0.09867721796035767\n",
      "Epoch: 28, Batch: 48, D Loss Real: 0.25149405002593994, D Loss Fake: 1.2476409673690796, G Loss: [10.509181022644043, 0.6616408228874207, 0.0984753966331482]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 49, SSIM Loss: 0.09961670637130737\n",
      "Epoch: 28, Batch: 49, D Loss Real: 0.24785330891609192, D Loss Fake: 1.1572424173355103, G Loss: [10.694029808044434, 0.6996243000030518, 0.09994405508041382]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 50, SSIM Loss: 0.10159134864807129\n",
      "Epoch: 28, Batch: 50, D Loss Real: 0.25681236386299133, D Loss Fake: 1.1745004653930664, G Loss: [10.869133949279785, 0.6645507216453552, 0.10204583406448364]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 51, SSIM Loss: 0.10029524564743042\n",
      "Epoch: 28, Batch: 51, D Loss Real: 0.2728006839752197, D Loss Fake: 1.1367617845535278, G Loss: [10.708353042602539, 0.6694640517234802, 0.10038888454437256]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 52, SSIM Loss: 0.10418224334716797\n",
      "Epoch: 28, Batch: 52, D Loss Real: 0.21612945199012756, D Loss Fake: 1.2115774154663086, G Loss: [11.094976425170898, 0.6723119020462036, 0.10422664880752563]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 53, SSIM Loss: 0.09901726245880127\n",
      "Epoch: 28, Batch: 53, D Loss Real: 0.20685052871704102, D Loss Fake: 1.2038904428482056, G Loss: [10.58786392211914, 0.6887481808662415, 0.09899115562438965]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 54, SSIM Loss: 0.10415244102478027\n",
      "Epoch: 28, Batch: 54, D Loss Real: 0.24725572764873505, D Loss Fake: 1.1717119216918945, G Loss: [11.200942039489746, 0.6756085157394409, 0.10525333881378174]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 28, Batch: 55, SSIM Loss: 0.0973505973815918\n",
      "Epoch: 28, Batch: 55, D Loss Real: 0.26773136854171753, D Loss Fake: 1.26121187210083, G Loss: [10.374252319335938, 0.6930334568023682, 0.0968121886253357]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 56, SSIM Loss: 0.09960675239562988\n",
      "Epoch: 28, Batch: 56, D Loss Real: 0.2938762605190277, D Loss Fake: 1.0984327793121338, G Loss: [10.6429443359375, 0.692044734954834, 0.09950900077819824]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 57, SSIM Loss: 0.10872781276702881\n",
      "Epoch: 28, Batch: 57, D Loss Real: 0.24287614226341248, D Loss Fake: 1.086639404296875, G Loss: [11.622319221496582, 0.7137628793716431, 0.1090855598449707]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 58, SSIM Loss: 0.10051417350769043\n",
      "Epoch: 28, Batch: 58, D Loss Real: 0.20119398832321167, D Loss Fake: 1.2120285034179688, G Loss: [10.727961540222168, 0.681157112121582, 0.10046803951263428]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 59, SSIM Loss: 0.09561455249786377\n",
      "Epoch: 28, Batch: 59, D Loss Real: 0.23782777786254883, D Loss Fake: 1.1875962018966675, G Loss: [10.255646705627441, 0.6797313094139099, 0.09575915336608887]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 60, SSIM Loss: 0.10235649347305298\n",
      "Epoch: 28, Batch: 60, D Loss Real: 0.2588770389556885, D Loss Fake: 1.0378170013427734, G Loss: [11.003934860229492, 0.7949997186660767, 0.10208934545516968]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 61, SSIM Loss: 0.09761285781860352\n",
      "Epoch: 28, Batch: 61, D Loss Real: 0.2243475466966629, D Loss Fake: 1.086213231086731, G Loss: [10.511120796203613, 0.719722330570221, 0.09791398048400879]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 28, Batch: 62, SSIM Loss: 0.10078704357147217\n",
      "Epoch: 28, Batch: 62, D Loss Real: 0.16159632802009583, D Loss Fake: 1.0077050924301147, G Loss: [10.877366065979004, 0.7796005606651306, 0.10097765922546387]\n",
      "1/1 [==============================] - 0s 145ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:51:13.748783: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:51:15.205339: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Batch: 1, SSIM Loss: 0.09723562002182007\n",
      "Epoch: 29, Batch: 1, D Loss Real: 0.13936643302440643, D Loss Fake: 1.0470613241195679, G Loss: [10.483100891113281, 0.7553848028182983, 0.09727716445922852]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 2, SSIM Loss: 0.0977715253829956\n",
      "Epoch: 29, Batch: 2, D Loss Real: 0.1339181810617447, D Loss Fake: 1.1200897693634033, G Loss: [10.53219985961914, 0.7681719660758972, 0.0976402759552002]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 29, Batch: 3, SSIM Loss: 0.10322391986846924\n",
      "Epoch: 29, Batch: 3, D Loss Real: 0.11547952890396118, D Loss Fake: 1.069926142692566, G Loss: [11.06814956665039, 0.7664280533790588, 0.10301721096038818]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 4, SSIM Loss: 0.10579478740692139\n",
      "Epoch: 29, Batch: 4, D Loss Real: 0.14818282425403595, D Loss Fake: 1.11942720413208, G Loss: [11.306224822998047, 0.7519111633300781, 0.10554313659667969]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 5, SSIM Loss: 0.09885501861572266\n",
      "Epoch: 29, Batch: 5, D Loss Real: 0.1373952329158783, D Loss Fake: 1.2184580564498901, G Loss: [10.592971801757812, 0.7238792777061462, 0.098690927028656]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 29, Batch: 6, SSIM Loss: 0.09683668613433838\n",
      "Epoch: 29, Batch: 6, D Loss Real: 0.15030039846897125, D Loss Fake: 1.1735655069351196, G Loss: [10.390707015991211, 0.7232628464698792, 0.09667444229125977]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 7, SSIM Loss: 0.10054504871368408\n",
      "Epoch: 29, Batch: 7, D Loss Real: 0.26479798555374146, D Loss Fake: 1.0692089796066284, G Loss: [10.806549072265625, 0.7644361257553101, 0.10042113065719604]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 8, SSIM Loss: 0.10060453414916992\n",
      "Epoch: 29, Batch: 8, D Loss Real: 0.24130326509475708, D Loss Fake: 1.2368510961532593, G Loss: [10.70885181427002, 0.6789635419845581, 0.10029888153076172]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 9, SSIM Loss: 0.10116899013519287\n",
      "Epoch: 29, Batch: 9, D Loss Real: 0.21582373976707458, D Loss Fake: 1.1445720195770264, G Loss: [10.791308403015137, 0.7001227736473083, 0.10091185569763184]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 10, SSIM Loss: 0.09748244285583496\n",
      "Epoch: 29, Batch: 10, D Loss Real: 0.21165180206298828, D Loss Fake: 1.1954398155212402, G Loss: [10.41960334777832, 0.6830415725708008, 0.0973656177520752]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 11, SSIM Loss: 0.0969700813293457\n",
      "Epoch: 29, Batch: 11, D Loss Real: 0.18821512162685394, D Loss Fake: 1.2325109243392944, G Loss: [10.39508056640625, 0.6994309425354004, 0.09695649147033691]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 12, SSIM Loss: 0.09673362970352173\n",
      "Epoch: 29, Batch: 12, D Loss Real: 0.21867023408412933, D Loss Fake: 1.1209094524383545, G Loss: [10.378615379333496, 0.6960130333900452, 0.09682601690292358]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 13, SSIM Loss: 0.10010010004043579\n",
      "Epoch: 29, Batch: 13, D Loss Real: 0.2128494679927826, D Loss Fake: 1.1667301654815674, G Loss: [10.692289352416992, 0.7024369835853577, 0.09989851713180542]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 14, SSIM Loss: 0.10454714298248291\n",
      "Epoch: 29, Batch: 14, D Loss Real: 0.20882363617420197, D Loss Fake: 1.166549801826477, G Loss: [11.188374519348145, 0.7046859264373779, 0.10483688116073608]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 29, Batch: 15, SSIM Loss: 0.10488951206207275\n",
      "Epoch: 29, Batch: 15, D Loss Real: 0.21832339465618134, D Loss Fake: 1.1525511741638184, G Loss: [11.239965438842773, 0.716002345085144, 0.1052396297454834]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 29, Batch: 16, SSIM Loss: 0.10405254364013672\n",
      "Epoch: 29, Batch: 16, D Loss Real: 0.2559863030910492, D Loss Fake: 1.0906625986099243, G Loss: [11.085431098937988, 0.7005555033683777, 0.10384875535964966]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 17, SSIM Loss: 0.09898978471755981\n",
      "Epoch: 29, Batch: 17, D Loss Real: 0.21662771701812744, D Loss Fake: 1.0543712377548218, G Loss: [10.794946670532227, 0.7563801407814026, 0.10038566589355469]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 18, SSIM Loss: 0.09777039289474487\n",
      "Epoch: 29, Batch: 18, D Loss Real: 0.197293221950531, D Loss Fake: 1.1784459352493286, G Loss: [10.509193420410156, 0.6942999958992004, 0.09814894199371338]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 19, SSIM Loss: 0.10196352005004883\n",
      "Epoch: 29, Batch: 19, D Loss Real: 0.14567363262176514, D Loss Fake: 1.1583828926086426, G Loss: [10.855545043945312, 0.7068657875061035, 0.10148680210113525]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 20, SSIM Loss: 0.1011168360710144\n",
      "Epoch: 29, Batch: 20, D Loss Real: 0.16388662159442902, D Loss Fake: 1.1509150266647339, G Loss: [10.832052230834961, 0.7316510677337646, 0.10100400447845459]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 21, SSIM Loss: 0.09768915176391602\n",
      "Epoch: 29, Batch: 21, D Loss Real: 0.18150827288627625, D Loss Fake: 1.0253829956054688, G Loss: [10.527002334594727, 0.7535756826400757, 0.09773427248001099]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 29, Batch: 22, SSIM Loss: 0.0978018045425415\n",
      "Epoch: 29, Batch: 22, D Loss Real: 0.185464546084404, D Loss Fake: 1.2646896839141846, G Loss: [10.528043746948242, 0.7424630522727966, 0.09785580635070801]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 23, SSIM Loss: 0.10236573219299316\n",
      "Epoch: 29, Batch: 23, D Loss Real: 0.2499922662973404, D Loss Fake: 1.1061513423919678, G Loss: [10.996849060058594, 0.7340739965438843, 0.10262775421142578]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 29, Batch: 24, SSIM Loss: 0.10157644748687744\n",
      "Epoch: 29, Batch: 24, D Loss Real: 0.27925801277160645, D Loss Fake: 1.143622875213623, G Loss: [10.831449508666992, 0.6961383819580078, 0.10135310888290405]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 25, SSIM Loss: 0.09670054912567139\n",
      "Epoch: 29, Batch: 25, D Loss Real: 0.22993335127830505, D Loss Fake: 1.1616302728652954, G Loss: [10.361862182617188, 0.6862753033638, 0.09675586223602295]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 26, SSIM Loss: 0.09941810369491577\n",
      "Epoch: 29, Batch: 26, D Loss Real: 0.1916111409664154, D Loss Fake: 1.1890220642089844, G Loss: [10.75694751739502, 0.7052919864654541, 0.10051655769348145]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 27, SSIM Loss: 0.0972212553024292\n",
      "Epoch: 29, Batch: 27, D Loss Real: 0.20773708820343018, D Loss Fake: 1.0623853206634521, G Loss: [10.477760314941406, 0.754454493522644, 0.09723305702209473]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 28, SSIM Loss: 0.09794902801513672\n",
      "Epoch: 29, Batch: 28, D Loss Real: 0.16351041197776794, D Loss Fake: 1.2831270694732666, G Loss: [10.576516151428223, 0.7377622127532959, 0.09838753938674927]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 29, SSIM Loss: 0.10518902540206909\n",
      "Epoch: 29, Batch: 29, D Loss Real: 0.3370398283004761, D Loss Fake: 1.0910420417785645, G Loss: [11.259601593017578, 0.7088281512260437, 0.1055077314376831]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 30, SSIM Loss: 0.10212451219558716\n",
      "Epoch: 29, Batch: 30, D Loss Real: 0.29789355397224426, D Loss Fake: 1.1398141384124756, G Loss: [10.82233715057373, 0.6590666174888611, 0.10163271427154541]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 31, SSIM Loss: 0.09652286767959595\n",
      "Epoch: 29, Batch: 31, D Loss Real: 0.265447735786438, D Loss Fake: 1.2188951969146729, G Loss: [10.289955139160156, 0.6457808017730713, 0.09644174575805664]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 32, SSIM Loss: 0.09843325614929199\n",
      "Epoch: 29, Batch: 32, D Loss Real: 0.1830953061580658, D Loss Fake: 1.2534470558166504, G Loss: [10.492010116577148, 0.6314288973808289, 0.09860581159591675]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 33, SSIM Loss: 0.09776318073272705\n",
      "Epoch: 29, Batch: 33, D Loss Real: 0.2378600686788559, D Loss Fake: 1.0691641569137573, G Loss: [10.525975227355957, 0.7258507013320923, 0.09800124168395996]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 34, SSIM Loss: 0.10160279273986816\n",
      "Epoch: 29, Batch: 34, D Loss Real: 0.20462164282798767, D Loss Fake: 1.0940370559692383, G Loss: [10.899236679077148, 0.7197592258453369, 0.1017947793006897]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 35, SSIM Loss: 0.09581536054611206\n",
      "Epoch: 29, Batch: 35, D Loss Real: 0.21294096112251282, D Loss Fake: 1.26548433303833, G Loss: [10.221846580505371, 0.7006775140762329, 0.0952116847038269]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 36, SSIM Loss: 0.10121655464172363\n",
      "Epoch: 29, Batch: 36, D Loss Real: 0.24153338372707367, D Loss Fake: 1.2550034523010254, G Loss: [10.819656372070312, 0.663668692111969, 0.10155987739562988]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 37, SSIM Loss: 0.09776520729064941\n",
      "Epoch: 29, Batch: 37, D Loss Real: 0.2629871368408203, D Loss Fake: 1.1535855531692505, G Loss: [10.409385681152344, 0.6665112376213074, 0.09742873907089233]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 38, SSIM Loss: 0.10224747657775879\n",
      "Epoch: 29, Batch: 38, D Loss Real: 0.2509598731994629, D Loss Fake: 1.1834394931793213, G Loss: [10.902795791625977, 0.6495095491409302, 0.10253286361694336]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 39, SSIM Loss: 0.10017168521881104\n",
      "Epoch: 29, Batch: 39, D Loss Real: 0.2492462694644928, D Loss Fake: 1.1651921272277832, G Loss: [10.768389701843262, 0.6612480282783508, 0.10107141733169556]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 29, Batch: 40, SSIM Loss: 0.10228359699249268\n",
      "Epoch: 29, Batch: 40, D Loss Real: 0.22748367488384247, D Loss Fake: 1.248863935470581, G Loss: [10.903996467590332, 0.6510804891586304, 0.10252916812896729]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 41, SSIM Loss: 0.09348124265670776\n",
      "Epoch: 29, Batch: 41, D Loss Real: 0.3082003891468048, D Loss Fake: 1.0705519914627075, G Loss: [10.057066917419434, 0.6981722116470337, 0.0935889482498169]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 42, SSIM Loss: 0.09785079956054688\n",
      "Epoch: 29, Batch: 42, D Loss Real: 0.21607176959514618, D Loss Fake: 1.0625642538070679, G Loss: [10.516060829162598, 0.7055766582489014, 0.09810483455657959]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 43, SSIM Loss: 0.09628987312316895\n",
      "Epoch: 29, Batch: 43, D Loss Real: 0.1903701275587082, D Loss Fake: 1.0773156881332397, G Loss: [10.32298755645752, 0.7225682735443115, 0.0960041880607605]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 29, Batch: 44, SSIM Loss: 0.09408479928970337\n",
      "Epoch: 29, Batch: 44, D Loss Real: 0.16267505288124084, D Loss Fake: 1.149661898612976, G Loss: [10.131901741027832, 0.7367080450057983, 0.09395194053649902]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 45, SSIM Loss: 0.10716944932937622\n",
      "Epoch: 29, Batch: 45, D Loss Real: 0.15264947712421417, D Loss Fake: 1.0497902631759644, G Loss: [11.395635604858398, 0.7498403787612915, 0.10645794868469238]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 29, Batch: 46, SSIM Loss: 0.09662890434265137\n",
      "Epoch: 29, Batch: 46, D Loss Real: 0.16979260742664337, D Loss Fake: 1.2459967136383057, G Loss: [10.376520156860352, 0.7126517295837402, 0.09663867950439453]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 47, SSIM Loss: 0.10576838254928589\n",
      "Epoch: 29, Batch: 47, D Loss Real: 0.15378057956695557, D Loss Fake: 1.2128608226776123, G Loss: [11.302620887756348, 0.7226053476333618, 0.10580015182495117]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 48, SSIM Loss: 0.09745633602142334\n",
      "Epoch: 29, Batch: 48, D Loss Real: 0.26926594972610474, D Loss Fake: 1.1036086082458496, G Loss: [10.476298332214355, 0.703557014465332, 0.09772741794586182]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 49, SSIM Loss: 0.09946310520172119\n",
      "Epoch: 29, Batch: 49, D Loss Real: 0.23801954090595245, D Loss Fake: 1.2910829782485962, G Loss: [10.6209716796875, 0.6877383589744568, 0.09933233261108398]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 50, SSIM Loss: 0.10093957185745239\n",
      "Epoch: 29, Batch: 50, D Loss Real: 0.267625629901886, D Loss Fake: 1.133787751197815, G Loss: [10.761517524719238, 0.6824194192886353, 0.10079097747802734]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 51, SSIM Loss: 0.09845423698425293\n",
      "Epoch: 29, Batch: 51, D Loss Real: 0.2870081663131714, D Loss Fake: 1.1783416271209717, G Loss: [10.53695011138916, 0.6562753319740295, 0.09880673885345459]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 52, SSIM Loss: 0.1028144359588623\n",
      "Epoch: 29, Batch: 52, D Loss Real: 0.23414234817028046, D Loss Fake: 1.1688799858093262, G Loss: [10.98406982421875, 0.6773359179496765, 0.10306733846664429]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 53, SSIM Loss: 0.09759187698364258\n",
      "Epoch: 29, Batch: 53, D Loss Real: 0.21341419219970703, D Loss Fake: 1.276696801185608, G Loss: [10.440366744995117, 0.6817153096199036, 0.09758651256561279]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 29, Batch: 54, SSIM Loss: 0.10178172588348389\n",
      "Epoch: 29, Batch: 54, D Loss Real: 0.24400758743286133, D Loss Fake: 1.09345543384552, G Loss: [10.888225555419922, 0.7265454530715942, 0.10161679983139038]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 29, Batch: 55, SSIM Loss: 0.09692513942718506\n",
      "Epoch: 29, Batch: 55, D Loss Real: 0.29535171389579773, D Loss Fake: 1.233764886856079, G Loss: [10.3910551071167, 0.6564010977745056, 0.09734654426574707]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 29, Batch: 56, SSIM Loss: 0.09871822595596313\n",
      "Epoch: 29, Batch: 56, D Loss Real: 0.25276124477386475, D Loss Fake: 1.2351096868515015, G Loss: [10.549036979675293, 0.7033751606941223, 0.09845662117004395]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 29, Batch: 57, SSIM Loss: 0.10702848434448242\n",
      "Epoch: 29, Batch: 57, D Loss Real: 0.2574532926082611, D Loss Fake: 1.1536842584609985, G Loss: [11.351112365722656, 0.6722126603126526, 0.1067889928817749]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 29, Batch: 58, SSIM Loss: 0.09879255294799805\n",
      "Epoch: 29, Batch: 58, D Loss Real: 0.25881102681159973, D Loss Fake: 1.1775898933410645, G Loss: [10.591521263122559, 0.6475536227226257, 0.09943968057632446]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 29, Batch: 59, SSIM Loss: 0.09531140327453613\n",
      "Epoch: 29, Batch: 59, D Loss Real: 0.23685306310653687, D Loss Fake: 1.1872249841690063, G Loss: [10.204276084899902, 0.6477080583572388, 0.09556567668914795]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 29, Batch: 60, SSIM Loss: 0.10141980648040771\n",
      "Epoch: 29, Batch: 60, D Loss Real: 0.21129831671714783, D Loss Fake: 1.1376680135726929, G Loss: [10.912728309631348, 0.7350567579269409, 0.10177671909332275]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 29, Batch: 61, SSIM Loss: 0.09638804197311401\n",
      "Epoch: 29, Batch: 61, D Loss Real: 0.17447708547115326, D Loss Fake: 1.2060563564300537, G Loss: [10.386375427246094, 0.7202185392379761, 0.09666156768798828]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 29, Batch: 62, SSIM Loss: 0.10217165946960449\n",
      "Epoch: 29, Batch: 62, D Loss Real: 0.17329567670822144, D Loss Fake: 1.2120777368545532, G Loss: [10.971412658691406, 0.7287713289260864, 0.10242640972137451]\n",
      "1/1 [==============================] - 0s 184ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:52:37.359959: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:52:38.975307: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Batch: 1, SSIM Loss: 0.0978095531463623\n",
      "Epoch: 30, Batch: 1, D Loss Real: 0.23488876223564148, D Loss Fake: 1.0574527978897095, G Loss: [10.49317741394043, 0.7232014536857605, 0.09769976139068604]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 2, SSIM Loss: 0.09730219841003418\n",
      "Epoch: 30, Batch: 2, D Loss Real: 0.2628382444381714, D Loss Fake: 1.2261691093444824, G Loss: [10.367639541625977, 0.6264652013778687, 0.09741175174713135]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 30, Batch: 3, SSIM Loss: 0.10124164819717407\n",
      "Epoch: 30, Batch: 3, D Loss Real: 0.1824055016040802, D Loss Fake: 1.2760730981826782, G Loss: [10.82334041595459, 0.6734089255332947, 0.10149931907653809]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 4, SSIM Loss: 0.1047372817993164\n",
      "Epoch: 30, Batch: 4, D Loss Real: 0.22111929953098297, D Loss Fake: 1.2047955989837646, G Loss: [11.181933403015137, 0.7147859334945679, 0.10467147827148438]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 5, SSIM Loss: 0.09791982173919678\n",
      "Epoch: 30, Batch: 5, D Loss Real: 0.24215857684612274, D Loss Fake: 1.1411683559417725, G Loss: [10.489930152893066, 0.698799729347229, 0.0979112982749939]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 30, Batch: 6, SSIM Loss: 0.09538614749908447\n",
      "Epoch: 30, Batch: 6, D Loss Real: 0.22527001798152924, D Loss Fake: 1.3382678031921387, G Loss: [10.235554695129395, 0.7046529650688171, 0.09530901908874512]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 30, Batch: 7, SSIM Loss: 0.09882700443267822\n",
      "Epoch: 30, Batch: 7, D Loss Real: 0.3046833276748657, D Loss Fake: 1.182060718536377, G Loss: [10.588092803955078, 0.6636443138122559, 0.09924447536468506]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 8, SSIM Loss: 0.09831088781356812\n",
      "Epoch: 30, Batch: 8, D Loss Real: 0.29769060015678406, D Loss Fake: 1.1599714756011963, G Loss: [10.468893051147461, 0.644974946975708, 0.09823918342590332]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 9, SSIM Loss: 0.09968703985214233\n",
      "Epoch: 30, Batch: 9, D Loss Real: 0.2562845051288605, D Loss Fake: 1.1997398138046265, G Loss: [10.623725891113281, 0.6325749754905701, 0.09991151094436646]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 10, SSIM Loss: 0.09679055213928223\n",
      "Epoch: 30, Batch: 10, D Loss Real: 0.2290075570344925, D Loss Fake: 1.3198533058166504, G Loss: [10.252104759216309, 0.6497253179550171, 0.0960237979888916]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 11, SSIM Loss: 0.09657877683639526\n",
      "Epoch: 30, Batch: 11, D Loss Real: 0.2592849135398865, D Loss Fake: 1.1715949773788452, G Loss: [10.321938514709473, 0.6592625379562378, 0.09662675857543945]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 12, SSIM Loss: 0.09642899036407471\n",
      "Epoch: 30, Batch: 12, D Loss Real: 0.2561795115470886, D Loss Fake: 1.2708150148391724, G Loss: [10.283110618591309, 0.6437159776687622, 0.09639394283294678]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 13, SSIM Loss: 0.09794509410858154\n",
      "Epoch: 30, Batch: 13, D Loss Real: 0.25809183716773987, D Loss Fake: 1.150672197341919, G Loss: [10.432440757751465, 0.6528444290161133, 0.09779596328735352]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 14, SSIM Loss: 0.10412418842315674\n",
      "Epoch: 30, Batch: 14, D Loss Real: 0.26573890447616577, D Loss Fake: 1.1004550457000732, G Loss: [11.090959548950195, 0.6817833781242371, 0.10409176349639893]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 15, SSIM Loss: 0.10438203811645508\n",
      "Epoch: 30, Batch: 15, D Loss Real: 0.22427134215831757, D Loss Fake: 1.3053838014602661, G Loss: [11.090953826904297, 0.6258196830749512, 0.10465133190155029]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 16, SSIM Loss: 0.10148578882217407\n",
      "Epoch: 30, Batch: 16, D Loss Real: 0.23979805409908295, D Loss Fake: 1.1952036619186401, G Loss: [10.795907020568848, 0.6714258193969727, 0.10124480724334717]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 17, SSIM Loss: 0.09718012809753418\n",
      "Epoch: 30, Batch: 17, D Loss Real: 0.2425227165222168, D Loss Fake: 1.123024344444275, G Loss: [10.45090389251709, 0.6788360476493835, 0.0977206826210022]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 18, SSIM Loss: 0.09665888547897339\n",
      "Epoch: 30, Batch: 18, D Loss Real: 0.2407856583595276, D Loss Fake: 1.2023357152938843, G Loss: [10.363316535949707, 0.6807621717453003, 0.09682554006576538]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 19, SSIM Loss: 0.09954047203063965\n",
      "Epoch: 30, Batch: 19, D Loss Real: 0.20481333136558533, D Loss Fake: 1.1925008296966553, G Loss: [10.615091323852539, 0.6882593631744385, 0.09926831722259521]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 20, SSIM Loss: 0.10093182325363159\n",
      "Epoch: 30, Batch: 20, D Loss Real: 0.23000440001487732, D Loss Fake: 1.1783835887908936, G Loss: [10.739298820495605, 0.686653733253479, 0.10052645206451416]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 21, SSIM Loss: 0.09648096561431885\n",
      "Epoch: 30, Batch: 21, D Loss Real: 0.23891635239124298, D Loss Fake: 1.0958044528961182, G Loss: [10.331568717956543, 0.6946842074394226, 0.09636884927749634]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 22, SSIM Loss: 0.09558933973312378\n",
      "Epoch: 30, Batch: 22, D Loss Real: 0.20127196609973907, D Loss Fake: 1.1981048583984375, G Loss: [10.304080963134766, 0.7139086127281189, 0.0959017276763916]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 23, SSIM Loss: 0.10064589977264404\n",
      "Epoch: 30, Batch: 23, D Loss Real: 0.21226561069488525, D Loss Fake: 1.0083657503128052, G Loss: [10.841338157653809, 0.7686715722084045, 0.1007266640663147]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 24, SSIM Loss: 0.10101979970932007\n",
      "Epoch: 30, Batch: 24, D Loss Real: 0.20860901474952698, D Loss Fake: 1.025322437286377, G Loss: [10.88039493560791, 0.7721982598304749, 0.1010819673538208]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 25, SSIM Loss: 0.09598207473754883\n",
      "Epoch: 30, Batch: 25, D Loss Real: 0.1868063062429428, D Loss Fake: 1.1072834730148315, G Loss: [10.357519149780273, 0.7254923582077026, 0.0963202714920044]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 30, Batch: 26, SSIM Loss: 0.10193049907684326\n",
      "Epoch: 30, Batch: 26, D Loss Real: 0.1509995460510254, D Loss Fake: 1.1799752712249756, G Loss: [10.82425308227539, 0.6969582438468933, 0.10127294063568115]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 27, SSIM Loss: 0.09747421741485596\n",
      "Epoch: 30, Batch: 27, D Loss Real: 0.18451009690761566, D Loss Fake: 1.1113578081130981, G Loss: [10.475785255432129, 0.7128600478172302, 0.09762924909591675]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 28, SSIM Loss: 0.09801614284515381\n",
      "Epoch: 30, Batch: 28, D Loss Real: 0.1622045487165451, D Loss Fake: 1.335638165473938, G Loss: [10.503226280212402, 0.6668385863304138, 0.09836387634277344]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 29, SSIM Loss: 0.10470914840698242\n",
      "Epoch: 30, Batch: 29, D Loss Real: 0.2928099036216736, D Loss Fake: 0.9967353940010071, G Loss: [11.239850044250488, 0.7757593393325806, 0.1046409010887146]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 30, SSIM Loss: 0.10095345973968506\n",
      "Epoch: 30, Batch: 30, D Loss Real: 0.2854178249835968, D Loss Fake: 1.13043212890625, G Loss: [10.761565208435059, 0.6684848070144653, 0.10093080997467041]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 31, SSIM Loss: 0.0970119833946228\n",
      "Epoch: 30, Batch: 31, D Loss Real: 0.26341453194618225, D Loss Fake: 1.1383575201034546, G Loss: [10.355055809020996, 0.6612064242362976, 0.09693849086761475]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 32, SSIM Loss: 0.09847509860992432\n",
      "Epoch: 30, Batch: 32, D Loss Real: 0.17528098821640015, D Loss Fake: 1.173604130744934, G Loss: [10.533451080322266, 0.6668262481689453, 0.098666250705719]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 33, SSIM Loss: 0.0981377363204956\n",
      "Epoch: 30, Batch: 33, D Loss Real: 0.1865679770708084, D Loss Fake: 1.2158924341201782, G Loss: [10.46917724609375, 0.6808964014053345, 0.09788280725479126]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 34, SSIM Loss: 0.10022282600402832\n",
      "Epoch: 30, Batch: 34, D Loss Real: 0.21395783126354218, D Loss Fake: 1.1699694395065308, G Loss: [10.710395812988281, 0.6668459177017212, 0.10043549537658691]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 35, SSIM Loss: 0.09590780735015869\n",
      "Epoch: 30, Batch: 35, D Loss Real: 0.24661211669445038, D Loss Fake: 1.0822346210479736, G Loss: [10.306432723999023, 0.7022167444229126, 0.09604215621948242]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 36, SSIM Loss: 0.1000288724899292\n",
      "Epoch: 30, Batch: 36, D Loss Real: 0.20973487198352814, D Loss Fake: 1.2043627500534058, G Loss: [10.703306198120117, 0.6863160133361816, 0.10016989707946777]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 37, SSIM Loss: 0.0972713828086853\n",
      "Epoch: 30, Batch: 37, D Loss Real: 0.19241094589233398, D Loss Fake: 1.1731146574020386, G Loss: [10.441755294799805, 0.714044451713562, 0.09727710485458374]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 38, SSIM Loss: 0.10227513313293457\n",
      "Epoch: 30, Batch: 38, D Loss Real: 0.21580854058265686, D Loss Fake: 1.1837220191955566, G Loss: [10.873600006103516, 0.660881519317627, 0.10212719440460205]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 39, SSIM Loss: 0.09846186637878418\n",
      "Epoch: 30, Batch: 39, D Loss Real: 0.23986384272575378, D Loss Fake: 1.0997222661972046, G Loss: [10.574849128723145, 0.7033661603927612, 0.09871482849121094]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 40, SSIM Loss: 0.10181546211242676\n",
      "Epoch: 30, Batch: 40, D Loss Real: 0.2091529816389084, D Loss Fake: 1.0402451753616333, G Loss: [10.942354202270508, 0.7207779884338379, 0.10221576690673828]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 41, SSIM Loss: 0.09425747394561768\n",
      "Epoch: 30, Batch: 41, D Loss Real: 0.2369993031024933, D Loss Fake: 1.152062177658081, G Loss: [10.13951587677002, 0.7207311391830444, 0.09418785572052002]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 42, SSIM Loss: 0.0971686840057373\n",
      "Epoch: 30, Batch: 42, D Loss Real: 0.1807519495487213, D Loss Fake: 1.1575953960418701, G Loss: [10.4132661819458, 0.6944667100906372, 0.09718799591064453]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 43, SSIM Loss: 0.09643197059631348\n",
      "Epoch: 30, Batch: 43, D Loss Real: 0.19733379781246185, D Loss Fake: 1.2139323949813843, G Loss: [10.28519344329834, 0.6710231304168701, 0.09614169597625732]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 44, SSIM Loss: 0.09390789270401001\n",
      "Epoch: 30, Batch: 44, D Loss Real: 0.23889292776584625, D Loss Fake: 1.1488932371139526, G Loss: [9.998226165771484, 0.6537324786186218, 0.09344494342803955]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 45, SSIM Loss: 0.10517615079879761\n",
      "Epoch: 30, Batch: 45, D Loss Real: 0.18086360394954681, D Loss Fake: 1.1491411924362183, G Loss: [11.170077323913574, 0.6848036050796509, 0.10485273599624634]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 46, SSIM Loss: 0.09693151712417603\n",
      "Epoch: 30, Batch: 46, D Loss Real: 0.2214960753917694, D Loss Fake: 1.1461399793624878, G Loss: [10.330702781677246, 0.6695711612701416, 0.09661132097244263]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 47, SSIM Loss: 0.10495543479919434\n",
      "Epoch: 30, Batch: 47, D Loss Real: 0.15554460883140564, D Loss Fake: 1.1619839668273926, G Loss: [11.188318252563477, 0.6935315132141113, 0.10494786500930786]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 48, SSIM Loss: 0.09724462032318115\n",
      "Epoch: 30, Batch: 48, D Loss Real: 0.1894192099571228, D Loss Fake: 1.1783151626586914, G Loss: [10.428998947143555, 0.7108727693557739, 0.09718126058578491]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 30, Batch: 49, SSIM Loss: 0.09833395481109619\n",
      "Epoch: 30, Batch: 49, D Loss Real: 0.2332378774881363, D Loss Fake: 1.0749810934066772, G Loss: [10.590677261352539, 0.7122623920440674, 0.09878414869308472]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 50, SSIM Loss: 0.10075819492340088\n",
      "Epoch: 30, Batch: 50, D Loss Real: 0.19632863998413086, D Loss Fake: 1.0170968770980835, G Loss: [10.892205238342285, 0.7541468143463135, 0.10138058662414551]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 51, SSIM Loss: 0.0985681414604187\n",
      "Epoch: 30, Batch: 51, D Loss Real: 0.20735280215740204, D Loss Fake: 1.0791683197021484, G Loss: [10.580875396728516, 0.7288950085639954, 0.09851980209350586]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 52, SSIM Loss: 0.10282266139984131\n",
      "Epoch: 30, Batch: 52, D Loss Real: 0.11243677139282227, D Loss Fake: 1.0977483987808228, G Loss: [10.968155860900879, 0.7193276882171631, 0.10248827934265137]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 53, SSIM Loss: 0.09680354595184326\n",
      "Epoch: 30, Batch: 53, D Loss Real: 0.127263605594635, D Loss Fake: 1.1112314462661743, G Loss: [10.416584014892578, 0.7198025584220886, 0.09696781635284424]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 54, SSIM Loss: 0.10071074962615967\n",
      "Epoch: 30, Batch: 54, D Loss Real: 0.14493723213672638, D Loss Fake: 1.01677405834198, G Loss: [10.823702812194824, 0.7884500026702881, 0.10035252571105957]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 55, SSIM Loss: 0.09645485877990723\n",
      "Epoch: 30, Batch: 55, D Loss Real: 0.23241308331489563, D Loss Fake: 1.1252129077911377, G Loss: [10.37248706817627, 0.7462893724441528, 0.09626197814941406]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 30, Batch: 56, SSIM Loss: 0.09772807359695435\n",
      "Epoch: 30, Batch: 56, D Loss Real: 0.22838257253170013, D Loss Fake: 1.1629753112792969, G Loss: [10.54209041595459, 0.7724359631538391, 0.09769654273986816]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 57, SSIM Loss: 0.10290342569351196\n",
      "Epoch: 30, Batch: 57, D Loss Real: 0.21323657035827637, D Loss Fake: 1.0817327499389648, G Loss: [11.0437593460083, 0.7382771372795105, 0.10305482149124146]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 30, Batch: 58, SSIM Loss: 0.09839141368865967\n",
      "Epoch: 30, Batch: 58, D Loss Real: 0.21279436349868774, D Loss Fake: 1.1305327415466309, G Loss: [10.536981582641602, 0.7081096172332764, 0.09828871488571167]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 59, SSIM Loss: 0.09471637010574341\n",
      "Epoch: 30, Batch: 59, D Loss Real: 0.18371447920799255, D Loss Fake: 1.3417280912399292, G Loss: [10.104435920715332, 0.6475040912628174, 0.09456932544708252]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 60, SSIM Loss: 0.1002204418182373\n",
      "Epoch: 30, Batch: 60, D Loss Real: 0.2225639969110489, D Loss Fake: 1.0928022861480713, G Loss: [10.720547676086426, 0.7104243040084839, 0.10010123252868652]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 61, SSIM Loss: 0.09499096870422363\n",
      "Epoch: 30, Batch: 61, D Loss Real: 0.19654208421707153, D Loss Fake: 1.1669639348983765, G Loss: [10.267887115478516, 0.7205945253372192, 0.09547293186187744]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 30, Batch: 62, SSIM Loss: 0.10103338956832886\n",
      "Epoch: 30, Batch: 62, D Loss Real: 0.21445636451244354, D Loss Fake: 1.1333887577056885, G Loss: [10.798178672790527, 0.7170780301094055, 0.10081100463867188]\n",
      "1/1 [==============================] - 0s 160ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:54:01.012409: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:54:02.572671: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Batch: 1, SSIM Loss: 0.09585833549499512\n",
      "Epoch: 31, Batch: 1, D Loss Real: 0.228491872549057, D Loss Fake: 1.1464335918426514, G Loss: [10.264350891113281, 0.6630918383598328, 0.09601259231567383]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 2, SSIM Loss: 0.09620356559753418\n",
      "Epoch: 31, Batch: 2, D Loss Real: 0.26320382952690125, D Loss Fake: 1.17137610912323, G Loss: [10.28036880493164, 0.6687734723091125, 0.09611594676971436]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 31, Batch: 3, SSIM Loss: 0.09930109977722168\n",
      "Epoch: 31, Batch: 3, D Loss Real: 0.16917890310287476, D Loss Fake: 1.1731147766113281, G Loss: [10.594297409057617, 0.6769664287567139, 0.09917330741882324]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 4, SSIM Loss: 0.10278314352035522\n",
      "Epoch: 31, Batch: 4, D Loss Real: 0.20919650793075562, D Loss Fake: 1.0853683948516846, G Loss: [10.95490837097168, 0.7042628526687622, 0.10250645875930786]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 5, SSIM Loss: 0.09688913822174072\n",
      "Epoch: 31, Batch: 5, D Loss Real: 0.15569767355918884, D Loss Fake: 1.1310206651687622, G Loss: [10.394266128540039, 0.7072956562042236, 0.09686970710754395]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 6, SSIM Loss: 0.09501802921295166\n",
      "Epoch: 31, Batch: 6, D Loss Real: 0.13199301064014435, D Loss Fake: 1.0897046327590942, G Loss: [10.257502555847168, 0.7553836107254028, 0.09502118825912476]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 7, SSIM Loss: 0.09802669286727905\n",
      "Epoch: 31, Batch: 7, D Loss Real: 0.1775694042444229, D Loss Fake: 1.101952075958252, G Loss: [10.54371452331543, 0.7532821297645569, 0.09790432453155518]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 8, SSIM Loss: 0.09721308946609497\n",
      "Epoch: 31, Batch: 8, D Loss Real: 0.15853732824325562, D Loss Fake: 1.144057035446167, G Loss: [10.53825855255127, 0.7877731323242188, 0.09750485420227051]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 9, SSIM Loss: 0.09934842586517334\n",
      "Epoch: 31, Batch: 9, D Loss Real: 0.223483607172966, D Loss Fake: 1.0170202255249023, G Loss: [10.666866302490234, 0.7431221604347229, 0.09923744201660156]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 10, SSIM Loss: 0.0963284969329834\n",
      "Epoch: 31, Batch: 10, D Loss Real: 0.23023514449596405, D Loss Fake: 1.1166620254516602, G Loss: [10.304688453674316, 0.698827862739563, 0.09605860710144043]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 31, Batch: 11, SSIM Loss: 0.09553682804107666\n",
      "Epoch: 31, Batch: 11, D Loss Real: 0.18065695464611053, D Loss Fake: 1.1938635110855103, G Loss: [10.192436218261719, 0.6763519048690796, 0.0951608419418335]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 12, SSIM Loss: 0.09585034847259521\n",
      "Epoch: 31, Batch: 12, D Loss Real: 0.13337492942810059, D Loss Fake: 1.1276254653930664, G Loss: [10.325785636901855, 0.7143036723136902, 0.09611481428146362]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 13, SSIM Loss: 0.09833681583404541\n",
      "Epoch: 31, Batch: 13, D Loss Real: 0.17364592850208282, D Loss Fake: 1.079609751701355, G Loss: [10.638065338134766, 0.7460842728614807, 0.0989198088645935]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 14, SSIM Loss: 0.10177814960479736\n",
      "Epoch: 31, Batch: 14, D Loss Real: 0.15492118895053864, D Loss Fake: 1.2079260349273682, G Loss: [10.942534446716309, 0.7466300129890442, 0.10195904970169067]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 15, SSIM Loss: 0.10734248161315918\n",
      "Epoch: 31, Batch: 15, D Loss Real: 0.18260826170444489, D Loss Fake: 1.0784766674041748, G Loss: [11.465709686279297, 0.7333089113235474, 0.10732400417327881]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 16, SSIM Loss: 0.09938931465148926\n",
      "Epoch: 31, Batch: 16, D Loss Real: 0.23401184380054474, D Loss Fake: 1.0445743799209595, G Loss: [10.624698638916016, 0.7196826338768005, 0.09905016422271729]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 17, SSIM Loss: 0.09762990474700928\n",
      "Epoch: 31, Batch: 17, D Loss Real: 0.1633351445198059, D Loss Fake: 1.1615345478057861, G Loss: [10.565098762512207, 0.7075873613357544, 0.09857511520385742]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 18, SSIM Loss: 0.09558689594268799\n",
      "Epoch: 31, Batch: 18, D Loss Real: 0.14609739184379578, D Loss Fake: 1.077364206314087, G Loss: [10.330521583557129, 0.7388464212417603, 0.095916748046875]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 19, SSIM Loss: 0.0993192195892334\n",
      "Epoch: 31, Batch: 19, D Loss Real: 0.1341063678264618, D Loss Fake: 1.0740641355514526, G Loss: [10.62558650970459, 0.7541876435279846, 0.09871399402618408]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 20, SSIM Loss: 0.10020840167999268\n",
      "Epoch: 31, Batch: 20, D Loss Real: 0.1541733294725418, D Loss Fake: 0.9955974817276001, G Loss: [10.777929306030273, 0.7620415687561035, 0.10015887022018433]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 21, SSIM Loss: 0.09575176239013672\n",
      "Epoch: 31, Batch: 21, D Loss Real: 0.16855737566947937, D Loss Fake: 0.9364603757858276, G Loss: [10.364078521728516, 0.8220425844192505, 0.09542036056518555]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 22, SSIM Loss: 0.09475243091583252\n",
      "Epoch: 31, Batch: 22, D Loss Real: 0.10309386253356934, D Loss Fake: 1.0347561836242676, G Loss: [10.255226135253906, 0.8030376434326172, 0.09452188014984131]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 23, SSIM Loss: 0.10009515285491943\n",
      "Epoch: 31, Batch: 23, D Loss Real: 0.07899788022041321, D Loss Fake: 1.0167994499206543, G Loss: [10.786297798156738, 0.7858193516731262, 0.10000479221343994]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 24, SSIM Loss: 0.09832119941711426\n",
      "Epoch: 31, Batch: 24, D Loss Real: 0.11619869619607925, D Loss Fake: 1.0649359226226807, G Loss: [10.585958480834961, 0.7286908030509949, 0.09857267141342163]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 25, SSIM Loss: 0.09665977954864502\n",
      "Epoch: 31, Batch: 25, D Loss Real: 0.1666911542415619, D Loss Fake: 1.0036226511001587, G Loss: [10.420816421508789, 0.7776191234588623, 0.09643197059631348]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 26, SSIM Loss: 0.09941565990447998\n",
      "Epoch: 31, Batch: 26, D Loss Real: 0.09704922884702682, D Loss Fake: 1.1832218170166016, G Loss: [10.650607109069824, 0.7519558668136597, 0.09898650646209717]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 27, SSIM Loss: 0.09739506244659424\n",
      "Epoch: 31, Batch: 27, D Loss Real: 0.18389274179935455, D Loss Fake: 0.9725791215896606, G Loss: [10.514649391174316, 0.797142744064331, 0.09717506170272827]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 28, SSIM Loss: 0.0974283218383789\n",
      "Epoch: 31, Batch: 28, D Loss Real: 0.1365281641483307, D Loss Fake: 1.024903655052185, G Loss: [10.50957202911377, 0.760898768901825, 0.09748673439025879]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 29, SSIM Loss: 0.10365206003189087\n",
      "Epoch: 31, Batch: 29, D Loss Real: 0.09094653278589249, D Loss Fake: 1.0611833333969116, G Loss: [11.180006980895996, 0.7563520073890686, 0.10423654317855835]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 30, SSIM Loss: 0.09877979755401611\n",
      "Epoch: 31, Batch: 30, D Loss Real: 0.1705341637134552, D Loss Fake: 1.0537724494934082, G Loss: [10.644952774047852, 0.7724153399467468, 0.09872537851333618]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 31, SSIM Loss: 0.09612536430358887\n",
      "Epoch: 31, Batch: 31, D Loss Real: 0.12917399406433105, D Loss Fake: 1.1594934463500977, G Loss: [10.376273155212402, 0.7574846744537354, 0.09618788957595825]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 32, SSIM Loss: 0.09755218029022217\n",
      "Epoch: 31, Batch: 32, D Loss Real: 0.10617852956056595, D Loss Fake: 0.9428235292434692, G Loss: [10.624045372009277, 0.8483706712722778, 0.09775674343109131]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 31, Batch: 33, SSIM Loss: 0.09675490856170654\n",
      "Epoch: 31, Batch: 33, D Loss Real: 0.17999662458896637, D Loss Fake: 0.9553712606430054, G Loss: [10.517694473266602, 0.7868485450744629, 0.0973084568977356]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 34, SSIM Loss: 0.09973478317260742\n",
      "Epoch: 31, Batch: 34, D Loss Real: 0.10724624991416931, D Loss Fake: 1.054119348526001, G Loss: [10.762951850891113, 0.8063112497329712, 0.09956640005111694]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 35, SSIM Loss: 0.09555864334106445\n",
      "Epoch: 31, Batch: 35, D Loss Real: 0.2285436987876892, D Loss Fake: 1.0346291065216064, G Loss: [10.339432716369629, 0.7252397537231445, 0.09614193439483643]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 36, SSIM Loss: 0.09873837232589722\n",
      "Epoch: 31, Batch: 36, D Loss Real: 0.1281142681837082, D Loss Fake: 1.1430360078811646, G Loss: [10.577735900878906, 0.6780723333358765, 0.09899663925170898]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 37, SSIM Loss: 0.09723162651062012\n",
      "Epoch: 31, Batch: 37, D Loss Real: 0.09518884867429733, D Loss Fake: 1.1392817497253418, G Loss: [10.391831398010254, 0.7319453954696655, 0.09659886360168457]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 38, SSIM Loss: 0.10031986236572266\n",
      "Epoch: 31, Batch: 38, D Loss Real: 0.06625206768512726, D Loss Fake: 1.3339817523956299, G Loss: [10.943769454956055, 0.8505687117576599, 0.10093200206756592]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 39, SSIM Loss: 0.09767532348632812\n",
      "Epoch: 31, Batch: 39, D Loss Real: 0.29637348651885986, D Loss Fake: 1.0280027389526367, G Loss: [10.570389747619629, 0.7770494222640991, 0.09793341159820557]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 40, SSIM Loss: 0.10261207818984985\n",
      "Epoch: 31, Batch: 40, D Loss Real: 0.3215661942958832, D Loss Fake: 1.0645694732666016, G Loss: [10.932708740234375, 0.7367804050445557, 0.10195928812026978]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 31, Batch: 41, SSIM Loss: 0.09329569339752197\n",
      "Epoch: 31, Batch: 41, D Loss Real: 0.3603641092777252, D Loss Fake: 1.1410356760025024, G Loss: [10.01110553741455, 0.6663843989372253, 0.09344720840454102]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 42, SSIM Loss: 0.09772276878356934\n",
      "Epoch: 31, Batch: 42, D Loss Real: 0.19964812695980072, D Loss Fake: 1.20609712600708, G Loss: [10.414053916931152, 0.643255352973938, 0.09770798683166504]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 43, SSIM Loss: 0.09633445739746094\n",
      "Epoch: 31, Batch: 43, D Loss Real: 0.17121966183185577, D Loss Fake: 1.1387953758239746, G Loss: [10.310776710510254, 0.6767112016677856, 0.09634065628051758]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 44, SSIM Loss: 0.09297126531600952\n",
      "Epoch: 31, Batch: 44, D Loss Real: 0.16307899355888367, D Loss Fake: 1.128556489944458, G Loss: [10.013379096984863, 0.7194779515266418, 0.09293901920318604]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 45, SSIM Loss: 0.10366660356521606\n",
      "Epoch: 31, Batch: 45, D Loss Real: 0.11163780838251114, D Loss Fake: 1.006017804145813, G Loss: [11.155921936035156, 0.7789197564125061, 0.10377001762390137]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 46, SSIM Loss: 0.0955197811126709\n",
      "Epoch: 31, Batch: 46, D Loss Real: 0.14954593777656555, D Loss Fake: 1.0333383083343506, G Loss: [10.297577857971191, 0.7559118866920471, 0.09541666507720947]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 47, SSIM Loss: 0.10333412885665894\n",
      "Epoch: 31, Batch: 47, D Loss Real: 0.07050129771232605, D Loss Fake: 1.2136332988739014, G Loss: [11.12983512878418, 0.7860811352729797, 0.10343754291534424]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 31, Batch: 48, SSIM Loss: 0.09696459770202637\n",
      "Epoch: 31, Batch: 48, D Loss Real: 0.2676421105861664, D Loss Fake: 1.0911691188812256, G Loss: [10.44019603729248, 0.760932207107544, 0.09679263830184937]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 49, SSIM Loss: 0.09737938642501831\n",
      "Epoch: 31, Batch: 49, D Loss Real: 0.21623031795024872, D Loss Fake: 1.0752651691436768, G Loss: [10.46357250213623, 0.6979416608810425, 0.09765630960464478]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 50, SSIM Loss: 0.09834575653076172\n",
      "Epoch: 31, Batch: 50, D Loss Real: 0.19156710803508759, D Loss Fake: 1.1076443195343018, G Loss: [10.60769271850586, 0.6725698709487915, 0.09935122728347778]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 51, SSIM Loss: 0.09624707698822021\n",
      "Epoch: 31, Batch: 51, D Loss Real: 0.18512815237045288, D Loss Fake: 1.1066774129867554, G Loss: [10.342044830322266, 0.6834461688995361, 0.09658598899841309]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 52, SSIM Loss: 0.10322821140289307\n",
      "Epoch: 31, Batch: 52, D Loss Real: 0.08526685833930969, D Loss Fake: 1.0648267269134521, G Loss: [11.069768905639648, 0.7346040606498718, 0.1033516526222229]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 31, Batch: 53, SSIM Loss: 0.09603297710418701\n",
      "Epoch: 31, Batch: 53, D Loss Real: 0.09714680910110474, D Loss Fake: 0.9684882164001465, G Loss: [10.382637023925781, 0.7779560089111328, 0.0960468053817749]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 54, SSIM Loss: 0.09994900226593018\n",
      "Epoch: 31, Batch: 54, D Loss Real: 0.09739977866411209, D Loss Fake: 0.9678984880447388, G Loss: [10.769373893737793, 0.7848442792892456, 0.099845290184021]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 55, SSIM Loss: 0.09541958570480347\n",
      "Epoch: 31, Batch: 55, D Loss Real: 0.13075903058052063, D Loss Fake: 1.1212797164916992, G Loss: [10.324938774108887, 0.7808282971382141, 0.09544110298156738]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 56, SSIM Loss: 0.09726738929748535\n",
      "Epoch: 31, Batch: 56, D Loss Real: 0.14149996638298035, D Loss Fake: 1.0790495872497559, G Loss: [10.510954856872559, 0.7942826747894287, 0.09716671705245972]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 31, Batch: 57, SSIM Loss: 0.10057073831558228\n",
      "Epoch: 31, Batch: 57, D Loss Real: 0.10834471881389618, D Loss Fake: 0.9654407501220703, G Loss: [10.893787384033203, 0.7889766097068787, 0.10104811191558838]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 58, SSIM Loss: 0.09727764129638672\n",
      "Epoch: 31, Batch: 58, D Loss Real: 0.17708434164524078, D Loss Fake: 1.0264002084732056, G Loss: [10.412760734558105, 0.7427834272384644, 0.0966997742652893]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 31, Batch: 59, SSIM Loss: 0.09485757350921631\n",
      "Epoch: 31, Batch: 59, D Loss Real: 0.11385536193847656, D Loss Fake: 1.0239710807800293, G Loss: [10.331452369689941, 0.8176029324531555, 0.09513849020004272]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 60, SSIM Loss: 0.09902691841125488\n",
      "Epoch: 31, Batch: 60, D Loss Real: 0.08850905299186707, D Loss Fake: 0.9873571991920471, G Loss: [10.708810806274414, 0.7896204590797424, 0.09919190406799316]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 61, SSIM Loss: 0.0940055251121521\n",
      "Epoch: 31, Batch: 61, D Loss Real: 0.09032284468412399, D Loss Fake: 1.044890284538269, G Loss: [10.187726974487305, 0.7688215374946594, 0.09418904781341553]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 31, Batch: 62, SSIM Loss: 0.0996553897857666\n",
      "Epoch: 31, Batch: 62, D Loss Real: 0.10847071558237076, D Loss Fake: 0.9795147180557251, G Loss: [10.811861038208008, 0.8115370869636536, 0.10000324249267578]\n",
      "1/1 [==============================] - 0s 162ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:55:24.642899: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:55:26.162523: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Batch: 1, SSIM Loss: 0.09544718265533447\n",
      "Epoch: 32, Batch: 1, D Loss Real: 0.13475580513477325, D Loss Fake: 1.004882574081421, G Loss: [10.314075469970703, 0.7712648510932922, 0.09542810916900635]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 2, SSIM Loss: 0.09638261795043945\n",
      "Epoch: 32, Batch: 2, D Loss Real: 0.11559687554836273, D Loss Fake: 1.0739179849624634, G Loss: [10.405011177062988, 0.8019034266471863, 0.0960310697555542]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 32, Batch: 3, SSIM Loss: 0.09868466854095459\n",
      "Epoch: 32, Batch: 3, D Loss Real: 0.07581813633441925, D Loss Fake: 0.9989157915115356, G Loss: [10.681355476379395, 0.8212690353393555, 0.09860086441040039]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 4, SSIM Loss: 0.1011154055595398\n",
      "Epoch: 32, Batch: 4, D Loss Real: 0.1129990890622139, D Loss Fake: 0.9723029732704163, G Loss: [10.939059257507324, 0.8008579015731812, 0.10138201713562012]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 5, SSIM Loss: 0.09679824113845825\n",
      "Epoch: 32, Batch: 5, D Loss Real: 0.0982084795832634, D Loss Fake: 0.9608233571052551, G Loss: [10.436692237854004, 0.7964165210723877, 0.09640276432037354]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 6, SSIM Loss: 0.09408295154571533\n",
      "Epoch: 32, Batch: 6, D Loss Real: 0.1028876006603241, D Loss Fake: 0.9960435628890991, G Loss: [10.193224906921387, 0.7893709540367126, 0.09403854608535767]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 7, SSIM Loss: 0.09926742315292358\n",
      "Epoch: 32, Batch: 7, D Loss Real: 0.055060554295778275, D Loss Fake: 0.9799363613128662, G Loss: [10.741203308105469, 0.8139781355857849, 0.09927225112915039]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 8, SSIM Loss: 0.09820067882537842\n",
      "Epoch: 32, Batch: 8, D Loss Real: 0.07580075412988663, D Loss Fake: 1.043870449066162, G Loss: [10.69162368774414, 0.8642370700836182, 0.0982738733291626]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 9, SSIM Loss: 0.100422203540802\n",
      "Epoch: 32, Batch: 9, D Loss Real: 0.12122911214828491, D Loss Fake: 0.9778674840927124, G Loss: [10.870316505432129, 0.8026390075683594, 0.1006767749786377]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 10, SSIM Loss: 0.09702229499816895\n",
      "Epoch: 32, Batch: 10, D Loss Real: 0.2005101591348648, D Loss Fake: 0.9898561835289001, G Loss: [10.478119850158691, 0.762192964553833, 0.09715926647186279]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 11, SSIM Loss: 0.09488195180892944\n",
      "Epoch: 32, Batch: 11, D Loss Real: 0.13044199347496033, D Loss Fake: 1.2393639087677002, G Loss: [10.274083137512207, 0.7791584134101868, 0.09494924545288086]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 12, SSIM Loss: 0.09513431787490845\n",
      "Epoch: 32, Batch: 12, D Loss Real: 0.09594468027353287, D Loss Fake: 1.0041217803955078, G Loss: [10.270761489868164, 0.7624491453170776, 0.09508311748504639]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 13, SSIM Loss: 0.09747976064682007\n",
      "Epoch: 32, Batch: 13, D Loss Real: 0.18025124073028564, D Loss Fake: 1.00783109664917, G Loss: [10.513874053955078, 0.7612721920013428, 0.09752601385116577]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 14, SSIM Loss: 0.10278761386871338\n",
      "Epoch: 32, Batch: 14, D Loss Real: 0.10183887183666229, D Loss Fake: 1.083688497543335, G Loss: [11.07845687866211, 0.7799897789955139, 0.10298466682434082]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 15, SSIM Loss: 0.10634195804595947\n",
      "Epoch: 32, Batch: 15, D Loss Real: 0.08481913805007935, D Loss Fake: 1.051150918006897, G Loss: [11.368816375732422, 0.771134614944458, 0.10597681999206543]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 16, SSIM Loss: 0.10016459226608276\n",
      "Epoch: 32, Batch: 16, D Loss Real: 0.1219046413898468, D Loss Fake: 0.942836344242096, G Loss: [10.806291580200195, 0.8010925054550171, 0.10005199909210205]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 17, SSIM Loss: 0.09569406509399414\n",
      "Epoch: 32, Batch: 17, D Loss Real: 0.11432818323373795, D Loss Fake: 1.0075246095657349, G Loss: [10.357871055603027, 0.7874994277954102, 0.09570372104644775]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 18, SSIM Loss: 0.09588766098022461\n",
      "Epoch: 32, Batch: 18, D Loss Real: 0.09118670970201492, D Loss Fake: 1.011041283607483, G Loss: [10.395069122314453, 0.780707836151123, 0.09614360332489014]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 19, SSIM Loss: 0.09711498022079468\n",
      "Epoch: 32, Batch: 19, D Loss Real: 0.07669492065906525, D Loss Fake: 0.9537000060081482, G Loss: [10.536201477050781, 0.8201435804367065, 0.09716057777404785]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 20, SSIM Loss: 0.09876441955566406\n",
      "Epoch: 32, Batch: 20, D Loss Real: 0.07363425940275192, D Loss Fake: 0.9343013167381287, G Loss: [10.69208812713623, 0.8149195313453674, 0.09877169132232666]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 21, SSIM Loss: 0.09461688995361328\n",
      "Epoch: 32, Batch: 21, D Loss Real: 0.09580441564321518, D Loss Fake: 0.9072744250297546, G Loss: [10.296248435974121, 0.8218278288841248, 0.09474420547485352]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 22, SSIM Loss: 0.09405219554901123\n",
      "Epoch: 32, Batch: 22, D Loss Real: 0.06734887510538101, D Loss Fake: 0.9684233069419861, G Loss: [10.182950973510742, 0.7980330586433411, 0.09384918212890625]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 23, SSIM Loss: 0.09833663702011108\n",
      "Epoch: 32, Batch: 23, D Loss Real: 0.052751533687114716, D Loss Fake: 0.9632333517074585, G Loss: [10.64905834197998, 0.8184879422187805, 0.09830570220947266]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 24, SSIM Loss: 0.09839224815368652\n",
      "Epoch: 32, Batch: 24, D Loss Real: 0.060806550085544586, D Loss Fake: 0.9876830577850342, G Loss: [10.647937774658203, 0.8249907493591309, 0.09822946786880493]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 25, SSIM Loss: 0.09511083364486694\n",
      "Epoch: 32, Batch: 25, D Loss Real: 0.11522243916988373, D Loss Fake: 0.8922393321990967, G Loss: [10.369264602661133, 0.8517856597900391, 0.09517478942871094]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 26, SSIM Loss: 0.0971459150314331\n",
      "Epoch: 32, Batch: 26, D Loss Real: 0.0653897300362587, D Loss Fake: 0.9156694412231445, G Loss: [10.557449340820312, 0.8345304727554321, 0.09722918272018433]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 27, SSIM Loss: 0.09813499450683594\n",
      "Epoch: 32, Batch: 27, D Loss Real: 0.07333606481552124, D Loss Fake: 0.953135073184967, G Loss: [10.651927947998047, 0.871627926826477, 0.09780299663543701]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 28, SSIM Loss: 0.098457932472229\n",
      "Epoch: 32, Batch: 28, D Loss Real: 0.06253653764724731, D Loss Fake: 0.9073892831802368, G Loss: [10.727693557739258, 0.8608896732330322, 0.09866803884506226]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 29, SSIM Loss: 0.1031649112701416\n",
      "Epoch: 32, Batch: 29, D Loss Real: 0.0548897460103035, D Loss Fake: 0.9314973950386047, G Loss: [11.156572341918945, 0.819571852684021, 0.10337001085281372]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 30, SSIM Loss: 0.09914898872375488\n",
      "Epoch: 32, Batch: 30, D Loss Real: 0.08067042380571365, D Loss Fake: 0.9918349385261536, G Loss: [10.681425094604492, 0.7860105633735657, 0.09895414113998413]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 31, SSIM Loss: 0.09539490938186646\n",
      "Epoch: 32, Batch: 31, D Loss Real: 0.06178406998515129, D Loss Fake: 1.093724250793457, G Loss: [10.375810623168945, 0.8060588836669922, 0.09569752216339111]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 32, SSIM Loss: 0.09821522235870361\n",
      "Epoch: 32, Batch: 32, D Loss Real: 0.07482114434242249, D Loss Fake: 0.98789381980896, G Loss: [10.737358093261719, 0.8662325143814087, 0.09871125221252441]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 33, SSIM Loss: 0.09658622741699219\n",
      "Epoch: 32, Batch: 33, D Loss Real: 0.19836336374282837, D Loss Fake: 0.949360728263855, G Loss: [10.451690673828125, 0.8035944104194641, 0.09648096561431885]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 34, SSIM Loss: 0.09687715768814087\n",
      "Epoch: 32, Batch: 34, D Loss Real: 0.12022840231657028, D Loss Fake: 0.9852012395858765, G Loss: [10.48932933807373, 0.7842864990234375, 0.09705042839050293]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 35, SSIM Loss: 0.09559917449951172\n",
      "Epoch: 32, Batch: 35, D Loss Real: 0.17736247181892395, D Loss Fake: 1.147562026977539, G Loss: [10.412302017211914, 0.8194829821586609, 0.09592819213867188]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 36, SSIM Loss: 0.0974961519241333\n",
      "Epoch: 32, Batch: 36, D Loss Real: 0.2571586072444916, D Loss Fake: 1.101496934890747, G Loss: [10.459892272949219, 0.7209588885307312, 0.0973893404006958]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 37, SSIM Loss: 0.09554564952850342\n",
      "Epoch: 32, Batch: 37, D Loss Real: 0.12287537753582001, D Loss Fake: 1.1191540956497192, G Loss: [10.32470989227295, 0.7840931415557861, 0.095406174659729]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 38, SSIM Loss: 0.09950965642929077\n",
      "Epoch: 32, Batch: 38, D Loss Real: 0.10920558124780655, D Loss Fake: 1.046953558921814, G Loss: [10.689478874206543, 0.758497953414917, 0.09930980205535889]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 39, SSIM Loss: 0.0975571870803833\n",
      "Epoch: 32, Batch: 39, D Loss Real: 0.13495925068855286, D Loss Fake: 1.0417609214782715, G Loss: [10.494353294372559, 0.753738284111023, 0.09740614891052246]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 40, SSIM Loss: 0.10128235816955566\n",
      "Epoch: 32, Batch: 40, D Loss Real: 0.08490625023841858, D Loss Fake: 0.9677670001983643, G Loss: [10.908199310302734, 0.7886835932731628, 0.10119515657424927]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 41, SSIM Loss: 0.09356582164764404\n",
      "Epoch: 32, Batch: 41, D Loss Real: 0.16510310769081116, D Loss Fake: 1.0548259019851685, G Loss: [10.136881828308105, 0.7776410579681396, 0.09359240531921387]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 42, SSIM Loss: 0.09593641757965088\n",
      "Epoch: 32, Batch: 42, D Loss Real: 0.150948166847229, D Loss Fake: 1.0345474481582642, G Loss: [10.368658065795898, 0.7769597768783569, 0.0959169864654541]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 43, SSIM Loss: 0.09606003761291504\n",
      "Epoch: 32, Batch: 43, D Loss Real: 0.08695394545793533, D Loss Fake: 1.0103380680084229, G Loss: [10.431476593017578, 0.8174619674682617, 0.09614014625549316]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 44, SSIM Loss: 0.09279274940490723\n",
      "Epoch: 32, Batch: 44, D Loss Real: 0.2009376585483551, D Loss Fake: 1.0644862651824951, G Loss: [10.080793380737305, 0.8182792067527771, 0.09262514114379883]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 45, SSIM Loss: 0.10393667221069336\n",
      "Epoch: 32, Batch: 45, D Loss Real: 0.068897545337677, D Loss Fake: 1.0182815790176392, G Loss: [11.224370002746582, 0.8052812814712524, 0.1041908860206604]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 46, SSIM Loss: 0.09444248676300049\n",
      "Epoch: 32, Batch: 46, D Loss Real: 0.1577998846769333, D Loss Fake: 1.003319501876831, G Loss: [10.207228660583496, 0.759082019329071, 0.0944814682006836]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 47, SSIM Loss: 0.10318958759307861\n",
      "Epoch: 32, Batch: 47, D Loss Real: 0.04809647798538208, D Loss Fake: 1.002845287322998, G Loss: [11.207734107971191, 0.7995473742485046, 0.10408186912536621]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 48, SSIM Loss: 0.09733283519744873\n",
      "Epoch: 32, Batch: 48, D Loss Real: 0.06580199301242828, D Loss Fake: 0.9180318117141724, G Loss: [10.549734115600586, 0.8184177875518799, 0.09731316566467285]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 49, SSIM Loss: 0.0959787368774414\n",
      "Epoch: 32, Batch: 49, D Loss Real: 0.0660853385925293, D Loss Fake: 0.9225487112998962, G Loss: [10.441823959350586, 0.8259497880935669, 0.09615874290466309]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 50, SSIM Loss: 0.0985184907913208\n",
      "Epoch: 32, Batch: 50, D Loss Real: 0.06958313286304474, D Loss Fake: 0.9352115392684937, G Loss: [10.65001392364502, 0.828241765499115, 0.09821772575378418]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 51, SSIM Loss: 0.09583640098571777\n",
      "Epoch: 32, Batch: 51, D Loss Real: 0.07301878184080124, D Loss Fake: 0.9844361543655396, G Loss: [10.457947731018066, 0.8034197092056274, 0.0965452790260315]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 52, SSIM Loss: 0.10219120979309082\n",
      "Epoch: 32, Batch: 52, D Loss Real: 0.06427707523107529, D Loss Fake: 0.9266645908355713, G Loss: [11.031923294067383, 0.8429988622665405, 0.10188925266265869]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 53, SSIM Loss: 0.09877121448516846\n",
      "Epoch: 32, Batch: 53, D Loss Real: 0.11366342753171921, D Loss Fake: 0.9115170240402222, G Loss: [10.723353385925293, 0.8374696969985962, 0.09885883331298828]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 54, SSIM Loss: 0.0985916256904602\n",
      "Epoch: 32, Batch: 54, D Loss Real: 0.08287119120359421, D Loss Fake: 0.9870086312294006, G Loss: [10.683910369873047, 0.806371808052063, 0.09877538681030273]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 55, SSIM Loss: 0.09728968143463135\n",
      "Epoch: 32, Batch: 55, D Loss Real: 0.12092588096857071, D Loss Fake: 0.9472140073776245, G Loss: [10.562789916992188, 0.8456110954284668, 0.09717178344726562]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 56, SSIM Loss: 0.09744799137115479\n",
      "Epoch: 32, Batch: 56, D Loss Real: 0.05443495884537697, D Loss Fake: 1.0309239625930786, G Loss: [10.576340675354004, 0.8547274470329285, 0.09721612930297852]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 57, SSIM Loss: 0.10222029685974121\n",
      "Epoch: 32, Batch: 57, D Loss Real: 0.05152549594640732, D Loss Fake: 1.010607361793518, G Loss: [11.093989372253418, 0.8907826542854309, 0.10203206539154053]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 58, SSIM Loss: 0.09688466787338257\n",
      "Epoch: 32, Batch: 58, D Loss Real: 0.2122630476951599, D Loss Fake: 0.964988648891449, G Loss: [10.520453453063965, 0.8305978178977966, 0.09689855575561523]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 32, Batch: 59, SSIM Loss: 0.09686410427093506\n",
      "Epoch: 32, Batch: 59, D Loss Real: 0.19217807054519653, D Loss Fake: 1.21853768825531, G Loss: [10.43557071685791, 0.7490823864936829, 0.09686487913131714]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 60, SSIM Loss: 0.09875458478927612\n",
      "Epoch: 32, Batch: 60, D Loss Real: 0.10184424370527267, D Loss Fake: 1.0436209440231323, G Loss: [10.628225326538086, 0.7693191766738892, 0.09858906269073486]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 61, SSIM Loss: 0.09427940845489502\n",
      "Epoch: 32, Batch: 61, D Loss Real: 0.12334427237510681, D Loss Fake: 1.023890495300293, G Loss: [10.180037498474121, 0.7767720818519592, 0.0940326452255249]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 32, Batch: 62, SSIM Loss: 0.10120630264282227\n",
      "Epoch: 32, Batch: 62, D Loss Real: 0.14227920770645142, D Loss Fake: 0.9971143007278442, G Loss: [10.83212947845459, 0.7625571489334106, 0.10069572925567627]\n",
      "1/1 [==============================] - 0s 157ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:56:48.090989: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:56:49.603375: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Batch: 1, SSIM Loss: 0.09547728300094604\n",
      "Epoch: 33, Batch: 1, D Loss Real: 0.12797759473323822, D Loss Fake: 1.0424506664276123, G Loss: [10.283116340637207, 0.747147262096405, 0.0953596830368042]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 2, SSIM Loss: 0.09652864933013916\n",
      "Epoch: 33, Batch: 2, D Loss Real: 0.1432953178882599, D Loss Fake: 1.0091840028762817, G Loss: [10.418044090270996, 0.7684577107429504, 0.0964958667755127]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 33, Batch: 3, SSIM Loss: 0.09750640392303467\n",
      "Epoch: 33, Batch: 3, D Loss Real: 0.042785272002220154, D Loss Fake: 0.9733551740646362, G Loss: [10.553632736206055, 0.8151158094406128, 0.09738516807556152]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 4, SSIM Loss: 0.0996505618095398\n",
      "Epoch: 33, Batch: 4, D Loss Real: 0.07947692275047302, D Loss Fake: 0.9209455847740173, G Loss: [10.795634269714355, 0.8381779193878174, 0.09957456588745117]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 33, Batch: 5, SSIM Loss: 0.09571504592895508\n",
      "Epoch: 33, Batch: 5, D Loss Real: 0.06801268458366394, D Loss Fake: 0.9382004737854004, G Loss: [10.43877124786377, 0.8691977262496948, 0.09569573402404785]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 33, Batch: 6, SSIM Loss: 0.09396731853485107\n",
      "Epoch: 33, Batch: 6, D Loss Real: 0.05588143318891525, D Loss Fake: 0.9739534854888916, G Loss: [10.250642776489258, 0.8509365916252136, 0.093997061252594]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 7, SSIM Loss: 0.09749150276184082\n",
      "Epoch: 33, Batch: 7, D Loss Real: 0.05301747843623161, D Loss Fake: 0.9223151206970215, G Loss: [10.648876190185547, 0.8799670338630676, 0.09768909215927124]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 8, SSIM Loss: 0.09644263982772827\n",
      "Epoch: 33, Batch: 8, D Loss Real: 0.09709852933883667, D Loss Fake: 1.0320559740066528, G Loss: [10.477846145629883, 0.873785138130188, 0.09604060649871826]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 9, SSIM Loss: 0.09853637218475342\n",
      "Epoch: 33, Batch: 9, D Loss Real: 0.09026592969894409, D Loss Fake: 0.9429848790168762, G Loss: [10.711259841918945, 0.8228915333747864, 0.09888368844985962]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 10, SSIM Loss: 0.0950326919555664\n",
      "Epoch: 33, Batch: 10, D Loss Real: 0.08952077478170395, D Loss Fake: 1.042757511138916, G Loss: [10.362491607666016, 0.836345911026001, 0.09526145458221436]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 11, SSIM Loss: 0.09365016222000122\n",
      "Epoch: 33, Batch: 11, D Loss Real: 0.24413460493087769, D Loss Fake: 0.9733218550682068, G Loss: [10.143567085266113, 0.7764828205108643, 0.09367084503173828]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 12, SSIM Loss: 0.09512996673583984\n",
      "Epoch: 33, Batch: 12, D Loss Real: 0.09981714189052582, D Loss Fake: 1.0763120651245117, G Loss: [10.273500442504883, 0.771190345287323, 0.09502309560775757]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 13, SSIM Loss: 0.0977698564529419\n",
      "Epoch: 33, Batch: 13, D Loss Real: 0.14734220504760742, D Loss Fake: 1.1505409479141235, G Loss: [10.43751049041748, 0.7853368520736694, 0.09652173519134521]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 14, SSIM Loss: 0.10359805822372437\n",
      "Epoch: 33, Batch: 14, D Loss Real: 0.17043748497962952, D Loss Fake: 1.00221586227417, G Loss: [11.120532989501953, 0.7596832513809204, 0.10360848903656006]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 33, Batch: 15, SSIM Loss: 0.10335767269134521\n",
      "Epoch: 33, Batch: 15, D Loss Real: 0.06926585733890533, D Loss Fake: 1.1865981817245483, G Loss: [11.140328407287598, 0.8028028011322021, 0.10337525606155396]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 16, SSIM Loss: 0.09882420301437378\n",
      "Epoch: 33, Batch: 16, D Loss Real: 0.15625403821468353, D Loss Fake: 0.9545552134513855, G Loss: [10.684403419494629, 0.78779137134552, 0.09896612167358398]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 17, SSIM Loss: 0.09543776512145996\n",
      "Epoch: 33, Batch: 17, D Loss Real: 0.2022850215435028, D Loss Fake: 1.0040702819824219, G Loss: [10.2772216796875, 0.7708296179771423, 0.09506392478942871]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 33, Batch: 18, SSIM Loss: 0.09611666202545166\n",
      "Epoch: 33, Batch: 18, D Loss Real: 0.12534067034721375, D Loss Fake: 1.061607837677002, G Loss: [10.389159202575684, 0.7668895721435547, 0.09622269868850708]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 19, SSIM Loss: 0.09774237871170044\n",
      "Epoch: 33, Batch: 19, D Loss Real: 0.08494365960359573, D Loss Fake: 0.9936947822570801, G Loss: [10.619436264038086, 0.843225359916687, 0.0977621078491211]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 20, SSIM Loss: 0.09887957572937012\n",
      "Epoch: 33, Batch: 20, D Loss Real: 0.08050863444805145, D Loss Fake: 0.9682191014289856, G Loss: [10.678776741027832, 0.8271418809890747, 0.09851634502410889]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 21, SSIM Loss: 0.09375840425491333\n",
      "Epoch: 33, Batch: 21, D Loss Real: 0.12205386161804199, D Loss Fake: 0.956198513507843, G Loss: [10.204882621765137, 0.8029473423957825, 0.09401935338973999]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 22, SSIM Loss: 0.09410607814788818\n",
      "Epoch: 33, Batch: 22, D Loss Real: 0.06342115998268127, D Loss Fake: 1.087347388267517, G Loss: [10.210301399230957, 0.7967369556427002, 0.09413564205169678]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 23, SSIM Loss: 0.09845191240310669\n",
      "Epoch: 33, Batch: 23, D Loss Real: 0.06244681775569916, D Loss Fake: 0.9203168749809265, G Loss: [10.680852890014648, 0.8508075475692749, 0.09830045700073242]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 24, SSIM Loss: 0.09765863418579102\n",
      "Epoch: 33, Batch: 24, D Loss Real: 0.10663841664791107, D Loss Fake: 0.9224722385406494, G Loss: [10.549260139465332, 0.8242502212524414, 0.09725010395050049]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 25, SSIM Loss: 0.09606009721755981\n",
      "Epoch: 33, Batch: 25, D Loss Real: 0.10493847727775574, D Loss Fake: 0.9879828691482544, G Loss: [10.374734878540039, 0.8070451617240906, 0.09567689895629883]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 26, SSIM Loss: 0.09547042846679688\n",
      "Epoch: 33, Batch: 26, D Loss Real: 0.04765664041042328, D Loss Fake: 1.0145078897476196, G Loss: [10.375922203063965, 0.8360679149627686, 0.09539854526519775]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 27, SSIM Loss: 0.09729695320129395\n",
      "Epoch: 33, Batch: 27, D Loss Real: 0.1115821823477745, D Loss Fake: 0.9010196924209595, G Loss: [10.584375381469727, 0.8300273418426514, 0.09754347801208496]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 28, SSIM Loss: 0.09718126058578491\n",
      "Epoch: 33, Batch: 28, D Loss Real: 0.10006234794855118, D Loss Fake: 0.8642264604568481, G Loss: [10.56126880645752, 0.8737381100654602, 0.09687530994415283]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 29, SSIM Loss: 0.101296067237854\n",
      "Epoch: 33, Batch: 29, D Loss Real: 0.042882729321718216, D Loss Fake: 0.8929033279418945, G Loss: [10.987584114074707, 0.852362334728241, 0.10135221481323242]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 30, SSIM Loss: 0.09817034006118774\n",
      "Epoch: 33, Batch: 30, D Loss Real: 0.05946551635861397, D Loss Fake: 0.8809464573860168, G Loss: [10.652400970458984, 0.8577253818511963, 0.09794676303863525]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 31, SSIM Loss: 0.09421837329864502\n",
      "Epoch: 33, Batch: 31, D Loss Real: 0.049387115985155106, D Loss Fake: 0.918520987033844, G Loss: [10.308466911315918, 0.8717530965805054, 0.0943671464920044]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 32, SSIM Loss: 0.09837323427200317\n",
      "Epoch: 33, Batch: 32, D Loss Real: 0.031216710805892944, D Loss Fake: 0.9810749888420105, G Loss: [10.680619239807129, 0.845101535320282, 0.09835517406463623]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 33, SSIM Loss: 0.09689640998840332\n",
      "Epoch: 33, Batch: 33, D Loss Real: 0.06495802104473114, D Loss Fake: 0.9340853691101074, G Loss: [10.532047271728516, 0.8474735617637634, 0.09684574604034424]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 34, SSIM Loss: 0.09706485271453857\n",
      "Epoch: 33, Batch: 34, D Loss Real: 0.054874662309885025, D Loss Fake: 0.9200900793075562, G Loss: [10.581183433532715, 0.8700793981552124, 0.0971110463142395]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 33, Batch: 35, SSIM Loss: 0.09761464595794678\n",
      "Epoch: 33, Batch: 35, D Loss Real: 0.19466632604599, D Loss Fake: 1.0255916118621826, G Loss: [10.492039680480957, 0.7750882506370544, 0.09716951847076416]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 36, SSIM Loss: 0.09651035070419312\n",
      "Epoch: 33, Batch: 36, D Loss Real: 0.05066996067762375, D Loss Fake: 1.026605248451233, G Loss: [10.464394569396973, 0.8213644623756409, 0.09643030166625977]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 37, SSIM Loss: 0.09496057033538818\n",
      "Epoch: 33, Batch: 37, D Loss Real: 0.05928090587258339, D Loss Fake: 1.0075467824935913, G Loss: [10.3438720703125, 0.8462715744972229, 0.09497600793838501]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 38, SSIM Loss: 0.09875863790512085\n",
      "Epoch: 33, Batch: 38, D Loss Real: 0.07413437217473984, D Loss Fake: 0.9150243997573853, G Loss: [10.725281715393066, 0.8654336333274841, 0.09859848022460938]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 39, SSIM Loss: 0.09638738632202148\n",
      "Epoch: 33, Batch: 39, D Loss Real: 0.08766993880271912, D Loss Fake: 0.9518309831619263, G Loss: [10.442566871643066, 0.8537953495979309, 0.09588772058486938]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 40, SSIM Loss: 0.09950554370880127\n",
      "Epoch: 33, Batch: 40, D Loss Real: 0.0684850811958313, D Loss Fake: 0.9228946566581726, G Loss: [10.792842864990234, 0.830939769744873, 0.09961903095245361]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 41, SSIM Loss: 0.09414064884185791\n",
      "Epoch: 33, Batch: 41, D Loss Real: 0.17265598475933075, D Loss Fake: 0.9882537722587585, G Loss: [10.253440856933594, 0.7854933738708496, 0.09467947483062744]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 42, SSIM Loss: 0.09409749507904053\n",
      "Epoch: 33, Batch: 42, D Loss Real: 0.07077068835496902, D Loss Fake: 1.0407726764678955, G Loss: [10.229286193847656, 0.8205373287200928, 0.09408748149871826]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 43, SSIM Loss: 0.09606480598449707\n",
      "Epoch: 33, Batch: 43, D Loss Real: 0.03977560997009277, D Loss Fake: 1.0775333642959595, G Loss: [10.445106506347656, 0.8585927486419678, 0.09586513042449951]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 44, SSIM Loss: 0.09168756008148193\n",
      "Epoch: 33, Batch: 44, D Loss Real: 0.2410649061203003, D Loss Fake: 1.2430075407028198, G Loss: [10.066150665283203, 0.8913989067077637, 0.09174752235412598]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 45, SSIM Loss: 0.10414886474609375\n",
      "Epoch: 33, Batch: 45, D Loss Real: 0.186717689037323, D Loss Fake: 1.031224250793457, G Loss: [11.236660957336426, 0.7999295592308044, 0.10436731576919556]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 46, SSIM Loss: 0.09495735168457031\n",
      "Epoch: 33, Batch: 46, D Loss Real: 0.36146360635757446, D Loss Fake: 1.0663857460021973, G Loss: [10.180286407470703, 0.6877818703651428, 0.09492504596710205]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 47, SSIM Loss: 0.10278201103210449\n",
      "Epoch: 33, Batch: 47, D Loss Real: 0.1136360764503479, D Loss Fake: 1.1050230264663696, G Loss: [11.013629913330078, 0.7019544839859009, 0.10311675071716309]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 48, SSIM Loss: 0.09663701057434082\n",
      "Epoch: 33, Batch: 48, D Loss Real: 0.11590027809143066, D Loss Fake: 1.0338841676712036, G Loss: [10.441183090209961, 0.7753598093986511, 0.09665822982788086]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 49, SSIM Loss: 0.09451842308044434\n",
      "Epoch: 33, Batch: 49, D Loss Real: 0.0733375996351242, D Loss Fake: 0.9717799425125122, G Loss: [10.279407501220703, 0.8356592655181885, 0.09443747997283936]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 50, SSIM Loss: 0.0969420075416565\n",
      "Epoch: 33, Batch: 50, D Loss Real: 0.07512734830379486, D Loss Fake: 0.9441065192222595, G Loss: [10.438223838806152, 0.8302651047706604, 0.09607958793640137]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 51, SSIM Loss: 0.09548282623291016\n",
      "Epoch: 33, Batch: 51, D Loss Real: 0.09749916940927505, D Loss Fake: 0.9370996952056885, G Loss: [10.303973197937012, 0.8040415048599243, 0.09499931335449219]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 52, SSIM Loss: 0.10083132982254028\n",
      "Epoch: 33, Batch: 52, D Loss Real: 0.04336456209421158, D Loss Fake: 0.9413655996322632, G Loss: [10.935523986816406, 0.8350697755813599, 0.10100454092025757]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 53, SSIM Loss: 0.09480863809585571\n",
      "Epoch: 33, Batch: 53, D Loss Real: 0.061282891780138016, D Loss Fake: 0.8964227437973022, G Loss: [10.362089157104492, 0.8740488290786743, 0.09488040208816528]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 54, SSIM Loss: 0.09984093904495239\n",
      "Epoch: 33, Batch: 54, D Loss Real: 0.06596796959638596, D Loss Fake: 1.0005613565444946, G Loss: [10.833894729614258, 0.8416527509689331, 0.09992241859436035]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 33, Batch: 55, SSIM Loss: 0.09479022026062012\n",
      "Epoch: 33, Batch: 55, D Loss Real: 0.12844687700271606, D Loss Fake: 0.908349871635437, G Loss: [10.344182968139648, 0.867569088935852, 0.09476613998413086]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 56, SSIM Loss: 0.09818816184997559\n",
      "Epoch: 33, Batch: 56, D Loss Real: 0.05794904753565788, D Loss Fake: 0.9573402404785156, G Loss: [10.625804901123047, 0.8226767778396606, 0.09803128242492676]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 57, SSIM Loss: 0.10222125053405762\n",
      "Epoch: 33, Batch: 57, D Loss Real: 0.041317086666822433, D Loss Fake: 0.9236149191856384, G Loss: [11.065163612365723, 0.8380017876625061, 0.10227161645889282]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 58, SSIM Loss: 0.09663617610931396\n",
      "Epoch: 33, Batch: 58, D Loss Real: 0.08677810430526733, D Loss Fake: 0.9073131680488586, G Loss: [10.437643051147461, 0.8514457941055298, 0.09586197137832642]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 59, SSIM Loss: 0.09550082683563232\n",
      "Epoch: 33, Batch: 59, D Loss Real: 0.06870947778224945, D Loss Fake: 1.297160029411316, G Loss: [10.4362211227417, 0.8903937935829163, 0.0954582691192627]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 33, Batch: 60, SSIM Loss: 0.10303735733032227\n",
      "Epoch: 33, Batch: 60, D Loss Real: 0.12068234384059906, D Loss Fake: 0.9113418459892273, G Loss: [11.134718894958496, 0.9072714447975159, 0.10227447748184204]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 61, SSIM Loss: 0.09260910749435425\n",
      "Epoch: 33, Batch: 61, D Loss Real: 0.1936981976032257, D Loss Fake: 0.9450764656066895, G Loss: [10.16059398651123, 0.8221257328987122, 0.09338468313217163]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 33, Batch: 62, SSIM Loss: 0.10057544708251953\n",
      "Epoch: 33, Batch: 62, D Loss Real: 0.15629038214683533, D Loss Fake: 0.9684496521949768, G Loss: [10.986862182617188, 0.8397731184959412, 0.10147088766098022]\n",
      "1/1 [==============================] - 0s 158ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:58:11.498859: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:58:12.989449: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Batch: 1, SSIM Loss: 0.09455043077468872\n",
      "Epoch: 34, Batch: 1, D Loss Real: 0.10031281411647797, D Loss Fake: 1.0610297918319702, G Loss: [10.211840629577637, 0.7769445776939392, 0.0943489670753479]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 2, SSIM Loss: 0.0957106351852417\n",
      "Epoch: 34, Batch: 2, D Loss Real: 0.11353175342082977, D Loss Fake: 0.9479041695594788, G Loss: [10.437809944152832, 0.8226451873779297, 0.09615164995193481]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 34, Batch: 3, SSIM Loss: 0.0975027084350586\n",
      "Epoch: 34, Batch: 3, D Loss Real: 0.03654921054840088, D Loss Fake: 1.0218762159347534, G Loss: [10.551167488098145, 0.8321059942245483, 0.09719061851501465]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 34, Batch: 4, SSIM Loss: 0.09863066673278809\n",
      "Epoch: 34, Batch: 4, D Loss Real: 0.096257284283638, D Loss Fake: 0.9310933351516724, G Loss: [10.711660385131836, 0.8321430683135986, 0.09879517555236816]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 5, SSIM Loss: 0.0959673523902893\n",
      "Epoch: 34, Batch: 5, D Loss Real: 0.08600698411464691, D Loss Fake: 0.8967180252075195, G Loss: [10.45096206665039, 0.8565578460693359, 0.09594404697418213]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 6, SSIM Loss: 0.09365272521972656\n",
      "Epoch: 34, Batch: 6, D Loss Real: 0.056076277047395706, D Loss Fake: 0.9970247745513916, G Loss: [10.17231273651123, 0.8236703276634216, 0.09348642826080322]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 7, SSIM Loss: 0.09703201055526733\n",
      "Epoch: 34, Batch: 7, D Loss Real: 0.03787314519286156, D Loss Fake: 0.9606450796127319, G Loss: [10.529975891113281, 0.8302502036094666, 0.09699726104736328]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 8, SSIM Loss: 0.09605741500854492\n",
      "Epoch: 34, Batch: 8, D Loss Real: 0.06227061152458191, D Loss Fake: 0.9190348982810974, G Loss: [10.504083633422852, 0.8600407838821411, 0.09644043445587158]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 9, SSIM Loss: 0.09913009405136108\n",
      "Epoch: 34, Batch: 9, D Loss Real: 0.06700461357831955, D Loss Fake: 0.9843737483024597, G Loss: [10.763128280639648, 0.8702113032341003, 0.09892916679382324]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 10, SSIM Loss: 0.09518730640411377\n",
      "Epoch: 34, Batch: 10, D Loss Real: 0.08200539648532867, D Loss Fake: 0.9304956793785095, G Loss: [10.383820533752441, 0.8480427265167236, 0.09535777568817139]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 11, SSIM Loss: 0.09240871667861938\n",
      "Epoch: 34, Batch: 11, D Loss Real: 0.15083001554012299, D Loss Fake: 0.9124572277069092, G Loss: [10.064352989196777, 0.8191723227500916, 0.09245181083679199]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 12, SSIM Loss: 0.09421712160110474\n",
      "Epoch: 34, Batch: 12, D Loss Real: 0.05327979847788811, D Loss Fake: 0.9669634103775024, G Loss: [10.264142036437988, 0.8527231812477112, 0.09411418437957764]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 13, SSIM Loss: 0.09591531753540039\n",
      "Epoch: 34, Batch: 13, D Loss Real: 0.10489052534103394, D Loss Fake: 1.082947015762329, G Loss: [10.411712646484375, 0.8125517964363098, 0.09599161148071289]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 14, SSIM Loss: 0.10142630338668823\n",
      "Epoch: 34, Batch: 14, D Loss Real: 0.1572664976119995, D Loss Fake: 0.9957269430160522, G Loss: [10.965200424194336, 0.8216578364372253, 0.10143542289733887]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 15, SSIM Loss: 0.10300290584564209\n",
      "Epoch: 34, Batch: 15, D Loss Real: 0.08357172459363937, D Loss Fake: 0.9700827598571777, G Loss: [11.161517143249512, 0.8101087212562561, 0.10351407527923584]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 16, SSIM Loss: 0.09864449501037598\n",
      "Epoch: 34, Batch: 16, D Loss Real: 0.09065147489309311, D Loss Fake: 0.9543507099151611, G Loss: [10.66933822631836, 0.80760657787323, 0.0986173152923584]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 17, SSIM Loss: 0.09617304801940918\n",
      "Epoch: 34, Batch: 17, D Loss Real: 0.09351909160614014, D Loss Fake: 0.9403377771377563, G Loss: [10.448297500610352, 0.8649783134460449, 0.0958331823348999]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 18, SSIM Loss: 0.0961371660232544\n",
      "Epoch: 34, Batch: 18, D Loss Real: 0.0758720114827156, D Loss Fake: 0.9933358430862427, G Loss: [10.413354873657227, 0.7918410301208496, 0.0962151288986206]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 19, SSIM Loss: 0.09824466705322266\n",
      "Epoch: 34, Batch: 19, D Loss Real: 0.07124254107475281, D Loss Fake: 0.9583358764648438, G Loss: [10.679742813110352, 0.8206340074539185, 0.09859108924865723]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 20, SSIM Loss: 0.09887421131134033\n",
      "Epoch: 34, Batch: 20, D Loss Real: 0.06246137619018555, D Loss Fake: 0.8537682294845581, G Loss: [10.741536140441895, 0.9015722274780273, 0.09839963912963867]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 21, SSIM Loss: 0.09393757581710815\n",
      "Epoch: 34, Batch: 21, D Loss Real: 0.06250539422035217, D Loss Fake: 0.9691721200942993, G Loss: [10.251381874084473, 0.8621721863746643, 0.09389209747314453]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 22, SSIM Loss: 0.0949256420135498\n",
      "Epoch: 34, Batch: 22, D Loss Real: 0.058906521648168564, D Loss Fake: 0.9044172763824463, G Loss: [10.363506317138672, 0.875173807144165, 0.09488332271575928]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 23, SSIM Loss: 0.09721243381500244\n",
      "Epoch: 34, Batch: 23, D Loss Real: 0.047080542892217636, D Loss Fake: 0.8940669298171997, G Loss: [10.659355163574219, 0.8976637721061707, 0.09761691093444824]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 24, SSIM Loss: 0.09614074230194092\n",
      "Epoch: 34, Batch: 24, D Loss Real: 0.05288773775100708, D Loss Fake: 0.9479814767837524, G Loss: [10.490584373474121, 0.8664425611495972, 0.09624141454696655]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 25, SSIM Loss: 0.09663975238800049\n",
      "Epoch: 34, Batch: 25, D Loss Real: 0.10398484766483307, D Loss Fake: 0.9381834268569946, G Loss: [10.498018264770508, 0.8715933561325073, 0.09626424312591553]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 26, SSIM Loss: 0.09599238634109497\n",
      "Epoch: 34, Batch: 26, D Loss Real: 0.053530506789684296, D Loss Fake: 0.9178657531738281, G Loss: [10.48901653289795, 0.8767658472061157, 0.09612250328063965]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 27, SSIM Loss: 0.09694993495941162\n",
      "Epoch: 34, Batch: 27, D Loss Real: 0.07398772984743118, D Loss Fake: 0.8876309990882874, G Loss: [10.541279792785645, 0.8688405752182007, 0.09672439098358154]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 28, SSIM Loss: 0.09787499904632568\n",
      "Epoch: 34, Batch: 28, D Loss Real: 0.08446452766656876, D Loss Fake: 0.9068679213523865, G Loss: [10.628372192382812, 0.8792939186096191, 0.09749078750610352]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 29, SSIM Loss: 0.10073554515838623\n",
      "Epoch: 34, Batch: 29, D Loss Real: 0.046949148178100586, D Loss Fake: 0.9537338614463806, G Loss: [10.905075073242188, 0.843894898891449, 0.10061180591583252]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 30, SSIM Loss: 0.09867310523986816\n",
      "Epoch: 34, Batch: 30, D Loss Real: 0.06543934345245361, D Loss Fake: 0.9303554892539978, G Loss: [10.773561477661133, 0.8621198534965515, 0.09911441802978516]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 31, SSIM Loss: 0.09480804204940796\n",
      "Epoch: 34, Batch: 31, D Loss Real: 0.06927906721830368, D Loss Fake: 0.9008514881134033, G Loss: [10.293410301208496, 0.8494839072227478, 0.09443926811218262]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 32, SSIM Loss: 0.09668481349945068\n",
      "Epoch: 34, Batch: 32, D Loss Real: 0.04224337637424469, D Loss Fake: 0.9781042337417603, G Loss: [10.511659622192383, 0.8342256546020508, 0.09677433967590332]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 33, SSIM Loss: 0.09664750099182129\n",
      "Epoch: 34, Batch: 33, D Loss Real: 0.08980695903301239, D Loss Fake: 0.900307297706604, G Loss: [10.520153045654297, 0.8623462319374084, 0.09657806158065796]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 34, SSIM Loss: 0.09696626663208008\n",
      "Epoch: 34, Batch: 34, D Loss Real: 0.06944944709539413, D Loss Fake: 0.8805235028266907, G Loss: [10.599306106567383, 0.863722026348114, 0.09735584259033203]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 35, SSIM Loss: 0.09620052576065063\n",
      "Epoch: 34, Batch: 35, D Loss Real: 0.20332962274551392, D Loss Fake: 1.0008108615875244, G Loss: [10.537393569946289, 0.8885695338249207, 0.09648823738098145]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 36, SSIM Loss: 0.09764242172241211\n",
      "Epoch: 34, Batch: 36, D Loss Real: 0.0630439892411232, D Loss Fake: 1.0289841890335083, G Loss: [10.557311058044434, 0.7780371904373169, 0.09779274463653564]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 37, SSIM Loss: 0.09527617692947388\n",
      "Epoch: 34, Batch: 37, D Loss Real: 0.08200042694807053, D Loss Fake: 0.9234379529953003, G Loss: [10.391234397888184, 0.872610867023468, 0.09518623352050781]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 38, SSIM Loss: 0.09779125452041626\n",
      "Epoch: 34, Batch: 38, D Loss Real: 0.06075942888855934, D Loss Fake: 0.9806034564971924, G Loss: [10.587158203125, 0.8203407526016235, 0.09766817092895508]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 39, SSIM Loss: 0.0961458683013916\n",
      "Epoch: 34, Batch: 39, D Loss Real: 0.07455416023731232, D Loss Fake: 1.0184870958328247, G Loss: [10.442158699035645, 0.8276193737983704, 0.0961453914642334]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 40, SSIM Loss: 0.0978659987449646\n",
      "Epoch: 34, Batch: 40, D Loss Real: 0.061765141785144806, D Loss Fake: 0.9813873767852783, G Loss: [10.700963973999023, 0.8927687406539917, 0.09808194637298584]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 41, SSIM Loss: 0.09312152862548828\n",
      "Epoch: 34, Batch: 41, D Loss Real: 0.21888120472431183, D Loss Fake: 0.9664434194564819, G Loss: [10.089061737060547, 0.8058640360832214, 0.09283196926116943]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 42, SSIM Loss: 0.09335839748382568\n",
      "Epoch: 34, Batch: 42, D Loss Real: 0.08799964934587479, D Loss Fake: 0.9725558161735535, G Loss: [10.166024208068848, 0.8259649276733398, 0.09340059757232666]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 43, SSIM Loss: 0.09515261650085449\n",
      "Epoch: 34, Batch: 43, D Loss Real: 0.041839491575956345, D Loss Fake: 0.965003252029419, G Loss: [10.411845207214355, 0.8614172339439392, 0.0955042839050293]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 44, SSIM Loss: 0.09131652116775513\n",
      "Epoch: 34, Batch: 44, D Loss Real: 0.12257786095142365, D Loss Fake: 0.9479238986968994, G Loss: [9.972723007202148, 0.843234658241272, 0.09129488468170166]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 45, SSIM Loss: 0.10298967361450195\n",
      "Epoch: 34, Batch: 45, D Loss Real: 0.05937247723340988, D Loss Fake: 0.9300980567932129, G Loss: [11.156585693359375, 0.8519496321678162, 0.10304635763168335]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 46, SSIM Loss: 0.09478628635406494\n",
      "Epoch: 34, Batch: 46, D Loss Real: 0.19914855062961578, D Loss Fake: 0.9991867542266846, G Loss: [10.238243103027344, 0.7663979530334473, 0.09471845626831055]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 47, SSIM Loss: 0.10162508487701416\n",
      "Epoch: 34, Batch: 47, D Loss Real: 0.03469529747962952, D Loss Fake: 0.9945517778396606, G Loss: [10.931659698486328, 0.8139201402664185, 0.1011773943901062]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 48, SSIM Loss: 0.09687066078186035\n",
      "Epoch: 34, Batch: 48, D Loss Real: 0.04529552534222603, D Loss Fake: 0.8388240337371826, G Loss: [10.579729080200195, 0.9000182747840881, 0.09679710865020752]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 49, SSIM Loss: 0.09460616111755371\n",
      "Epoch: 34, Batch: 49, D Loss Real: 0.05799740552902222, D Loss Fake: 0.91762375831604, G Loss: [10.451560974121094, 1.0186847448349, 0.09432876110076904]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 50, SSIM Loss: 0.0956106185913086\n",
      "Epoch: 34, Batch: 50, D Loss Real: 0.08844251930713654, D Loss Fake: 0.8959258794784546, G Loss: [10.438348770141602, 0.8531954288482666, 0.09585154056549072]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 51, SSIM Loss: 0.095436692237854\n",
      "Epoch: 34, Batch: 51, D Loss Real: 0.12502673268318176, D Loss Fake: 0.9140483140945435, G Loss: [10.365618705749512, 0.8232852220535278, 0.09542334079742432]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 52, SSIM Loss: 0.10029935836791992\n",
      "Epoch: 34, Batch: 52, D Loss Real: 0.03221376612782478, D Loss Fake: 0.9832693934440613, G Loss: [10.834830284118652, 0.8408476710319519, 0.09993982315063477]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 53, SSIM Loss: 0.09312599897384644\n",
      "Epoch: 34, Batch: 53, D Loss Real: 0.04741086810827255, D Loss Fake: 0.9566127061843872, G Loss: [10.156028747558594, 0.8361036777496338, 0.09319925308227539]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 54, SSIM Loss: 0.10001617670059204\n",
      "Epoch: 34, Batch: 54, D Loss Real: 0.050626467913389206, D Loss Fake: 0.9799625873565674, G Loss: [10.860396385192871, 0.8992264866828918, 0.09961169958114624]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 55, SSIM Loss: 0.09541189670562744\n",
      "Epoch: 34, Batch: 55, D Loss Real: 0.15033815801143646, D Loss Fake: 0.957037091255188, G Loss: [10.461111068725586, 0.8779603242874146, 0.09583151340484619]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 56, SSIM Loss: 0.09651243686676025\n",
      "Epoch: 34, Batch: 56, D Loss Real: 0.07023266702890396, D Loss Fake: 0.9180946350097656, G Loss: [10.475019454956055, 0.8465921878814697, 0.09628427028656006]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 57, SSIM Loss: 0.10120898485183716\n",
      "Epoch: 34, Batch: 57, D Loss Real: 0.05494215339422226, D Loss Fake: 0.9224188327789307, G Loss: [10.959997177124023, 0.8549708127975464, 0.10105025768280029]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 58, SSIM Loss: 0.09642356634140015\n",
      "Epoch: 34, Batch: 58, D Loss Real: 0.12767735123634338, D Loss Fake: 1.0456117391586304, G Loss: [10.413841247558594, 0.7663102149963379, 0.09647530317306519]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 59, SSIM Loss: 0.09542357921600342\n",
      "Epoch: 34, Batch: 59, D Loss Real: 0.08008506894111633, D Loss Fake: 1.0715757608413696, G Loss: [10.520309448242188, 0.9664362668991089, 0.09553873538970947]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 34, Batch: 60, SSIM Loss: 0.09747326374053955\n",
      "Epoch: 34, Batch: 60, D Loss Real: 0.09184937924146652, D Loss Fake: 0.9483842849731445, G Loss: [10.703130722045898, 0.8368086814880371, 0.09866321086883545]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 61, SSIM Loss: 0.09619754552841187\n",
      "Epoch: 34, Batch: 61, D Loss Real: 0.12667924165725708, D Loss Fake: 0.8943871855735779, G Loss: [10.488221168518066, 0.8756372332572937, 0.09612584114074707]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 34, Batch: 62, SSIM Loss: 0.09898728132247925\n",
      "Epoch: 34, Batch: 62, D Loss Real: 0.10488681495189667, D Loss Fake: 0.965854287147522, G Loss: [10.742185592651367, 0.8469983339309692, 0.09895187616348267]\n",
      "1/1 [==============================] - 0s 169ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 03:59:34.897535: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 03:59:36.382402: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Batch: 1, SSIM Loss: 0.09430932998657227\n",
      "Epoch: 35, Batch: 1, D Loss Real: 0.10167285799980164, D Loss Fake: 0.95843106508255, G Loss: [10.270644187927246, 0.8288153409957886, 0.09441828727722168]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 2, SSIM Loss: 0.0978231430053711\n",
      "Epoch: 35, Batch: 2, D Loss Real: 0.11088509112596512, D Loss Fake: 0.9468960165977478, G Loss: [10.603385925292969, 0.8579551577568054, 0.09745430946350098]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 35, Batch: 3, SSIM Loss: 0.09706616401672363\n",
      "Epoch: 35, Batch: 3, D Loss Real: 0.05962159112095833, D Loss Fake: 0.9731280207633972, G Loss: [10.54605484008789, 0.8505489230155945, 0.0969550609588623]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 35, Batch: 4, SSIM Loss: 0.09803521633148193\n",
      "Epoch: 35, Batch: 4, D Loss Real: 0.1209847703576088, D Loss Fake: 0.9597668647766113, G Loss: [10.596481323242188, 0.81125807762146, 0.09785223007202148]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 5, SSIM Loss: 0.09546321630477905\n",
      "Epoch: 35, Batch: 5, D Loss Real: 0.07055886089801788, D Loss Fake: 1.047216534614563, G Loss: [10.370859146118164, 0.8349502086639404, 0.09535908699035645]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 35, Batch: 6, SSIM Loss: 0.09333682060241699\n",
      "Epoch: 35, Batch: 6, D Loss Real: 0.11179903149604797, D Loss Fake: 1.0060069561004639, G Loss: [10.22396183013916, 0.8941951990127563, 0.09329766035079956]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 35, Batch: 7, SSIM Loss: 0.09689551591873169\n",
      "Epoch: 35, Batch: 7, D Loss Real: 0.08313625305891037, D Loss Fake: 0.9109618663787842, G Loss: [10.521787643432617, 0.8298518061637878, 0.09691935777664185]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 35, Batch: 8, SSIM Loss: 0.09620463848114014\n",
      "Epoch: 35, Batch: 8, D Loss Real: 0.07907765358686447, D Loss Fake: 0.9140200614929199, G Loss: [10.47521686553955, 0.8522500991821289, 0.0962296724319458]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 35, Batch: 9, SSIM Loss: 0.09865450859069824\n",
      "Epoch: 35, Batch: 9, D Loss Real: 0.062193822115659714, D Loss Fake: 0.9062691926956177, G Loss: [10.770868301391602, 0.8846148252487183, 0.09886252880096436]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 35, Batch: 10, SSIM Loss: 0.0948532223701477\n",
      "Epoch: 35, Batch: 10, D Loss Real: 0.07046349346637726, D Loss Fake: 0.9571527242660522, G Loss: [10.341052055358887, 0.872114896774292, 0.09468936920166016]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 35, Batch: 11, SSIM Loss: 0.09263372421264648\n",
      "Epoch: 35, Batch: 11, D Loss Real: 0.24533608555793762, D Loss Fake: 0.9412342309951782, G Loss: [10.039155006408691, 0.7965546250343323, 0.09242600202560425]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 12, SSIM Loss: 0.09448075294494629\n",
      "Epoch: 35, Batch: 12, D Loss Real: 0.06460335850715637, D Loss Fake: 1.058501124382019, G Loss: [10.25770092010498, 0.8061262369155884, 0.09451574087142944]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 13, SSIM Loss: 0.09644496440887451\n",
      "Epoch: 35, Batch: 13, D Loss Real: 0.13870754837989807, D Loss Fake: 1.0411407947540283, G Loss: [10.402912139892578, 0.7896954417228699, 0.09613215923309326]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 14, SSIM Loss: 0.09948158264160156\n",
      "Epoch: 35, Batch: 14, D Loss Real: 0.11058685183525085, D Loss Fake: 1.0631606578826904, G Loss: [10.765087127685547, 0.8496994972229004, 0.09915387630462646]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 15, SSIM Loss: 0.10079419612884521\n",
      "Epoch: 35, Batch: 15, D Loss Real: 0.0950377881526947, D Loss Fake: 0.9307078719139099, G Loss: [10.970529556274414, 0.877734899520874, 0.10092794895172119]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 16, SSIM Loss: 0.10086381435394287\n",
      "Epoch: 35, Batch: 16, D Loss Real: 0.08021838217973709, D Loss Fake: 0.9068833589553833, G Loss: [10.977563858032227, 0.8944901823997498, 0.10083073377609253]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 17, SSIM Loss: 0.09476685523986816\n",
      "Epoch: 35, Batch: 17, D Loss Real: 0.11699996888637543, D Loss Fake: 0.9692163467407227, G Loss: [10.271278381347656, 0.8417869210243225, 0.09429490566253662]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 35, Batch: 18, SSIM Loss: 0.09541952610015869\n",
      "Epoch: 35, Batch: 18, D Loss Real: 0.1142156794667244, D Loss Fake: 0.9395030736923218, G Loss: [10.358907699584961, 0.8410528898239136, 0.09517854452133179]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 35, Batch: 19, SSIM Loss: 0.09668415784835815\n",
      "Epoch: 35, Batch: 19, D Loss Real: 0.06335102021694183, D Loss Fake: 0.9350360631942749, G Loss: [10.552217483520508, 0.8627320528030396, 0.09689486026763916]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 35, Batch: 20, SSIM Loss: 0.09685385227203369\n",
      "Epoch: 35, Batch: 20, D Loss Real: 0.05741206556558609, D Loss Fake: 0.9521369338035583, G Loss: [10.5518217086792, 0.8352391719818115, 0.09716582298278809]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 21, SSIM Loss: 0.09377014636993408\n",
      "Epoch: 35, Batch: 21, D Loss Real: 0.057430680841207504, D Loss Fake: 0.9306244850158691, G Loss: [10.194533348083496, 0.8563932776451111, 0.09338140487670898]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 22, SSIM Loss: 0.09455335140228271\n",
      "Epoch: 35, Batch: 22, D Loss Real: 0.045679789036512375, D Loss Fake: 0.8828341364860535, G Loss: [10.357498168945312, 0.8733503818511963, 0.09484148025512695]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 23, SSIM Loss: 0.09790992736816406\n",
      "Epoch: 35, Batch: 23, D Loss Real: 0.0530717670917511, D Loss Fake: 0.8961365222930908, G Loss: [10.702041625976562, 0.8757683038711548, 0.0982627272605896]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 24, SSIM Loss: 0.09616971015930176\n",
      "Epoch: 35, Batch: 24, D Loss Real: 0.04883454740047455, D Loss Fake: 0.9178111553192139, G Loss: [10.509723663330078, 0.8685890436172485, 0.09641134738922119]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 25, SSIM Loss: 0.09656625986099243\n",
      "Epoch: 35, Batch: 25, D Loss Real: 0.06064434349536896, D Loss Fake: 0.9150195717811584, G Loss: [10.533757209777832, 0.8945896029472351, 0.09639167785644531]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 26, SSIM Loss: 0.09645789861679077\n",
      "Epoch: 35, Batch: 26, D Loss Real: 0.044527169317007065, D Loss Fake: 0.9379011392593384, G Loss: [10.549715042114258, 0.9014633893966675, 0.09648251533508301]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 35, Batch: 27, SSIM Loss: 0.09691917896270752\n",
      "Epoch: 35, Batch: 27, D Loss Real: 0.0955338180065155, D Loss Fake: 0.8276775479316711, G Loss: [10.627861022949219, 0.9155582785606384, 0.09712302684783936]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 28, SSIM Loss: 0.09726035594940186\n",
      "Epoch: 35, Batch: 28, D Loss Real: 0.07782459259033203, D Loss Fake: 0.9442086815834045, G Loss: [10.591336250305176, 0.8968738317489624, 0.09694463014602661]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 29, SSIM Loss: 0.10041558742523193\n",
      "Epoch: 35, Batch: 29, D Loss Real: 0.04880722612142563, D Loss Fake: 0.8899232149124146, G Loss: [10.966176986694336, 0.9094908237457275, 0.10056686401367188]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 30, SSIM Loss: 0.0983399748802185\n",
      "Epoch: 35, Batch: 30, D Loss Real: 0.09179802238941193, D Loss Fake: 0.9196596741676331, G Loss: [10.64947509765625, 0.859168291091919, 0.09790307283401489]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 31, SSIM Loss: 0.09459644556045532\n",
      "Epoch: 35, Batch: 31, D Loss Real: 0.0793696790933609, D Loss Fake: 0.8716122508049011, G Loss: [10.348652839660645, 0.873272716999054, 0.09475380182266235]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 32, SSIM Loss: 0.09633219242095947\n",
      "Epoch: 35, Batch: 32, D Loss Real: 0.03586454689502716, D Loss Fake: 0.9428392052650452, G Loss: [10.471860885620117, 0.8389635682106018, 0.0963289737701416]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 33, SSIM Loss: 0.09549713134765625\n",
      "Epoch: 35, Batch: 33, D Loss Real: 0.09676915407180786, D Loss Fake: 0.8839684128761292, G Loss: [10.451546669006348, 0.8749988675117493, 0.09576547145843506]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 34, SSIM Loss: 0.096474289894104\n",
      "Epoch: 35, Batch: 34, D Loss Real: 0.04998256266117096, D Loss Fake: 0.9384793639183044, G Loss: [10.504528045654297, 0.8594363927841187, 0.09645092487335205]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 35, SSIM Loss: 0.09686946868896484\n",
      "Epoch: 35, Batch: 35, D Loss Real: 0.21521861851215363, D Loss Fake: 1.0395764112472534, G Loss: [10.445283889770508, 0.8414131999015808, 0.09603869915008545]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 36, SSIM Loss: 0.09623247385025024\n",
      "Epoch: 35, Batch: 36, D Loss Real: 0.08482515811920166, D Loss Fake: 1.0050603151321411, G Loss: [10.395927429199219, 0.8113690614700317, 0.09584558010101318]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 35, Batch: 37, SSIM Loss: 0.09362304210662842\n",
      "Epoch: 35, Batch: 37, D Loss Real: 0.09548164159059525, D Loss Fake: 0.9100798964500427, G Loss: [10.269477844238281, 0.8988537788391113, 0.09370625019073486]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 38, SSIM Loss: 0.09800565242767334\n",
      "Epoch: 35, Batch: 38, D Loss Real: 0.07719728350639343, D Loss Fake: 0.9632384777069092, G Loss: [10.64577579498291, 0.843881368637085, 0.09801894426345825]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 39, SSIM Loss: 0.09452849626541138\n",
      "Epoch: 35, Batch: 39, D Loss Real: 0.08782505244016647, D Loss Fake: 0.9695391654968262, G Loss: [10.276512145996094, 0.8445303440093994, 0.09431982040405273]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 40, SSIM Loss: 0.09882330894470215\n",
      "Epoch: 35, Batch: 40, D Loss Real: 0.06505761295557022, D Loss Fake: 0.9389928579330444, G Loss: [10.758382797241211, 0.8662054538726807, 0.0989217758178711]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 41, SSIM Loss: 0.09308075904846191\n",
      "Epoch: 35, Batch: 41, D Loss Real: 0.19555112719535828, D Loss Fake: 1.0111806392669678, G Loss: [10.140073776245117, 0.7941245436668396, 0.09345948696136475]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 42, SSIM Loss: 0.09282588958740234\n",
      "Epoch: 35, Batch: 42, D Loss Real: 0.10493896156549454, D Loss Fake: 1.1132922172546387, G Loss: [10.129212379455566, 0.831317126750946, 0.09297895431518555]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 43, SSIM Loss: 0.09575307369232178\n",
      "Epoch: 35, Batch: 43, D Loss Real: 0.0494222454726696, D Loss Fake: 1.0545233488082886, G Loss: [10.502257347106934, 0.9238981008529663, 0.09578359127044678]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 44, SSIM Loss: 0.0921897292137146\n",
      "Epoch: 35, Batch: 44, D Loss Real: 0.3517543375492096, D Loss Fake: 0.9496673941612244, G Loss: [10.059317588806152, 0.8328410387039185, 0.09226477146148682]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 45, SSIM Loss: 0.10282516479492188\n",
      "Epoch: 35, Batch: 45, D Loss Real: 0.10068906843662262, D Loss Fake: 0.9803206920623779, G Loss: [11.12253189086914, 0.8033409714698792, 0.10319191217422485]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 46, SSIM Loss: 0.09520560503005981\n",
      "Epoch: 35, Batch: 46, D Loss Real: 0.2574046552181244, D Loss Fake: 1.0411884784698486, G Loss: [10.279685020446777, 0.7673670053482056, 0.09512317180633545]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 47, SSIM Loss: 0.10154062509536743\n",
      "Epoch: 35, Batch: 47, D Loss Real: 0.06445921212434769, D Loss Fake: 1.0610817670822144, G Loss: [10.96451187133789, 0.7686787843704224, 0.10195833444595337]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 48, SSIM Loss: 0.09566283226013184\n",
      "Epoch: 35, Batch: 48, D Loss Real: 0.059014324098825455, D Loss Fake: 0.9090566039085388, G Loss: [10.46419906616211, 0.8951626420021057, 0.09569036960601807]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 49, SSIM Loss: 0.09416842460632324\n",
      "Epoch: 35, Batch: 49, D Loss Real: 0.06275984644889832, D Loss Fake: 0.9504464268684387, G Loss: [10.279603004455566, 0.875742495059967, 0.09403860569000244]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 50, SSIM Loss: 0.09545457363128662\n",
      "Epoch: 35, Batch: 50, D Loss Real: 0.060383811593055725, D Loss Fake: 0.8447471857070923, G Loss: [10.452812194824219, 0.8898195624351501, 0.09562993049621582]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 51, SSIM Loss: 0.09440779685974121\n",
      "Epoch: 35, Batch: 51, D Loss Real: 0.08730044960975647, D Loss Fake: 0.8704487085342407, G Loss: [10.281200408935547, 0.8685595989227295, 0.09412640333175659]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 35, Batch: 52, SSIM Loss: 0.09977412223815918\n",
      "Epoch: 35, Batch: 52, D Loss Real: 0.03747239708900452, D Loss Fake: 0.962405800819397, G Loss: [10.88320541381836, 0.8768252730369568, 0.10006380081176758]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 53, SSIM Loss: 0.09316796064376831\n",
      "Epoch: 35, Batch: 53, D Loss Real: 0.08058713376522064, D Loss Fake: 0.9153498411178589, G Loss: [10.201200485229492, 0.8595073223114014, 0.09341692924499512]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 54, SSIM Loss: 0.09880232810974121\n",
      "Epoch: 35, Batch: 54, D Loss Real: 0.06453370302915573, D Loss Fake: 0.885611891746521, G Loss: [10.744522094726562, 0.8691236972808838, 0.09875398874282837]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 55, SSIM Loss: 0.09473168849945068\n",
      "Epoch: 35, Batch: 55, D Loss Real: 0.11127594113349915, D Loss Fake: 0.9335381984710693, G Loss: [10.337865829467773, 0.8863334059715271, 0.09451532363891602]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 56, SSIM Loss: 0.09564554691314697\n",
      "Epoch: 35, Batch: 56, D Loss Real: 0.062464069575071335, D Loss Fake: 0.896399199962616, G Loss: [10.418198585510254, 0.855044424533844, 0.09563153982162476]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 57, SSIM Loss: 0.09816259145736694\n",
      "Epoch: 35, Batch: 57, D Loss Real: 0.0472976416349411, D Loss Fake: 0.8930718898773193, G Loss: [10.757331848144531, 0.8841084837913513, 0.09873223304748535]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 58, SSIM Loss: 0.09492731094360352\n",
      "Epoch: 35, Batch: 58, D Loss Real: 0.15298506617546082, D Loss Fake: 0.9957981109619141, G Loss: [10.311981201171875, 0.8302352428436279, 0.09481745958328247]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 59, SSIM Loss: 0.09544563293457031\n",
      "Epoch: 35, Batch: 59, D Loss Real: 0.11571130901575089, D Loss Fake: 0.9517601728439331, G Loss: [10.466862678527832, 0.9305967688560486, 0.09536266326904297]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 60, SSIM Loss: 0.0977368950843811\n",
      "Epoch: 35, Batch: 60, D Loss Real: 0.05362892523407936, D Loss Fake: 0.9211380481719971, G Loss: [10.67564868927002, 0.893656849861145, 0.09781992435455322]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 35, Batch: 61, SSIM Loss: 0.09221482276916504\n",
      "Epoch: 35, Batch: 61, D Loss Real: 0.07646320760250092, D Loss Fake: 0.9662003517150879, G Loss: [10.127195358276367, 0.8802320957183838, 0.09246963262557983]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 35, Batch: 62, SSIM Loss: 0.09978973865509033\n",
      "Epoch: 35, Batch: 62, D Loss Real: 0.1301763504743576, D Loss Fake: 1.0026429891586304, G Loss: [10.823949813842773, 0.8520503640174866, 0.09971898794174194]\n",
      "1/1 [==============================] - 0s 148ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:00:58.177375: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:00:59.667777: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Batch: 1, SSIM Loss: 0.09429192543029785\n",
      "Epoch: 36, Batch: 1, D Loss Real: 0.10596111416816711, D Loss Fake: 0.894953191280365, G Loss: [10.289347648620605, 0.8748835325241089, 0.09414464235305786]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 2, SSIM Loss: 0.09539419412612915\n",
      "Epoch: 36, Batch: 2, D Loss Real: 0.15627270936965942, D Loss Fake: 0.9167927503585815, G Loss: [10.385758399963379, 0.8365808725357056, 0.09549176692962646]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 36, Batch: 3, SSIM Loss: 0.09616595506668091\n",
      "Epoch: 36, Batch: 3, D Loss Real: 0.032108597457408905, D Loss Fake: 1.0935542583465576, G Loss: [10.465697288513184, 0.8654987812042236, 0.09600198268890381]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 36, Batch: 4, SSIM Loss: 0.09745562076568604\n",
      "Epoch: 36, Batch: 4, D Loss Real: 0.1510513871908188, D Loss Fake: 0.9014676809310913, G Loss: [10.601033210754395, 0.878329336643219, 0.09722703695297241]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 36, Batch: 5, SSIM Loss: 0.09475302696228027\n",
      "Epoch: 36, Batch: 5, D Loss Real: 0.1392180472612381, D Loss Fake: 0.9853031635284424, G Loss: [10.294849395751953, 0.8144448399543762, 0.09480404853820801]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 6, SSIM Loss: 0.09357678890228271\n",
      "Epoch: 36, Batch: 6, D Loss Real: 0.04325181990861893, D Loss Fake: 0.9242717027664185, G Loss: [10.186529159545898, 0.8513273000717163, 0.09335201978683472]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 7, SSIM Loss: 0.0966184139251709\n",
      "Epoch: 36, Batch: 7, D Loss Real: 0.041291236877441406, D Loss Fake: 0.9127244353294373, G Loss: [10.5182523727417, 0.8687258958816528, 0.09649527072906494]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 8, SSIM Loss: 0.0957646369934082\n",
      "Epoch: 36, Batch: 8, D Loss Real: 0.06156765669584274, D Loss Fake: 0.8742998838424683, G Loss: [10.463499069213867, 0.875698447227478, 0.095878005027771]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 9, SSIM Loss: 0.09765535593032837\n",
      "Epoch: 36, Batch: 9, D Loss Real: 0.05445210635662079, D Loss Fake: 0.9408984780311584, G Loss: [10.702070236206055, 0.9160845279693604, 0.09785985946655273]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 10, SSIM Loss: 0.09427207708358765\n",
      "Epoch: 36, Batch: 10, D Loss Real: 0.06663793325424194, D Loss Fake: 0.8563938736915588, G Loss: [10.33544635772705, 0.9054967761039734, 0.09429949522018433]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 36, Batch: 11, SSIM Loss: 0.09210121631622314\n",
      "Epoch: 36, Batch: 11, D Loss Real: 0.13402390480041504, D Loss Fake: 0.9701855182647705, G Loss: [10.041617393493652, 0.8317881226539612, 0.09209829568862915]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 12, SSIM Loss: 0.09329897165298462\n",
      "Epoch: 36, Batch: 12, D Loss Real: 0.053924791514873505, D Loss Fake: 0.986519455909729, G Loss: [10.221982955932617, 0.8736271262168884, 0.093483567237854]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 36, Batch: 13, SSIM Loss: 0.0946512222290039\n",
      "Epoch: 36, Batch: 13, D Loss Real: 0.13857056200504303, D Loss Fake: 0.9237666726112366, G Loss: [10.267775535583496, 0.8221800327301025, 0.09445595741271973]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 36, Batch: 14, SSIM Loss: 0.09808802604675293\n",
      "Epoch: 36, Batch: 14, D Loss Real: 0.11291210353374481, D Loss Fake: 0.9496073722839355, G Loss: [10.657546043395996, 0.8479928374290466, 0.09809553623199463]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 15, SSIM Loss: 0.09718042612075806\n",
      "Epoch: 36, Batch: 15, D Loss Real: 0.09200611710548401, D Loss Fake: 0.9344356060028076, G Loss: [10.56251049041748, 0.8305619359016418, 0.09731948375701904]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 16, SSIM Loss: 0.09829521179199219\n",
      "Epoch: 36, Batch: 16, D Loss Real: 0.07325903326272964, D Loss Fake: 0.9452821016311646, G Loss: [10.710233688354492, 0.8523525595664978, 0.0985788106918335]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 17, SSIM Loss: 0.09400904178619385\n",
      "Epoch: 36, Batch: 17, D Loss Real: 0.07019983232021332, D Loss Fake: 0.9398142695426941, G Loss: [10.27746295928955, 0.8848311901092529, 0.0939263105392456]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 18, SSIM Loss: 0.09525430202484131\n",
      "Epoch: 36, Batch: 18, D Loss Real: 0.09424223005771637, D Loss Fake: 0.9056100249290466, G Loss: [10.370121955871582, 0.8482561707496643, 0.09521865844726562]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 19, SSIM Loss: 0.09596896171569824\n",
      "Epoch: 36, Batch: 19, D Loss Real: 0.04816257953643799, D Loss Fake: 0.9731341600418091, G Loss: [10.484313011169434, 0.9141493439674377, 0.09570163488388062]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 20, SSIM Loss: 0.09628880023956299\n",
      "Epoch: 36, Batch: 20, D Loss Real: 0.0767114907503128, D Loss Fake: 0.8600652813911438, G Loss: [10.510309219360352, 0.8834080100059509, 0.09626901149749756]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 21, SSIM Loss: 0.09427165985107422\n",
      "Epoch: 36, Batch: 21, D Loss Real: 0.0872323140501976, D Loss Fake: 0.8539757132530212, G Loss: [10.266578674316406, 0.8698824048042297, 0.09396696090698242]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 22, SSIM Loss: 0.09352457523345947\n",
      "Epoch: 36, Batch: 22, D Loss Real: 0.04939143732190132, D Loss Fake: 0.971157431602478, G Loss: [10.216367721557617, 0.8459508419036865, 0.09370416402816772]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 36, Batch: 23, SSIM Loss: 0.09680306911468506\n",
      "Epoch: 36, Batch: 23, D Loss Real: 0.05775134265422821, D Loss Fake: 0.9412379264831543, G Loss: [10.53249454498291, 0.8575643301010132, 0.09674930572509766]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 24, SSIM Loss: 0.09700167179107666\n",
      "Epoch: 36, Batch: 24, D Loss Real: 0.05452611297369003, D Loss Fake: 0.8835992217063904, G Loss: [10.4522123336792, 0.8817148208618164, 0.09570497274398804]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 25, SSIM Loss: 0.09633004665374756\n",
      "Epoch: 36, Batch: 25, D Loss Real: 0.05979451537132263, D Loss Fake: 0.9382814764976501, G Loss: [10.535191535949707, 0.9109013080596924, 0.09624290466308594]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 26, SSIM Loss: 0.09535175561904907\n",
      "Epoch: 36, Batch: 26, D Loss Real: 0.061072662472724915, D Loss Fake: 0.8509232401847839, G Loss: [10.434322357177734, 0.9110732078552246, 0.09523248672485352]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 27, SSIM Loss: 0.09463608264923096\n",
      "Epoch: 36, Batch: 27, D Loss Real: 0.07602041214704514, D Loss Fake: 0.8020963668823242, G Loss: [10.423920631408691, 0.9144821166992188, 0.09509438276290894]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 28, SSIM Loss: 0.09698182344436646\n",
      "Epoch: 36, Batch: 28, D Loss Real: 0.05951869115233421, D Loss Fake: 0.9522081613540649, G Loss: [10.617137908935547, 0.9098889827728271, 0.09707248210906982]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 29, SSIM Loss: 0.09982961416244507\n",
      "Epoch: 36, Batch: 29, D Loss Real: 0.04655328392982483, D Loss Fake: 0.8654084205627441, G Loss: [10.973069190979004, 0.9314925670623779, 0.10041576623916626]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 30, SSIM Loss: 0.09750491380691528\n",
      "Epoch: 36, Batch: 30, D Loss Real: 0.11248139292001724, D Loss Fake: 0.8986704349517822, G Loss: [10.627394676208496, 0.8948622941970825, 0.09732532501220703]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 31, SSIM Loss: 0.09445631504058838\n",
      "Epoch: 36, Batch: 31, D Loss Real: 0.061716340482234955, D Loss Fake: 0.8546649217605591, G Loss: [10.365883827209473, 0.8988486528396606, 0.0946703553199768]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 32, SSIM Loss: 0.0962483286857605\n",
      "Epoch: 36, Batch: 32, D Loss Real: 0.0333421491086483, D Loss Fake: 1.1099177598953247, G Loss: [10.533178329467773, 0.9359725117683411, 0.09597206115722656]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 33, SSIM Loss: 0.09525024890899658\n",
      "Epoch: 36, Batch: 33, D Loss Real: 0.2512088418006897, D Loss Fake: 1.0219700336456299, G Loss: [10.410348892211914, 0.8796379566192627, 0.0953071117401123]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 34, SSIM Loss: 0.09618914127349854\n",
      "Epoch: 36, Batch: 34, D Loss Real: 0.23202918469905853, D Loss Fake: 0.9403835535049438, G Loss: [10.483438491821289, 0.8520791530609131, 0.09631359577178955]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 35, SSIM Loss: 0.09696590900421143\n",
      "Epoch: 36, Batch: 35, D Loss Real: 0.39806342124938965, D Loss Fake: 1.0879967212677002, G Loss: [10.410008430480957, 0.7222989797592163, 0.0968770980834961]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 36, Batch: 36, SSIM Loss: 0.0943748950958252\n",
      "Epoch: 36, Batch: 36, D Loss Real: 0.16172757744789124, D Loss Fake: 1.1332926750183105, G Loss: [10.219962120056152, 0.7279220223426819, 0.09492039680480957]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 36, Batch: 37, SSIM Loss: 0.09373784065246582\n",
      "Epoch: 36, Batch: 37, D Loss Real: 0.1339283287525177, D Loss Fake: 1.0436060428619385, G Loss: [10.158533096313477, 0.7776198387145996, 0.09380912780761719]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 38, SSIM Loss: 0.09688562154769897\n",
      "Epoch: 36, Batch: 38, D Loss Real: 0.08490626513957977, D Loss Fake: 1.0684465169906616, G Loss: [10.474434852600098, 0.7999444603919983, 0.09674489498138428]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 39, SSIM Loss: 0.09461712837219238\n",
      "Epoch: 36, Batch: 39, D Loss Real: 0.1861729472875595, D Loss Fake: 0.9520684480667114, G Loss: [10.264342308044434, 0.8048948645591736, 0.09459447860717773]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 36, Batch: 40, SSIM Loss: 0.09872794151306152\n",
      "Epoch: 36, Batch: 40, D Loss Real: 0.06764426827430725, D Loss Fake: 0.9789078235626221, G Loss: [10.709426879882812, 0.8160864114761353, 0.0989333987236023]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 41, SSIM Loss: 0.09232622385025024\n",
      "Epoch: 36, Batch: 41, D Loss Real: 0.16308674216270447, D Loss Fake: 1.0375947952270508, G Loss: [10.093147277832031, 0.8564543128013611, 0.09236693382263184]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 42, SSIM Loss: 0.09259581565856934\n",
      "Epoch: 36, Batch: 42, D Loss Real: 0.12700878083705902, D Loss Fake: 0.9678657054901123, G Loss: [10.059189796447754, 0.8201118111610413, 0.09239077568054199]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 43, SSIM Loss: 0.09613925218582153\n",
      "Epoch: 36, Batch: 43, D Loss Real: 0.036422085016965866, D Loss Fake: 0.8777508735656738, G Loss: [10.493865013122559, 0.8840469121932983, 0.09609818458557129]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 44, SSIM Loss: 0.09138232469558716\n",
      "Epoch: 36, Batch: 44, D Loss Real: 0.09810454398393631, D Loss Fake: 0.8757022023200989, G Loss: [10.004437446594238, 0.8460939526557922, 0.09158343076705933]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 45, SSIM Loss: 0.10318708419799805\n",
      "Epoch: 36, Batch: 45, D Loss Real: 0.032905805855989456, D Loss Fake: 0.9554457068443298, G Loss: [11.127874374389648, 0.8824743032455444, 0.10245400667190552]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 46, SSIM Loss: 0.09447813034057617\n",
      "Epoch: 36, Batch: 46, D Loss Real: 0.16243448853492737, D Loss Fake: 0.9675570726394653, G Loss: [10.27291202545166, 0.828674852848053, 0.09444236755371094]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 47, SSIM Loss: 0.10161387920379639\n",
      "Epoch: 36, Batch: 47, D Loss Real: 0.03841003030538559, D Loss Fake: 0.9292223453521729, G Loss: [10.990060806274414, 0.8406052589416504, 0.10149455070495605]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 36, Batch: 48, SSIM Loss: 0.09704381227493286\n",
      "Epoch: 36, Batch: 48, D Loss Real: 0.038073617964982986, D Loss Fake: 0.926351010799408, G Loss: [10.608555793762207, 0.8893505930900574, 0.09719204902648926]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 49, SSIM Loss: 0.09373635053634644\n",
      "Epoch: 36, Batch: 49, D Loss Real: 0.058011218905448914, D Loss Fake: 0.9555869102478027, G Loss: [10.42756175994873, 1.0439072847366333, 0.09383654594421387]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 50, SSIM Loss: 0.09570527076721191\n",
      "Epoch: 36, Batch: 50, D Loss Real: 0.08527029305696487, D Loss Fake: 0.787132740020752, G Loss: [10.602226257324219, 0.9397169351577759, 0.09662508964538574]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 51, SSIM Loss: 0.09515142440795898\n",
      "Epoch: 36, Batch: 51, D Loss Real: 0.07875147461891174, D Loss Fake: 0.908359169960022, G Loss: [10.430176734924316, 0.9236765503883362, 0.09506499767303467]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 52, SSIM Loss: 0.10088515281677246\n",
      "Epoch: 36, Batch: 52, D Loss Real: 0.09146319329738617, D Loss Fake: 0.874460756778717, G Loss: [10.95570182800293, 0.8840368986129761, 0.10071665048599243]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 53, SSIM Loss: 0.09348750114440918\n",
      "Epoch: 36, Batch: 53, D Loss Real: 0.11671563982963562, D Loss Fake: 1.008750081062317, G Loss: [10.176735877990723, 0.8110226988792419, 0.09365713596343994]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 54, SSIM Loss: 0.09827446937561035\n",
      "Epoch: 36, Batch: 54, D Loss Real: 0.06559798866510391, D Loss Fake: 1.0365564823150635, G Loss: [10.656235694885254, 0.8423429727554321, 0.09813892841339111]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 55, SSIM Loss: 0.09449046850204468\n",
      "Epoch: 36, Batch: 55, D Loss Real: 0.14989206194877625, D Loss Fake: 0.9063534736633301, G Loss: [10.310235977172852, 0.8657490015029907, 0.0944448709487915]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 56, SSIM Loss: 0.09686523675918579\n",
      "Epoch: 36, Batch: 56, D Loss Real: 0.05581023916602135, D Loss Fake: 0.8971943855285645, G Loss: [10.526607513427734, 0.8550263047218323, 0.09671580791473389]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 57, SSIM Loss: 0.0981016755104065\n",
      "Epoch: 36, Batch: 57, D Loss Real: 0.03784745931625366, D Loss Fake: 0.894535481929779, G Loss: [10.667695045471191, 0.8631898760795593, 0.09804505109786987]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 58, SSIM Loss: 0.09502661228179932\n",
      "Epoch: 36, Batch: 58, D Loss Real: 0.11365630477666855, D Loss Fake: 0.9792515635490417, G Loss: [10.254959106445312, 0.8054717183113098, 0.09449487924575806]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 59, SSIM Loss: 0.0952344536781311\n",
      "Epoch: 36, Batch: 59, D Loss Real: 0.10142859071493149, D Loss Fake: 0.9331427216529846, G Loss: [10.343157768249512, 0.8172152042388916, 0.09525942802429199]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 60, SSIM Loss: 0.09781455993652344\n",
      "Epoch: 36, Batch: 60, D Loss Real: 0.04092852771282196, D Loss Fake: 1.0548350811004639, G Loss: [10.635229110717773, 0.8214911222457886, 0.09813737869262695]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 61, SSIM Loss: 0.09274184703826904\n",
      "Epoch: 36, Batch: 61, D Loss Real: 0.07801836729049683, D Loss Fake: 0.9814025163650513, G Loss: [10.410141944885254, 1.0040762424468994, 0.09406065940856934]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 36, Batch: 62, SSIM Loss: 0.09803152084350586\n",
      "Epoch: 36, Batch: 62, D Loss Real: 0.136111781001091, D Loss Fake: 0.9369238615036011, G Loss: [10.731353759765625, 0.9712485671043396, 0.09760105609893799]\n",
      "1/1 [==============================] - 0s 146ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:02:21.484084: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:02:22.962029: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Batch: 1, SSIM Loss: 0.09415405988693237\n",
      "Epoch: 37, Batch: 1, D Loss Real: 0.11407096683979034, D Loss Fake: 0.9310860633850098, G Loss: [10.339683532714844, 0.8983668088912964, 0.094413161277771]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 2, SSIM Loss: 0.09651988744735718\n",
      "Epoch: 37, Batch: 2, D Loss Real: 0.12820224463939667, D Loss Fake: 1.0474270582199097, G Loss: [10.531275749206543, 0.8848005533218384, 0.09646475315093994]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 3, SSIM Loss: 0.0963517427444458\n",
      "Epoch: 37, Batch: 3, D Loss Real: 0.06563420593738556, D Loss Fake: 1.0019922256469727, G Loss: [10.535719871520996, 0.9007717370986938, 0.09634947776794434]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 4, SSIM Loss: 0.09780240058898926\n",
      "Epoch: 37, Batch: 4, D Loss Real: 0.19603130221366882, D Loss Fake: 0.9340912699699402, G Loss: [10.679515838623047, 0.8667263984680176, 0.09812790155410767]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 5, SSIM Loss: 0.09495151042938232\n",
      "Epoch: 37, Batch: 5, D Loss Real: 0.11025582253932953, D Loss Fake: 1.177396535873413, G Loss: [10.33771800994873, 0.8335313200950623, 0.09504187107086182]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 6, SSIM Loss: 0.09370648860931396\n",
      "Epoch: 37, Batch: 6, D Loss Real: 0.195584237575531, D Loss Fake: 0.9716737270355225, G Loss: [10.195775985717773, 0.810274600982666, 0.09385502338409424]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 7, SSIM Loss: 0.09761327505111694\n",
      "Epoch: 37, Batch: 7, D Loss Real: 0.125832200050354, D Loss Fake: 1.0459500551223755, G Loss: [10.544198036193848, 0.7756584882736206, 0.09768539667129517]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 8, SSIM Loss: 0.09664225578308105\n",
      "Epoch: 37, Batch: 8, D Loss Real: 0.11547089368104935, D Loss Fake: 1.0377278327941895, G Loss: [10.514241218566895, 0.8470949530601501, 0.096671462059021]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 9, SSIM Loss: 0.09770727157592773\n",
      "Epoch: 37, Batch: 9, D Loss Real: 0.12358932197093964, D Loss Fake: 0.9686053991317749, G Loss: [10.574249267578125, 0.8263153433799744, 0.09747934341430664]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 10, SSIM Loss: 0.09577274322509766\n",
      "Epoch: 37, Batch: 10, D Loss Real: 0.10743243992328644, D Loss Fake: 1.0335670709609985, G Loss: [10.43083381652832, 0.8481712937355042, 0.09582662582397461]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 11, SSIM Loss: 0.09204733371734619\n",
      "Epoch: 37, Batch: 11, D Loss Real: 0.2161824256181717, D Loss Fake: 0.9400293827056885, G Loss: [9.998793601989746, 0.8206077814102173, 0.0917818546295166]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 12, SSIM Loss: 0.09453845024108887\n",
      "Epoch: 37, Batch: 12, D Loss Real: 0.07777383178472519, D Loss Fake: 1.2059446573257446, G Loss: [10.27856159210205, 0.8316009640693665, 0.09446960687637329]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 13, SSIM Loss: 0.09506845474243164\n",
      "Epoch: 37, Batch: 13, D Loss Real: 0.1751278042793274, D Loss Fake: 0.9492363333702087, G Loss: [10.43242073059082, 0.8603623509407043, 0.09572058916091919]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 14, SSIM Loss: 0.09981578588485718\n",
      "Epoch: 37, Batch: 14, D Loss Real: 0.2581283152103424, D Loss Fake: 0.938735842704773, G Loss: [10.795526504516602, 0.8108664751052856, 0.09984660148620605]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 15, SSIM Loss: 0.09867697954177856\n",
      "Epoch: 37, Batch: 15, D Loss Real: 0.14633743464946747, D Loss Fake: 1.1291258335113525, G Loss: [10.654370307922363, 0.8228229284286499, 0.09831547737121582]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 16, SSIM Loss: 0.09814739227294922\n",
      "Epoch: 37, Batch: 16, D Loss Real: 0.1034591943025589, D Loss Fake: 1.0598900318145752, G Loss: [10.642799377441406, 0.8194947242736816, 0.09823304414749146]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 17, SSIM Loss: 0.09494292736053467\n",
      "Epoch: 37, Batch: 17, D Loss Real: 0.12450778484344482, D Loss Fake: 1.1241543292999268, G Loss: [10.318745613098145, 0.7772525548934937, 0.09541493654251099]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 18, SSIM Loss: 0.09495019912719727\n",
      "Epoch: 37, Batch: 18, D Loss Real: 0.15948449075222015, D Loss Fake: 1.335416316986084, G Loss: [10.450111389160156, 0.9415020942687988, 0.09508609771728516]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 19, SSIM Loss: 0.09707844257354736\n",
      "Epoch: 37, Batch: 19, D Loss Real: 0.1795930415391922, D Loss Fake: 1.0636944770812988, G Loss: [10.512558937072754, 0.8043984770774841, 0.09708160161972046]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 20, SSIM Loss: 0.09722554683685303\n",
      "Epoch: 37, Batch: 20, D Loss Real: 0.12982895970344543, D Loss Fake: 1.0973490476608276, G Loss: [10.450813293457031, 0.773344099521637, 0.09677469730377197]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 21, SSIM Loss: 0.09247040748596191\n",
      "Epoch: 37, Batch: 21, D Loss Real: 0.08940069377422333, D Loss Fake: 0.8623677492141724, G Loss: [10.165305137634277, 0.9053661823272705, 0.09259939193725586]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 22, SSIM Loss: 0.092521071434021\n",
      "Epoch: 37, Batch: 22, D Loss Real: 0.06662984192371368, D Loss Fake: 1.1033397912979126, G Loss: [10.095690727233887, 0.8659652471542358, 0.0922972559928894]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 23, SSIM Loss: 0.09671247005462646\n",
      "Epoch: 37, Batch: 23, D Loss Real: 0.09717907011508942, D Loss Fake: 0.9344884157180786, G Loss: [10.521318435668945, 0.8358557224273682, 0.09685462713241577]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 24, SSIM Loss: 0.09600472450256348\n",
      "Epoch: 37, Batch: 24, D Loss Real: 0.12437427043914795, D Loss Fake: 0.9710491895675659, G Loss: [10.38701343536377, 0.8239967226982117, 0.09563016891479492]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 25, SSIM Loss: 0.0958092212677002\n",
      "Epoch: 37, Batch: 25, D Loss Real: 0.0985860526561737, D Loss Fake: 1.0373716354370117, G Loss: [10.400812149047852, 0.8157411217689514, 0.09585070610046387]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 26, SSIM Loss: 0.09509128332138062\n",
      "Epoch: 37, Batch: 26, D Loss Real: 0.07702811062335968, D Loss Fake: 0.9822830557823181, G Loss: [10.395625114440918, 0.9131457805633545, 0.09482479095458984]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 27, SSIM Loss: 0.0939568281173706\n",
      "Epoch: 37, Batch: 27, D Loss Real: 0.09141357243061066, D Loss Fake: 0.951918363571167, G Loss: [10.311833381652832, 0.8829746246337891, 0.09428858757019043]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 28, SSIM Loss: 0.09820777177810669\n",
      "Epoch: 37, Batch: 28, D Loss Real: 0.14803661406040192, D Loss Fake: 0.9901304244995117, G Loss: [10.687891960144043, 0.896213173866272, 0.09791678190231323]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 29, SSIM Loss: 0.09984225034713745\n",
      "Epoch: 37, Batch: 29, D Loss Real: 0.10575491935014725, D Loss Fake: 0.9836739301681519, G Loss: [10.901046752929688, 0.9213334918022156, 0.09979712963104248]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 30, SSIM Loss: 0.09746289253234863\n",
      "Epoch: 37, Batch: 30, D Loss Real: 0.1884744018316269, D Loss Fake: 0.7837359309196472, G Loss: [10.678465843200684, 0.9643508195877075, 0.09714114665985107]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 31, SSIM Loss: 0.0945059061050415\n",
      "Epoch: 37, Batch: 31, D Loss Real: 0.09273726493120193, D Loss Fake: 1.1279518604278564, G Loss: [10.274999618530273, 0.833957314491272, 0.09441041946411133]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 32, SSIM Loss: 0.09601849317550659\n",
      "Epoch: 37, Batch: 32, D Loss Real: 0.10612592101097107, D Loss Fake: 0.9434651136398315, G Loss: [10.451179504394531, 0.8396980166435242, 0.09611481428146362]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 33, SSIM Loss: 0.09543204307556152\n",
      "Epoch: 37, Batch: 33, D Loss Real: 0.17457756400108337, D Loss Fake: 0.9169685244560242, G Loss: [10.352104187011719, 0.8560173511505127, 0.09496086835861206]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 34, SSIM Loss: 0.09562027454376221\n",
      "Epoch: 37, Batch: 34, D Loss Real: 0.0918036699295044, D Loss Fake: 1.058591604232788, G Loss: [10.386890411376953, 0.7960149645805359, 0.0959087610244751]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 35, SSIM Loss: 0.09644663333892822\n",
      "Epoch: 37, Batch: 35, D Loss Real: 0.19827322661876678, D Loss Fake: 1.1108964681625366, G Loss: [10.497383117675781, 0.8338375091552734, 0.09663546085357666]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 36, SSIM Loss: 0.09512203931808472\n",
      "Epoch: 37, Batch: 36, D Loss Real: 0.17037232220172882, D Loss Fake: 1.0783010721206665, G Loss: [10.284331321716309, 0.7764371633529663, 0.09507894515991211]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 37, SSIM Loss: 0.09457641839981079\n",
      "Epoch: 37, Batch: 37, D Loss Real: 0.25961893796920776, D Loss Fake: 1.084261417388916, G Loss: [10.198331832885742, 0.7757545709609985, 0.09422576427459717]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 38, SSIM Loss: 0.09734612703323364\n",
      "Epoch: 37, Batch: 38, D Loss Real: 0.17287243902683258, D Loss Fake: 1.0367121696472168, G Loss: [10.448816299438477, 0.7836847305297852, 0.09665131568908691]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 39, SSIM Loss: 0.09445691108703613\n",
      "Epoch: 37, Batch: 39, D Loss Real: 0.14057528972625732, D Loss Fake: 1.1769665479660034, G Loss: [10.241591453552246, 0.7928245663642883, 0.09448766708374023]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 40, SSIM Loss: 0.09822458028793335\n",
      "Epoch: 37, Batch: 40, D Loss Real: 0.222581684589386, D Loss Fake: 0.9892604947090149, G Loss: [10.651086807250977, 0.795220673084259, 0.09855866432189941]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 41, SSIM Loss: 0.0925755500793457\n",
      "Epoch: 37, Batch: 41, D Loss Real: 0.2963216304779053, D Loss Fake: 1.1067652702331543, G Loss: [9.956206321716309, 0.7017871737480164, 0.09254419803619385]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 42, SSIM Loss: 0.09262979030609131\n",
      "Epoch: 37, Batch: 42, D Loss Real: 0.20833617448806763, D Loss Fake: 1.264405369758606, G Loss: [9.953721046447754, 0.7109838724136353, 0.09242737293243408]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 43, SSIM Loss: 0.09549486637115479\n",
      "Epoch: 37, Batch: 43, D Loss Real: 0.12879154086112976, D Loss Fake: 1.0857065916061401, G Loss: [10.348334312438965, 0.8171338438987732, 0.09531199932098389]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 44, SSIM Loss: 0.09243112802505493\n",
      "Epoch: 37, Batch: 44, D Loss Real: 0.27995654940605164, D Loss Fake: 1.0288103818893433, G Loss: [9.986822128295898, 0.7684513926506042, 0.09218370914459229]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 45, SSIM Loss: 0.10222786664962769\n",
      "Epoch: 37, Batch: 45, D Loss Real: 0.14668743312358856, D Loss Fake: 1.0298374891281128, G Loss: [10.96215534210205, 0.8061860799789429, 0.10155969858169556]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 46, SSIM Loss: 0.09419208765029907\n",
      "Epoch: 37, Batch: 46, D Loss Real: 0.2495388388633728, D Loss Fake: 1.1718472242355347, G Loss: [10.138050079345703, 0.7323834896087646, 0.09405666589736938]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 47, SSIM Loss: 0.1011505126953125\n",
      "Epoch: 37, Batch: 47, D Loss Real: 0.08523988723754883, D Loss Fake: 1.1759529113769531, G Loss: [10.8561372756958, 0.7579718828201294, 0.10098165273666382]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 48, SSIM Loss: 0.09584701061248779\n",
      "Epoch: 37, Batch: 48, D Loss Real: 0.10232806950807571, D Loss Fake: 0.9600772261619568, G Loss: [10.38119888305664, 0.8279209136962891, 0.09553277492523193]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 49, SSIM Loss: 0.09447973966598511\n",
      "Epoch: 37, Batch: 49, D Loss Real: 0.15808814764022827, D Loss Fake: 1.1251047849655151, G Loss: [10.237515449523926, 0.8010749816894531, 0.09436440467834473]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 50, SSIM Loss: 0.09428787231445312\n",
      "Epoch: 37, Batch: 50, D Loss Real: 0.16057288646697998, D Loss Fake: 0.8818992972373962, G Loss: [10.302528381347656, 0.8218848705291748, 0.09480643272399902]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 51, SSIM Loss: 0.0939948558807373\n",
      "Epoch: 37, Batch: 51, D Loss Real: 0.1153188943862915, D Loss Fake: 1.0126285552978516, G Loss: [10.268248558044434, 0.8349613547325134, 0.09433287382125854]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 37, Batch: 52, SSIM Loss: 0.1005704402923584\n",
      "Epoch: 37, Batch: 52, D Loss Real: 0.07143758982419968, D Loss Fake: 0.9796376824378967, G Loss: [10.838725090026855, 0.8088188767433167, 0.10029906034469604]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 53, SSIM Loss: 0.09398913383483887\n",
      "Epoch: 37, Batch: 53, D Loss Real: 0.1504611223936081, D Loss Fake: 1.1659176349639893, G Loss: [10.225564956665039, 0.8387690186500549, 0.0938679575920105]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 54, SSIM Loss: 0.09865820407867432\n",
      "Epoch: 37, Batch: 54, D Loss Real: 0.14967003464698792, D Loss Fake: 1.0755959749221802, G Loss: [10.676204681396484, 0.8335471153259277, 0.09842658042907715]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 55, SSIM Loss: 0.09433156251907349\n",
      "Epoch: 37, Batch: 55, D Loss Real: 0.22510863840579987, D Loss Fake: 0.9550737142562866, G Loss: [10.206544876098633, 0.8128476142883301, 0.0939369797706604]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 56, SSIM Loss: 0.09579282999038696\n",
      "Epoch: 37, Batch: 56, D Loss Real: 0.10223765671253204, D Loss Fake: 1.1023920774459839, G Loss: [10.343189239501953, 0.7451362013816833, 0.09598052501678467]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 57, SSIM Loss: 0.09825533628463745\n",
      "Epoch: 37, Batch: 57, D Loss Real: 0.0882686972618103, D Loss Fake: 1.048346996307373, G Loss: [10.620635986328125, 0.8151057362556458, 0.09805530309677124]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 58, SSIM Loss: 0.09464609622955322\n",
      "Epoch: 37, Batch: 58, D Loss Real: 0.1987098753452301, D Loss Fake: 1.1423532962799072, G Loss: [10.283370018005371, 0.8068033456802368, 0.09476566314697266]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 59, SSIM Loss: 0.09431213140487671\n",
      "Epoch: 37, Batch: 59, D Loss Real: 0.15946064889431, D Loss Fake: 0.9206784963607788, G Loss: [10.332476615905762, 0.8674256205558777, 0.0946505069732666]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 60, SSIM Loss: 0.09679532051086426\n",
      "Epoch: 37, Batch: 60, D Loss Real: 0.13286951184272766, D Loss Fake: 0.9926373958587646, G Loss: [10.47154426574707, 0.8389754295349121, 0.09632569551467896]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 61, SSIM Loss: 0.09334522485733032\n",
      "Epoch: 37, Batch: 61, D Loss Real: 0.1888752430677414, D Loss Fake: 1.0076972246170044, G Loss: [10.044756889343262, 0.7629786133766174, 0.09281778335571289]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 37, Batch: 62, SSIM Loss: 0.0972793698310852\n",
      "Epoch: 37, Batch: 62, D Loss Real: 0.09558817744255066, D Loss Fake: 0.9742456674575806, G Loss: [10.569999694824219, 0.7963873744010925, 0.09773612022399902]\n",
      "1/1 [==============================] - 0s 146ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:03:44.749319: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:03:46.222868: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Batch: 1, SSIM Loss: 0.09299486875534058\n",
      "Epoch: 38, Batch: 1, D Loss Real: 0.05111644044518471, D Loss Fake: 0.9959295392036438, G Loss: [10.114916801452637, 0.8210031986236572, 0.09293913841247559]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 2, SSIM Loss: 0.09574109315872192\n",
      "Epoch: 38, Batch: 2, D Loss Real: 0.12460900843143463, D Loss Fake: 0.9538639187812805, G Loss: [10.407238960266113, 0.8411228060722351, 0.09566116333007812]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 38, Batch: 3, SSIM Loss: 0.09614956378936768\n",
      "Epoch: 38, Batch: 3, D Loss Real: 0.07305780053138733, D Loss Fake: 1.0184921026229858, G Loss: [10.451228141784668, 0.8551481366157532, 0.09596079587936401]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 38, Batch: 4, SSIM Loss: 0.09660845994949341\n",
      "Epoch: 38, Batch: 4, D Loss Real: 0.11761301010847092, D Loss Fake: 0.9628809690475464, G Loss: [10.547528266906738, 0.8474798202514648, 0.09700047969818115]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 38, Batch: 5, SSIM Loss: 0.09391957521438599\n",
      "Epoch: 38, Batch: 5, D Loss Real: 0.10316700488328934, D Loss Fake: 1.0922791957855225, G Loss: [10.297518730163574, 0.900482714176178, 0.09397035837173462]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 38, Batch: 6, SSIM Loss: 0.09324765205383301\n",
      "Epoch: 38, Batch: 6, D Loss Real: 0.15564627945423126, D Loss Fake: 0.8494747877120972, G Loss: [10.236536026000977, 0.8789994716644287, 0.0935753583908081]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 38, Batch: 7, SSIM Loss: 0.09696811437606812\n",
      "Epoch: 38, Batch: 7, D Loss Real: 0.11021742224693298, D Loss Fake: 0.9881267547607422, G Loss: [10.49110221862793, 0.8037257194519043, 0.09687376022338867]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 8, SSIM Loss: 0.09596288204193115\n",
      "Epoch: 38, Batch: 8, D Loss Real: 0.12235657125711441, D Loss Fake: 1.109945297241211, G Loss: [10.509422302246094, 0.9402359127998352, 0.09569185972213745]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 9, SSIM Loss: 0.0975496768951416\n",
      "Epoch: 38, Batch: 9, D Loss Real: 0.14092989265918732, D Loss Fake: 1.0084384679794312, G Loss: [10.589494705200195, 0.8485455513000488, 0.09740948677062988]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 10, SSIM Loss: 0.0949711799621582\n",
      "Epoch: 38, Batch: 10, D Loss Real: 0.15929576754570007, D Loss Fake: 0.8957940340042114, G Loss: [10.37470817565918, 0.87601637840271, 0.0949869155883789]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 11, SSIM Loss: 0.09093356132507324\n",
      "Epoch: 38, Batch: 11, D Loss Real: 0.14327004551887512, D Loss Fake: 1.0097603797912598, G Loss: [9.939215660095215, 0.8222622275352478, 0.09116953611373901]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 12, SSIM Loss: 0.09529447555541992\n",
      "Epoch: 38, Batch: 12, D Loss Real: 0.12249480187892914, D Loss Fake: 1.1313879489898682, G Loss: [10.2938232421875, 0.7957041263580322, 0.09498119354248047]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 13, SSIM Loss: 0.09555685520172119\n",
      "Epoch: 38, Batch: 13, D Loss Real: 0.16825270652770996, D Loss Fake: 1.0511119365692139, G Loss: [10.245185852050781, 0.795285701751709, 0.09449899196624756]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 14, SSIM Loss: 0.10043942928314209\n",
      "Epoch: 38, Batch: 14, D Loss Real: 0.1201004609465599, D Loss Fake: 1.0503467321395874, G Loss: [10.876277923583984, 0.8418487906455994, 0.10034430027008057]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 38, Batch: 15, SSIM Loss: 0.09745246171951294\n",
      "Epoch: 38, Batch: 15, D Loss Real: 0.16841226816177368, D Loss Fake: 0.8438080549240112, G Loss: [10.710752487182617, 0.979973316192627, 0.09730780124664307]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 38, Batch: 16, SSIM Loss: 0.09847843647003174\n",
      "Epoch: 38, Batch: 16, D Loss Real: 0.1570471227169037, D Loss Fake: 0.9599350690841675, G Loss: [10.639680862426758, 0.8065119385719299, 0.09833168983459473]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 38, Batch: 17, SSIM Loss: 0.09475290775299072\n",
      "Epoch: 38, Batch: 17, D Loss Real: 0.08365972340106964, D Loss Fake: 1.0880532264709473, G Loss: [10.311357498168945, 0.8490906953811646, 0.0946226716041565]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 18, SSIM Loss: 0.09554088115692139\n",
      "Epoch: 38, Batch: 18, D Loss Real: 0.0816214308142662, D Loss Fake: 0.9064040184020996, G Loss: [10.432579040527344, 0.8994362354278564, 0.09533143043518066]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 19, SSIM Loss: 0.09676790237426758\n",
      "Epoch: 38, Batch: 19, D Loss Real: 0.07849377393722534, D Loss Fake: 0.9340764284133911, G Loss: [10.536967277526855, 0.9095720052719116, 0.09627395868301392]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 20, SSIM Loss: 0.09645110368728638\n",
      "Epoch: 38, Batch: 20, D Loss Real: 0.06357190012931824, D Loss Fake: 0.970480740070343, G Loss: [10.528776168823242, 0.8798696398735046, 0.0964890718460083]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 21, SSIM Loss: 0.09354913234710693\n",
      "Epoch: 38, Batch: 21, D Loss Real: 0.07344308495521545, D Loss Fake: 0.8642466068267822, G Loss: [10.229884147644043, 0.9211407899856567, 0.09308743476867676]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 22, SSIM Loss: 0.09239643812179565\n",
      "Epoch: 38, Batch: 22, D Loss Real: 0.0554400309920311, D Loss Fake: 0.9148145318031311, G Loss: [10.098101615905762, 0.8619267344474792, 0.09236174821853638]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 23, SSIM Loss: 0.09616720676422119\n",
      "Epoch: 38, Batch: 23, D Loss Real: 0.05389697477221489, D Loss Fake: 0.9665747880935669, G Loss: [10.50676441192627, 0.8728530406951904, 0.09633910655975342]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 38, Batch: 24, SSIM Loss: 0.0953671932220459\n",
      "Epoch: 38, Batch: 24, D Loss Real: 0.09741643071174622, D Loss Fake: 0.8608493804931641, G Loss: [10.381734848022461, 0.8829361796379089, 0.09498798847198486]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 25, SSIM Loss: 0.09557580947875977\n",
      "Epoch: 38, Batch: 25, D Loss Real: 0.049771424382925034, D Loss Fake: 1.019184947013855, G Loss: [10.512468338012695, 0.9330243468284607, 0.0957944393157959]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 26, SSIM Loss: 0.09477579593658447\n",
      "Epoch: 38, Batch: 26, D Loss Real: 0.08687601238489151, D Loss Fake: 0.9055060744285583, G Loss: [10.386110305786133, 0.9070163369178772, 0.09479093551635742]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 27, SSIM Loss: 0.09221863746643066\n",
      "Epoch: 38, Batch: 27, D Loss Real: 0.10034682601690292, D Loss Fake: 0.8753392696380615, G Loss: [10.111331939697266, 0.9158608913421631, 0.09195470809936523]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 28, SSIM Loss: 0.09738922119140625\n",
      "Epoch: 38, Batch: 28, D Loss Real: 0.12057627737522125, D Loss Fake: 0.9876376390457153, G Loss: [10.666813850402832, 0.8844038248062134, 0.0978240966796875]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 29, SSIM Loss: 0.09905993938446045\n",
      "Epoch: 38, Batch: 29, D Loss Real: 0.10070192813873291, D Loss Fake: 0.941434383392334, G Loss: [10.78306770324707, 0.8759536743164062, 0.09907114505767822]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 30, SSIM Loss: 0.0969698429107666\n",
      "Epoch: 38, Batch: 30, D Loss Real: 0.17106741666793823, D Loss Fake: 0.9128578901290894, G Loss: [10.511451721191406, 0.8566733598709106, 0.09654778242111206]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 31, SSIM Loss: 0.09428322315216064\n",
      "Epoch: 38, Batch: 31, D Loss Real: 0.05313241854310036, D Loss Fake: 1.354498267173767, G Loss: [10.340259552001953, 0.9028776288032532, 0.09437382221221924]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 32, SSIM Loss: 0.09530550241470337\n",
      "Epoch: 38, Batch: 32, D Loss Real: 0.18199920654296875, D Loss Fake: 0.8556619882583618, G Loss: [10.471820831298828, 0.9425585269927979, 0.09529262781143188]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 33, SSIM Loss: 0.09450185298919678\n",
      "Epoch: 38, Batch: 33, D Loss Real: 0.36577409505844116, D Loss Fake: 0.9352504014968872, G Loss: [10.292983055114746, 0.8464463353157043, 0.09446537494659424]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 34, SSIM Loss: 0.09462082386016846\n",
      "Epoch: 38, Batch: 34, D Loss Real: 0.17059756815433502, D Loss Fake: 1.0400620698928833, G Loss: [10.21864128112793, 0.7818197011947632, 0.09436821937561035]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 35, SSIM Loss: 0.09652972221374512\n",
      "Epoch: 38, Batch: 35, D Loss Real: 0.25708502531051636, D Loss Fake: 1.2371975183486938, G Loss: [10.356550216674805, 0.7028680443763733, 0.09653681516647339]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 36, SSIM Loss: 0.09533333778381348\n",
      "Epoch: 38, Batch: 36, D Loss Real: 0.12190014868974686, D Loss Fake: 1.2469720840454102, G Loss: [10.251520156860352, 0.7095140218734741, 0.09542006254196167]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 37, SSIM Loss: 0.09408289194107056\n",
      "Epoch: 38, Batch: 37, D Loss Real: 0.14472384750843048, D Loss Fake: 1.1321301460266113, G Loss: [10.205862045288086, 0.7882329821586609, 0.0941762924194336]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 38, SSIM Loss: 0.09619718790054321\n",
      "Epoch: 38, Batch: 38, D Loss Real: 0.10680839419364929, D Loss Fake: 0.9903011322021484, G Loss: [10.440176963806152, 0.8424575924873352, 0.09597718715667725]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 39, SSIM Loss: 0.09375184774398804\n",
      "Epoch: 38, Batch: 39, D Loss Real: 0.14865516126155853, D Loss Fake: 1.0510809421539307, G Loss: [10.207483291625977, 0.8337231874465942, 0.09373760223388672]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 40, SSIM Loss: 0.09794461727142334\n",
      "Epoch: 38, Batch: 40, D Loss Real: 0.1601203829050064, D Loss Fake: 1.0622721910476685, G Loss: [10.6452054977417, 0.8481860756874084, 0.09797018766403198]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 41, SSIM Loss: 0.09259182214736938\n",
      "Epoch: 38, Batch: 41, D Loss Real: 0.24570593237876892, D Loss Fake: 1.0304107666015625, G Loss: [10.0460205078125, 0.7828271389007568, 0.09263193607330322]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 38, Batch: 42, SSIM Loss: 0.09219181537628174\n",
      "Epoch: 38, Batch: 42, D Loss Real: 0.25541067123413086, D Loss Fake: 1.2509359121322632, G Loss: [9.926725387573242, 0.6864266395568848, 0.09240299463272095]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 38, Batch: 43, SSIM Loss: 0.09495925903320312\n",
      "Epoch: 38, Batch: 43, D Loss Real: 0.11452514678239822, D Loss Fake: 1.1486575603485107, G Loss: [10.271162033081055, 0.7869666218757629, 0.09484195709228516]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 44, SSIM Loss: 0.09249931573867798\n",
      "Epoch: 38, Batch: 44, D Loss Real: 0.2296576201915741, D Loss Fake: 0.9603925943374634, G Loss: [10.01595687866211, 0.79044508934021, 0.0922551155090332]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 45, SSIM Loss: 0.1009676456451416\n",
      "Epoch: 38, Batch: 45, D Loss Real: 0.13239161670207977, D Loss Fake: 1.062687873840332, G Loss: [10.86423110961914, 0.7811577916145325, 0.10083073377609253]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 46, SSIM Loss: 0.09414267539978027\n",
      "Epoch: 38, Batch: 46, D Loss Real: 0.2363705188035965, D Loss Fake: 1.079654574394226, G Loss: [10.235406875610352, 0.7825988531112671, 0.09452807903289795]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 47, SSIM Loss: 0.10052013397216797\n",
      "Epoch: 38, Batch: 47, D Loss Real: 0.0914381593465805, D Loss Fake: 1.0208638906478882, G Loss: [10.89993667602539, 0.812673807144165, 0.10087263584136963]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 48, SSIM Loss: 0.09593755006790161\n",
      "Epoch: 38, Batch: 48, D Loss Real: 0.09399326890707016, D Loss Fake: 0.9162204265594482, G Loss: [10.459242820739746, 0.8321754932403564, 0.09627068042755127]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 38, Batch: 49, SSIM Loss: 0.0931132435798645\n",
      "Epoch: 38, Batch: 49, D Loss Real: 0.14063142240047455, D Loss Fake: 1.1024901866912842, G Loss: [10.142548561096191, 0.8323211669921875, 0.09310227632522583]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 50, SSIM Loss: 0.09359085559844971\n",
      "Epoch: 38, Batch: 50, D Loss Real: 0.17963707447052002, D Loss Fake: 0.9185206890106201, G Loss: [10.217463493347168, 0.8761756420135498, 0.09341287612915039]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 51, SSIM Loss: 0.09327453374862671\n",
      "Epoch: 38, Batch: 51, D Loss Real: 0.20245955884456635, D Loss Fake: 0.9810757040977478, G Loss: [10.136804580688477, 0.8127065896987915, 0.09324097633361816]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 52, SSIM Loss: 0.09915703535079956\n",
      "Epoch: 38, Batch: 52, D Loss Real: 0.05676976963877678, D Loss Fake: 0.9876118302345276, G Loss: [10.772473335266113, 0.8394008278846741, 0.09933072328567505]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 53, SSIM Loss: 0.09300172328948975\n",
      "Epoch: 38, Batch: 53, D Loss Real: 0.1289314478635788, D Loss Fake: 0.9364311099052429, G Loss: [10.150370597839355, 0.8440824747085571, 0.0930628776550293]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 54, SSIM Loss: 0.0971841812133789\n",
      "Epoch: 38, Batch: 54, D Loss Real: 0.11607623845338821, D Loss Fake: 0.9917277097702026, G Loss: [10.558345794677734, 0.8361972570419312, 0.0972214937210083]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 55, SSIM Loss: 0.09469056129455566\n",
      "Epoch: 38, Batch: 55, D Loss Real: 0.20778611302375793, D Loss Fake: 1.020632266998291, G Loss: [10.238045692443848, 0.8122682571411133, 0.09425777196884155]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 56, SSIM Loss: 0.09539556503295898\n",
      "Epoch: 38, Batch: 56, D Loss Real: 0.11542180925607681, D Loss Fake: 1.064166784286499, G Loss: [10.30148983001709, 0.7819608449935913, 0.09519529342651367]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 57, SSIM Loss: 0.09742677211761475\n",
      "Epoch: 38, Batch: 57, D Loss Real: 0.07974572479724884, D Loss Fake: 1.025678038597107, G Loss: [10.587750434875488, 0.8256779909133911, 0.09762072563171387]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 38, Batch: 58, SSIM Loss: 0.0947641134262085\n",
      "Epoch: 38, Batch: 58, D Loss Real: 0.19219867885112762, D Loss Fake: 1.0599350929260254, G Loss: [10.246731758117676, 0.7924333810806274, 0.0945429801940918]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 59, SSIM Loss: 0.09352850914001465\n",
      "Epoch: 38, Batch: 59, D Loss Real: 0.09633459150791168, D Loss Fake: 1.1617110967636108, G Loss: [10.301168441772461, 0.9368376731872559, 0.09364330768585205]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 60, SSIM Loss: 0.09577304124832153\n",
      "Epoch: 38, Batch: 60, D Loss Real: 0.2424965351819992, D Loss Fake: 0.9032878279685974, G Loss: [10.45053482055664, 0.8508010506629944, 0.09599733352661133]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 61, SSIM Loss: 0.09228527545928955\n",
      "Epoch: 38, Batch: 61, D Loss Real: 0.2778279483318329, D Loss Fake: 0.9607872366905212, G Loss: [10.056612014770508, 0.8243348598480225, 0.09232276678085327]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 38, Batch: 62, SSIM Loss: 0.09741151332855225\n",
      "Epoch: 38, Batch: 62, D Loss Real: 0.1641039252281189, D Loss Fake: 1.260790228843689, G Loss: [10.482028007507324, 0.7796738743782043, 0.09702354669570923]\n",
      "1/1 [==============================] - 0s 144ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:05:08.055440: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:05:09.537560: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Batch: 1, SSIM Loss: 0.09291732311248779\n",
      "Epoch: 39, Batch: 1, D Loss Real: 0.24455179274082184, D Loss Fake: 0.9953739643096924, G Loss: [10.0931978225708, 0.7991942167282104, 0.09294003248214722]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 2, SSIM Loss: 0.0937880277633667\n",
      "Epoch: 39, Batch: 2, D Loss Real: 0.286274254322052, D Loss Fake: 1.0173094272613525, G Loss: [10.172420501708984, 0.7774774432182312, 0.09394943714141846]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 39, Batch: 3, SSIM Loss: 0.095691978931427\n",
      "Epoch: 39, Batch: 3, D Loss Real: 0.13603626191616058, D Loss Fake: 1.073905110359192, G Loss: [10.314950942993164, 0.7681288719177246, 0.09546822309494019]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 4, SSIM Loss: 0.09637492895126343\n",
      "Epoch: 39, Batch: 4, D Loss Real: 0.15779316425323486, D Loss Fake: 1.0163774490356445, G Loss: [10.4666166305542, 0.8281700611114502, 0.09638446569442749]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 5, SSIM Loss: 0.09379351139068604\n",
      "Epoch: 39, Batch: 5, D Loss Real: 0.12526735663414001, D Loss Fake: 1.0492868423461914, G Loss: [10.196542739868164, 0.8148375749588013, 0.09381705522537231]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 6, SSIM Loss: 0.09198629856109619\n",
      "Epoch: 39, Batch: 6, D Loss Real: 0.11899327486753464, D Loss Fake: 0.9434022903442383, G Loss: [10.077921867370605, 0.8673471212387085, 0.09210574626922607]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 7, SSIM Loss: 0.09733104705810547\n",
      "Epoch: 39, Batch: 7, D Loss Real: 0.07898988574743271, D Loss Fake: 0.9984301924705505, G Loss: [10.535345077514648, 0.8222559094429016, 0.09713089466094971]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 8, SSIM Loss: 0.09541916847229004\n",
      "Epoch: 39, Batch: 8, D Loss Real: 0.1537204086780548, D Loss Fake: 0.9388503432273865, G Loss: [10.432172775268555, 0.8677139282226562, 0.09564459323883057]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 9, SSIM Loss: 0.09711909294128418\n",
      "Epoch: 39, Batch: 9, D Loss Real: 0.10061122477054596, D Loss Fake: 0.9392660856246948, G Loss: [10.535212516784668, 0.8292160630226135, 0.09705996513366699]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 10, SSIM Loss: 0.09447455406188965\n",
      "Epoch: 39, Batch: 10, D Loss Real: 0.074791818857193, D Loss Fake: 0.9237040877342224, G Loss: [10.314791679382324, 0.8794599175453186, 0.0943533182144165]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 11, SSIM Loss: 0.09081661701202393\n",
      "Epoch: 39, Batch: 11, D Loss Real: 0.10228168219327927, D Loss Fake: 0.9579282402992249, G Loss: [9.917405128479004, 0.8458585143089294, 0.09071546792984009]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 12, SSIM Loss: 0.09335446357727051\n",
      "Epoch: 39, Batch: 12, D Loss Real: 0.07408808171749115, D Loss Fake: 0.90245121717453, G Loss: [10.19811725616455, 0.8705390095710754, 0.09327578544616699]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 13, SSIM Loss: 0.09412944316864014\n",
      "Epoch: 39, Batch: 13, D Loss Real: 0.05424921214580536, D Loss Fake: 0.9379587173461914, G Loss: [10.263625144958496, 0.8380919694900513, 0.09425532817840576]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 14, SSIM Loss: 0.09790974855422974\n",
      "Epoch: 39, Batch: 14, D Loss Real: 0.07822512090206146, D Loss Fake: 0.8951154947280884, G Loss: [10.684805870056152, 0.8881334066390991, 0.09796673059463501]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 15, SSIM Loss: 0.09614861011505127\n",
      "Epoch: 39, Batch: 15, D Loss Real: 0.08337558805942535, D Loss Fake: 0.8973684310913086, G Loss: [10.48727798461914, 0.8799809217453003, 0.0960729718208313]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 16, SSIM Loss: 0.0973062515258789\n",
      "Epoch: 39, Batch: 16, D Loss Real: 0.06384193897247314, D Loss Fake: 0.9736611843109131, G Loss: [10.589926719665527, 0.8649517297744751, 0.09724974632263184]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 17, SSIM Loss: 0.09339118003845215\n",
      "Epoch: 39, Batch: 17, D Loss Real: 0.08076729625463486, D Loss Fake: 0.9398481845855713, G Loss: [10.208044052124023, 0.8856207728385925, 0.09322422742843628]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 18, SSIM Loss: 0.09428989887237549\n",
      "Epoch: 39, Batch: 18, D Loss Real: 0.09121805429458618, D Loss Fake: 0.9669407606124878, G Loss: [10.25515079498291, 0.8798765540122986, 0.09375274181365967]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 19, SSIM Loss: 0.09521162509918213\n",
      "Epoch: 39, Batch: 19, D Loss Real: 0.10708806663751602, D Loss Fake: 0.9460862278938293, G Loss: [10.417759895324707, 0.8962991833686829, 0.0952146053314209]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 39, Batch: 20, SSIM Loss: 0.09590888023376465\n",
      "Epoch: 39, Batch: 20, D Loss Real: 0.07625852525234222, D Loss Fake: 1.0795042514801025, G Loss: [10.465462684631348, 0.9066899418830872, 0.09558773040771484]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 21, SSIM Loss: 0.09215569496154785\n",
      "Epoch: 39, Batch: 21, D Loss Real: 0.306684285402298, D Loss Fake: 0.9075585603713989, G Loss: [10.079437255859375, 0.8712166547775269, 0.0920822024345398]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 39, Batch: 22, SSIM Loss: 0.09191775321960449\n",
      "Epoch: 39, Batch: 22, D Loss Real: 0.1356675624847412, D Loss Fake: 1.1221511363983154, G Loss: [9.980466842651367, 0.803401529788971, 0.09177064895629883]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 23, SSIM Loss: 0.09561121463775635\n",
      "Epoch: 39, Batch: 23, D Loss Real: 0.15295493602752686, D Loss Fake: 0.9483597874641418, G Loss: [10.382612228393555, 0.8263546824455261, 0.09556257724761963]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 24, SSIM Loss: 0.09459757804870605\n",
      "Epoch: 39, Batch: 24, D Loss Real: 0.12076635658740997, D Loss Fake: 1.4937069416046143, G Loss: [10.330791473388672, 0.8630224466323853, 0.09467768669128418]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 25, SSIM Loss: 0.09465324878692627\n",
      "Epoch: 39, Batch: 25, D Loss Real: 0.3226880729198456, D Loss Fake: 0.917850911617279, G Loss: [10.296192169189453, 0.839820384979248, 0.09456372261047363]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 26, SSIM Loss: 0.09402841329574585\n",
      "Epoch: 39, Batch: 26, D Loss Real: 0.3161119520664215, D Loss Fake: 1.006367802619934, G Loss: [10.155147552490234, 0.7654492855072021, 0.09389698505401611]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 27, SSIM Loss: 0.09147775173187256\n",
      "Epoch: 39, Batch: 27, D Loss Real: 0.22066578269004822, D Loss Fake: 1.050987720489502, G Loss: [9.888069152832031, 0.7640108466148376, 0.09124058485031128]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 28, SSIM Loss: 0.09759843349456787\n",
      "Epoch: 39, Batch: 28, D Loss Real: 0.20280209183692932, D Loss Fake: 1.1375229358673096, G Loss: [10.497910499572754, 0.7572129964828491, 0.09740698337554932]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 29, SSIM Loss: 0.09734022617340088\n",
      "Epoch: 39, Batch: 29, D Loss Real: 0.13419634103775024, D Loss Fake: 1.0600404739379883, G Loss: [10.507291793823242, 0.7811191082000732, 0.09726172685623169]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 30, SSIM Loss: 0.09710371494293213\n",
      "Epoch: 39, Batch: 30, D Loss Real: 0.20190663635730743, D Loss Fake: 0.9623543620109558, G Loss: [10.483296394348145, 0.8073223829269409, 0.09675973653793335]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 31, SSIM Loss: 0.09352356195449829\n",
      "Epoch: 39, Batch: 31, D Loss Real: 0.09306071698665619, D Loss Fake: 0.9527496695518494, G Loss: [10.225003242492676, 0.8601480722427368, 0.09364855289459229]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 32, SSIM Loss: 0.0951915979385376\n",
      "Epoch: 39, Batch: 32, D Loss Real: 0.07148797810077667, D Loss Fake: 0.9435204863548279, G Loss: [10.380489349365234, 0.8403552174568176, 0.0954013466835022]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 33, SSIM Loss: 0.0951886773109436\n",
      "Epoch: 39, Batch: 33, D Loss Real: 0.0968538224697113, D Loss Fake: 0.8734707236289978, G Loss: [10.44453239440918, 0.8956409692764282, 0.09548890590667725]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 39, Batch: 34, SSIM Loss: 0.09440386295318604\n",
      "Epoch: 39, Batch: 34, D Loss Real: 0.05821327120065689, D Loss Fake: 0.9205401539802551, G Loss: [10.285704612731934, 0.863003134727478, 0.09422701597213745]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 35, SSIM Loss: 0.09644454717636108\n",
      "Epoch: 39, Batch: 35, D Loss Real: 0.19781702756881714, D Loss Fake: 0.9514685273170471, G Loss: [10.477071762084961, 0.8493598103523254, 0.09627711772918701]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 36, SSIM Loss: 0.09466981887817383\n",
      "Epoch: 39, Batch: 36, D Loss Real: 0.09625989943742752, D Loss Fake: 0.9871379137039185, G Loss: [10.22264289855957, 0.7963169813156128, 0.09426325559616089]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 37, SSIM Loss: 0.09396839141845703\n",
      "Epoch: 39, Batch: 37, D Loss Real: 0.15241995453834534, D Loss Fake: 0.9944921731948853, G Loss: [10.214877128601074, 0.7761719822883606, 0.09438705444335938]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 38, SSIM Loss: 0.09562122821807861\n",
      "Epoch: 39, Batch: 38, D Loss Real: 0.040125638246536255, D Loss Fake: 1.00897216796875, G Loss: [10.415943145751953, 0.8602930307388306, 0.09555649757385254]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 39, Batch: 39, SSIM Loss: 0.09348750114440918\n",
      "Epoch: 39, Batch: 39, D Loss Real: 0.09269842505455017, D Loss Fake: 0.912208080291748, G Loss: [10.260043144226074, 0.8865808844566345, 0.09373462200164795]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 40, SSIM Loss: 0.09764641523361206\n",
      "Epoch: 39, Batch: 40, D Loss Real: 0.1547086089849472, D Loss Fake: 0.9198439121246338, G Loss: [10.61672306060791, 0.848547101020813, 0.09768176078796387]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 41, SSIM Loss: 0.0924222469329834\n",
      "Epoch: 39, Batch: 41, D Loss Real: 0.12210610508918762, D Loss Fake: 0.9790108799934387, G Loss: [10.083255767822266, 0.8254919052124023, 0.09257763624191284]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 42, SSIM Loss: 0.0917813777923584\n",
      "Epoch: 39, Batch: 42, D Loss Real: 0.1847626119852066, D Loss Fake: 1.0843958854675293, G Loss: [9.968056678771973, 0.7566835284233093, 0.09211373329162598]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 43, SSIM Loss: 0.09447211027145386\n",
      "Epoch: 39, Batch: 43, D Loss Real: 0.059237584471702576, D Loss Fake: 1.001367211341858, G Loss: [10.283985137939453, 0.8617193698883057, 0.09422266483306885]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 44, SSIM Loss: 0.09152889251708984\n",
      "Epoch: 39, Batch: 44, D Loss Real: 0.15267881751060486, D Loss Fake: 0.9274903535842896, G Loss: [10.000673294067383, 0.855961799621582, 0.09144711494445801]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 45, SSIM Loss: 0.1009795069694519\n",
      "Epoch: 39, Batch: 45, D Loss Real: 0.06625007838010788, D Loss Fake: 0.9613956809043884, G Loss: [10.966034889221191, 0.876083254814148, 0.10089951753616333]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 46, SSIM Loss: 0.09393513202667236\n",
      "Epoch: 39, Batch: 46, D Loss Real: 0.23956704139709473, D Loss Fake: 0.9528703689575195, G Loss: [10.212396621704102, 0.8272220492362976, 0.09385174512863159]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 39, Batch: 47, SSIM Loss: 0.10089844465255737\n",
      "Epoch: 39, Batch: 47, D Loss Real: 0.050111185759305954, D Loss Fake: 0.9805779457092285, G Loss: [10.922816276550293, 0.8242576122283936, 0.100985586643219]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 48, SSIM Loss: 0.09603965282440186\n",
      "Epoch: 39, Batch: 48, D Loss Real: 0.04744897410273552, D Loss Fake: 0.8755025863647461, G Loss: [10.491168975830078, 0.8831746578216553, 0.09607994556427002]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 39, Batch: 49, SSIM Loss: 0.09329569339752197\n",
      "Epoch: 39, Batch: 49, D Loss Real: 0.10205485671758652, D Loss Fake: 1.0346649885177612, G Loss: [10.246106147766113, 0.8929398059844971, 0.09353166818618774]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 50, SSIM Loss: 0.0936044454574585\n",
      "Epoch: 39, Batch: 50, D Loss Real: 0.2200668454170227, D Loss Fake: 0.9013954401016235, G Loss: [10.255661964416504, 0.8745349049568176, 0.0938112735748291]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 51, SSIM Loss: 0.0922386646270752\n",
      "Epoch: 39, Batch: 51, D Loss Real: 0.15219856798648834, D Loss Fake: 0.9643702507019043, G Loss: [10.201827049255371, 0.9076989889144897, 0.0929412841796875]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 52, SSIM Loss: 0.09853935241699219\n",
      "Epoch: 39, Batch: 52, D Loss Real: 0.10064293444156647, D Loss Fake: 0.9576704502105713, G Loss: [10.759486198425293, 0.9238853454589844, 0.09835600852966309]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 53, SSIM Loss: 0.09227043390274048\n",
      "Epoch: 39, Batch: 53, D Loss Real: 0.25314435362815857, D Loss Fake: 0.9738968014717102, G Loss: [10.03036117553711, 0.7962188720703125, 0.09234142303466797]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 54, SSIM Loss: 0.09704470634460449\n",
      "Epoch: 39, Batch: 54, D Loss Real: 0.17170986533164978, D Loss Fake: 0.9929584264755249, G Loss: [10.473186492919922, 0.7830814123153687, 0.0969010591506958]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 55, SSIM Loss: 0.09370028972625732\n",
      "Epoch: 39, Batch: 55, D Loss Real: 0.13683654367923737, D Loss Fake: 1.2332024574279785, G Loss: [10.156294822692871, 0.8318035006523132, 0.09324491024017334]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 56, SSIM Loss: 0.09465068578720093\n",
      "Epoch: 39, Batch: 56, D Loss Real: 0.222875714302063, D Loss Fake: 0.9621633887290955, G Loss: [10.30404281616211, 0.8001118898391724, 0.09503930807113647]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 57, SSIM Loss: 0.09623289108276367\n",
      "Epoch: 39, Batch: 57, D Loss Real: 0.1493901163339615, D Loss Fake: 0.9822648167610168, G Loss: [10.477038383483887, 0.7942816019058228, 0.09682756662368774]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 58, SSIM Loss: 0.09427785873413086\n",
      "Epoch: 39, Batch: 58, D Loss Real: 0.18588517606258392, D Loss Fake: 1.2071144580841064, G Loss: [10.210119247436523, 0.769894003868103, 0.0944022536277771]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 59, SSIM Loss: 0.09281301498413086\n",
      "Epoch: 39, Batch: 59, D Loss Real: 0.22672875225543976, D Loss Fake: 0.9710392951965332, G Loss: [10.109964370727539, 0.8255753517150879, 0.09284389019012451]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 60, SSIM Loss: 0.09557443857192993\n",
      "Epoch: 39, Batch: 60, D Loss Real: 0.10077559947967529, D Loss Fake: 1.0347709655761719, G Loss: [10.346813201904297, 0.8150048851966858, 0.09531807899475098]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 61, SSIM Loss: 0.09381961822509766\n",
      "Epoch: 39, Batch: 61, D Loss Real: 0.13678185641765594, D Loss Fake: 0.9630183577537537, G Loss: [10.151193618774414, 0.8236628770828247, 0.09327530860900879]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 39, Batch: 62, SSIM Loss: 0.09799420833587646\n",
      "Epoch: 39, Batch: 62, D Loss Real: 0.09621940553188324, D Loss Fake: 0.9387513399124146, G Loss: [10.675447463989258, 0.8572692275047302, 0.09818178415298462]\n",
      "1/1 [==============================] - 0s 144ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:06:31.312402: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:06:32.781195: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Batch: 1, SSIM Loss: 0.09327161312103271\n",
      "Epoch: 40, Batch: 1, D Loss Real: 0.08848854154348373, D Loss Fake: 0.9388096332550049, G Loss: [10.165359497070312, 0.8231955766677856, 0.09342163801193237]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 2, SSIM Loss: 0.09548735618591309\n",
      "Epoch: 40, Batch: 2, D Loss Real: 0.09649498760700226, D Loss Fake: 0.8971306681632996, G Loss: [10.472649574279785, 0.8935098648071289, 0.09579139947891235]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 40, Batch: 3, SSIM Loss: 0.09485459327697754\n",
      "Epoch: 40, Batch: 3, D Loss Real: 0.04368314519524574, D Loss Fake: 0.9707420468330383, G Loss: [10.400434494018555, 0.9119236469268799, 0.09488511085510254]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 4, SSIM Loss: 0.09489107131958008\n",
      "Epoch: 40, Batch: 4, D Loss Real: 0.1042904183268547, D Loss Fake: 0.9311912655830383, G Loss: [10.37964153289795, 0.8875123262405396, 0.0949212908744812]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 5, SSIM Loss: 0.09365242719650269\n",
      "Epoch: 40, Batch: 5, D Loss Real: 0.09446863830089569, D Loss Fake: 0.902625560760498, G Loss: [10.239248275756836, 0.8657152652740479, 0.09373533725738525]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 40, Batch: 6, SSIM Loss: 0.09232604503631592\n",
      "Epoch: 40, Batch: 6, D Loss Real: 0.040003255009651184, D Loss Fake: 0.9475184082984924, G Loss: [10.097434043884277, 0.8849693536758423, 0.09212464094161987]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 40, Batch: 7, SSIM Loss: 0.09700942039489746\n",
      "Epoch: 40, Batch: 7, D Loss Real: 0.0721537321805954, D Loss Fake: 0.818272590637207, G Loss: [10.631548881530762, 0.9324315190315247, 0.09699118137359619]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 8, SSIM Loss: 0.09677338600158691\n",
      "Epoch: 40, Batch: 8, D Loss Real: 0.15109078586101532, D Loss Fake: 0.9212340116500854, G Loss: [10.549057006835938, 0.880396842956543, 0.09668660163879395]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 9, SSIM Loss: 0.09710872173309326\n",
      "Epoch: 40, Batch: 9, D Loss Real: 0.093464694917202, D Loss Fake: 0.9177067875862122, G Loss: [10.58314037322998, 0.8713086843490601, 0.0971183180809021]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 10, SSIM Loss: 0.09377962350845337\n",
      "Epoch: 40, Batch: 10, D Loss Real: 0.05983751267194748, D Loss Fake: 0.9144498705863953, G Loss: [10.29133129119873, 0.9026698470115662, 0.0938866138458252]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 11, SSIM Loss: 0.09130793809890747\n",
      "Epoch: 40, Batch: 11, D Loss Real: 0.07548686116933823, D Loss Fake: 0.9920417666435242, G Loss: [10.003366470336914, 0.8781152367591858, 0.09125250577926636]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 12, SSIM Loss: 0.09380203485488892\n",
      "Epoch: 40, Batch: 12, D Loss Real: 0.05682167038321495, D Loss Fake: 0.935316801071167, G Loss: [10.321166038513184, 0.9304416179656982, 0.09390723705291748]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 13, SSIM Loss: 0.09468609094619751\n",
      "Epoch: 40, Batch: 13, D Loss Real: 0.06887385249137878, D Loss Fake: 0.9087064266204834, G Loss: [10.417638778686523, 0.9111632704734802, 0.09506475925445557]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 14, SSIM Loss: 0.09762400388717651\n",
      "Epoch: 40, Batch: 14, D Loss Real: 0.08415758609771729, D Loss Fake: 0.8252077102661133, G Loss: [10.664289474487305, 0.9280257225036621, 0.09736263751983643]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 15, SSIM Loss: 0.09650158882141113\n",
      "Epoch: 40, Batch: 15, D Loss Real: 0.058490704745054245, D Loss Fake: 1.036432147026062, G Loss: [10.571229934692383, 0.891059398651123, 0.09680169820785522]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 16, SSIM Loss: 0.09621483087539673\n",
      "Epoch: 40, Batch: 16, D Loss Real: 0.1304236799478531, D Loss Fake: 0.8893295526504517, G Loss: [10.525270462036133, 0.8968551158905029, 0.09628415107727051]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 17, SSIM Loss: 0.09330272674560547\n",
      "Epoch: 40, Batch: 17, D Loss Real: 0.11642962694168091, D Loss Fake: 1.0164923667907715, G Loss: [10.173237800598145, 0.8503322601318359, 0.09322905540466309]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 18, SSIM Loss: 0.09406125545501709\n",
      "Epoch: 40, Batch: 18, D Loss Real: 0.10158713907003403, D Loss Fake: 0.976474404335022, G Loss: [10.280677795410156, 0.9087767601013184, 0.0937190055847168]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 19, SSIM Loss: 0.09531199932098389\n",
      "Epoch: 40, Batch: 19, D Loss Real: 0.11747954785823822, D Loss Fake: 0.9853036403656006, G Loss: [10.409624099731445, 0.8980343341827393, 0.09511590003967285]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 20, SSIM Loss: 0.0951661467552185\n",
      "Epoch: 40, Batch: 20, D Loss Real: 0.10341677069664001, D Loss Fake: 0.918549120426178, G Loss: [10.398633003234863, 0.8661447167396545, 0.09532487392425537]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 21, SSIM Loss: 0.09195798635482788\n",
      "Epoch: 40, Batch: 21, D Loss Real: 0.12017457187175751, D Loss Fake: 0.9047155380249023, G Loss: [10.086830139160156, 0.8523544073104858, 0.09234476089477539]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 22, SSIM Loss: 0.09123271703720093\n",
      "Epoch: 40, Batch: 22, D Loss Real: 0.03706267476081848, D Loss Fake: 1.032036304473877, G Loss: [10.015886306762695, 0.8977111577987671, 0.09118175506591797]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 40, Batch: 23, SSIM Loss: 0.09479355812072754\n",
      "Epoch: 40, Batch: 23, D Loss Real: 0.12515713274478912, D Loss Fake: 0.8480508327484131, G Loss: [10.387483596801758, 0.9058268070220947, 0.09481656551361084]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 24, SSIM Loss: 0.09486925601959229\n",
      "Epoch: 40, Batch: 24, D Loss Real: 0.23735307157039642, D Loss Fake: 0.9642775058746338, G Loss: [10.240703582763672, 0.7847549915313721, 0.09455949068069458]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 25, SSIM Loss: 0.0943794846534729\n",
      "Epoch: 40, Batch: 25, D Loss Real: 0.05243947356939316, D Loss Fake: 0.9894384741783142, G Loss: [10.318770408630371, 0.8463525176048279, 0.09472417831420898]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 26, SSIM Loss: 0.0932653546333313\n",
      "Epoch: 40, Batch: 26, D Loss Real: 0.040246978402137756, D Loss Fake: 0.8679413795471191, G Loss: [10.245935440063477, 0.9129748344421387, 0.09332960844039917]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 27, SSIM Loss: 0.09085643291473389\n",
      "Epoch: 40, Batch: 27, D Loss Real: 0.06296220421791077, D Loss Fake: 0.8437904715538025, G Loss: [10.013097763061523, 0.9302085638046265, 0.09082889556884766]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 28, SSIM Loss: 0.09655106067657471\n",
      "Epoch: 40, Batch: 28, D Loss Real: 0.09547093510627747, D Loss Fake: 0.8486813902854919, G Loss: [10.593841552734375, 0.9191606044769287, 0.09674680233001709]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 29, SSIM Loss: 0.09788477420806885\n",
      "Epoch: 40, Batch: 29, D Loss Real: 0.03673119470477104, D Loss Fake: 1.2138067483901978, G Loss: [10.684975624084473, 0.9462860822677612, 0.09738689661026001]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 30, SSIM Loss: 0.09612089395523071\n",
      "Epoch: 40, Batch: 30, D Loss Real: 0.27386602759361267, D Loss Fake: 0.9683154821395874, G Loss: [10.50765323638916, 0.873349130153656, 0.0963430404663086]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 31, SSIM Loss: 0.09322118759155273\n",
      "Epoch: 40, Batch: 31, D Loss Real: 0.3046209514141083, D Loss Fake: 0.934959352016449, G Loss: [10.169811248779297, 0.8322668075561523, 0.09337544441223145]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 40, Batch: 32, SSIM Loss: 0.09480220079421997\n",
      "Epoch: 40, Batch: 32, D Loss Real: 0.11009509116411209, D Loss Fake: 1.0054785013198853, G Loss: [10.283373832702637, 0.8237940669059753, 0.09459578990936279]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 33, SSIM Loss: 0.0938190221786499\n",
      "Epoch: 40, Batch: 33, D Loss Real: 0.09793853014707565, D Loss Fake: 0.9414922595024109, G Loss: [10.28355884552002, 0.8860814571380615, 0.093974769115448]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 34, SSIM Loss: 0.0941239595413208\n",
      "Epoch: 40, Batch: 34, D Loss Real: 0.050057120621204376, D Loss Fake: 0.9697661399841309, G Loss: [10.3214693069458, 0.915546715259552, 0.09405922889709473]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 40, Batch: 35, SSIM Loss: 0.09401977062225342\n",
      "Epoch: 40, Batch: 35, D Loss Real: 0.24859149754047394, D Loss Fake: 0.9419562816619873, G Loss: [10.278765678405762, 0.8361142873764038, 0.09442651271820068]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 36, SSIM Loss: 0.09474676847457886\n",
      "Epoch: 40, Batch: 36, D Loss Real: 0.05364507436752319, D Loss Fake: 1.035078763961792, G Loss: [10.300104141235352, 0.8177200555801392, 0.09482383728027344]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 37, SSIM Loss: 0.09447342157363892\n",
      "Epoch: 40, Batch: 37, D Loss Real: 0.10313437134027481, D Loss Fake: 0.9706451892852783, G Loss: [10.239574432373047, 0.8236137628555298, 0.09415960311889648]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 38, SSIM Loss: 0.09586846828460693\n",
      "Epoch: 40, Batch: 38, D Loss Real: 0.025259923189878464, D Loss Fake: 1.0496504306793213, G Loss: [10.459553718566895, 0.8908809423446655, 0.09568673372268677]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 39, SSIM Loss: 0.0934140682220459\n",
      "Epoch: 40, Batch: 39, D Loss Real: 0.1076321005821228, D Loss Fake: 0.8577975034713745, G Loss: [10.248726844787598, 0.9092218279838562, 0.09339505434036255]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 40, SSIM Loss: 0.09696686267852783\n",
      "Epoch: 40, Batch: 40, D Loss Real: 0.2095390409231186, D Loss Fake: 0.9449872970581055, G Loss: [10.552966117858887, 0.839066207408905, 0.09713900089263916]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 41, SSIM Loss: 0.09218418598175049\n",
      "Epoch: 40, Batch: 41, D Loss Real: 0.16435179114341736, D Loss Fake: 1.0216190814971924, G Loss: [10.068965911865234, 0.8492006659507751, 0.09219765663146973]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 42, SSIM Loss: 0.09208440780639648\n",
      "Epoch: 40, Batch: 42, D Loss Real: 0.08411875367164612, D Loss Fake: 1.2116706371307373, G Loss: [10.025771141052246, 0.8162340521812439, 0.09209537506103516]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 43, SSIM Loss: 0.09449350833892822\n",
      "Epoch: 40, Batch: 43, D Loss Real: 0.11509791016578674, D Loss Fake: 0.9146028757095337, G Loss: [10.378524780273438, 0.9226828813552856, 0.09455841779708862]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 40, Batch: 44, SSIM Loss: 0.09171056747436523\n",
      "Epoch: 40, Batch: 44, D Loss Real: 0.33840590715408325, D Loss Fake: 0.9711364507675171, G Loss: [9.968805313110352, 0.7849100828170776, 0.09183895587921143]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 45, SSIM Loss: 0.10040271282196045\n",
      "Epoch: 40, Batch: 45, D Loss Real: 0.13462233543395996, D Loss Fake: 1.020632266998291, G Loss: [10.807181358337402, 0.7874317169189453, 0.10019749402999878]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 46, SSIM Loss: 0.09316813945770264\n",
      "Epoch: 40, Batch: 46, D Loss Real: 0.30703696608543396, D Loss Fake: 1.1417441368103027, G Loss: [10.052816390991211, 0.738922655582428, 0.0931389331817627]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 47, SSIM Loss: 0.09984695911407471\n",
      "Epoch: 40, Batch: 47, D Loss Real: 0.048201482743024826, D Loss Fake: 1.1210941076278687, G Loss: [10.746111869812012, 0.8037293553352356, 0.09942382574081421]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 48, SSIM Loss: 0.09581983089447021\n",
      "Epoch: 40, Batch: 48, D Loss Real: 0.04170142859220505, D Loss Fake: 0.9101914763450623, G Loss: [10.49224853515625, 0.9410631656646729, 0.09551185369491577]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 49, SSIM Loss: 0.09305500984191895\n",
      "Epoch: 40, Batch: 49, D Loss Real: 0.15657949447631836, D Loss Fake: 0.9620726108551025, G Loss: [10.169144630432129, 0.8798980116844177, 0.09289246797561646]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 50, SSIM Loss: 0.09378957748413086\n",
      "Epoch: 40, Batch: 50, D Loss Real: 0.10887487977743149, D Loss Fake: 0.8831283450126648, G Loss: [10.261104583740234, 0.8808484077453613, 0.0938025712966919]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 51, SSIM Loss: 0.09248185157775879\n",
      "Epoch: 40, Batch: 51, D Loss Real: 0.059381887316703796, D Loss Fake: 0.8806613683700562, G Loss: [10.140914916992188, 0.8868770599365234, 0.09254038333892822]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 52, SSIM Loss: 0.09867829084396362\n",
      "Epoch: 40, Batch: 52, D Loss Real: 0.022805094718933105, D Loss Fake: 1.0208779573440552, G Loss: [10.83421802520752, 0.9436255693435669, 0.09890592098236084]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 53, SSIM Loss: 0.09214204549789429\n",
      "Epoch: 40, Batch: 53, D Loss Real: 0.11557050049304962, D Loss Fake: 0.830392599105835, G Loss: [10.178322792053223, 0.9815282821655273, 0.09196794033050537]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 54, SSIM Loss: 0.09679210186004639\n",
      "Epoch: 40, Batch: 54, D Loss Real: 0.13276083767414093, D Loss Fake: 0.8817827701568604, G Loss: [10.563172340393066, 0.8816139698028564, 0.09681558609008789]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 55, SSIM Loss: 0.09313327074050903\n",
      "Epoch: 40, Batch: 55, D Loss Real: 0.2134564220905304, D Loss Fake: 0.9847894906997681, G Loss: [10.177711486816406, 0.841740608215332, 0.09335970878601074]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 56, SSIM Loss: 0.09463930130004883\n",
      "Epoch: 40, Batch: 56, D Loss Real: 0.08657608181238174, D Loss Fake: 0.9920271635055542, G Loss: [10.292179107666016, 0.8207037448883057, 0.09471476078033447]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 57, SSIM Loss: 0.09578418731689453\n",
      "Epoch: 40, Batch: 57, D Loss Real: 0.061240054666996, D Loss Fake: 0.968350887298584, G Loss: [10.406177520751953, 0.8395729660987854, 0.09566605091094971]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 58, SSIM Loss: 0.09407234191894531\n",
      "Epoch: 40, Batch: 58, D Loss Real: 0.18285155296325684, D Loss Fake: 0.9514656662940979, G Loss: [10.262725830078125, 0.8218034505844116, 0.09440922737121582]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 59, SSIM Loss: 0.09337025880813599\n",
      "Epoch: 40, Batch: 59, D Loss Real: 0.07042969763278961, D Loss Fake: 1.1780091524124146, G Loss: [10.28325080871582, 0.9288735389709473, 0.09354376792907715]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 60, SSIM Loss: 0.09526264667510986\n",
      "Epoch: 40, Batch: 60, D Loss Real: 0.14429639279842377, D Loss Fake: 0.8912293910980225, G Loss: [10.422533988952637, 0.916176438331604, 0.09506356716156006]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 61, SSIM Loss: 0.09214019775390625\n",
      "Epoch: 40, Batch: 61, D Loss Real: 0.22589202225208282, D Loss Fake: 0.9979500770568848, G Loss: [10.037923812866211, 0.8405090570449829, 0.09197413921356201]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 40, Batch: 62, SSIM Loss: 0.09702646732330322\n",
      "Epoch: 40, Batch: 62, D Loss Real: 0.24327805638313293, D Loss Fake: 1.0041189193725586, G Loss: [10.552721977233887, 0.8116304874420166, 0.09741091728210449]\n",
      "\n",
      "Epoch 40: val_loss improved from 12.62685 to 10.55272, saving model to checkpoints/model_checkpoint_{epoch:02d}_{val_loss:.2f}\n",
      "1/1 [==============================] - 0s 148ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:07:59.443920: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:08:01.021285: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Batch: 1, SSIM Loss: 0.09245145320892334\n",
      "Epoch: 41, Batch: 1, D Loss Real: 0.10907010734081268, D Loss Fake: 0.9608213901519775, G Loss: [10.086322784423828, 0.8186947107315063, 0.09267628192901611]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 2, SSIM Loss: 0.09521722793579102\n",
      "Epoch: 41, Batch: 2, D Loss Real: 0.05909353122115135, D Loss Fake: 1.5032649040222168, G Loss: [11.092272758483887, 1.5550587177276611, 0.09537214040756226]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 41, Batch: 3, SSIM Loss: 0.09531688690185547\n",
      "Epoch: 41, Batch: 3, D Loss Real: 0.35181817412376404, D Loss Fake: 0.7892436385154724, G Loss: [10.501357078552246, 0.981774091720581, 0.09519582986831665]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 4, SSIM Loss: 0.09449267387390137\n",
      "Epoch: 41, Batch: 4, D Loss Real: 0.3618607819080353, D Loss Fake: 0.9786946177482605, G Loss: [10.324753761291504, 0.845909833908081, 0.09478843212127686]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 5, SSIM Loss: 0.0941929817199707\n",
      "Epoch: 41, Batch: 5, D Loss Real: 0.3102627396583557, D Loss Fake: 1.0805963277816772, G Loss: [10.173141479492188, 0.7787232398986816, 0.09394419193267822]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 6, SSIM Loss: 0.09315681457519531\n",
      "Epoch: 41, Batch: 6, D Loss Real: 0.23361900448799133, D Loss Fake: 1.109694004058838, G Loss: [10.10848617553711, 0.7574000358581543, 0.09351086616516113]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 7, SSIM Loss: 0.09637242555618286\n",
      "Epoch: 41, Batch: 7, D Loss Real: 0.13081011176109314, D Loss Fake: 1.0944592952728271, G Loss: [10.395812034606934, 0.779997706413269, 0.09615814685821533]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 8, SSIM Loss: 0.0966755747795105\n",
      "Epoch: 41, Batch: 8, D Loss Real: 0.12482507526874542, D Loss Fake: 0.9852034449577332, G Loss: [10.525803565979004, 0.8586276173591614, 0.09667176008224487]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 9, SSIM Loss: 0.09661197662353516\n",
      "Epoch: 41, Batch: 9, D Loss Real: 0.10104160010814667, D Loss Fake: 0.971077561378479, G Loss: [10.545890808105469, 0.8630268573760986, 0.0968286395072937]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 10, SSIM Loss: 0.09403765201568604\n",
      "Epoch: 41, Batch: 10, D Loss Real: 0.1046665832400322, D Loss Fake: 0.9133748412132263, G Loss: [10.307321548461914, 0.8960933089256287, 0.09411227703094482]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 11, SSIM Loss: 0.09157902002334595\n",
      "Epoch: 41, Batch: 11, D Loss Real: 0.11895801872015, D Loss Fake: 0.9793841242790222, G Loss: [10.008074760437012, 0.8637385964393616, 0.09144335985183716]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 12, SSIM Loss: 0.09389805793762207\n",
      "Epoch: 41, Batch: 12, D Loss Real: 0.06045735627412796, D Loss Fake: 0.9117258787155151, G Loss: [10.287601470947266, 0.8955013155937195, 0.0939210057258606]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 13, SSIM Loss: 0.09400033950805664\n",
      "Epoch: 41, Batch: 13, D Loss Real: 0.06409820169210434, D Loss Fake: 0.9143896102905273, G Loss: [10.228160858154297, 0.8605877757072449, 0.09367573261260986]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 14, SSIM Loss: 0.09797286987304688\n",
      "Epoch: 41, Batch: 14, D Loss Real: 0.07103458046913147, D Loss Fake: 0.8771450519561768, G Loss: [10.715557098388672, 0.9044003486633301, 0.09811156988143921]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 15, SSIM Loss: 0.09585791826248169\n",
      "Epoch: 41, Batch: 15, D Loss Real: 0.05401775613427162, D Loss Fake: 0.8423031568527222, G Loss: [10.539629936218262, 0.9294171929359436, 0.09610211849212646]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 16, SSIM Loss: 0.0965726375579834\n",
      "Epoch: 41, Batch: 16, D Loss Real: 0.05531316250562668, D Loss Fake: 0.8641453981399536, G Loss: [10.575484275817871, 0.9004473090171814, 0.09675037860870361]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 17, SSIM Loss: 0.09331655502319336\n",
      "Epoch: 41, Batch: 17, D Loss Real: 0.05045127868652344, D Loss Fake: 0.9069538712501526, G Loss: [10.19649600982666, 0.8907210826873779, 0.09305775165557861]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 41, Batch: 18, SSIM Loss: 0.09413480758666992\n",
      "Epoch: 41, Batch: 18, D Loss Real: 0.042339909821748734, D Loss Fake: 0.8723993897438049, G Loss: [10.24536418914795, 0.9029079675674438, 0.09342455863952637]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 19, SSIM Loss: 0.09491622447967529\n",
      "Epoch: 41, Batch: 19, D Loss Real: 0.05015048757195473, D Loss Fake: 0.8161671757698059, G Loss: [10.416351318359375, 0.934396505355835, 0.09481954574584961]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 20, SSIM Loss: 0.0951727032661438\n",
      "Epoch: 41, Batch: 20, D Loss Real: 0.03270915523171425, D Loss Fake: 0.939196765422821, G Loss: [10.400740623474121, 0.9151984453201294, 0.0948554277420044]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 21, SSIM Loss: 0.09209591150283813\n",
      "Epoch: 41, Batch: 21, D Loss Real: 0.05131964385509491, D Loss Fake: 0.8125813603401184, G Loss: [10.12232494354248, 0.928350567817688, 0.09193974733352661]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 22, SSIM Loss: 0.091403067111969\n",
      "Epoch: 41, Batch: 22, D Loss Real: 0.04727805405855179, D Loss Fake: 0.8249142169952393, G Loss: [10.063663482666016, 0.9224513173103333, 0.09141212701797485]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 23, SSIM Loss: 0.09441471099853516\n",
      "Epoch: 41, Batch: 23, D Loss Real: 0.04075820371508598, D Loss Fake: 0.9211487174034119, G Loss: [10.332045555114746, 0.8770802617073059, 0.09454965591430664]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 24, SSIM Loss: 0.09440433979034424\n",
      "Epoch: 41, Batch: 24, D Loss Real: 0.04597683250904083, D Loss Fake: 0.8530043363571167, G Loss: [10.344104766845703, 0.9104650020599365, 0.09433639049530029]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 25, SSIM Loss: 0.09448015689849854\n",
      "Epoch: 41, Batch: 25, D Loss Real: 0.041928574442863464, D Loss Fake: 0.8490440845489502, G Loss: [10.412881851196289, 0.9218790531158447, 0.09491002559661865]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 26, SSIM Loss: 0.092659592628479\n",
      "Epoch: 41, Batch: 26, D Loss Real: 0.03520747274160385, D Loss Fake: 0.8364719152450562, G Loss: [10.206149101257324, 0.9141481518745422, 0.09292000532150269]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 27, SSIM Loss: 0.09097349643707275\n",
      "Epoch: 41, Batch: 27, D Loss Real: 0.028258098289370537, D Loss Fake: 0.792542040348053, G Loss: [10.027618408203125, 0.940413773059845, 0.09087204933166504]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 28, SSIM Loss: 0.09738039970397949\n",
      "Epoch: 41, Batch: 28, D Loss Real: 0.046627938747406006, D Loss Fake: 0.9162591099739075, G Loss: [10.73766040802002, 0.9602873921394348, 0.0977737307548523]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 29, SSIM Loss: 0.09663593769073486\n",
      "Epoch: 41, Batch: 29, D Loss Real: 0.03378435596823692, D Loss Fake: 0.9793213605880737, G Loss: [10.636548042297363, 0.9457917809486389, 0.09690755605697632]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 30, SSIM Loss: 0.0965278148651123\n",
      "Epoch: 41, Batch: 30, D Loss Real: 0.12970615923404694, D Loss Fake: 0.8544184565544128, G Loss: [10.547229766845703, 0.905534565448761, 0.09641695022583008]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 31, SSIM Loss: 0.09355545043945312\n",
      "Epoch: 41, Batch: 31, D Loss Real: 0.07000831514596939, D Loss Fake: 0.8453227281570435, G Loss: [10.300448417663574, 0.9559546709060669, 0.09344494342803955]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 32, SSIM Loss: 0.11217498779296875\n",
      "Epoch: 41, Batch: 32, D Loss Real: 0.050633497536182404, D Loss Fake: 0.892761766910553, G Loss: [12.307734489440918, 0.940813422203064, 0.11366921663284302]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 33, SSIM Loss: 0.11727142333984375\n",
      "Epoch: 41, Batch: 33, D Loss Real: 0.08668297529220581, D Loss Fake: 0.776989758014679, G Loss: [12.719504356384277, 1.0694843530654907, 0.11650019884109497]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 34, SSIM Loss: 0.12237894535064697\n",
      "Epoch: 41, Batch: 34, D Loss Real: 0.05869428068399429, D Loss Fake: 0.7849777936935425, G Loss: [13.224982261657715, 0.9952596426010132, 0.12229722738265991]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 35, SSIM Loss: 0.10457396507263184\n",
      "Epoch: 41, Batch: 35, D Loss Real: 0.158461332321167, D Loss Fake: 0.9354133605957031, G Loss: [11.359367370605469, 0.9054462909698486, 0.10453921556472778]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 36, SSIM Loss: 0.12021684646606445\n",
      "Epoch: 41, Batch: 36, D Loss Real: 0.059169214218854904, D Loss Fake: 0.9215795397758484, G Loss: [12.912553787231445, 0.9088159799575806, 0.12003737688064575]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 41, Batch: 37, SSIM Loss: 0.11094242334365845\n",
      "Epoch: 41, Batch: 37, D Loss Real: 0.13139085471630096, D Loss Fake: 0.9303245544433594, G Loss: [11.965776443481445, 0.8823587894439697, 0.11083418130874634]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 38, SSIM Loss: 0.12525039911270142\n",
      "Epoch: 41, Batch: 38, D Loss Real: 0.03161470964550972, D Loss Fake: 0.9532341361045837, G Loss: [13.327004432678223, 0.9105284810066223, 0.12416476011276245]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 39, SSIM Loss: 0.1116875410079956\n",
      "Epoch: 41, Batch: 39, D Loss Real: 0.09851586073637009, D Loss Fake: 0.8476374745368958, G Loss: [12.123476028442383, 0.934516191482544, 0.11188960075378418]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 40, SSIM Loss: 0.11757874488830566\n",
      "Epoch: 41, Batch: 40, D Loss Real: 0.09157593548297882, D Loss Fake: 0.7676323652267456, G Loss: [12.902427673339844, 1.1346476078033447, 0.11767780780792236]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 41, SSIM Loss: 0.10268878936767578\n",
      "Epoch: 41, Batch: 41, D Loss Real: 0.15452592074871063, D Loss Fake: 0.9623318314552307, G Loss: [11.141861915588379, 0.8315098285675049, 0.10310351848602295]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 42, SSIM Loss: 0.11172425746917725\n",
      "Epoch: 41, Batch: 42, D Loss Real: 0.05737239494919777, D Loss Fake: 0.9967427253723145, G Loss: [12.048077583312988, 0.8775174617767334, 0.11170560121536255]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 41, Batch: 43, SSIM Loss: 0.10713529586791992\n",
      "Epoch: 41, Batch: 43, D Loss Real: 0.028056805953383446, D Loss Fake: 0.8624585866928101, G Loss: [11.677967071533203, 0.9443866014480591, 0.10733580589294434]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 44, SSIM Loss: 0.10308098793029785\n",
      "Epoch: 41, Batch: 44, D Loss Real: 0.07167134433984756, D Loss Fake: 0.8410197496414185, G Loss: [11.25697135925293, 0.944014847278595, 0.1031295657157898]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 45, SSIM Loss: 0.11345547437667847\n",
      "Epoch: 41, Batch: 45, D Loss Real: 0.029498983174562454, D Loss Fake: 0.8540591597557068, G Loss: [12.297113418579102, 0.9407361149787903, 0.11356377601623535]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 46, SSIM Loss: 0.10728102922439575\n",
      "Epoch: 41, Batch: 46, D Loss Real: 0.13015729188919067, D Loss Fake: 0.8567303419113159, G Loss: [11.684401512145996, 0.9106767177581787, 0.10773724317550659]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 41, Batch: 47, SSIM Loss: 0.11297601461410522\n",
      "Epoch: 41, Batch: 47, D Loss Real: 0.018072322010993958, D Loss Fake: 0.8736115097999573, G Loss: [12.222088813781738, 0.920828104019165, 0.11301261186599731]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 48, SSIM Loss: 0.10634618997573853\n",
      "Epoch: 41, Batch: 48, D Loss Real: 0.01856737770140171, D Loss Fake: 0.8158376812934875, G Loss: [11.584750175476074, 0.9507206082344055, 0.10634028911590576]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 49, SSIM Loss: 0.10688912868499756\n",
      "Epoch: 41, Batch: 49, D Loss Real: 0.03353354334831238, D Loss Fake: 0.7930597066879272, G Loss: [11.6421537399292, 0.9482107758522034, 0.10693943500518799]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 50, SSIM Loss: 0.10589039325714111\n",
      "Epoch: 41, Batch: 50, D Loss Real: 0.027476327493786812, D Loss Fake: 0.8237707614898682, G Loss: [11.61899185180664, 0.9444856643676758, 0.10674506425857544]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 51, SSIM Loss: 0.1105460524559021\n",
      "Epoch: 41, Batch: 51, D Loss Real: 0.022772230207920074, D Loss Fake: 0.8071515560150146, G Loss: [11.993285179138184, 0.9535936117172241, 0.11039692163467407]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 52, SSIM Loss: 0.11432605981826782\n",
      "Epoch: 41, Batch: 52, D Loss Real: 0.01378326304256916, D Loss Fake: 0.7753279805183411, G Loss: [12.358856201171875, 0.9697439670562744, 0.1138911247253418]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 53, SSIM Loss: 0.10596710443496704\n",
      "Epoch: 41, Batch: 53, D Loss Real: 0.019610561430454254, D Loss Fake: 0.8194929957389832, G Loss: [11.51318645477295, 0.9588843584060669, 0.10554301738739014]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 54, SSIM Loss: 0.11209660768508911\n",
      "Epoch: 41, Batch: 54, D Loss Real: 0.02675626054406166, D Loss Fake: 0.8389409780502319, G Loss: [12.094644546508789, 0.9440279006958008, 0.11150616407394409]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 55, SSIM Loss: 0.10383933782577515\n",
      "Epoch: 41, Batch: 55, D Loss Real: 0.05320640653371811, D Loss Fake: 0.7891273498535156, G Loss: [11.339913368225098, 0.9836298823356628, 0.10356283187866211]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 56, SSIM Loss: 0.10859918594360352\n",
      "Epoch: 41, Batch: 56, D Loss Real: 0.02286924049258232, D Loss Fake: 0.8186119198799133, G Loss: [11.73093032836914, 0.9484258890151978, 0.10782504081726074]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 57, SSIM Loss: 0.11069995164871216\n",
      "Epoch: 41, Batch: 57, D Loss Real: 0.015317356213927269, D Loss Fake: 0.7907081246376038, G Loss: [11.998615264892578, 0.9665467143058777, 0.11032068729400635]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 58, SSIM Loss: 0.10736197233200073\n",
      "Epoch: 41, Batch: 58, D Loss Real: 0.03526615351438522, D Loss Fake: 0.8534307479858398, G Loss: [11.732819557189941, 0.9316054582595825, 0.1080121397972107]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 59, SSIM Loss: 0.10023903846740723\n",
      "Epoch: 41, Batch: 59, D Loss Real: 0.03851154446601868, D Loss Fake: 0.8498921990394592, G Loss: [10.966317176818848, 0.9329366683959961, 0.1003338098526001]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 60, SSIM Loss: 0.1025991439819336\n",
      "Epoch: 41, Batch: 60, D Loss Real: 0.020895259454846382, D Loss Fake: 0.8085752725601196, G Loss: [11.257498741149902, 0.9580963850021362, 0.10299402475357056]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 61, SSIM Loss: 0.10084307193756104\n",
      "Epoch: 41, Batch: 61, D Loss Real: 0.03425568342208862, D Loss Fake: 0.7722787857055664, G Loss: [11.10550594329834, 0.9785573482513428, 0.10126948356628418]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 41, Batch: 62, SSIM Loss: 0.10792922973632812\n",
      "Epoch: 41, Batch: 62, D Loss Real: 0.040550827980041504, D Loss Fake: 0.815878689289093, G Loss: [11.792051315307617, 0.9449120163917542, 0.10847139358520508]\n",
      "1/1 [==============================] - 0s 148ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:09:22.796973: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:09:24.276396: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Batch: 1, SSIM Loss: 0.11142456531524658\n",
      "Epoch: 42, Batch: 1, D Loss Real: 0.0257207453250885, D Loss Fake: 0.8651264905929565, G Loss: [12.032770156860352, 0.9497337937355042, 0.11083036661148071]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 2, SSIM Loss: 0.11023974418640137\n",
      "Epoch: 42, Batch: 2, D Loss Real: 0.07121346890926361, D Loss Fake: 0.766322910785675, G Loss: [12.025434494018555, 1.0099234580993652, 0.11015510559082031]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 42, Batch: 3, SSIM Loss: 0.10626649856567383\n",
      "Epoch: 42, Batch: 3, D Loss Real: 0.024987585842609406, D Loss Fake: 0.8233249187469482, G Loss: [11.637968063354492, 0.9984794855117798, 0.10639488697052002]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 42, Batch: 4, SSIM Loss: 0.1053658127784729\n",
      "Epoch: 42, Batch: 4, D Loss Real: 0.04564882814884186, D Loss Fake: 0.8114900588989258, G Loss: [11.520787239074707, 0.9695364832878113, 0.10551249980926514]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 42, Batch: 5, SSIM Loss: 0.10063207149505615\n",
      "Epoch: 42, Batch: 5, D Loss Real: 0.040372058749198914, D Loss Fake: 0.8450974822044373, G Loss: [11.007418632507324, 0.954987645149231, 0.10052430629730225]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 6, SSIM Loss: 0.09890824556350708\n",
      "Epoch: 42, Batch: 6, D Loss Real: 0.017646873369812965, D Loss Fake: 0.8638865947723389, G Loss: [10.8596830368042, 0.9600074291229248, 0.09899675846099854]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 7, SSIM Loss: 0.10321509838104248\n",
      "Epoch: 42, Batch: 7, D Loss Real: 0.021187592297792435, D Loss Fake: 0.8378379940986633, G Loss: [11.273080825805664, 0.9621148109436035, 0.10310965776443481]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 8, SSIM Loss: 0.10036104917526245\n",
      "Epoch: 42, Batch: 8, D Loss Real: 0.0356021523475647, D Loss Fake: 0.791008472442627, G Loss: [11.043330192565918, 0.9797293543815613, 0.10063600540161133]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 9, SSIM Loss: 0.10113692283630371\n",
      "Epoch: 42, Batch: 9, D Loss Real: 0.028284823521971703, D Loss Fake: 0.7730263471603394, G Loss: [11.08909797668457, 0.979375422000885, 0.1010972261428833]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 10, SSIM Loss: 0.10190117359161377\n",
      "Epoch: 42, Batch: 10, D Loss Real: 0.02447369508445263, D Loss Fake: 0.8075170516967773, G Loss: [11.144474983215332, 0.9850720167160034, 0.10159403085708618]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 42, Batch: 11, SSIM Loss: 0.09892332553863525\n",
      "Epoch: 42, Batch: 11, D Loss Real: 0.04954477399587631, D Loss Fake: 0.7999805808067322, G Loss: [10.928349494934082, 0.9547399282455444, 0.09973609447479248]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 12, SSIM Loss: 0.09806489944458008\n",
      "Epoch: 42, Batch: 12, D Loss Real: 0.02638879418373108, D Loss Fake: 0.8799791932106018, G Loss: [10.74388313293457, 0.9401641488075256, 0.09803718328475952]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 13, SSIM Loss: 0.10053569078445435\n",
      "Epoch: 42, Batch: 13, D Loss Real: 0.06927916407585144, D Loss Fake: 0.8593718409538269, G Loss: [10.95218563079834, 0.910596489906311, 0.10041588544845581]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 14, SSIM Loss: 0.10794097185134888\n",
      "Epoch: 42, Batch: 14, D Loss Real: 0.06085510551929474, D Loss Fake: 0.8425902724266052, G Loss: [11.679405212402344, 0.9431414604187012, 0.10736262798309326]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 15, SSIM Loss: 0.1026996374130249\n",
      "Epoch: 42, Batch: 15, D Loss Real: 0.039275895804166794, D Loss Fake: 0.9696815609931946, G Loss: [11.23534107208252, 0.9548272490501404, 0.10280513763427734]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 16, SSIM Loss: 0.10324347019195557\n",
      "Epoch: 42, Batch: 16, D Loss Real: 0.07848896831274033, D Loss Fake: 0.8134143352508545, G Loss: [11.261225700378418, 0.9678255915641785, 0.10293400287628174]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 17, SSIM Loss: 0.09997713565826416\n",
      "Epoch: 42, Batch: 17, D Loss Real: 0.065276138484478, D Loss Fake: 0.7920831441879272, G Loss: [10.919116973876953, 0.9891380667686462, 0.09929978847503662]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 18, SSIM Loss: 0.10277462005615234\n",
      "Epoch: 42, Batch: 18, D Loss Real: 0.07198139280080795, D Loss Fake: 0.8177273273468018, G Loss: [11.222005844116211, 0.9567625522613525, 0.10265243053436279]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 19, SSIM Loss: 0.10253584384918213\n",
      "Epoch: 42, Batch: 19, D Loss Real: 0.049152202904224396, D Loss Fake: 0.9335542917251587, G Loss: [11.22266674041748, 0.9452702403068542, 0.10277396440505981]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 20, SSIM Loss: 0.10125875473022461\n",
      "Epoch: 42, Batch: 20, D Loss Real: 0.04664483293890953, D Loss Fake: 0.7688825130462646, G Loss: [11.134106636047363, 0.9915537238121033, 0.10142552852630615]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 21, SSIM Loss: 0.0968160629272461\n",
      "Epoch: 42, Batch: 21, D Loss Real: 0.06480132788419724, D Loss Fake: 0.8228066563606262, G Loss: [10.640050888061523, 0.9781854748725891, 0.09661865234375]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 22, SSIM Loss: 0.09713190793991089\n",
      "Epoch: 42, Batch: 22, D Loss Real: 0.03849589824676514, D Loss Fake: 0.8420252799987793, G Loss: [10.725648880004883, 0.9462255835533142, 0.09779423475265503]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 23, SSIM Loss: 0.10325944423675537\n",
      "Epoch: 42, Batch: 23, D Loss Real: 0.033465106040239334, D Loss Fake: 0.8395805358886719, G Loss: [11.253790855407715, 0.9718579649925232, 0.10281932353973389]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 42, Batch: 24, SSIM Loss: 0.09933525323867798\n",
      "Epoch: 42, Batch: 24, D Loss Real: 0.044780950993299484, D Loss Fake: 0.8436712026596069, G Loss: [10.917118072509766, 0.9483838081359863, 0.09968733787536621]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 25, SSIM Loss: 0.10130560398101807\n",
      "Epoch: 42, Batch: 25, D Loss Real: 0.025891782715916634, D Loss Fake: 0.8948946595191956, G Loss: [11.031270980834961, 0.9410099983215332, 0.10090261697769165]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 26, SSIM Loss: 0.09874880313873291\n",
      "Epoch: 42, Batch: 26, D Loss Real: 0.05348958075046539, D Loss Fake: 0.799079418182373, G Loss: [10.881118774414062, 0.9425337314605713, 0.09938585758209229]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 27, SSIM Loss: 0.09592568874359131\n",
      "Epoch: 42, Batch: 27, D Loss Real: 0.07051517814397812, D Loss Fake: 0.8100852966308594, G Loss: [10.652020454406738, 0.9554049372673035, 0.09696614742279053]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 28, SSIM Loss: 0.09992814064025879\n",
      "Epoch: 42, Batch: 28, D Loss Real: 0.05824236199259758, D Loss Fake: 0.8187913298606873, G Loss: [10.920709609985352, 0.9453126788139343, 0.0997539758682251]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 29, SSIM Loss: 0.10507982969284058\n",
      "Epoch: 42, Batch: 29, D Loss Real: 0.024091945961117744, D Loss Fake: 0.8738747239112854, G Loss: [11.46505355834961, 0.9974579811096191, 0.10467594861984253]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 30, SSIM Loss: 0.10069644451141357\n",
      "Epoch: 42, Batch: 30, D Loss Real: 0.09080168604850769, D Loss Fake: 0.8433154225349426, G Loss: [11.002293586730957, 0.9149404168128967, 0.10087352991104126]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 31, SSIM Loss: 0.09895360469818115\n",
      "Epoch: 42, Batch: 31, D Loss Real: 0.06399401277303696, D Loss Fake: 0.8313280344009399, G Loss: [10.869524955749512, 0.9260818958282471, 0.09943443536758423]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 32, SSIM Loss: 0.10250163078308105\n",
      "Epoch: 42, Batch: 32, D Loss Real: 0.03203312307596207, D Loss Fake: 0.875949501991272, G Loss: [11.252654075622559, 0.9456393122673035, 0.10307013988494873]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 42, Batch: 33, SSIM Loss: 0.10025900602340698\n",
      "Epoch: 42, Batch: 33, D Loss Real: 0.09557808190584183, D Loss Fake: 0.8336619138717651, G Loss: [10.985074043273926, 0.9216642379760742, 0.10063409805297852]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 34, SSIM Loss: 0.09906387329101562\n",
      "Epoch: 42, Batch: 34, D Loss Real: 0.051167700439691544, D Loss Fake: 0.8262653350830078, G Loss: [10.766711235046387, 0.9526284337043762, 0.09814083576202393]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 42, Batch: 35, SSIM Loss: 0.09602141380310059\n",
      "Epoch: 42, Batch: 35, D Loss Real: 0.16203072667121887, D Loss Fake: 0.8544069528579712, G Loss: [10.5215425491333, 0.9073721170425415, 0.09614169597625732]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 36, SSIM Loss: 0.09715616703033447\n",
      "Epoch: 42, Batch: 36, D Loss Real: 0.02201937325298786, D Loss Fake: 0.9622296690940857, G Loss: [10.65366268157959, 0.9171009063720703, 0.0973656177520752]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 37, SSIM Loss: 0.09494227170944214\n",
      "Epoch: 42, Batch: 37, D Loss Real: 0.048788320273160934, D Loss Fake: 0.7954862117767334, G Loss: [10.447517395019531, 0.9835280776023865, 0.09463989734649658]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 38, SSIM Loss: 0.10209602117538452\n",
      "Epoch: 42, Batch: 38, D Loss Real: 0.02161792293190956, D Loss Fake: 0.8225007653236389, G Loss: [11.167094230651855, 0.9620278477668762, 0.10205066204071045]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 39, SSIM Loss: 0.09761369228363037\n",
      "Epoch: 42, Batch: 39, D Loss Real: 0.04822099953889847, D Loss Fake: 0.7938030958175659, G Loss: [10.766396522521973, 0.9509417414665222, 0.09815454483032227]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 40, SSIM Loss: 0.10078203678131104\n",
      "Epoch: 42, Batch: 40, D Loss Real: 0.05117053911089897, D Loss Fake: 1.2038609981536865, G Loss: [11.077189445495605, 0.9799829125404358, 0.10097205638885498]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 41, SSIM Loss: 0.0983818769454956\n",
      "Epoch: 42, Batch: 41, D Loss Real: 0.4223068058490753, D Loss Fake: 1.108909010887146, G Loss: [10.805710792541504, 0.9167936444282532, 0.09888917207717896]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 42, SSIM Loss: 0.09794855117797852\n",
      "Epoch: 42, Batch: 42, D Loss Real: 0.4167645275592804, D Loss Fake: 0.9653272032737732, G Loss: [10.612574577331543, 0.8386639356613159, 0.09773910045623779]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 42, Batch: 43, SSIM Loss: 0.10108107328414917\n",
      "Epoch: 42, Batch: 43, D Loss Real: 0.26911282539367676, D Loss Fake: 1.0955582857131958, G Loss: [10.870373725891113, 0.7742413282394409, 0.10096132755279541]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 42, Batch: 44, SSIM Loss: 0.09766149520874023\n",
      "Epoch: 42, Batch: 44, D Loss Real: 0.2544127404689789, D Loss Fake: 1.1559475660324097, G Loss: [10.482154846191406, 0.7579306960105896, 0.09724223613739014]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 45, SSIM Loss: 0.10309737920761108\n",
      "Epoch: 42, Batch: 45, D Loss Real: 0.14645735919475555, D Loss Fake: 1.054537296295166, G Loss: [11.138861656188965, 0.8043996095657349, 0.1033446192741394]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 46, SSIM Loss: 0.09801948070526123\n",
      "Epoch: 42, Batch: 46, D Loss Real: 0.344451367855072, D Loss Fake: 1.0010541677474976, G Loss: [10.64814567565918, 0.824262261390686, 0.09823882579803467]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 47, SSIM Loss: 0.10706031322479248\n",
      "Epoch: 42, Batch: 47, D Loss Real: 0.13762995600700378, D Loss Fake: 1.1204484701156616, G Loss: [11.469517707824707, 0.7980743050575256, 0.10671442747116089]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 48, SSIM Loss: 0.0997423529624939\n",
      "Epoch: 42, Batch: 48, D Loss Real: 0.1564246267080307, D Loss Fake: 0.993139386177063, G Loss: [10.78304672241211, 0.845151424407959, 0.09937894344329834]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 49, SSIM Loss: 0.0969955325126648\n",
      "Epoch: 42, Batch: 49, D Loss Real: 0.12670326232910156, D Loss Fake: 1.0206632614135742, G Loss: [10.612712860107422, 0.927518904209137, 0.09685194492340088]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 50, SSIM Loss: 0.09807050228118896\n",
      "Epoch: 42, Batch: 50, D Loss Real: 0.1419946849346161, D Loss Fake: 0.9169230461120605, G Loss: [10.665665626525879, 0.9063164591789246, 0.09759348630905151]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 51, SSIM Loss: 0.09661388397216797\n",
      "Epoch: 42, Batch: 51, D Loss Real: 0.16519245505332947, D Loss Fake: 0.9286001324653625, G Loss: [10.50623607635498, 0.849436342716217, 0.09656798839569092]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 52, SSIM Loss: 0.10384345054626465\n",
      "Epoch: 42, Batch: 52, D Loss Real: 0.04797745496034622, D Loss Fake: 1.0424325466156006, G Loss: [11.352273941040039, 0.9107322692871094, 0.1044154167175293]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 53, SSIM Loss: 0.09605675935745239\n",
      "Epoch: 42, Batch: 53, D Loss Real: 0.1364571750164032, D Loss Fake: 0.8364092707633972, G Loss: [10.54941463470459, 0.9251836538314819, 0.09624230861663818]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 54, SSIM Loss: 0.1012948751449585\n",
      "Epoch: 42, Batch: 54, D Loss Real: 0.16332171857357025, D Loss Fake: 0.8952991366386414, G Loss: [11.016807556152344, 0.8659404516220093, 0.10150867700576782]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 55, SSIM Loss: 0.10006844997406006\n",
      "Epoch: 42, Batch: 55, D Loss Real: 0.15796755254268646, D Loss Fake: 0.9557732343673706, G Loss: [10.791112899780273, 0.8748785853385925, 0.09916234016418457]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 56, SSIM Loss: 0.09902620315551758\n",
      "Epoch: 42, Batch: 56, D Loss Real: 0.06103748828172684, D Loss Fake: 0.8999133110046387, G Loss: [10.780396461486816, 0.8897870779037476, 0.09890609979629517]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 57, SSIM Loss: 0.10311329364776611\n",
      "Epoch: 42, Batch: 57, D Loss Real: 0.04639315977692604, D Loss Fake: 0.818820059299469, G Loss: [11.296977043151855, 0.9497902393341064, 0.10347187519073486]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 58, SSIM Loss: 0.09913891553878784\n",
      "Epoch: 42, Batch: 58, D Loss Real: 0.07920636981725693, D Loss Fake: 0.8557435274124146, G Loss: [10.804659843444824, 0.8908449411392212, 0.09913814067840576]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 59, SSIM Loss: 0.09719264507293701\n",
      "Epoch: 42, Batch: 59, D Loss Real: 0.0566411055624485, D Loss Fake: 0.8381627798080444, G Loss: [10.684043884277344, 0.9185328483581543, 0.09765511751174927]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 42, Batch: 60, SSIM Loss: 0.10861074924468994\n",
      "Epoch: 42, Batch: 60, D Loss Real: 0.027353642508387566, D Loss Fake: 0.8952402472496033, G Loss: [11.83771800994873, 0.9192439317703247, 0.10918474197387695]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 42, Batch: 61, SSIM Loss: 0.0983196496963501\n",
      "Epoch: 42, Batch: 61, D Loss Real: 0.05540125072002411, D Loss Fake: 0.8147640228271484, G Loss: [10.772000312805176, 0.961171567440033, 0.09810829162597656]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 42, Batch: 62, SSIM Loss: 0.10096186399459839\n",
      "Epoch: 42, Batch: 62, D Loss Real: 0.11414016038179398, D Loss Fake: 0.8066830039024353, G Loss: [11.048240661621094, 0.9375285506248474, 0.10110712051391602]\n",
      "1/1 [==============================] - 0s 142ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:10:45.980829: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:10:47.441552: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Batch: 1, SSIM Loss: 0.09874331951141357\n",
      "Epoch: 43, Batch: 1, D Loss Real: 0.03876660019159317, D Loss Fake: 0.9617495536804199, G Loss: [10.773818969726562, 0.9033436179161072, 0.0987047553062439]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 2, SSIM Loss: 0.09625434875488281\n",
      "Epoch: 43, Batch: 2, D Loss Real: 0.06864586472511292, D Loss Fake: 0.8137694597244263, G Loss: [10.592864990234375, 0.989096999168396, 0.09603768587112427]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 43, Batch: 3, SSIM Loss: 0.09869444370269775\n",
      "Epoch: 43, Batch: 3, D Loss Real: 0.028439849615097046, D Loss Fake: 0.8607977032661438, G Loss: [10.817546844482422, 0.9542949199676514, 0.09863251447677612]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 4, SSIM Loss: 0.10056793689727783\n",
      "Epoch: 43, Batch: 4, D Loss Real: 0.09121929109096527, D Loss Fake: 1.0687665939331055, G Loss: [11.039978981018066, 1.0035289525985718, 0.10036450624465942]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 5, SSIM Loss: 0.09540915489196777\n",
      "Epoch: 43, Batch: 5, D Loss Real: 0.1971445381641388, D Loss Fake: 0.8900305032730103, G Loss: [10.43066692352295, 0.8840892910957336, 0.0954657793045044]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 6, SSIM Loss: 0.0960850715637207\n",
      "Epoch: 43, Batch: 6, D Loss Real: 0.07284664362668991, D Loss Fake: 0.8683179616928101, G Loss: [10.553776741027832, 0.965094804763794, 0.09588682651519775]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 7, SSIM Loss: 0.0983438491821289\n",
      "Epoch: 43, Batch: 7, D Loss Real: 0.03681939095258713, D Loss Fake: 0.8893823623657227, G Loss: [10.727741241455078, 0.9316821098327637, 0.09796059131622314]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 8, SSIM Loss: 0.09781908988952637\n",
      "Epoch: 43, Batch: 8, D Loss Real: 0.0777563825249672, D Loss Fake: 0.8571751713752747, G Loss: [10.732250213623047, 0.9528264403343201, 0.09779423475265503]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 9, SSIM Loss: 0.09894859790802002\n",
      "Epoch: 43, Batch: 9, D Loss Real: 0.10134658217430115, D Loss Fake: 0.8330798745155334, G Loss: [10.820734977722168, 0.923836350440979, 0.0989689826965332]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 10, SSIM Loss: 0.09702479839324951\n",
      "Epoch: 43, Batch: 10, D Loss Real: 0.06358715146780014, D Loss Fake: 0.857035756111145, G Loss: [10.581717491149902, 0.899931788444519, 0.09681785106658936]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 11, SSIM Loss: 0.09255903959274292\n",
      "Epoch: 43, Batch: 11, D Loss Real: 0.07276833057403564, D Loss Fake: 0.9063357710838318, G Loss: [10.171462059020996, 0.9019273519515991, 0.09269535541534424]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 43, Batch: 12, SSIM Loss: 0.09570229053497314\n",
      "Epoch: 43, Batch: 12, D Loss Real: 0.039694130420684814, D Loss Fake: 0.8254281282424927, G Loss: [10.483464241027832, 0.9403017163276672, 0.0954316258430481]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 13, SSIM Loss: 0.09789466857910156\n",
      "Epoch: 43, Batch: 13, D Loss Real: 0.05086761340498924, D Loss Fake: 0.7974767684936523, G Loss: [10.673352241516113, 0.9458744525909424, 0.0972747802734375]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 14, SSIM Loss: 0.10280025005340576\n",
      "Epoch: 43, Batch: 14, D Loss Real: 0.04062711447477341, D Loss Fake: 0.8770768046379089, G Loss: [11.32020092010498, 0.9798074960708618, 0.10340392589569092]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 15, SSIM Loss: 0.10023897886276245\n",
      "Epoch: 43, Batch: 15, D Loss Real: 0.09212566912174225, D Loss Fake: 0.7582803964614868, G Loss: [11.16673755645752, 1.1221147775650024, 0.10044622421264648]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 16, SSIM Loss: 0.10017383098602295\n",
      "Epoch: 43, Batch: 16, D Loss Real: 0.1399584412574768, D Loss Fake: 0.8678457140922546, G Loss: [10.95211410522461, 0.8916717767715454, 0.10060441493988037]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 17, SSIM Loss: 0.09947061538696289\n",
      "Epoch: 43, Batch: 17, D Loss Real: 0.0791008248925209, D Loss Fake: 0.8681995868682861, G Loss: [10.879715919494629, 0.9047478437423706, 0.09974968433380127]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 18, SSIM Loss: 0.09792494773864746\n",
      "Epoch: 43, Batch: 18, D Loss Real: 0.06808559596538544, D Loss Fake: 0.8535125851631165, G Loss: [10.750874519348145, 0.9166215062141418, 0.09834253787994385]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 19, SSIM Loss: 0.10106158256530762\n",
      "Epoch: 43, Batch: 19, D Loss Real: 0.02934802696108818, D Loss Fake: 0.8221815228462219, G Loss: [11.003495216369629, 0.9336721897125244, 0.10069823265075684]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 20, SSIM Loss: 0.10109817981719971\n",
      "Epoch: 43, Batch: 20, D Loss Real: 0.019117150455713272, D Loss Fake: 0.8346173167228699, G Loss: [11.101543426513672, 0.9425159692764282, 0.10159027576446533]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 21, SSIM Loss: 0.0976148247718811\n",
      "Epoch: 43, Batch: 21, D Loss Real: 0.022273829206824303, D Loss Fake: 0.818459153175354, G Loss: [10.677562713623047, 0.9409947991371155, 0.09736567735671997]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 22, SSIM Loss: 0.09566712379455566\n",
      "Epoch: 43, Batch: 22, D Loss Real: 0.021385470405220985, D Loss Fake: 0.7751917839050293, G Loss: [10.525240898132324, 0.9821500778198242, 0.09543091058731079]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 23, SSIM Loss: 0.09976184368133545\n",
      "Epoch: 43, Batch: 23, D Loss Real: 0.02466430328786373, D Loss Fake: 0.7659714818000793, G Loss: [10.972310066223145, 0.9704305529594421, 0.10001879930496216]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 24, SSIM Loss: 0.10050851106643677\n",
      "Epoch: 43, Batch: 24, D Loss Real: 0.020299015566706657, D Loss Fake: 0.8055566549301147, G Loss: [10.98482608795166, 0.9657505750656128, 0.10019075870513916]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 25, SSIM Loss: 0.0992741584777832\n",
      "Epoch: 43, Batch: 25, D Loss Real: 0.030442096292972565, D Loss Fake: 0.8827036023139954, G Loss: [10.873112678527832, 0.9777520298957825, 0.09895360469818115]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 26, SSIM Loss: 0.09656989574432373\n",
      "Epoch: 43, Batch: 26, D Loss Real: 0.03835628554224968, D Loss Fake: 0.7858327627182007, G Loss: [10.633605003356934, 0.991576611995697, 0.0964202880859375]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 27, SSIM Loss: 0.09367454051971436\n",
      "Epoch: 43, Batch: 27, D Loss Real: 0.03610840439796448, D Loss Fake: 0.7499243021011353, G Loss: [10.349281311035156, 1.0187227725982666, 0.09330558776855469]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 28, SSIM Loss: 0.09854435920715332\n",
      "Epoch: 43, Batch: 28, D Loss Real: 0.05973244830965996, D Loss Fake: 0.8356906771659851, G Loss: [10.787643432617188, 0.9494855403900146, 0.09838157892227173]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 29, SSIM Loss: 0.10014581680297852\n",
      "Epoch: 43, Batch: 29, D Loss Real: 0.026913154870271683, D Loss Fake: 1.0179550647735596, G Loss: [11.039703369140625, 1.03049898147583, 0.10009205341339111]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 30, SSIM Loss: 0.0980040431022644\n",
      "Epoch: 43, Batch: 30, D Loss Real: 0.1311478167772293, D Loss Fake: 0.7693259716033936, G Loss: [10.79985237121582, 0.9985237717628479, 0.09801328182220459]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 31, SSIM Loss: 0.09673821926116943\n",
      "Epoch: 43, Batch: 31, D Loss Real: 0.10073831677436829, D Loss Fake: 0.9582270383834839, G Loss: [10.609016418457031, 1.0050811767578125, 0.09603935480117798]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 32, SSIM Loss: 0.09754109382629395\n",
      "Epoch: 43, Batch: 32, D Loss Real: 0.17293310165405273, D Loss Fake: 0.8347459435462952, G Loss: [10.739278793334961, 0.942766547203064, 0.09796512126922607]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 33, SSIM Loss: 0.09555864334106445\n",
      "Epoch: 43, Batch: 33, D Loss Real: 0.1936478167772293, D Loss Fake: 0.985842764377594, G Loss: [10.409751892089844, 0.8618028163909912, 0.09547948837280273]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 34, SSIM Loss: 0.09571939706802368\n",
      "Epoch: 43, Batch: 34, D Loss Real: 0.06901824474334717, D Loss Fake: 0.9968848824501038, G Loss: [10.47122859954834, 0.8997002840042114, 0.09571528434753418]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 35, SSIM Loss: 0.0956571102142334\n",
      "Epoch: 43, Batch: 35, D Loss Real: 0.21151700615882874, D Loss Fake: 0.9584826827049255, G Loss: [10.411532402038574, 0.8518059253692627, 0.0955972671508789]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 36, SSIM Loss: 0.09614765644073486\n",
      "Epoch: 43, Batch: 36, D Loss Real: 0.08689352124929428, D Loss Fake: 0.9448176622390747, G Loss: [10.495687484741211, 0.8536826372146606, 0.0964200496673584]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 37, SSIM Loss: 0.09399867057800293\n",
      "Epoch: 43, Batch: 37, D Loss Real: 0.15895886719226837, D Loss Fake: 0.9371459484100342, G Loss: [10.175765037536621, 0.8125193119049072, 0.09363245964050293]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 38, SSIM Loss: 0.09940344095230103\n",
      "Epoch: 43, Batch: 38, D Loss Real: 0.0272049717605114, D Loss Fake: 1.031628966331482, G Loss: [10.88574504852295, 0.8984386920928955, 0.09987306594848633]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 39, SSIM Loss: 0.09500199556350708\n",
      "Epoch: 43, Batch: 39, D Loss Real: 0.15030835568904877, D Loss Fake: 0.7956008315086365, G Loss: [10.449524879455566, 0.9405574202537537, 0.09508967399597168]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 40, SSIM Loss: 0.10016441345214844\n",
      "Epoch: 43, Batch: 40, D Loss Real: 0.1481342911720276, D Loss Fake: 0.9737027287483215, G Loss: [10.973329544067383, 0.9087993502616882, 0.10064530372619629]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 41, SSIM Loss: 0.09518718719482422\n",
      "Epoch: 43, Batch: 41, D Loss Real: 0.2798437774181366, D Loss Fake: 1.0131103992462158, G Loss: [10.277223587036133, 0.7535400390625, 0.09523683786392212]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 42, SSIM Loss: 0.09606891870498657\n",
      "Epoch: 43, Batch: 42, D Loss Real: 0.12425786256790161, D Loss Fake: 1.0686655044555664, G Loss: [10.367382049560547, 0.8055574893951416, 0.09561824798583984]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 43, SSIM Loss: 0.09812331199645996\n",
      "Epoch: 43, Batch: 43, D Loss Real: 0.04861188679933548, D Loss Fake: 1.0338118076324463, G Loss: [10.740293502807617, 0.9106950759887695, 0.09829598665237427]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 44, SSIM Loss: 0.09318506717681885\n",
      "Epoch: 43, Batch: 44, D Loss Real: 0.17382977902889252, D Loss Fake: 0.8160368204116821, G Loss: [10.305931091308594, 0.9304481744766235, 0.0937548279762268]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 45, SSIM Loss: 0.1024981141090393\n",
      "Epoch: 43, Batch: 45, D Loss Real: 0.10082560777664185, D Loss Fake: 0.8573915958404541, G Loss: [11.135004043579102, 0.8928340077400208, 0.10242170095443726]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 46, SSIM Loss: 0.09506654739379883\n",
      "Epoch: 43, Batch: 46, D Loss Real: 0.18200907111167908, D Loss Fake: 0.9769713282585144, G Loss: [10.352452278137207, 0.8276062607765198, 0.09524846076965332]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 47, SSIM Loss: 0.1035197377204895\n",
      "Epoch: 43, Batch: 47, D Loss Real: 0.03722447529435158, D Loss Fake: 0.9762042760848999, G Loss: [11.21761703491211, 0.8670793771743774, 0.10350537300109863]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 48, SSIM Loss: 0.09926813840866089\n",
      "Epoch: 43, Batch: 48, D Loss Real: 0.036154136061668396, D Loss Fake: 0.8852113485336304, G Loss: [10.887650489807129, 0.9562404155731201, 0.09931409358978271]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 49, SSIM Loss: 0.0960761308670044\n",
      "Epoch: 43, Batch: 49, D Loss Real: 0.1936938762664795, D Loss Fake: 0.7957207560539246, G Loss: [10.613655090332031, 0.9474987983703613, 0.09666156768798828]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 50, SSIM Loss: 0.09771686792373657\n",
      "Epoch: 43, Batch: 50, D Loss Real: 0.1182832270860672, D Loss Fake: 0.9050561189651489, G Loss: [10.579001426696777, 0.8443523645401001, 0.0973464846611023]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 51, SSIM Loss: 0.09447348117828369\n",
      "Epoch: 43, Batch: 51, D Loss Real: 0.059268802404403687, D Loss Fake: 0.8606893420219421, G Loss: [10.309774398803711, 0.8812369108200073, 0.09428536891937256]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 52, SSIM Loss: 0.10201370716094971\n",
      "Epoch: 43, Batch: 52, D Loss Real: 0.023823607712984085, D Loss Fake: 0.9665030837059021, G Loss: [11.139738082885742, 0.9558904767036438, 0.10183846950531006]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 53, SSIM Loss: 0.09355008602142334\n",
      "Epoch: 43, Batch: 53, D Loss Real: 0.071699358522892, D Loss Fake: 0.7562921047210693, G Loss: [10.397672653198242, 1.0084630250930786, 0.09389209747314453]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 54, SSIM Loss: 0.09834891557693481\n",
      "Epoch: 43, Batch: 54, D Loss Real: 0.0999811440706253, D Loss Fake: 0.7711330056190491, G Loss: [10.896049499511719, 0.9901031255722046, 0.09905946254730225]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 55, SSIM Loss: 0.09766566753387451\n",
      "Epoch: 43, Batch: 55, D Loss Real: 0.15071988105773926, D Loss Fake: 0.9989991188049316, G Loss: [10.589797019958496, 0.8850110769271851, 0.09704786539077759]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 56, SSIM Loss: 0.09564489126205444\n",
      "Epoch: 43, Batch: 56, D Loss Real: 0.0631275326013565, D Loss Fake: 0.8476577401161194, G Loss: [10.491401672363281, 0.9405804872512817, 0.09550821781158447]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 57, SSIM Loss: 0.09833002090454102\n",
      "Epoch: 43, Batch: 57, D Loss Real: 0.044119127094745636, D Loss Fake: 0.8025514483451843, G Loss: [10.776497840881348, 0.9466791152954102, 0.09829819202423096]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 58, SSIM Loss: 0.09646499156951904\n",
      "Epoch: 43, Batch: 58, D Loss Real: 0.07903854548931122, D Loss Fake: 0.8446764349937439, G Loss: [10.523078918457031, 0.9096065759658813, 0.0961347222328186]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 59, SSIM Loss: 0.09518349170684814\n",
      "Epoch: 43, Batch: 59, D Loss Real: 0.05348256975412369, D Loss Fake: 1.2998862266540527, G Loss: [10.924871444702148, 1.4175734519958496, 0.09507298469543457]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 60, SSIM Loss: 0.09955006837844849\n",
      "Epoch: 43, Batch: 60, D Loss Real: 0.1307377815246582, D Loss Fake: 0.682068943977356, G Loss: [11.203727722167969, 1.1517443656921387, 0.10051983594894409]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 61, SSIM Loss: 0.09500610828399658\n",
      "Epoch: 43, Batch: 61, D Loss Real: 0.19134396314620972, D Loss Fake: 0.8570406436920166, G Loss: [10.407524108886719, 0.959175169467926, 0.09448349475860596]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 43, Batch: 62, SSIM Loss: 0.09976553916931152\n",
      "Epoch: 43, Batch: 62, D Loss Real: 0.18188023567199707, D Loss Fake: 0.9345707893371582, G Loss: [10.859803199768066, 0.8723902106285095, 0.09987413883209229]\n",
      "1/1 [==============================] - 0s 143ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:12:09.196543: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:12:10.650885: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Batch: 1, SSIM Loss: 0.09503054618835449\n",
      "Epoch: 44, Batch: 1, D Loss Real: 0.07503179460763931, D Loss Fake: 0.9382936954498291, G Loss: [10.36781120300293, 0.8713790774345398, 0.09496432542800903]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 2, SSIM Loss: 0.09594380855560303\n",
      "Epoch: 44, Batch: 2, D Loss Real: 0.09536851942539215, D Loss Fake: 0.9206048250198364, G Loss: [10.436517715454102, 0.8642739653587341, 0.09572243690490723]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 44, Batch: 3, SSIM Loss: 0.09747827053070068\n",
      "Epoch: 44, Batch: 3, D Loss Real: 0.0328487865626812, D Loss Fake: 0.9584773182868958, G Loss: [10.649482727050781, 0.8937522172927856, 0.09755730628967285]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 4, SSIM Loss: 0.09943079948425293\n",
      "Epoch: 44, Batch: 4, D Loss Real: 0.052865441888570786, D Loss Fake: 0.9557521939277649, G Loss: [10.91528606414795, 0.9929358959197998, 0.09922349452972412]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 5, SSIM Loss: 0.09459584951400757\n",
      "Epoch: 44, Batch: 5, D Loss Real: 0.07505442947149277, D Loss Fake: 0.8679763078689575, G Loss: [10.45854663848877, 0.9470811486244202, 0.09511464834213257]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 6, SSIM Loss: 0.0947955846786499\n",
      "Epoch: 44, Batch: 6, D Loss Real: 0.03720072656869888, D Loss Fake: 0.7311455011367798, G Loss: [10.4811372756958, 1.0249319076538086, 0.09456205368041992]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 7, SSIM Loss: 0.09726405143737793\n",
      "Epoch: 44, Batch: 7, D Loss Real: 0.045097410678863525, D Loss Fake: 0.818766176700592, G Loss: [10.666728973388672, 0.9260134696960449, 0.09740716218948364]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 8, SSIM Loss: 0.09706997871398926\n",
      "Epoch: 44, Batch: 8, D Loss Real: 0.05832640454173088, D Loss Fake: 0.8649170398712158, G Loss: [10.624811172485352, 0.9079670906066895, 0.0971684455871582]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 9, SSIM Loss: 0.09902685880661011\n",
      "Epoch: 44, Batch: 9, D Loss Real: 0.0392037034034729, D Loss Fake: 0.8669146299362183, G Loss: [10.832883834838867, 0.9548325538635254, 0.09878051280975342]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 10, SSIM Loss: 0.09421825408935547\n",
      "Epoch: 44, Batch: 10, D Loss Real: 0.037637244910001755, D Loss Fake: 0.798095703125, G Loss: [10.41950511932373, 0.9990742802619934, 0.09420430660247803]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 11, SSIM Loss: 0.09295934438705444\n",
      "Epoch: 44, Batch: 11, D Loss Real: 0.07596026360988617, D Loss Fake: 1.0072534084320068, G Loss: [10.22518253326416, 0.9773972034454346, 0.09247785806655884]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 12, SSIM Loss: 0.0949411392211914\n",
      "Epoch: 44, Batch: 12, D Loss Real: 0.0903351828455925, D Loss Fake: 0.7698395848274231, G Loss: [10.476762771606445, 0.9808850288391113, 0.09495878219604492]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 13, SSIM Loss: 0.09600275754928589\n",
      "Epoch: 44, Batch: 13, D Loss Real: 0.08178816735744476, D Loss Fake: 0.8608829975128174, G Loss: [10.481256484985352, 0.9102397561073303, 0.0957101583480835]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 14, SSIM Loss: 0.10082435607910156\n",
      "Epoch: 44, Batch: 14, D Loss Real: 0.059680402278900146, D Loss Fake: 0.838783860206604, G Loss: [11.016508102416992, 0.9676356911659241, 0.10048872232437134]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 15, SSIM Loss: 0.09745591878890991\n",
      "Epoch: 44, Batch: 15, D Loss Real: 0.09376469999551773, D Loss Fake: 0.8539597988128662, G Loss: [10.631305694580078, 0.9308644533157349, 0.09700441360473633]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 16, SSIM Loss: 0.09876179695129395\n",
      "Epoch: 44, Batch: 16, D Loss Real: 0.07133080810308456, D Loss Fake: 0.9296170473098755, G Loss: [10.85702896118164, 0.9520008563995361, 0.09905028343200684]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 17, SSIM Loss: 0.09717917442321777\n",
      "Epoch: 44, Batch: 17, D Loss Real: 0.07619934529066086, D Loss Fake: 1.0847331285476685, G Loss: [10.604986190795898, 0.9526877403259277, 0.0965229868888855]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 18, SSIM Loss: 0.09488928318023682\n",
      "Epoch: 44, Batch: 18, D Loss Real: 0.19590796530246735, D Loss Fake: 0.8283165693283081, G Loss: [10.438767433166504, 0.9052556753158569, 0.09533512592315674]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 19, SSIM Loss: 0.09702575206756592\n",
      "Epoch: 44, Batch: 19, D Loss Real: 0.11769749224185944, D Loss Fake: 0.8551108241081238, G Loss: [10.637395858764648, 0.9202889204025269, 0.09717106819152832]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 20, SSIM Loss: 0.09638869762420654\n",
      "Epoch: 44, Batch: 20, D Loss Real: 0.05265551805496216, D Loss Fake: 0.901970624923706, G Loss: [10.55112075805664, 0.8818055391311646, 0.09669315814971924]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 21, SSIM Loss: 0.09468191862106323\n",
      "Epoch: 44, Batch: 21, D Loss Real: 0.06012450531125069, D Loss Fake: 0.8408757448196411, G Loss: [10.39758586883545, 0.9345910549163818, 0.09462994337081909]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 22, SSIM Loss: 0.09396117925643921\n",
      "Epoch: 44, Batch: 22, D Loss Real: 0.03554032742977142, D Loss Fake: 0.8363307118415833, G Loss: [10.309484481811523, 0.9577541947364807, 0.09351730346679688]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 23, SSIM Loss: 0.09602344036102295\n",
      "Epoch: 44, Batch: 23, D Loss Real: 0.06084708869457245, D Loss Fake: 0.7593586444854736, G Loss: [10.64542007446289, 0.9849140048027039, 0.09660506248474121]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 24, SSIM Loss: 0.09551084041595459\n",
      "Epoch: 44, Batch: 24, D Loss Real: 0.06341321021318436, D Loss Fake: 0.7997172474861145, G Loss: [10.582518577575684, 0.9712339043617249, 0.09611284732818604]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 25, SSIM Loss: 0.09566879272460938\n",
      "Epoch: 44, Batch: 25, D Loss Real: 0.045341916382312775, D Loss Fake: 0.7865749597549438, G Loss: [10.531941413879395, 0.9527959227561951, 0.09579145908355713]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 26, SSIM Loss: 0.09454888105392456\n",
      "Epoch: 44, Batch: 26, D Loss Real: 0.04663819074630737, D Loss Fake: 0.7945411801338196, G Loss: [10.43460750579834, 0.9733479619026184, 0.09461259841918945]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 27, SSIM Loss: 0.09197783470153809\n",
      "Epoch: 44, Batch: 27, D Loss Real: 0.025069262832403183, D Loss Fake: 0.7825402021408081, G Loss: [10.16474437713623, 0.9790490865707397, 0.0918569564819336]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 28, SSIM Loss: 0.09769672155380249\n",
      "Epoch: 44, Batch: 28, D Loss Real: 0.0393870584666729, D Loss Fake: 0.8486373424530029, G Loss: [10.770127296447754, 0.9826574921607971, 0.0978747010231018]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 29, SSIM Loss: 0.09712612628936768\n",
      "Epoch: 44, Batch: 29, D Loss Real: 0.029742060229182243, D Loss Fake: 0.8318367600440979, G Loss: [10.728638648986816, 0.9851980209350586, 0.097434401512146]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 30, SSIM Loss: 0.0966644287109375\n",
      "Epoch: 44, Batch: 30, D Loss Real: 0.07015205174684525, D Loss Fake: 0.7900351285934448, G Loss: [10.645621299743652, 0.984530508518219, 0.0966109037399292]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 31, SSIM Loss: 0.09291088581085205\n",
      "Epoch: 44, Batch: 31, D Loss Real: 0.10730280727148056, D Loss Fake: 0.7912456393241882, G Loss: [10.254179000854492, 0.956474781036377, 0.09297704696655273]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 32, SSIM Loss: 0.09604692459106445\n",
      "Epoch: 44, Batch: 32, D Loss Real: 0.04685097187757492, D Loss Fake: 0.827573299407959, G Loss: [10.626819610595703, 0.9684887528419495, 0.0965833067893982]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 33, SSIM Loss: 0.09502708911895752\n",
      "Epoch: 44, Batch: 33, D Loss Real: 0.04389682039618492, D Loss Fake: 0.9328281879425049, G Loss: [10.439587593078613, 0.9588724374771118, 0.09480714797973633]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 34, SSIM Loss: 0.09646987915039062\n",
      "Epoch: 44, Batch: 34, D Loss Real: 0.09400416165590286, D Loss Fake: 0.8343257904052734, G Loss: [10.541544914245605, 0.9410368204116821, 0.09600508213043213]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 35, SSIM Loss: 0.09500312805175781\n",
      "Epoch: 44, Batch: 35, D Loss Real: 0.20963819324970245, D Loss Fake: 0.9752746820449829, G Loss: [10.397855758666992, 0.930898129940033, 0.09466958045959473]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 36, SSIM Loss: 0.09576582908630371\n",
      "Epoch: 44, Batch: 36, D Loss Real: 0.10611532628536224, D Loss Fake: 0.889715313911438, G Loss: [10.434224128723145, 0.8803262710571289, 0.09553897380828857]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 37, SSIM Loss: 0.09342396259307861\n",
      "Epoch: 44, Batch: 37, D Loss Real: 0.18356382846832275, D Loss Fake: 0.929729700088501, G Loss: [10.161391258239746, 0.840189516544342, 0.09321200847625732]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 38, SSIM Loss: 0.09686517715454102\n",
      "Epoch: 44, Batch: 38, D Loss Real: 0.023002926260232925, D Loss Fake: 1.4618937969207764, G Loss: [10.770966529846191, 1.0289567708969116, 0.0974200963973999]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 39, SSIM Loss: 0.09591734409332275\n",
      "Epoch: 44, Batch: 39, D Loss Real: 0.40131840109825134, D Loss Fake: 0.7979027628898621, G Loss: [10.500839233398438, 0.9466437101364136, 0.09554195404052734]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 44, Batch: 40, SSIM Loss: 0.0978473424911499\n",
      "Epoch: 44, Batch: 40, D Loss Real: 0.40586045384407043, D Loss Fake: 0.9972337484359741, G Loss: [10.529739379882812, 0.7374826669692993, 0.09792256355285645]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 41, SSIM Loss: 0.09362101554870605\n",
      "Epoch: 44, Batch: 41, D Loss Real: 0.38257908821105957, D Loss Fake: 1.1147207021713257, G Loss: [10.107818603515625, 0.7000958323478699, 0.0940772294998169]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 42, SSIM Loss: 0.09498381614685059\n",
      "Epoch: 44, Batch: 42, D Loss Real: 0.27836859226226807, D Loss Fake: 1.208458423614502, G Loss: [10.129700660705566, 0.6654003858566284, 0.0946429967880249]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 44, Batch: 43, SSIM Loss: 0.09560668468475342\n",
      "Epoch: 44, Batch: 43, D Loss Real: 0.1600012481212616, D Loss Fake: 1.1292588710784912, G Loss: [10.298564910888672, 0.7172913551330566, 0.09581273794174194]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 44, Batch: 44, SSIM Loss: 0.0918077826499939\n",
      "Epoch: 44, Batch: 44, D Loss Real: 0.17833098769187927, D Loss Fake: 0.9089149832725525, G Loss: [10.059236526489258, 0.8891445398330688, 0.09170091152191162]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 45, SSIM Loss: 0.10138702392578125\n",
      "Epoch: 44, Batch: 45, D Loss Real: 0.07491153478622437, D Loss Fake: 0.9199044704437256, G Loss: [11.08583927154541, 0.9342144727706909, 0.1015162467956543]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 46, SSIM Loss: 0.09373962879180908\n",
      "Epoch: 44, Batch: 46, D Loss Real: 0.2533346116542816, D Loss Fake: 0.8851460814476013, G Loss: [10.266931533813477, 0.8755581378936768, 0.093913733959198]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 47, SSIM Loss: 0.10146927833557129\n",
      "Epoch: 44, Batch: 47, D Loss Real: 0.054462239146232605, D Loss Fake: 1.103716254234314, G Loss: [11.02470874786377, 0.8787106275558472, 0.10145998001098633]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 48, SSIM Loss: 0.09567499160766602\n",
      "Epoch: 44, Batch: 48, D Loss Real: 0.09922289848327637, D Loss Fake: 0.9112393260002136, G Loss: [10.448782920837402, 0.90557861328125, 0.09543204307556152]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 49, SSIM Loss: 0.09396940469741821\n",
      "Epoch: 44, Batch: 49, D Loss Real: 0.20008128881454468, D Loss Fake: 1.0226837396621704, G Loss: [10.248038291931152, 0.8530705571174622, 0.09394967555999756]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 50, SSIM Loss: 0.09594762325286865\n",
      "Epoch: 44, Batch: 50, D Loss Real: 0.09299620985984802, D Loss Fake: 1.120106816291809, G Loss: [10.523672103881836, 0.947690486907959, 0.0957598090171814]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 51, SSIM Loss: 0.09362602233886719\n",
      "Epoch: 44, Batch: 51, D Loss Real: 0.1849697083234787, D Loss Fake: 0.8524073362350464, G Loss: [10.234894752502441, 0.8951987028121948, 0.09339696168899536]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 52, SSIM Loss: 0.10014951229095459\n",
      "Epoch: 44, Batch: 52, D Loss Real: 0.07021117210388184, D Loss Fake: 0.8513049483299255, G Loss: [10.891722679138184, 0.8988010287284851, 0.09992921352386475]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 53, SSIM Loss: 0.09278488159179688\n",
      "Epoch: 44, Batch: 53, D Loss Real: 0.06677170842885971, D Loss Fake: 0.8219641447067261, G Loss: [10.239490509033203, 0.9193859696388245, 0.09320104122161865]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 54, SSIM Loss: 0.09774810075759888\n",
      "Epoch: 44, Batch: 54, D Loss Real: 0.06671544164419174, D Loss Fake: 0.8475669622421265, G Loss: [10.725960731506348, 0.9499647617340088, 0.09775996208190918]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 55, SSIM Loss: 0.0951041579246521\n",
      "Epoch: 44, Batch: 55, D Loss Real: 0.12504363059997559, D Loss Fake: 0.9108360409736633, G Loss: [10.412089347839355, 0.9033126831054688, 0.09508776664733887]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 56, SSIM Loss: 0.09480893611907959\n",
      "Epoch: 44, Batch: 56, D Loss Real: 0.06880354136228561, D Loss Fake: 0.9953517317771912, G Loss: [10.444028854370117, 0.9585222601890564, 0.09485507011413574]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 57, SSIM Loss: 0.09781670570373535\n",
      "Epoch: 44, Batch: 57, D Loss Real: 0.0639478862285614, D Loss Fake: 0.8358079195022583, G Loss: [10.7247314453125, 0.9386979937553406, 0.09786033630371094]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 58, SSIM Loss: 0.09504640102386475\n",
      "Epoch: 44, Batch: 58, D Loss Real: 0.09471946954727173, D Loss Fake: 1.2505602836608887, G Loss: [10.540365219116211, 1.0172715187072754, 0.09523093700408936]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 59, SSIM Loss: 0.09632682800292969\n",
      "Epoch: 44, Batch: 59, D Loss Real: 0.20487840473651886, D Loss Fake: 0.9017833471298218, G Loss: [10.560081481933594, 0.961790144443512, 0.09598290920257568]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 60, SSIM Loss: 0.09670239686965942\n",
      "Epoch: 44, Batch: 60, D Loss Real: 0.1574135571718216, D Loss Fake: 0.8604445457458496, G Loss: [10.598689079284668, 0.9132862687110901, 0.09685403108596802]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 44, Batch: 61, SSIM Loss: 0.09456276893615723\n",
      "Epoch: 44, Batch: 61, D Loss Real: 0.09886183589696884, D Loss Fake: 0.9286400079727173, G Loss: [10.298493385314941, 0.9154829382896423, 0.09383010864257812]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 44, Batch: 62, SSIM Loss: 0.09790229797363281\n",
      "Epoch: 44, Batch: 62, D Loss Real: 0.13747252523899078, D Loss Fake: 0.8917810320854187, G Loss: [10.621440887451172, 0.8720759749412537, 0.09749364852905273]\n",
      "1/1 [==============================] - 0s 143ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:13:32.334664: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:13:33.796045: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Batch: 1, SSIM Loss: 0.09367763996124268\n",
      "Epoch: 45, Batch: 1, D Loss Real: 0.093732550740242, D Loss Fake: 0.9183821678161621, G Loss: [10.248147964477539, 0.8875012397766113, 0.09360647201538086]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 2, SSIM Loss: 0.09447479248046875\n",
      "Epoch: 45, Batch: 2, D Loss Real: 0.10242335498332977, D Loss Fake: 0.8821827173233032, G Loss: [10.334259986877441, 0.8820062875747681, 0.09452253580093384]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 3, SSIM Loss: 0.09543657302856445\n",
      "Epoch: 45, Batch: 3, D Loss Real: 0.03055228851735592, D Loss Fake: 0.8897700309753418, G Loss: [10.458597183227539, 0.9331914186477661, 0.09525406360626221]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 4, SSIM Loss: 0.09554779529571533\n",
      "Epoch: 45, Batch: 4, D Loss Real: 0.07038071006536484, D Loss Fake: 0.879847526550293, G Loss: [10.481358528137207, 0.9437096118927002, 0.09537649154663086]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 5, SSIM Loss: 0.09396857023239136\n",
      "Epoch: 45, Batch: 5, D Loss Real: 0.11361132562160492, D Loss Fake: 0.9347332715988159, G Loss: [10.338075637817383, 0.9652804732322693, 0.0937279462814331]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 6, SSIM Loss: 0.09360897541046143\n",
      "Epoch: 45, Batch: 6, D Loss Real: 0.1025371104478836, D Loss Fake: 0.7991974949836731, G Loss: [10.325887680053711, 0.9926161766052246, 0.09333270788192749]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 7, SSIM Loss: 0.09564483165740967\n",
      "Epoch: 45, Batch: 7, D Loss Real: 0.10316063463687897, D Loss Fake: 0.8757523894309998, G Loss: [10.447434425354004, 0.8931798934936523, 0.0955425500869751]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 8, SSIM Loss: 0.09618347883224487\n",
      "Epoch: 45, Batch: 8, D Loss Real: 0.09987062215805054, D Loss Fake: 0.9366341829299927, G Loss: [10.525205612182617, 0.9127640724182129, 0.09612441062927246]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 9, SSIM Loss: 0.09699583053588867\n",
      "Epoch: 45, Batch: 9, D Loss Real: 0.08493133634328842, D Loss Fake: 0.8544014692306519, G Loss: [10.638213157653809, 0.9350484609603882, 0.09703165292739868]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 10, SSIM Loss: 0.09260952472686768\n",
      "Epoch: 45, Batch: 10, D Loss Real: 0.09882437437772751, D Loss Fake: 0.795175313949585, G Loss: [10.20004653930664, 0.948958158493042, 0.0925108790397644]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 11, SSIM Loss: 0.09160184860229492\n",
      "Epoch: 45, Batch: 11, D Loss Real: 0.07509832829236984, D Loss Fake: 1.0212947130203247, G Loss: [10.085049629211426, 0.9179510474205017, 0.09167098999023438]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 12, SSIM Loss: 0.09410464763641357\n",
      "Epoch: 45, Batch: 12, D Loss Real: 0.08082452416419983, D Loss Fake: 0.7974036931991577, G Loss: [10.428449630737305, 0.9875560998916626, 0.09440892934799194]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 13, SSIM Loss: 0.09470009803771973\n",
      "Epoch: 45, Batch: 13, D Loss Real: 0.06425973773002625, D Loss Fake: 0.9458966851234436, G Loss: [10.437647819519043, 0.9473374485969543, 0.09490311145782471]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 14, SSIM Loss: 0.09965360164642334\n",
      "Epoch: 45, Batch: 14, D Loss Real: 0.12320393323898315, D Loss Fake: 0.8648265600204468, G Loss: [10.89743423461914, 0.9475056529045105, 0.09949928522109985]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 15, SSIM Loss: 0.09553855657577515\n",
      "Epoch: 45, Batch: 15, D Loss Real: 0.14677727222442627, D Loss Fake: 0.8815085291862488, G Loss: [10.477914810180664, 0.8918610215187073, 0.0958605408668518]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 16, SSIM Loss: 0.09772515296936035\n",
      "Epoch: 45, Batch: 16, D Loss Real: 0.0806737169623375, D Loss Fake: 1.0030405521392822, G Loss: [10.70440673828125, 0.9137482047080994, 0.09790658950805664]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 17, SSIM Loss: 0.0948648452758789\n",
      "Epoch: 45, Batch: 17, D Loss Real: 0.09802143275737762, D Loss Fake: 0.8799058198928833, G Loss: [10.43295955657959, 0.9309412240982056, 0.09502017498016357]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 18, SSIM Loss: 0.09298765659332275\n",
      "Epoch: 45, Batch: 18, D Loss Real: 0.06785088777542114, D Loss Fake: 0.9508073925971985, G Loss: [10.261273384094238, 0.9697787761688232, 0.09291493892669678]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 19, SSIM Loss: 0.0964210033416748\n",
      "Epoch: 45, Batch: 19, D Loss Real: 0.12438832223415375, D Loss Fake: 0.8206461071968079, G Loss: [10.623254776000977, 0.9622713327407837, 0.09660983085632324]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 20, SSIM Loss: 0.09593343734741211\n",
      "Epoch: 45, Batch: 20, D Loss Real: 0.08546039462089539, D Loss Fake: 0.934302031993866, G Loss: [10.52857494354248, 0.9196979999542236, 0.09608876705169678]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 21, SSIM Loss: 0.09334230422973633\n",
      "Epoch: 45, Batch: 21, D Loss Real: 0.08355413377285004, D Loss Fake: 0.8094820976257324, G Loss: [10.32634162902832, 1.0026249885559082, 0.09323716163635254]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 22, SSIM Loss: 0.0929877758026123\n",
      "Epoch: 45, Batch: 22, D Loss Real: 0.06346326321363449, D Loss Fake: 0.971539318561554, G Loss: [10.230835914611816, 0.9344548583030701, 0.0929638147354126]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 23, SSIM Loss: 0.09556275606155396\n",
      "Epoch: 45, Batch: 23, D Loss Real: 0.09247791022062302, D Loss Fake: 0.8339011669158936, G Loss: [10.531866073608398, 0.9897293448448181, 0.09542137384414673]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 24, SSIM Loss: 0.09484922885894775\n",
      "Epoch: 45, Batch: 24, D Loss Real: 0.09065624326467514, D Loss Fake: 0.9344901442527771, G Loss: [10.41711711883545, 0.9290117025375366, 0.09488105773925781]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 25, SSIM Loss: 0.09518378973007202\n",
      "Epoch: 45, Batch: 25, D Loss Real: 0.05491587519645691, D Loss Fake: 0.8999930024147034, G Loss: [10.490581512451172, 0.9744017124176025, 0.0951617956161499]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 26, SSIM Loss: 0.0932474136352539\n",
      "Epoch: 45, Batch: 26, D Loss Real: 0.08367335051298141, D Loss Fake: 1.0239337682724, G Loss: [10.279987335205078, 0.9595434665679932, 0.09320443868637085]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 27, SSIM Loss: 0.0911211371421814\n",
      "Epoch: 45, Batch: 27, D Loss Real: 0.08795404434204102, D Loss Fake: 0.7204891443252563, G Loss: [10.200389862060547, 1.0688157081604004, 0.09131574630737305]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 28, SSIM Loss: 0.096366286277771\n",
      "Epoch: 45, Batch: 28, D Loss Real: 0.1584096997976303, D Loss Fake: 1.0434389114379883, G Loss: [10.536275863647461, 0.9254612922668457, 0.09610813856124878]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 29, SSIM Loss: 0.09763318300247192\n",
      "Epoch: 45, Batch: 29, D Loss Real: 0.13574010133743286, D Loss Fake: 0.9379872679710388, G Loss: [10.644740104675293, 0.9018419981002808, 0.09742897748947144]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 30, SSIM Loss: 0.09619861841201782\n",
      "Epoch: 45, Batch: 30, D Loss Real: 0.12975919246673584, D Loss Fake: 0.9868388772010803, G Loss: [10.558778762817383, 0.9464206695556641, 0.0961235761642456]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 31, SSIM Loss: 0.09337723255157471\n",
      "Epoch: 45, Batch: 31, D Loss Real: 0.15705497562885284, D Loss Fake: 0.9612667560577393, G Loss: [10.221137046813965, 0.8746516704559326, 0.09346485137939453]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 32, SSIM Loss: 0.09588921070098877\n",
      "Epoch: 45, Batch: 32, D Loss Real: 0.10680073499679565, D Loss Fake: 0.9913995862007141, G Loss: [10.426068305969238, 0.830805778503418, 0.09595263004302979]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 33, SSIM Loss: 0.09360462427139282\n",
      "Epoch: 45, Batch: 33, D Loss Real: 0.10269518941640854, D Loss Fake: 1.0174115896224976, G Loss: [10.27954387664795, 0.9188488721847534, 0.09360694885253906]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 34, SSIM Loss: 0.09438329935073853\n",
      "Epoch: 45, Batch: 34, D Loss Real: 0.20331551134586334, D Loss Fake: 1.0094530582427979, G Loss: [10.28175163269043, 0.8359887599945068, 0.09445762634277344]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 45, Batch: 35, SSIM Loss: 0.0947076678276062\n",
      "Epoch: 45, Batch: 35, D Loss Real: 0.3192637860774994, D Loss Fake: 1.006635308265686, G Loss: [10.248819351196289, 0.7711378335952759, 0.09477680921554565]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 36, SSIM Loss: 0.09399741888046265\n",
      "Epoch: 45, Batch: 36, D Loss Real: 0.10633614659309387, D Loss Fake: 1.2959845066070557, G Loss: [10.242085456848145, 0.8384639024734497, 0.09403622150421143]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 37, SSIM Loss: 0.09371274709701538\n",
      "Epoch: 45, Batch: 37, D Loss Real: 0.28534719347953796, D Loss Fake: 1.0028008222579956, G Loss: [10.183883666992188, 0.8276953101158142, 0.09356188774108887]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 38, SSIM Loss: 0.09674370288848877\n",
      "Epoch: 45, Batch: 38, D Loss Real: 0.16339625418186188, D Loss Fake: 1.1002988815307617, G Loss: [10.504158973693848, 0.8016076683998108, 0.09702551364898682]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 39, SSIM Loss: 0.09364628791809082\n",
      "Epoch: 45, Batch: 39, D Loss Real: 0.206296905875206, D Loss Fake: 0.9734967350959778, G Loss: [10.213106155395508, 0.8461224436759949, 0.0936698317527771]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 40, SSIM Loss: 0.09708136320114136\n",
      "Epoch: 45, Batch: 40, D Loss Real: 0.17333340644836426, D Loss Fake: 1.296926736831665, G Loss: [10.556376457214355, 0.8489966988563538, 0.09707379341125488]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 41, SSIM Loss: 0.09418481588363647\n",
      "Epoch: 45, Batch: 41, D Loss Real: 0.351873517036438, D Loss Fake: 0.9927801489830017, G Loss: [10.220049858093262, 0.8063310384750366, 0.09413719177246094]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 42, SSIM Loss: 0.09438931941986084\n",
      "Epoch: 45, Batch: 42, D Loss Real: 0.2412298172712326, D Loss Fake: 1.0076942443847656, G Loss: [10.289548873901367, 0.7814518213272095, 0.09508097171783447]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 43, SSIM Loss: 0.0950319766998291\n",
      "Epoch: 45, Batch: 43, D Loss Real: 0.09459914267063141, D Loss Fake: 1.0315388441085815, G Loss: [10.339731216430664, 0.8510827422142029, 0.09488648176193237]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 44, SSIM Loss: 0.09257614612579346\n",
      "Epoch: 45, Batch: 44, D Loss Real: 0.13329008221626282, D Loss Fake: 0.9738020300865173, G Loss: [10.121065139770508, 0.8714499473571777, 0.09249615669250488]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 45, SSIM Loss: 0.10038745403289795\n",
      "Epoch: 45, Batch: 45, D Loss Real: 0.06953411549329758, D Loss Fake: 0.8326728343963623, G Loss: [11.028289794921875, 0.9899139404296875, 0.10038375854492188]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 45, Batch: 46, SSIM Loss: 0.0943828821182251\n",
      "Epoch: 45, Batch: 46, D Loss Real: 0.194431334733963, D Loss Fake: 0.9655700922012329, G Loss: [10.267614364624023, 0.8501517176628113, 0.09417462348937988]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 47, SSIM Loss: 0.10030430555343628\n",
      "Epoch: 45, Batch: 47, D Loss Real: 0.03839091956615448, D Loss Fake: 1.038225531578064, G Loss: [10.96330451965332, 0.9192301630973816, 0.10044074058532715]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 48, SSIM Loss: 0.0954657793045044\n",
      "Epoch: 45, Batch: 48, D Loss Real: 0.0537506639957428, D Loss Fake: 1.2450315952301025, G Loss: [10.53100299835205, 1.0173027515411377, 0.09513700008392334]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 49, SSIM Loss: 0.0928504467010498\n",
      "Epoch: 45, Batch: 49, D Loss Real: 0.3475382328033447, D Loss Fake: 0.8323295712471008, G Loss: [10.198894500732422, 0.9106785655021667, 0.09288215637207031]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 45, Batch: 50, SSIM Loss: 0.09540241956710815\n",
      "Epoch: 45, Batch: 50, D Loss Real: 0.19341737031936646, D Loss Fake: 1.1216416358947754, G Loss: [10.410394668579102, 0.8191074132919312, 0.0959128737449646]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 45, Batch: 51, SSIM Loss: 0.09348118305206299\n",
      "Epoch: 45, Batch: 51, D Loss Real: 0.18206331133842468, D Loss Fake: 0.9665131568908691, G Loss: [10.270050048828125, 0.902429461479187, 0.09367620944976807]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 52, SSIM Loss: 0.0981711745262146\n",
      "Epoch: 45, Batch: 52, D Loss Real: 0.1063755601644516, D Loss Fake: 1.0474014282226562, G Loss: [10.702033042907715, 0.8700911998748779, 0.098319411277771]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 53, SSIM Loss: 0.0917467474937439\n",
      "Epoch: 45, Batch: 53, D Loss Real: 0.1376812756061554, D Loss Fake: 0.9239082336425781, G Loss: [10.087932586669922, 0.9109570384025574, 0.0917697548866272]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 54, SSIM Loss: 0.09700536727905273\n",
      "Epoch: 45, Batch: 54, D Loss Real: 0.14956089854240417, D Loss Fake: 0.9265412092208862, G Loss: [10.575702667236328, 0.8835582733154297, 0.09692144393920898]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 55, SSIM Loss: 0.09392672777175903\n",
      "Epoch: 45, Batch: 55, D Loss Real: 0.20381468534469604, D Loss Fake: 1.23988676071167, G Loss: [10.240126609802246, 0.8099204301834106, 0.09430205821990967]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 56, SSIM Loss: 0.09580498933792114\n",
      "Epoch: 45, Batch: 56, D Loss Real: 0.08524957299232483, D Loss Fake: 1.256876826286316, G Loss: [10.565374374389648, 1.0087356567382812, 0.09556639194488525]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 57, SSIM Loss: 0.09799420833587646\n",
      "Epoch: 45, Batch: 57, D Loss Real: 0.231223464012146, D Loss Fake: 0.84398353099823, G Loss: [10.76121711730957, 0.9340615272521973, 0.09827154874801636]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 58, SSIM Loss: 0.0947265625\n",
      "Epoch: 45, Batch: 58, D Loss Real: 0.35468778014183044, D Loss Fake: 0.9142090082168579, G Loss: [10.237884521484375, 0.8277053833007812, 0.09410178661346436]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 59, SSIM Loss: 0.09307444095611572\n",
      "Epoch: 45, Batch: 59, D Loss Real: 0.22815269231796265, D Loss Fake: 1.2473822832107544, G Loss: [10.015756607055664, 0.7247393131256104, 0.09291017055511475]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 60, SSIM Loss: 0.09905493259429932\n",
      "Epoch: 45, Batch: 60, D Loss Real: 0.12119901925325394, D Loss Fake: 0.9851043820381165, G Loss: [10.779823303222656, 0.889802873134613, 0.0989001989364624]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 61, SSIM Loss: 0.09369254112243652\n",
      "Epoch: 45, Batch: 61, D Loss Real: 0.167323037981987, D Loss Fake: 1.0496742725372314, G Loss: [10.259612083435059, 0.9078226089477539, 0.09351789951324463]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 45, Batch: 62, SSIM Loss: 0.0976095199584961\n",
      "Epoch: 45, Batch: 62, D Loss Real: 0.21213026344776154, D Loss Fake: 0.8726788759231567, G Loss: [10.712846755981445, 0.910207986831665, 0.09802639484405518]\n",
      "1/1 [==============================] - 0s 141ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:14:55.310421: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:14:56.769087: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Batch: 1, SSIM Loss: 0.09295427799224854\n",
      "Epoch: 46, Batch: 1, D Loss Real: 0.1237853392958641, D Loss Fake: 1.0355441570281982, G Loss: [10.1929349899292, 0.9050166606903076, 0.09287917613983154]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 2, SSIM Loss: 0.09483873844146729\n",
      "Epoch: 46, Batch: 2, D Loss Real: 0.14987970888614655, D Loss Fake: 1.0260224342346191, G Loss: [10.355554580688477, 0.8339860439300537, 0.09521567821502686]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 46, Batch: 3, SSIM Loss: 0.09499943256378174\n",
      "Epoch: 46, Batch: 3, D Loss Real: 0.06017034500837326, D Loss Fake: 1.0986487865447998, G Loss: [10.499115943908691, 0.9860895872116089, 0.09513026475906372]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 4, SSIM Loss: 0.09494131803512573\n",
      "Epoch: 46, Batch: 4, D Loss Real: 0.13528236746788025, D Loss Fake: 0.8993023037910461, G Loss: [10.401680946350098, 0.9452009201049805, 0.09456479549407959]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 46, Batch: 5, SSIM Loss: 0.09410268068313599\n",
      "Epoch: 46, Batch: 5, D Loss Real: 0.14811740815639496, D Loss Fake: 1.121555209159851, G Loss: [10.34151554107666, 0.9081210494041443, 0.0943339467048645]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 6, SSIM Loss: 0.09423774480819702\n",
      "Epoch: 46, Batch: 6, D Loss Real: 0.10385674983263016, D Loss Fake: 0.9073201417922974, G Loss: [10.36125659942627, 0.927390992641449, 0.09433865547180176]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 46, Batch: 7, SSIM Loss: 0.09644007682800293\n",
      "Epoch: 46, Batch: 7, D Loss Real: 0.08861647546291351, D Loss Fake: 1.0856388807296753, G Loss: [10.559700965881348, 0.9187806248664856, 0.09640920162200928]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 8, SSIM Loss: 0.09590274095535278\n",
      "Epoch: 46, Batch: 8, D Loss Real: 0.2017780989408493, D Loss Fake: 0.8450273275375366, G Loss: [10.511330604553223, 0.9466562867164612, 0.09564673900604248]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 46, Batch: 9, SSIM Loss: 0.09663468599319458\n",
      "Epoch: 46, Batch: 9, D Loss Real: 0.11712085455656052, D Loss Fake: 1.0674777030944824, G Loss: [10.589645385742188, 0.9456915259361267, 0.09643954038619995]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 10, SSIM Loss: 0.09275317192077637\n",
      "Epoch: 46, Batch: 10, D Loss Real: 0.1851257085800171, D Loss Fake: 1.0110442638397217, G Loss: [10.160459518432617, 0.8720529079437256, 0.09288406372070312]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 11, SSIM Loss: 0.09279888868331909\n",
      "Epoch: 46, Batch: 11, D Loss Real: 0.1502126306295395, D Loss Fake: 1.2904689311981201, G Loss: [10.179774284362793, 0.8981627821922302, 0.09281611442565918]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 12, SSIM Loss: 0.09551870822906494\n",
      "Epoch: 46, Batch: 12, D Loss Real: 0.17832964658737183, D Loss Fake: 0.9596656560897827, G Loss: [10.491079330444336, 0.9019736647605896, 0.0958910584449768]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 13, SSIM Loss: 0.09370666742324829\n",
      "Epoch: 46, Batch: 13, D Loss Real: 0.1330415904521942, D Loss Fake: 1.1329454183578491, G Loss: [10.30390739440918, 0.9078903794288635, 0.09396016597747803]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 14, SSIM Loss: 0.09819871187210083\n",
      "Epoch: 46, Batch: 14, D Loss Real: 0.2710139751434326, D Loss Fake: 0.8828288316726685, G Loss: [10.70760440826416, 0.8569483160972595, 0.09850656986236572]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 15, SSIM Loss: 0.0963747501373291\n",
      "Epoch: 46, Batch: 15, D Loss Real: 0.238414004445076, D Loss Fake: 1.0804275274276733, G Loss: [10.385455131530762, 0.7795819044113159, 0.09605872631072998]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 16, SSIM Loss: 0.098807692527771\n",
      "Epoch: 46, Batch: 16, D Loss Real: 0.11188584566116333, D Loss Fake: 1.237077236175537, G Loss: [10.662959098815918, 0.7761335968971252, 0.09886825084686279]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 17, SSIM Loss: 0.09297740459442139\n",
      "Epoch: 46, Batch: 17, D Loss Real: 0.15507858991622925, D Loss Fake: 1.0115960836410522, G Loss: [10.160778999328613, 0.871353268623352, 0.09289425611495972]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 18, SSIM Loss: 0.09276187419891357\n",
      "Epoch: 46, Batch: 18, D Loss Real: 0.13786256313323975, D Loss Fake: 1.0040333271026611, G Loss: [10.175222396850586, 0.8989994525909424, 0.09276223182678223]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 19, SSIM Loss: 0.09540098905563354\n",
      "Epoch: 46, Batch: 19, D Loss Real: 0.17180459201335907, D Loss Fake: 0.9191398024559021, G Loss: [10.452446937561035, 0.9003200531005859, 0.09552127122879028]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 20, SSIM Loss: 0.09509676694869995\n",
      "Epoch: 46, Batch: 20, D Loss Real: 0.13957414031028748, D Loss Fake: 1.3448076248168945, G Loss: [10.423751831054688, 0.8822044134140015, 0.09541547298431396]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 21, SSIM Loss: 0.09300875663757324\n",
      "Epoch: 46, Batch: 21, D Loss Real: 0.16990730166435242, D Loss Fake: 0.7839725613594055, G Loss: [10.283430099487305, 1.0116287469863892, 0.09271800518035889]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 22, SSIM Loss: 0.09208536148071289\n",
      "Epoch: 46, Batch: 22, D Loss Real: 0.17175644636154175, D Loss Fake: 1.0036492347717285, G Loss: [10.044379234313965, 0.8553823232650757, 0.09188997745513916]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 23, SSIM Loss: 0.09497618675231934\n",
      "Epoch: 46, Batch: 23, D Loss Real: 0.19462847709655762, D Loss Fake: 0.9661303758621216, G Loss: [10.33251953125, 0.8479311466217041, 0.09484589099884033]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 24, SSIM Loss: 0.09577924013137817\n",
      "Epoch: 46, Batch: 24, D Loss Real: 0.10788091272115707, D Loss Fake: 0.9198939204216003, G Loss: [10.46705150604248, 0.9018522500991821, 0.09565198421478271]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 25, SSIM Loss: 0.09584462642669678\n",
      "Epoch: 46, Batch: 25, D Loss Real: 0.07377900183200836, D Loss Fake: 0.951711893081665, G Loss: [10.459701538085938, 0.9093445539474487, 0.09550356864929199]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 26, SSIM Loss: 0.09306693077087402\n",
      "Epoch: 46, Batch: 26, D Loss Real: 0.06768474727869034, D Loss Fake: 1.2221601009368896, G Loss: [10.151869773864746, 0.8701149225234985, 0.09281754493713379]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 27, SSIM Loss: 0.09173887968063354\n",
      "Epoch: 46, Batch: 27, D Loss Real: 0.09255611896514893, D Loss Fake: 0.8395460844039917, G Loss: [10.235929489135742, 1.0457098484039307, 0.09190219640731812]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 28, SSIM Loss: 0.09650963544845581\n",
      "Epoch: 46, Batch: 28, D Loss Real: 0.16808582842350006, D Loss Fake: 0.9852741956710815, G Loss: [10.587910652160645, 0.9127474427223206, 0.0967516303062439]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 29, SSIM Loss: 0.09666597843170166\n",
      "Epoch: 46, Batch: 29, D Loss Real: 0.15598757565021515, D Loss Fake: 1.4196370840072632, G Loss: [10.595268249511719, 0.9221674203872681, 0.09673100709915161]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 30, SSIM Loss: 0.09547233581542969\n",
      "Epoch: 46, Batch: 30, D Loss Real: 0.20682233572006226, D Loss Fake: 0.9576260447502136, G Loss: [10.4714994430542, 0.8949639201164246, 0.09576535224914551]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 31, SSIM Loss: 0.09306252002716064\n",
      "Epoch: 46, Batch: 31, D Loss Real: 0.2727525532245636, D Loss Fake: 0.9991623163223267, G Loss: [10.13723087310791, 0.8070955276489258, 0.09330135583877563]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 32, SSIM Loss: 0.09566009044647217\n",
      "Epoch: 46, Batch: 32, D Loss Real: 0.15189072489738464, D Loss Fake: 0.9602105617523193, G Loss: [10.41526985168457, 0.8638882040977478, 0.09551382064819336]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 33, SSIM Loss: 0.09394872188568115\n",
      "Epoch: 46, Batch: 33, D Loss Real: 0.14440512657165527, D Loss Fake: 0.926177442073822, G Loss: [10.379523277282715, 1.0051912069320679, 0.09374332427978516]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 34, SSIM Loss: 0.0945960283279419\n",
      "Epoch: 46, Batch: 34, D Loss Real: 0.16200199723243713, D Loss Fake: 0.9932304620742798, G Loss: [10.28686809539795, 0.8451290130615234, 0.09441739320755005]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 35, SSIM Loss: 0.09477818012237549\n",
      "Epoch: 46, Batch: 35, D Loss Real: 0.2591232657432556, D Loss Fake: 1.0819642543792725, G Loss: [10.252293586730957, 0.8077945113182068, 0.09444499015808105]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 46, Batch: 36, SSIM Loss: 0.09405171871185303\n",
      "Epoch: 46, Batch: 36, D Loss Real: 0.11510561406612396, D Loss Fake: 1.2573679685592651, G Loss: [10.17068862915039, 0.7815319895744324, 0.09389156103134155]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 37, SSIM Loss: 0.0932013988494873\n",
      "Epoch: 46, Batch: 37, D Loss Real: 0.145847350358963, D Loss Fake: 1.2722370624542236, G Loss: [10.229263305664062, 0.9177068471908569, 0.09311556816101074]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 38, SSIM Loss: 0.09692955017089844\n",
      "Epoch: 46, Batch: 38, D Loss Real: 0.13292446732521057, D Loss Fake: 1.1825792789459229, G Loss: [10.564043045043945, 0.86287522315979, 0.09701168537139893]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 39, SSIM Loss: 0.09402495622634888\n",
      "Epoch: 46, Batch: 39, D Loss Real: 0.23224085569381714, D Loss Fake: 0.990185558795929, G Loss: [10.308103561401367, 0.8844479918479919, 0.09423655271530151]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 40, SSIM Loss: 0.096885085105896\n",
      "Epoch: 46, Batch: 40, D Loss Real: 0.20113711059093475, D Loss Fake: 1.1887301206588745, G Loss: [10.45962142944336, 0.7920288443565369, 0.09667593240737915]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 41, SSIM Loss: 0.09212708473205566\n",
      "Epoch: 46, Batch: 41, D Loss Real: 0.28559523820877075, D Loss Fake: 1.188161849975586, G Loss: [10.090877532958984, 0.8027100563049316, 0.09288167953491211]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 42, SSIM Loss: 0.09292685985565186\n",
      "Epoch: 46, Batch: 42, D Loss Real: 0.26639607548713684, D Loss Fake: 1.0634551048278809, G Loss: [10.100982666015625, 0.7761275768280029, 0.09324854612350464]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 43, SSIM Loss: 0.09580504894256592\n",
      "Epoch: 46, Batch: 43, D Loss Real: 0.17226599156856537, D Loss Fake: 1.2228643894195557, G Loss: [10.314103126525879, 0.7364709973335266, 0.09577631950378418]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 46, Batch: 44, SSIM Loss: 0.09227418899536133\n",
      "Epoch: 46, Batch: 44, D Loss Real: 0.22666846215724945, D Loss Fake: 1.0812594890594482, G Loss: [10.025128364562988, 0.8066922426223755, 0.09218436479568481]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 45, SSIM Loss: 0.10055339336395264\n",
      "Epoch: 46, Batch: 45, D Loss Real: 0.16392835974693298, D Loss Fake: 0.8834584951400757, G Loss: [11.048333168029785, 1.0112630128860474, 0.10037070512771606]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 46, SSIM Loss: 0.0947883129119873\n",
      "Epoch: 46, Batch: 46, D Loss Real: 0.3537924289703369, D Loss Fake: 1.095085859298706, G Loss: [10.248636245727539, 0.7973311543464661, 0.09451305866241455]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 47, SSIM Loss: 0.10070997476577759\n",
      "Epoch: 46, Batch: 47, D Loss Real: 0.10309691727161407, D Loss Fake: 1.1248104572296143, G Loss: [10.91028881072998, 0.8276088237762451, 0.10082679986953735]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 48, SSIM Loss: 0.09459584951400757\n",
      "Epoch: 46, Batch: 48, D Loss Real: 0.10870162397623062, D Loss Fake: 1.2845796346664429, G Loss: [10.369129180908203, 0.8880512714385986, 0.09481078386306763]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 49, SSIM Loss: 0.09369724988937378\n",
      "Epoch: 46, Batch: 49, D Loss Real: 0.2632065713405609, D Loss Fake: 0.9880205392837524, G Loss: [10.257996559143066, 0.8953649997711182, 0.09362632036209106]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 50, SSIM Loss: 0.09580463171005249\n",
      "Epoch: 46, Batch: 50, D Loss Real: 0.1751713752746582, D Loss Fake: 1.2069257497787476, G Loss: [10.377445220947266, 0.821104109287262, 0.09556341171264648]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 51, SSIM Loss: 0.09291964769363403\n",
      "Epoch: 46, Batch: 51, D Loss Real: 0.2477935403585434, D Loss Fake: 0.9530186057090759, G Loss: [10.171882629394531, 0.8797811269760132, 0.09292101860046387]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 52, SSIM Loss: 0.09845137596130371\n",
      "Epoch: 46, Batch: 52, D Loss Real: 0.12427955120801926, D Loss Fake: 1.0270681381225586, G Loss: [10.691113471984863, 0.8588027358055115, 0.09832310676574707]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 53, SSIM Loss: 0.0917133092880249\n",
      "Epoch: 46, Batch: 53, D Loss Real: 0.14459927380084991, D Loss Fake: 0.9258392453193665, G Loss: [10.081000328063965, 0.9092344641685486, 0.0917176604270935]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 54, SSIM Loss: 0.09676319360733032\n",
      "Epoch: 46, Batch: 54, D Loss Real: 0.15005135536193848, D Loss Fake: 1.0106728076934814, G Loss: [10.578917503356934, 0.8909991383552551, 0.09687918424606323]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 55, SSIM Loss: 0.09472882747650146\n",
      "Epoch: 46, Batch: 55, D Loss Real: 0.20166254043579102, D Loss Fake: 1.2362985610961914, G Loss: [10.373530387878418, 0.8829509019851685, 0.0949057936668396]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 56, SSIM Loss: 0.09537523984909058\n",
      "Epoch: 46, Batch: 56, D Loss Real: 0.16850613057613373, D Loss Fake: 1.0870825052261353, G Loss: [10.392266273498535, 0.8921023607254028, 0.09500163793563843]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 57, SSIM Loss: 0.09660178422927856\n",
      "Epoch: 46, Batch: 57, D Loss Real: 0.21005015075206757, D Loss Fake: 1.1216692924499512, G Loss: [10.515390396118164, 0.8517791032791138, 0.09663611650466919]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 58, SSIM Loss: 0.09346920251846313\n",
      "Epoch: 46, Batch: 58, D Loss Real: 0.3214139938354492, D Loss Fake: 1.0909223556518555, G Loss: [10.158611297607422, 0.8403551578521729, 0.09318256378173828]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 59, SSIM Loss: 0.09254568815231323\n",
      "Epoch: 46, Batch: 59, D Loss Real: 0.24716860055923462, D Loss Fake: 1.2024155855178833, G Loss: [9.941656112670898, 0.7057383060455322, 0.09235918521881104]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 60, SSIM Loss: 0.09647095203399658\n",
      "Epoch: 46, Batch: 60, D Loss Real: 0.16139233112335205, D Loss Fake: 1.0021957159042358, G Loss: [10.513625144958496, 0.8460265398025513, 0.09667599201202393]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 61, SSIM Loss: 0.09409105777740479\n",
      "Epoch: 46, Batch: 61, D Loss Real: 0.15626876056194305, D Loss Fake: 1.1255697011947632, G Loss: [10.248373985290527, 0.8370625972747803, 0.09411311149597168]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 46, Batch: 62, SSIM Loss: 0.09777486324310303\n",
      "Epoch: 46, Batch: 62, D Loss Real: 0.1840609908103943, D Loss Fake: 0.9476872682571411, G Loss: [10.68430233001709, 0.8937629461288452, 0.09790539741516113]\n",
      "1/1 [==============================] - 0s 144ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:16:18.393906: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:16:19.856493: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Batch: 1, SSIM Loss: 0.09436678886413574\n",
      "Epoch: 47, Batch: 1, D Loss Real: 0.1280229389667511, D Loss Fake: 1.1918153762817383, G Loss: [10.377888679504395, 0.9297535419464111, 0.09448134899139404]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 2, SSIM Loss: 0.09593749046325684\n",
      "Epoch: 47, Batch: 2, D Loss Real: 0.2911042869091034, D Loss Fake: 1.149643898010254, G Loss: [10.446209907531738, 0.833077073097229, 0.0961313247680664]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 47, Batch: 3, SSIM Loss: 0.09516370296478271\n",
      "Epoch: 47, Batch: 3, D Loss Real: 0.15238255262374878, D Loss Fake: 1.0479990243911743, G Loss: [10.435637474060059, 0.9053080081939697, 0.09530329704284668]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 4, SSIM Loss: 0.09437429904937744\n",
      "Epoch: 47, Batch: 4, D Loss Real: 0.19876065850257874, D Loss Fake: 1.0468533039093018, G Loss: [10.292287826538086, 0.8487368822097778, 0.09443551301956177]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 5, SSIM Loss: 0.09440428018569946\n",
      "Epoch: 47, Batch: 5, D Loss Real: 0.15591222047805786, D Loss Fake: 1.181768536567688, G Loss: [10.259505271911621, 0.8285838961601257, 0.09430921077728271]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 6, SSIM Loss: 0.09440469741821289\n",
      "Epoch: 47, Batch: 6, D Loss Real: 0.11183539032936096, D Loss Fake: 0.9362070560455322, G Loss: [10.292702674865723, 0.8925551176071167, 0.09400147199630737]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 7, SSIM Loss: 0.09639203548431396\n",
      "Epoch: 47, Batch: 7, D Loss Real: 0.10899143666028976, D Loss Fake: 1.1618622541427612, G Loss: [10.536705017089844, 0.9348317980766296, 0.0960187315940857]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 8, SSIM Loss: 0.0954163670539856\n",
      "Epoch: 47, Batch: 8, D Loss Real: 0.3177151679992676, D Loss Fake: 1.087764024734497, G Loss: [10.362588882446289, 0.834726095199585, 0.09527862071990967]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 9, SSIM Loss: 0.0960623025894165\n",
      "Epoch: 47, Batch: 9, D Loss Real: 0.22142556309700012, D Loss Fake: 1.1258516311645508, G Loss: [10.393179893493652, 0.7780335545539856, 0.09615147113800049]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 10, SSIM Loss: 0.09209585189819336\n",
      "Epoch: 47, Batch: 10, D Loss Real: 0.22551396489143372, D Loss Fake: 1.0814392566680908, G Loss: [10.03621768951416, 0.8044536113739014, 0.09231764078140259]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 11, SSIM Loss: 0.09168803691864014\n",
      "Epoch: 47, Batch: 11, D Loss Real: 0.23973381519317627, D Loss Fake: 1.2799088954925537, G Loss: [9.973361015319824, 0.8046049475669861, 0.09168756008148193]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 12, SSIM Loss: 0.09497761726379395\n",
      "Epoch: 47, Batch: 12, D Loss Real: 0.2773730754852295, D Loss Fake: 1.0778131484985352, G Loss: [10.337600708007812, 0.7843480110168457, 0.09553253650665283]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 47, Batch: 13, SSIM Loss: 0.09396696090698242\n",
      "Epoch: 47, Batch: 13, D Loss Real: 0.22563305497169495, D Loss Fake: 0.9759571552276611, G Loss: [10.243843078613281, 0.8523684740066528, 0.09391474723815918]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 14, SSIM Loss: 0.09699511528015137\n",
      "Epoch: 47, Batch: 14, D Loss Real: 0.1987655907869339, D Loss Fake: 0.9107340574264526, G Loss: [10.64760684967041, 0.9224763512611389, 0.097251296043396]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 15, SSIM Loss: 0.0958019495010376\n",
      "Epoch: 47, Batch: 15, D Loss Real: 0.1716071367263794, D Loss Fake: 0.9696568846702576, G Loss: [10.445198059082031, 0.8758981823921204, 0.09569299221038818]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 16, SSIM Loss: 0.09746766090393066\n",
      "Epoch: 47, Batch: 16, D Loss Real: 0.10095175355672836, D Loss Fake: 1.0146507024765015, G Loss: [10.597611427307129, 0.8529615998268127, 0.0974465012550354]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 17, SSIM Loss: 0.0942387580871582\n",
      "Epoch: 47, Batch: 17, D Loss Real: 0.0871056541800499, D Loss Fake: 1.0430059432983398, G Loss: [10.349274635314941, 0.9090250134468079, 0.0944024920463562]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 18, SSIM Loss: 0.09356176853179932\n",
      "Epoch: 47, Batch: 18, D Loss Real: 0.10033893585205078, D Loss Fake: 0.9916278123855591, G Loss: [10.336380958557129, 0.9561247229576111, 0.0938025712966919]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 19, SSIM Loss: 0.09597432613372803\n",
      "Epoch: 47, Batch: 19, D Loss Real: 0.10635441541671753, D Loss Fake: 0.966705322265625, G Loss: [10.556042671203613, 0.958777666091919, 0.09597265720367432]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 47, Batch: 20, SSIM Loss: 0.09611952304840088\n",
      "Epoch: 47, Batch: 20, D Loss Real: 0.11329986155033112, D Loss Fake: 1.1891313791275024, G Loss: [10.452896118164062, 0.8882938623428345, 0.09564602375030518]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 21, SSIM Loss: 0.09282416105270386\n",
      "Epoch: 47, Batch: 21, D Loss Real: 0.14990155398845673, D Loss Fake: 0.799254834651947, G Loss: [10.269525527954102, 1.0001084804534912, 0.09269416332244873]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 22, SSIM Loss: 0.09246701002120972\n",
      "Epoch: 47, Batch: 22, D Loss Real: 0.1514740288257599, D Loss Fake: 1.1042276620864868, G Loss: [10.085598945617676, 0.8618519306182861, 0.09223747253417969]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 23, SSIM Loss: 0.0936928391456604\n",
      "Epoch: 47, Batch: 23, D Loss Real: 0.17248299717903137, D Loss Fake: 1.043757677078247, G Loss: [10.208974838256836, 0.8338905572891235, 0.09375083446502686]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 24, SSIM Loss: 0.0942908525466919\n",
      "Epoch: 47, Batch: 24, D Loss Real: 0.15961292386054993, D Loss Fake: 1.0652799606323242, G Loss: [10.254828453063965, 0.8104727864265442, 0.09444355964660645]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 25, SSIM Loss: 0.09460079669952393\n",
      "Epoch: 47, Batch: 25, D Loss Real: 0.1595240980386734, D Loss Fake: 1.1395622491836548, G Loss: [10.353267669677734, 0.8469830751419067, 0.09506285190582275]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 47, Batch: 26, SSIM Loss: 0.09245538711547852\n",
      "Epoch: 47, Batch: 26, D Loss Real: 0.2027498036623001, D Loss Fake: 0.9696707725524902, G Loss: [10.121102333068848, 0.8555124998092651, 0.09265589714050293]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 27, SSIM Loss: 0.09078115224838257\n",
      "Epoch: 47, Batch: 27, D Loss Real: 0.18226051330566406, D Loss Fake: 0.9107716679573059, G Loss: [9.966268539428711, 0.8967185020446777, 0.09069550037384033]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 28, SSIM Loss: 0.09759855270385742\n",
      "Epoch: 47, Batch: 28, D Loss Real: 0.14811097085475922, D Loss Fake: 1.1325021982192993, G Loss: [10.557733535766602, 0.7974067330360413, 0.09760326147079468]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 29, SSIM Loss: 0.09642887115478516\n",
      "Epoch: 47, Batch: 29, D Loss Real: 0.11694109439849854, D Loss Fake: 1.521075963973999, G Loss: [10.596248626708984, 0.9250673055648804, 0.09671181440353394]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 30, SSIM Loss: 0.09517645835876465\n",
      "Epoch: 47, Batch: 30, D Loss Real: 0.3168642520904541, D Loss Fake: 0.9717907905578613, G Loss: [10.384500503540039, 0.8978546857833862, 0.09486645460128784]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 31, SSIM Loss: 0.09296154975891113\n",
      "Epoch: 47, Batch: 31, D Loss Real: 0.3407168388366699, D Loss Fake: 0.9789513945579529, G Loss: [10.142183303833008, 0.8325937390327454, 0.09309589862823486]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 32, SSIM Loss: 0.09461700916290283\n",
      "Epoch: 47, Batch: 32, D Loss Real: 0.24487443268299103, D Loss Fake: 1.0877618789672852, G Loss: [10.215441703796387, 0.7441800236701965, 0.09471261501312256]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 33, SSIM Loss: 0.0940239429473877\n",
      "Epoch: 47, Batch: 33, D Loss Real: 0.21781887114048004, D Loss Fake: 1.0649893283843994, G Loss: [10.192865371704102, 0.8327482342720032, 0.09360116720199585]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 34, SSIM Loss: 0.09359246492385864\n",
      "Epoch: 47, Batch: 34, D Loss Real: 0.18254655599594116, D Loss Fake: 1.1964812278747559, G Loss: [10.081178665161133, 0.7491238713264465, 0.09332054853439331]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 35, SSIM Loss: 0.09511518478393555\n",
      "Epoch: 47, Batch: 35, D Loss Real: 0.30219072103500366, D Loss Fake: 1.2628809213638306, G Loss: [10.213216781616211, 0.7722760438919067, 0.09440940618515015]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 36, SSIM Loss: 0.09327918291091919\n",
      "Epoch: 47, Batch: 36, D Loss Real: 0.23562955856323242, D Loss Fake: 1.2312421798706055, G Loss: [10.05922794342041, 0.7606409192085266, 0.09298586845397949]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 47, Batch: 37, SSIM Loss: 0.09292739629745483\n",
      "Epoch: 47, Batch: 37, D Loss Real: 0.3178727924823761, D Loss Fake: 1.2383813858032227, G Loss: [9.972344398498535, 0.7004128098487854, 0.09271931648254395]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 38, SSIM Loss: 0.0965878963470459\n",
      "Epoch: 47, Batch: 38, D Loss Real: 0.24783742427825928, D Loss Fake: 1.3193892240524292, G Loss: [10.4461669921875, 0.7432515621185303, 0.09702914953231812]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 39, SSIM Loss: 0.0929720401763916\n",
      "Epoch: 47, Batch: 39, D Loss Real: 0.3314334750175476, D Loss Fake: 1.040244221687317, G Loss: [10.095203399658203, 0.8045191764831543, 0.09290683269500732]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 40, SSIM Loss: 0.09747391939163208\n",
      "Epoch: 47, Batch: 40, D Loss Real: 0.30973178148269653, D Loss Fake: 1.1976490020751953, G Loss: [10.392631530761719, 0.6809423565864563, 0.09711688756942749]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 47, Batch: 41, SSIM Loss: 0.09207344055175781\n",
      "Epoch: 47, Batch: 41, D Loss Real: 0.35983026027679443, D Loss Fake: 1.2569518089294434, G Loss: [9.845108985900879, 0.6829690337181091, 0.09162139892578125]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 42, SSIM Loss: 0.09204041957855225\n",
      "Epoch: 47, Batch: 42, D Loss Real: 0.2582660913467407, D Loss Fake: 1.1852670907974243, G Loss: [9.921146392822266, 0.7189757823944092, 0.09202170372009277]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 43, SSIM Loss: 0.09458762407302856\n",
      "Epoch: 47, Batch: 43, D Loss Real: 0.1762271225452423, D Loss Fake: 1.258628010749817, G Loss: [10.225133895874023, 0.808506429195404, 0.09416627883911133]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 44, SSIM Loss: 0.09156215190887451\n",
      "Epoch: 47, Batch: 44, D Loss Real: 0.2629639208316803, D Loss Fake: 1.0796676874160767, G Loss: [9.953422546386719, 0.7727454900741577, 0.09180676937103271]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 45, SSIM Loss: 0.09891963005065918\n",
      "Epoch: 47, Batch: 45, D Loss Real: 0.23709002137184143, D Loss Fake: 1.1071016788482666, G Loss: [10.657573699951172, 0.7902035713195801, 0.09867370128631592]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 46, SSIM Loss: 0.09335911273956299\n",
      "Epoch: 47, Batch: 46, D Loss Real: 0.3203458786010742, D Loss Fake: 1.1980193853378296, G Loss: [10.084351539611816, 0.7467722296714783, 0.0933758020401001]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 47, SSIM Loss: 0.09963500499725342\n",
      "Epoch: 47, Batch: 47, D Loss Real: 0.17850261926651, D Loss Fake: 1.222002387046814, G Loss: [10.65921688079834, 0.7492474913597107, 0.09909969568252563]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 48, SSIM Loss: 0.09362626075744629\n",
      "Epoch: 47, Batch: 48, D Loss Real: 0.16541676223278046, D Loss Fake: 1.304762363433838, G Loss: [10.176633834838867, 0.8040541410446167, 0.09372580051422119]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 49, SSIM Loss: 0.09268391132354736\n",
      "Epoch: 47, Batch: 49, D Loss Real: 0.32993459701538086, D Loss Fake: 1.0302108526229858, G Loss: [10.043754577636719, 0.7922552227973938, 0.0925149917602539]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 50, SSIM Loss: 0.09496086835861206\n",
      "Epoch: 47, Batch: 50, D Loss Real: 0.23992277681827545, D Loss Fake: 1.1657280921936035, G Loss: [10.210268020629883, 0.7247551679611206, 0.09485512971878052]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 51, SSIM Loss: 0.09217357635498047\n",
      "Epoch: 47, Batch: 51, D Loss Real: 0.2693949043750763, D Loss Fake: 1.0372813940048218, G Loss: [10.018240928649902, 0.7890635132789612, 0.09229177236557007]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 52, SSIM Loss: 0.09735804796218872\n",
      "Epoch: 47, Batch: 52, D Loss Real: 0.137944757938385, D Loss Fake: 1.1895802021026611, G Loss: [10.535842895507812, 0.7810714244842529, 0.09754770994186401]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 53, SSIM Loss: 0.09156429767608643\n",
      "Epoch: 47, Batch: 53, D Loss Real: 0.2127438187599182, D Loss Fake: 1.0212572813034058, G Loss: [9.935419082641602, 0.8117717504501343, 0.09123647212982178]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 54, SSIM Loss: 0.09634590148925781\n",
      "Epoch: 47, Batch: 54, D Loss Real: 0.2377716451883316, D Loss Fake: 1.0320165157318115, G Loss: [10.410567283630371, 0.8286735415458679, 0.09581893682479858]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 55, SSIM Loss: 0.09445488452911377\n",
      "Epoch: 47, Batch: 55, D Loss Real: 0.28966429829597473, D Loss Fake: 1.3194564580917358, G Loss: [10.260030746459961, 0.7866175174713135, 0.09473413228988647]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 56, SSIM Loss: 0.09483766555786133\n",
      "Epoch: 47, Batch: 56, D Loss Real: 0.21266472339630127, D Loss Fake: 1.1488902568817139, G Loss: [10.208026885986328, 0.7627891302108765, 0.0944523811340332]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 57, SSIM Loss: 0.09604132175445557\n",
      "Epoch: 47, Batch: 57, D Loss Real: 0.22793635725975037, D Loss Fake: 1.064720869064331, G Loss: [10.370992660522461, 0.7925204634666443, 0.09578472375869751]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 47, Batch: 58, SSIM Loss: 0.09300220012664795\n",
      "Epoch: 47, Batch: 58, D Loss Real: 0.2816484868526459, D Loss Fake: 1.0524410009384155, G Loss: [10.095037460327148, 0.7748971581459045, 0.0932013988494873]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 59, SSIM Loss: 0.09192728996276855\n",
      "Epoch: 47, Batch: 59, D Loss Real: 0.21889007091522217, D Loss Fake: 1.217017650604248, G Loss: [10.025909423828125, 0.8104062080383301, 0.09215503931045532]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 47, Batch: 60, SSIM Loss: 0.09527969360351562\n",
      "Epoch: 47, Batch: 60, D Loss Real: 0.21416763961315155, D Loss Fake: 1.0440785884857178, G Loss: [10.35580825805664, 0.8388066291809082, 0.0951700210571289]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 47, Batch: 61, SSIM Loss: 0.09142410755157471\n",
      "Epoch: 47, Batch: 61, D Loss Real: 0.2603517174720764, D Loss Fake: 1.1438120603561401, G Loss: [9.902891159057617, 0.7654396295547485, 0.09137451648712158]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 47, Batch: 62, SSIM Loss: 0.09862697124481201\n",
      "Epoch: 47, Batch: 62, D Loss Real: 0.23100978136062622, D Loss Fake: 1.2386291027069092, G Loss: [10.570664405822754, 0.7438791990280151, 0.09826785326004028]\n",
      "1/1 [==============================] - 0s 139ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:17:41.382407: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:17:42.862549: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Batch: 1, SSIM Loss: 0.09168028831481934\n",
      "Epoch: 48, Batch: 1, D Loss Real: 0.21723778545856476, D Loss Fake: 1.1150476932525635, G Loss: [9.936491966247559, 0.8100017309188843, 0.09126490354537964]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 48, Batch: 2, SSIM Loss: 0.09483975172042847\n",
      "Epoch: 48, Batch: 2, D Loss Real: 0.2735559046268463, D Loss Fake: 1.1241893768310547, G Loss: [10.209137916564941, 0.7484263181686401, 0.09460711479187012]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 48, Batch: 3, SSIM Loss: 0.09432792663574219\n",
      "Epoch: 48, Batch: 3, D Loss Real: 0.18499822914600372, D Loss Fake: 1.0950000286102295, G Loss: [10.226285934448242, 0.7892495393753052, 0.09437036514282227]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 4, SSIM Loss: 0.09333133697509766\n",
      "Epoch: 48, Batch: 4, D Loss Real: 0.2433440089225769, D Loss Fake: 1.190381646156311, G Loss: [10.115772247314453, 0.7649593353271484, 0.09350812435150146]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 5, SSIM Loss: 0.0937567949295044\n",
      "Epoch: 48, Batch: 5, D Loss Real: 0.23810864984989166, D Loss Fake: 1.143879771232605, G Loss: [10.197150230407715, 0.7996727824211121, 0.093974769115448]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 6, SSIM Loss: 0.09285449981689453\n",
      "Epoch: 48, Batch: 6, D Loss Real: 0.19150686264038086, D Loss Fake: 0.9551764726638794, G Loss: [10.16206169128418, 0.8895455598831177, 0.09272515773773193]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 7, SSIM Loss: 0.09517478942871094\n",
      "Epoch: 48, Batch: 7, D Loss Real: 0.15386170148849487, D Loss Fake: 1.0435333251953125, G Loss: [10.41834831237793, 0.8618758916854858, 0.09556472301483154]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 8, SSIM Loss: 0.09594762325286865\n",
      "Epoch: 48, Batch: 8, D Loss Real: 0.23673416674137115, D Loss Fake: 1.4401679039001465, G Loss: [10.487747192382812, 0.8649106025695801, 0.09622836112976074]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 48, Batch: 9, SSIM Loss: 0.09632623195648193\n",
      "Epoch: 48, Batch: 9, D Loss Real: 0.22402334213256836, D Loss Fake: 1.1877026557922363, G Loss: [10.435047149658203, 0.8087723255157471, 0.09626275300979614]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 10, SSIM Loss: 0.09098023176193237\n",
      "Epoch: 48, Batch: 10, D Loss Real: 0.3051372468471527, D Loss Fake: 1.175112247467041, G Loss: [9.820989608764648, 0.7316333651542664, 0.09089356660842896]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 11, SSIM Loss: 0.09125065803527832\n",
      "Epoch: 48, Batch: 11, D Loss Real: 0.29170021414756775, D Loss Fake: 1.245139241218567, G Loss: [9.763665199279785, 0.6763883829116821, 0.09087276458740234]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 12, SSIM Loss: 0.09400057792663574\n",
      "Epoch: 48, Batch: 12, D Loss Real: 0.2327900230884552, D Loss Fake: 1.0571123361587524, G Loss: [10.263314247131348, 0.7931013703346252, 0.09470212459564209]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 13, SSIM Loss: 0.09263879060745239\n",
      "Epoch: 48, Batch: 13, D Loss Real: 0.23385408520698547, D Loss Fake: 1.0129294395446777, G Loss: [10.07591724395752, 0.8274463415145874, 0.09248471260070801]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 14, SSIM Loss: 0.09614574909210205\n",
      "Epoch: 48, Batch: 14, D Loss Real: 0.18024201691150665, D Loss Fake: 0.9378569722175598, G Loss: [10.571223258972168, 0.9247480034828186, 0.09646475315093994]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 15, SSIM Loss: 0.09452056884765625\n",
      "Epoch: 48, Batch: 15, D Loss Real: 0.11810244619846344, D Loss Fake: 1.1355376243591309, G Loss: [10.338943481445312, 0.8781599998474121, 0.09460783004760742]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 16, SSIM Loss: 0.09731435775756836\n",
      "Epoch: 48, Batch: 16, D Loss Real: 0.10525020211935043, D Loss Fake: 1.0286180973052979, G Loss: [10.526811599731445, 0.8661270141601562, 0.09660685062408447]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 17, SSIM Loss: 0.09358572959899902\n",
      "Epoch: 48, Batch: 17, D Loss Real: 0.12818527221679688, D Loss Fake: 1.0736502408981323, G Loss: [10.228142738342285, 0.8664761781692505, 0.09361666440963745]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 18, SSIM Loss: 0.09187448024749756\n",
      "Epoch: 48, Batch: 18, D Loss Real: 0.143596351146698, D Loss Fake: 1.033048391342163, G Loss: [10.075150489807129, 0.8808128237724304, 0.09194338321685791]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 48, Batch: 19, SSIM Loss: 0.09491026401519775\n",
      "Epoch: 48, Batch: 19, D Loss Real: 0.18716952204704285, D Loss Fake: 1.1007343530654907, G Loss: [10.33065414428711, 0.8354915380477905, 0.09495162963867188]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 20, SSIM Loss: 0.09546864032745361\n",
      "Epoch: 48, Batch: 20, D Loss Real: 0.16580425202846527, D Loss Fake: 1.2812786102294922, G Loss: [10.356648445129395, 0.8465309739112854, 0.09510117769241333]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 21, SSIM Loss: 0.09131711721420288\n",
      "Epoch: 48, Batch: 21, D Loss Real: 0.3232839107513428, D Loss Fake: 1.0190911293029785, G Loss: [9.989386558532715, 0.8618409633636475, 0.09127545356750488]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 22, SSIM Loss: 0.09120428562164307\n",
      "Epoch: 48, Batch: 22, D Loss Real: 0.26892971992492676, D Loss Fake: 1.0715442895889282, G Loss: [9.929350852966309, 0.7931143641471863, 0.0913623571395874]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 23, SSIM Loss: 0.0937160849571228\n",
      "Epoch: 48, Batch: 23, D Loss Real: 0.1817290335893631, D Loss Fake: 1.2145541906356812, G Loss: [10.145879745483398, 0.773257851600647, 0.09372621774673462]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 24, SSIM Loss: 0.09381675720214844\n",
      "Epoch: 48, Batch: 24, D Loss Real: 0.22245053946971893, D Loss Fake: 1.1692715883255005, G Loss: [10.187531471252441, 0.7938276529312134, 0.09393703937530518]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 25, SSIM Loss: 0.09370160102844238\n",
      "Epoch: 48, Batch: 25, D Loss Real: 0.21505863964557648, D Loss Fake: 1.1350374221801758, G Loss: [10.197531700134277, 0.8052706122398376, 0.09392261505126953]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 26, SSIM Loss: 0.0921163558959961\n",
      "Epoch: 48, Batch: 26, D Loss Real: 0.26729610562324524, D Loss Fake: 1.0855016708374023, G Loss: [10.020950317382812, 0.7922801971435547, 0.09228670597076416]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 27, SSIM Loss: 0.09037888050079346\n",
      "Epoch: 48, Batch: 27, D Loss Real: 0.19525541365146637, D Loss Fake: 1.0728260278701782, G Loss: [9.853343963623047, 0.842289924621582, 0.09011054039001465]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 28, SSIM Loss: 0.09518295526504517\n",
      "Epoch: 48, Batch: 28, D Loss Real: 0.18165923655033112, D Loss Fake: 1.1256134510040283, G Loss: [10.310467720031738, 0.811072587966919, 0.0949939489364624]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 29, SSIM Loss: 0.09483373165130615\n",
      "Epoch: 48, Batch: 29, D Loss Real: 0.2063547968864441, D Loss Fake: 1.1028242111206055, G Loss: [10.336792945861816, 0.8309128880500793, 0.09505879878997803]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 30, SSIM Loss: 0.09309655427932739\n",
      "Epoch: 48, Batch: 30, D Loss Real: 0.19286170601844788, D Loss Fake: 1.0495009422302246, G Loss: [10.171168327331543, 0.85731041431427, 0.09313857555389404]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 31, SSIM Loss: 0.09247255325317383\n",
      "Epoch: 48, Batch: 31, D Loss Real: 0.24734698235988617, D Loss Fake: 1.0123565196990967, G Loss: [10.110881805419922, 0.8245623111724854, 0.09286320209503174]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 32, SSIM Loss: 0.09375941753387451\n",
      "Epoch: 48, Batch: 32, D Loss Real: 0.14403730630874634, D Loss Fake: 1.1085232496261597, G Loss: [10.258378982543945, 0.8617668151855469, 0.09396612644195557]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 33, SSIM Loss: 0.09266775846481323\n",
      "Epoch: 48, Batch: 33, D Loss Real: 0.21985341608524323, D Loss Fake: 0.9521612524986267, G Loss: [10.147924423217773, 0.8791751265525818, 0.09268748760223389]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 34, SSIM Loss: 0.0922054648399353\n",
      "Epoch: 48, Batch: 34, D Loss Real: 0.16321143507957458, D Loss Fake: 1.127108097076416, G Loss: [10.104804992675781, 0.8433992266654968, 0.0926140546798706]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 35, SSIM Loss: 0.09328538179397583\n",
      "Epoch: 48, Batch: 35, D Loss Real: 0.3407112956047058, D Loss Fake: 1.0465255975723267, G Loss: [10.171995162963867, 0.7941102981567383, 0.09377884864807129]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 36, SSIM Loss: 0.09262001514434814\n",
      "Epoch: 48, Batch: 36, D Loss Real: 0.1881009042263031, D Loss Fake: 1.2111377716064453, G Loss: [10.039651870727539, 0.7521033883094788, 0.09287548065185547]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 37, SSIM Loss: 0.09169042110443115\n",
      "Epoch: 48, Batch: 37, D Loss Real: 0.2070799469947815, D Loss Fake: 1.24509859085083, G Loss: [9.973001480102539, 0.7872282266616821, 0.09185773134231567]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 38, SSIM Loss: 0.09488224983215332\n",
      "Epoch: 48, Batch: 38, D Loss Real: 0.22187639772891998, D Loss Fake: 1.1601808071136475, G Loss: [10.285630226135254, 0.7951347827911377, 0.09490495920181274]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 39, SSIM Loss: 0.0918741226196289\n",
      "Epoch: 48, Batch: 39, D Loss Real: 0.2755741775035858, D Loss Fake: 1.078065276145935, G Loss: [9.996749877929688, 0.791771650314331, 0.09204977750778198]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 40, SSIM Loss: 0.09566891193389893\n",
      "Epoch: 48, Batch: 40, D Loss Real: 0.20302388072013855, D Loss Fake: 1.0056054592132568, G Loss: [10.562511444091797, 0.9977543354034424, 0.09564757347106934]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 41, SSIM Loss: 0.09217751026153564\n",
      "Epoch: 48, Batch: 41, D Loss Real: 0.31746649742126465, D Loss Fake: 1.0176142454147339, G Loss: [10.10196304321289, 0.8507082462310791, 0.09251254796981812]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 42, SSIM Loss: 0.09178954362869263\n",
      "Epoch: 48, Batch: 42, D Loss Real: 0.19207143783569336, D Loss Fake: 0.9702280759811401, G Loss: [10.102230072021484, 0.8976330757141113, 0.09204596281051636]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 43, SSIM Loss: 0.09440982341766357\n",
      "Epoch: 48, Batch: 43, D Loss Real: 0.0912179946899414, D Loss Fake: 1.0353351831436157, G Loss: [10.316262245178223, 0.8833025693893433, 0.0943295955657959]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 44, SSIM Loss: 0.09142816066741943\n",
      "Epoch: 48, Batch: 44, D Loss Real: 0.095384381711483, D Loss Fake: 0.9851983785629272, G Loss: [10.052959442138672, 0.9130640625953674, 0.09139895439147949]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 45, SSIM Loss: 0.10018372535705566\n",
      "Epoch: 48, Batch: 45, D Loss Real: 0.07085605710744858, D Loss Fake: 0.9517620801925659, G Loss: [10.957476615905762, 0.9355100393295288, 0.10021966695785522]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 46, SSIM Loss: 0.0937267541885376\n",
      "Epoch: 48, Batch: 46, D Loss Real: 0.12664814293384552, D Loss Fake: 1.005772352218628, G Loss: [10.269289016723633, 0.8831902742385864, 0.09386098384857178]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 48, Batch: 47, SSIM Loss: 0.09783029556274414\n",
      "Epoch: 48, Batch: 47, D Loss Real: 0.06543687731027603, D Loss Fake: 0.9541148543357849, G Loss: [10.688364028930664, 0.9132081270217896, 0.09775155782699585]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 48, Batch: 48, SSIM Loss: 0.09367245435714722\n",
      "Epoch: 48, Batch: 48, D Loss Real: 0.06097397580742836, D Loss Fake: 1.031776785850525, G Loss: [10.324125289916992, 0.948911190032959, 0.09375214576721191]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 48, Batch: 49, SSIM Loss: 0.09223037958145142\n",
      "Epoch: 48, Batch: 49, D Loss Real: 0.13317622244358063, D Loss Fake: 0.9157987833023071, G Loss: [10.155142784118652, 0.9025943279266357, 0.09252548217773438]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 48, Batch: 50, SSIM Loss: 0.09453916549682617\n",
      "Epoch: 48, Batch: 50, D Loss Real: 0.07769647240638733, D Loss Fake: 1.0774884223937988, G Loss: [10.401163101196289, 0.9187558889389038, 0.09482407569885254]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 48, Batch: 51, SSIM Loss: 0.0923837423324585\n",
      "Epoch: 48, Batch: 51, D Loss Real: 0.12756918370723724, D Loss Fake: 0.9673582315444946, G Loss: [10.139425277709961, 0.9197670817375183, 0.09219658374786377]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 48, Batch: 52, SSIM Loss: 0.09749436378479004\n",
      "Epoch: 48, Batch: 52, D Loss Real: 0.09221950173377991, D Loss Fake: 1.1217306852340698, G Loss: [10.655914306640625, 0.903044581413269, 0.09752869606018066]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 48, Batch: 53, SSIM Loss: 0.09089577198028564\n",
      "Epoch: 48, Batch: 53, D Loss Real: 0.19131456315517426, D Loss Fake: 0.9337026476860046, G Loss: [10.001873016357422, 0.9073779582977295, 0.09094494581222534]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 48, Batch: 54, SSIM Loss: 0.09496968984603882\n",
      "Epoch: 48, Batch: 54, D Loss Real: 0.22464081645011902, D Loss Fake: 1.0761115550994873, G Loss: [10.302986145019531, 0.8169305920600891, 0.09486055374145508]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 48, Batch: 55, SSIM Loss: 0.09281599521636963\n",
      "Epoch: 48, Batch: 55, D Loss Real: 0.24363411962985992, D Loss Fake: 1.0562324523925781, G Loss: [10.091521263122559, 0.8353198766708374, 0.09256201982498169]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 48, Batch: 56, SSIM Loss: 0.09450745582580566\n",
      "Epoch: 48, Batch: 56, D Loss Real: 0.10997926443815231, D Loss Fake: 1.3712058067321777, G Loss: [10.247520446777344, 0.8430037498474121, 0.09404516220092773]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 48, Batch: 57, SSIM Loss: 0.09466266632080078\n",
      "Epoch: 48, Batch: 57, D Loss Real: 0.23442380130290985, D Loss Fake: 1.0139364004135132, G Loss: [10.364691734313965, 0.8753937482833862, 0.09489297866821289]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 48, Batch: 58, SSIM Loss: 0.09250998497009277\n",
      "Epoch: 48, Batch: 58, D Loss Real: 0.3116302788257599, D Loss Fake: 1.0754015445709229, G Loss: [10.05765151977539, 0.7724693417549133, 0.09285181760787964]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 48, Batch: 59, SSIM Loss: 0.09221971035003662\n",
      "Epoch: 48, Batch: 59, D Loss Real: 0.26862290501594543, D Loss Fake: 1.2668721675872803, G Loss: [9.89537239074707, 0.7076802253723145, 0.09187692403793335]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 48, Batch: 60, SSIM Loss: 0.09547853469848633\n",
      "Epoch: 48, Batch: 60, D Loss Real: 0.19786690175533295, D Loss Fake: 1.1197208166122437, G Loss: [10.369999885559082, 0.7707372903823853, 0.09599262475967407]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 48, Batch: 61, SSIM Loss: 0.09167742729187012\n",
      "Epoch: 48, Batch: 61, D Loss Real: 0.17766135931015015, D Loss Fake: 1.2117788791656494, G Loss: [9.99018383026123, 0.8063004016876221, 0.09183883666992188]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 48, Batch: 62, SSIM Loss: 0.09536361694335938\n",
      "Epoch: 48, Batch: 62, D Loss Real: 0.277020663022995, D Loss Fake: 1.0234086513519287, G Loss: [10.388737678527832, 0.8285763263702393, 0.09560161828994751]\n",
      "1/1 [==============================] - 0s 174ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:19:04.914807: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:19:06.504349: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Batch: 1, SSIM Loss: 0.09199410676956177\n",
      "Epoch: 49, Batch: 1, D Loss Real: 0.2183510959148407, D Loss Fake: 1.0751099586486816, G Loss: [9.993428230285645, 0.8234094381332397, 0.09170019626617432]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 2, SSIM Loss: 0.09354841709136963\n",
      "Epoch: 49, Batch: 2, D Loss Real: 0.25673219561576843, D Loss Fake: 1.152978777885437, G Loss: [10.139533042907715, 0.778856098651886, 0.09360677003860474]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 49, Batch: 3, SSIM Loss: 0.09421533346176147\n",
      "Epoch: 49, Batch: 3, D Loss Real: 0.18065965175628662, D Loss Fake: 1.1385356187820435, G Loss: [10.216795921325684, 0.8123805522918701, 0.09404414892196655]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 4, SSIM Loss: 0.09291839599609375\n",
      "Epoch: 49, Batch: 4, D Loss Real: 0.18639352917671204, D Loss Fake: 1.1512889862060547, G Loss: [10.088886260986328, 0.8198632597923279, 0.09269022941589355]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 49, Batch: 5, SSIM Loss: 0.0941922664642334\n",
      "Epoch: 49, Batch: 5, D Loss Real: 0.24205711483955383, D Loss Fake: 1.102461814880371, G Loss: [10.206881523132324, 0.8547459840774536, 0.0935213565826416]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 6, SSIM Loss: 0.09198641777038574\n",
      "Epoch: 49, Batch: 6, D Loss Real: 0.26123958826065063, D Loss Fake: 1.0413296222686768, G Loss: [10.039798736572266, 0.8185191750526428, 0.09221279621124268]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 7, SSIM Loss: 0.09495371580123901\n",
      "Epoch: 49, Batch: 7, D Loss Real: 0.22936828434467316, D Loss Fake: 1.2006555795669556, G Loss: [10.234564781188965, 0.7507978677749634, 0.09483766555786133]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 8, SSIM Loss: 0.09533178806304932\n",
      "Epoch: 49, Batch: 8, D Loss Real: 0.23773938417434692, D Loss Fake: 1.1437982320785522, G Loss: [10.251276016235352, 0.7808785438537598, 0.09470397233963013]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 9, SSIM Loss: 0.09577244520187378\n",
      "Epoch: 49, Batch: 9, D Loss Real: 0.12468315660953522, D Loss Fake: 1.2353663444519043, G Loss: [10.462536811828613, 0.8674286603927612, 0.09595108032226562]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 10, SSIM Loss: 0.09029841423034668\n",
      "Epoch: 49, Batch: 10, D Loss Real: 0.2845689058303833, D Loss Fake: 0.9926360249519348, G Loss: [9.89703369140625, 0.8775525093078613, 0.09019482135772705]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 11, SSIM Loss: 0.09056949615478516\n",
      "Epoch: 49, Batch: 11, D Loss Real: 0.3445979356765747, D Loss Fake: 1.0982259511947632, G Loss: [9.793987274169922, 0.7462824583053589, 0.09047704935073853]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 12, SSIM Loss: 0.09431111812591553\n",
      "Epoch: 49, Batch: 12, D Loss Real: 0.2245558649301529, D Loss Fake: 1.1451153755187988, G Loss: [10.173162460327148, 0.7436837553977966, 0.09429478645324707]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 13, SSIM Loss: 0.09166908264160156\n",
      "Epoch: 49, Batch: 13, D Loss Real: 0.16466525197029114, D Loss Fake: 1.1828198432922363, G Loss: [9.966428756713867, 0.7832843065261841, 0.09183144569396973]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 14, SSIM Loss: 0.09363263845443726\n",
      "Epoch: 49, Batch: 14, D Loss Real: 0.1990419179201126, D Loss Fake: 1.0239343643188477, G Loss: [10.190389633178711, 0.8343564867973328, 0.09356033802032471]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 15, SSIM Loss: 0.09391921758651733\n",
      "Epoch: 49, Batch: 15, D Loss Real: 0.15717776119709015, D Loss Fake: 1.1623693704605103, G Loss: [10.227078437805176, 0.8402525782585144, 0.09386825561523438]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 16, SSIM Loss: 0.09526193141937256\n",
      "Epoch: 49, Batch: 16, D Loss Real: 0.2433502972126007, D Loss Fake: 1.0169408321380615, G Loss: [10.365689277648926, 0.8356102705001831, 0.09530079364776611]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 17, SSIM Loss: 0.09302079677581787\n",
      "Epoch: 49, Batch: 17, D Loss Real: 0.28342729806900024, D Loss Fake: 1.057258129119873, G Loss: [10.093622207641602, 0.784639835357666, 0.09308981895446777]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 18, SSIM Loss: 0.0907813310623169\n",
      "Epoch: 49, Batch: 18, D Loss Real: 0.1930934190750122, D Loss Fake: 1.057924747467041, G Loss: [9.906432151794434, 0.771460771560669, 0.09134972095489502]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 19, SSIM Loss: 0.0934826135635376\n",
      "Epoch: 49, Batch: 19, D Loss Real: 0.15305601060390472, D Loss Fake: 1.1693456172943115, G Loss: [10.166230201721191, 0.8393010497093201, 0.09326928853988647]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 20, SSIM Loss: 0.09460669755935669\n",
      "Epoch: 49, Batch: 20, D Loss Real: 0.1928907036781311, D Loss Fake: 1.065975308418274, G Loss: [10.276363372802734, 0.816462516784668, 0.09459900856018066]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 21, SSIM Loss: 0.091175377368927\n",
      "Epoch: 49, Batch: 21, D Loss Real: 0.2576790153980255, D Loss Fake: 0.9749262928962708, G Loss: [10.046649932861328, 0.929922878742218, 0.09116727113723755]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 22, SSIM Loss: 0.09079217910766602\n",
      "Epoch: 49, Batch: 22, D Loss Real: 0.14090164005756378, D Loss Fake: 1.049753189086914, G Loss: [9.943090438842773, 0.8767179250717163, 0.09066373109817505]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 23, SSIM Loss: 0.09308266639709473\n",
      "Epoch: 49, Batch: 23, D Loss Real: 0.14655648171901703, D Loss Fake: 0.9820455312728882, G Loss: [10.245125770568848, 0.909703254699707, 0.0933542251586914]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 24, SSIM Loss: 0.093841552734375\n",
      "Epoch: 49, Batch: 24, D Loss Real: 0.12977099418640137, D Loss Fake: 1.0636186599731445, G Loss: [10.23430347442627, 0.8750206828117371, 0.0935928225517273]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 25, SSIM Loss: 0.09336364269256592\n",
      "Epoch: 49, Batch: 25, D Loss Real: 0.1167350634932518, D Loss Fake: 1.1510213613510132, G Loss: [10.290703773498535, 0.937722384929657, 0.09352982044219971]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 26, SSIM Loss: 0.09106892347335815\n",
      "Epoch: 49, Batch: 26, D Loss Real: 0.3309464454650879, D Loss Fake: 1.0634716749191284, G Loss: [9.92460823059082, 0.8239143490791321, 0.09100693464279175]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 27, SSIM Loss: 0.09017717838287354\n",
      "Epoch: 49, Batch: 27, D Loss Real: 0.2425999939441681, D Loss Fake: 1.091200590133667, G Loss: [9.816514015197754, 0.805424690246582, 0.0901108980178833]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 28, SSIM Loss: 0.0945976972579956\n",
      "Epoch: 49, Batch: 28, D Loss Real: 0.1456320732831955, D Loss Fake: 1.169128656387329, G Loss: [10.311408042907715, 0.8079845905303955, 0.09503424167633057]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 29, SSIM Loss: 0.09465587139129639\n",
      "Epoch: 49, Batch: 29, D Loss Real: 0.19425766170024872, D Loss Fake: 1.0670818090438843, G Loss: [10.230010032653809, 0.7953816056251526, 0.09434628486633301]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 30, SSIM Loss: 0.0926898717880249\n",
      "Epoch: 49, Batch: 30, D Loss Real: 0.15971864759922028, D Loss Fake: 1.0441315174102783, G Loss: [10.129144668579102, 0.8576478958129883, 0.09271496534347534]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 31, SSIM Loss: 0.09168839454650879\n",
      "Epoch: 49, Batch: 31, D Loss Real: 0.16917651891708374, D Loss Fake: 0.995057225227356, G Loss: [10.059797286987305, 0.8696910738945007, 0.09190106391906738]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 32, SSIM Loss: 0.09333682060241699\n",
      "Epoch: 49, Batch: 32, D Loss Real: 0.11151082813739777, D Loss Fake: 1.0472462177276611, G Loss: [10.151087760925293, 0.8662338852882385, 0.09284853935241699]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 33, SSIM Loss: 0.09211921691894531\n",
      "Epoch: 49, Batch: 33, D Loss Real: 0.15772747993469238, D Loss Fake: 1.0670300722122192, G Loss: [10.11817741394043, 0.917299747467041, 0.09200876951217651]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 34, SSIM Loss: 0.09211969375610352\n",
      "Epoch: 49, Batch: 34, D Loss Real: 0.24949654936790466, D Loss Fake: 1.0985056161880493, G Loss: [9.986030578613281, 0.7971403002738953, 0.0918889045715332]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 35, SSIM Loss: 0.0932236909866333\n",
      "Epoch: 49, Batch: 35, D Loss Real: 0.31380146741867065, D Loss Fake: 1.2275550365447998, G Loss: [10.173651695251465, 0.7894377112388611, 0.09384214878082275]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 36, SSIM Loss: 0.09182155132293701\n",
      "Epoch: 49, Batch: 36, D Loss Real: 0.2503858208656311, D Loss Fake: 1.2199516296386719, G Loss: [10.03088665008545, 0.851342499256134, 0.09179544448852539]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 37, SSIM Loss: 0.0919342041015625\n",
      "Epoch: 49, Batch: 37, D Loss Real: 0.3654937744140625, D Loss Fake: 1.1664917469024658, G Loss: [9.944116592407227, 0.7554942965507507, 0.09188622236251831]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 38, SSIM Loss: 0.09363394975662231\n",
      "Epoch: 49, Batch: 38, D Loss Real: 0.22853681445121765, D Loss Fake: 1.119374394416809, G Loss: [10.23034954071045, 0.7895697951316833, 0.09440779685974121]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 39, SSIM Loss: 0.09192979335784912\n",
      "Epoch: 49, Batch: 39, D Loss Real: 0.15973764657974243, D Loss Fake: 1.0589346885681152, G Loss: [10.05498218536377, 0.828385591506958, 0.09226596355438232]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 40, SSIM Loss: 0.09516006708145142\n",
      "Epoch: 49, Batch: 40, D Loss Real: 0.0945124477148056, D Loss Fake: 1.0760105848312378, G Loss: [10.449524879455566, 0.8841356039047241, 0.09565389156341553]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 41, SSIM Loss: 0.09028494358062744\n",
      "Epoch: 49, Batch: 41, D Loss Real: 0.18982438743114471, D Loss Fake: 1.1010968685150146, G Loss: [9.954933166503906, 0.8793148994445801, 0.09075617790222168]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 42, SSIM Loss: 0.09082841873168945\n",
      "Epoch: 49, Batch: 42, D Loss Real: 0.14528390765190125, D Loss Fake: 0.9960389137268066, G Loss: [9.959671974182129, 0.8871777653694153, 0.09072494506835938]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 49, Batch: 43, SSIM Loss: 0.0936439037322998\n",
      "Epoch: 49, Batch: 43, D Loss Real: 0.10653799027204514, D Loss Fake: 1.1594650745391846, G Loss: [10.237276077270508, 0.8706737160682678, 0.09366601705551147]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 44, SSIM Loss: 0.0900307297706604\n",
      "Epoch: 49, Batch: 44, D Loss Real: 0.24861450493335724, D Loss Fake: 0.9708024859428406, G Loss: [9.892353057861328, 0.8725667595863342, 0.0901978611946106]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 45, SSIM Loss: 0.09896647930145264\n",
      "Epoch: 49, Batch: 45, D Loss Real: 0.1691921353340149, D Loss Fake: 1.1460516452789307, G Loss: [10.782849311828613, 0.8452050089836121, 0.09937644004821777]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 49, Batch: 46, SSIM Loss: 0.09279489517211914\n",
      "Epoch: 49, Batch: 46, D Loss Real: 0.37735795974731445, D Loss Fake: 1.0993674993515015, G Loss: [10.042367935180664, 0.7674980163574219, 0.09274870157241821]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 47, SSIM Loss: 0.09663927555084229\n",
      "Epoch: 49, Batch: 47, D Loss Real: 0.21835678815841675, D Loss Fake: 1.1377757787704468, G Loss: [10.455909729003906, 0.7786065936088562, 0.09677302837371826]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 48, SSIM Loss: 0.09267503023147583\n",
      "Epoch: 49, Batch: 48, D Loss Real: 0.14892099797725677, D Loss Fake: 1.1195242404937744, G Loss: [10.080729484558105, 0.7995122671127319, 0.092812180519104]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 49, SSIM Loss: 0.09292209148406982\n",
      "Epoch: 49, Batch: 49, D Loss Real: 0.2095809280872345, D Loss Fake: 1.0123239755630493, G Loss: [10.11405086517334, 0.8392524123191833, 0.09274798631668091]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 50, SSIM Loss: 0.09394121170043945\n",
      "Epoch: 49, Batch: 50, D Loss Real: 0.12221887707710266, D Loss Fake: 1.2934353351593018, G Loss: [10.236274719238281, 0.8816246390342712, 0.09354650974273682]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 51, SSIM Loss: 0.09188520908355713\n",
      "Epoch: 49, Batch: 51, D Loss Real: 0.2589763402938843, D Loss Fake: 0.9851647615432739, G Loss: [9.995177268981934, 0.8598353266716003, 0.0913534164428711]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 52, SSIM Loss: 0.09647101163864136\n",
      "Epoch: 49, Batch: 52, D Loss Real: 0.2061777412891388, D Loss Fake: 1.0783137083053589, G Loss: [10.437302589416504, 0.8033982515335083, 0.09633904695510864]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 53, SSIM Loss: 0.08998030424118042\n",
      "Epoch: 49, Batch: 53, D Loss Real: 0.1932285726070404, D Loss Fake: 1.042165756225586, G Loss: [9.840583801269531, 0.8238427639007568, 0.09016740322113037]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 54, SSIM Loss: 0.09435778856277466\n",
      "Epoch: 49, Batch: 54, D Loss Real: 0.19182127714157104, D Loss Fake: 1.1095829010009766, G Loss: [10.257425308227539, 0.8065491914749146, 0.09450876712799072]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 55, SSIM Loss: 0.09243893623352051\n",
      "Epoch: 49, Batch: 55, D Loss Real: 0.2643708288669586, D Loss Fake: 1.0635743141174316, G Loss: [10.010383605957031, 0.815305233001709, 0.09195077419281006]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 56, SSIM Loss: 0.09332674741744995\n",
      "Epoch: 49, Batch: 56, D Loss Real: 0.1155809536576271, D Loss Fake: 1.1640413999557495, G Loss: [10.142282485961914, 0.8238177299499512, 0.09318464994430542]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 57, SSIM Loss: 0.0934913158416748\n",
      "Epoch: 49, Batch: 57, D Loss Real: 0.16413414478302002, D Loss Fake: 1.0096745491027832, G Loss: [10.168143272399902, 0.8221052289009094, 0.09346038103103638]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 58, SSIM Loss: 0.09182453155517578\n",
      "Epoch: 49, Batch: 58, D Loss Real: 0.22695189714431763, D Loss Fake: 1.0780655145645142, G Loss: [10.008368492126465, 0.8049455285072327, 0.0920342206954956]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 59, SSIM Loss: 0.09172093868255615\n",
      "Epoch: 49, Batch: 59, D Loss Real: 0.18472763895988464, D Loss Fake: 1.2316043376922607, G Loss: [10.004579544067383, 0.8194798231124878, 0.09185099601745605]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 60, SSIM Loss: 0.09575849771499634\n",
      "Epoch: 49, Batch: 60, D Loss Real: 0.20376388728618622, D Loss Fake: 0.9975711703300476, G Loss: [10.417978286743164, 0.8495143055915833, 0.09568464756011963]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 61, SSIM Loss: 0.08998441696166992\n",
      "Epoch: 49, Batch: 61, D Loss Real: 0.19333131611347198, D Loss Fake: 0.9994933605194092, G Loss: [9.806768417358398, 0.8275013566017151, 0.08979266881942749]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 49, Batch: 62, SSIM Loss: 0.0962514877319336\n",
      "Epoch: 49, Batch: 62, D Loss Real: 0.14021079242229462, D Loss Fake: 1.0655522346496582, G Loss: [10.481799125671387, 0.8253458142280579, 0.09656453132629395]\n",
      "1/1 [==============================] - 0s 166ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 04:20:28.545165: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-07 04:20:30.091809: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/model_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Batch: 1, SSIM Loss: 0.09116536378860474\n",
      "Epoch: 50, Batch: 1, D Loss Real: 0.1170102059841156, D Loss Fake: 1.2997130155563354, G Loss: [10.008305549621582, 0.8918943405151367, 0.09116411209106445]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 2, SSIM Loss: 0.0928049087524414\n",
      "Epoch: 50, Batch: 2, D Loss Real: 0.31944888830184937, D Loss Fake: 0.9730131030082703, G Loss: [10.137211799621582, 0.8540032505989075, 0.09283208847045898]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 50, Batch: 3, SSIM Loss: 0.09303134679794312\n",
      "Epoch: 50, Batch: 3, D Loss Real: 0.26529383659362793, D Loss Fake: 1.0873085260391235, G Loss: [10.053717613220215, 0.7488128542900085, 0.0930490493774414]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 4, SSIM Loss: 0.09228640794754028\n",
      "Epoch: 50, Batch: 4, D Loss Real: 0.18984946608543396, D Loss Fake: 1.1113924980163574, G Loss: [9.9841947555542, 0.7818997502326965, 0.09202295541763306]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 5, SSIM Loss: 0.09237957000732422\n",
      "Epoch: 50, Batch: 5, D Loss Real: 0.1864117980003357, D Loss Fake: 1.251488208770752, G Loss: [10.079510688781738, 0.8099755644798279, 0.09269535541534424]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 6, SSIM Loss: 0.09155833721160889\n",
      "Epoch: 50, Batch: 6, D Loss Real: 0.23636184632778168, D Loss Fake: 1.0602085590362549, G Loss: [9.949384689331055, 0.8166422247886658, 0.09132742881774902]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 7, SSIM Loss: 0.09395921230316162\n",
      "Epoch: 50, Batch: 7, D Loss Real: 0.2109033763408661, D Loss Fake: 1.0156418085098267, G Loss: [10.264714241027832, 0.8651631474494934, 0.09399551153182983]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 8, SSIM Loss: 0.0957837700843811\n",
      "Epoch: 50, Batch: 8, D Loss Real: 0.16016997396945953, D Loss Fake: 0.9539933204650879, G Loss: [10.491913795471191, 0.8989992737770081, 0.09592914581298828]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 9, SSIM Loss: 0.0958591103553772\n",
      "Epoch: 50, Batch: 9, D Loss Real: 0.09421544522047043, D Loss Fake: 0.928594172000885, G Loss: [10.548261642456055, 0.9288458824157715, 0.09619414806365967]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 10, SSIM Loss: 0.0901792049407959\n",
      "Epoch: 50, Batch: 10, D Loss Real: 0.09261469542980194, D Loss Fake: 0.9967581033706665, G Loss: [9.996989250183105, 0.914838969707489, 0.09082150459289551]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 11, SSIM Loss: 0.09053492546081543\n",
      "Epoch: 50, Batch: 11, D Loss Real: 0.1043420284986496, D Loss Fake: 1.0257039070129395, G Loss: [9.973610877990723, 0.9122859239578247, 0.09061324596405029]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 12, SSIM Loss: 0.09405767917633057\n",
      "Epoch: 50, Batch: 12, D Loss Real: 0.09762886166572571, D Loss Fake: 1.0315011739730835, G Loss: [10.302352905273438, 0.927370548248291, 0.09374982118606567]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch 50, Batch: 13, SSIM Loss: 0.09149622917175293\n",
      "Epoch: 50, Batch: 13, D Loss Real: 0.1257043480873108, D Loss Fake: 1.0842375755310059, G Loss: [10.030383110046387, 0.8732136487960815, 0.09157168865203857]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 14, SSIM Loss: 0.09369206428527832\n",
      "Epoch: 50, Batch: 14, D Loss Real: 0.15306305885314941, D Loss Fake: 1.1151554584503174, G Loss: [10.190740585327148, 0.8561654090881348, 0.0933457612991333]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 15, SSIM Loss: 0.09326589107513428\n",
      "Epoch: 50, Batch: 15, D Loss Real: 0.13401395082473755, D Loss Fake: 1.090366244316101, G Loss: [10.211071014404297, 0.9000804424285889, 0.09310990571975708]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 16, SSIM Loss: 0.09615147113800049\n",
      "Epoch: 50, Batch: 16, D Loss Real: 0.21872347593307495, D Loss Fake: 1.0999325513839722, G Loss: [10.41993236541748, 0.8299857974052429, 0.09589946269989014]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 17, SSIM Loss: 0.09385621547698975\n",
      "Epoch: 50, Batch: 17, D Loss Real: 0.30761072039604187, D Loss Fake: 1.3030056953430176, G Loss: [10.162586212158203, 0.7913052439689636, 0.09371280670166016]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 18, SSIM Loss: 0.09166377782821655\n",
      "Epoch: 50, Batch: 18, D Loss Real: 0.2575501799583435, D Loss Fake: 1.1147288084030151, G Loss: [9.93960189819336, 0.7750185132026672, 0.09164583683013916]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 19, SSIM Loss: 0.0943373441696167\n",
      "Epoch: 50, Batch: 19, D Loss Real: 0.2291988730430603, D Loss Fake: 1.2249153852462769, G Loss: [10.227137565612793, 0.7947207689285278, 0.09432417154312134]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 20, SSIM Loss: 0.09333992004394531\n",
      "Epoch: 50, Batch: 20, D Loss Real: 0.19668765366077423, D Loss Fake: 1.175534963607788, G Loss: [10.13129711151123, 0.8011729717254639, 0.09330123662948608]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 21, SSIM Loss: 0.09117662906646729\n",
      "Epoch: 50, Batch: 21, D Loss Real: 0.2675141394138336, D Loss Fake: 1.0164604187011719, G Loss: [9.942922592163086, 0.843033492565155, 0.09099888801574707]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 22, SSIM Loss: 0.0897371768951416\n",
      "Epoch: 50, Batch: 22, D Loss Real: 0.21206870675086975, D Loss Fake: 1.075676679611206, G Loss: [9.789358139038086, 0.823638916015625, 0.08965718746185303]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 23, SSIM Loss: 0.0929611325263977\n",
      "Epoch: 50, Batch: 23, D Loss Real: 0.13691945374011993, D Loss Fake: 1.1534916162490845, G Loss: [10.099369049072266, 0.8139185905456543, 0.09285449981689453]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 24, SSIM Loss: 0.09323686361312866\n",
      "Epoch: 50, Batch: 24, D Loss Real: 0.18163897097110748, D Loss Fake: 1.1974482536315918, G Loss: [10.171762466430664, 0.8306061029434204, 0.09341156482696533]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 25, SSIM Loss: 0.09237372875213623\n",
      "Epoch: 50, Batch: 25, D Loss Real: 0.18742892146110535, D Loss Fake: 1.1134812831878662, G Loss: [10.112028121948242, 0.8404651880264282, 0.09271562099456787]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 26, SSIM Loss: 0.09120404720306396\n",
      "Epoch: 50, Batch: 26, D Loss Real: 0.23065389692783356, D Loss Fake: 1.1860707998275757, G Loss: [9.902605056762695, 0.8198761940002441, 0.09082728624343872]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 27, SSIM Loss: 0.09009373188018799\n",
      "Epoch: 50, Batch: 27, D Loss Real: 0.2263609915971756, D Loss Fake: 0.9472362995147705, G Loss: [9.882119178771973, 0.8840475082397461, 0.08998072147369385]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 28, SSIM Loss: 0.09498131275177002\n",
      "Epoch: 50, Batch: 28, D Loss Real: 0.1501961201429367, D Loss Fake: 1.0543242692947388, G Loss: [10.37881851196289, 0.8739275932312012, 0.09504890441894531]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 29, SSIM Loss: 0.0939939022064209\n",
      "Epoch: 50, Batch: 29, D Loss Real: 0.15736141800880432, D Loss Fake: 1.1861904859542847, G Loss: [10.192456245422363, 0.8038848042488098, 0.09388571977615356]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 30, SSIM Loss: 0.09309953451156616\n",
      "Epoch: 50, Batch: 30, D Loss Real: 0.1542150378227234, D Loss Fake: 1.0237112045288086, G Loss: [10.1332426071167, 0.8870477080345154, 0.09246194362640381]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 31, SSIM Loss: 0.09213221073150635\n",
      "Epoch: 50, Batch: 31, D Loss Real: 0.1927751749753952, D Loss Fake: 1.2940025329589844, G Loss: [10.028145790100098, 0.8213264346122742, 0.09206819534301758]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 32, SSIM Loss: 0.09304815530776978\n",
      "Epoch: 50, Batch: 32, D Loss Real: 0.19727379083633423, D Loss Fake: 1.0822128057479858, G Loss: [10.129682540893555, 0.8211591839790344, 0.09308522939682007]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 50, Batch: 33, SSIM Loss: 0.09223389625549316\n",
      "Epoch: 50, Batch: 33, D Loss Real: 0.2660905122756958, D Loss Fake: 1.1592105627059937, G Loss: [9.967659950256348, 0.7610130906105042, 0.09206646680831909]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 34, SSIM Loss: 0.09173834323883057\n",
      "Epoch: 50, Batch: 34, D Loss Real: 0.27904561161994934, D Loss Fake: 1.3452017307281494, G Loss: [9.909187316894531, 0.7170838713645935, 0.09192103147506714]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 35, SSIM Loss: 0.09260940551757812\n",
      "Epoch: 50, Batch: 35, D Loss Real: 0.3539625108242035, D Loss Fake: 1.1771516799926758, G Loss: [10.037616729736328, 0.7565170526504517, 0.0928109884262085]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 36, SSIM Loss: 0.09176433086395264\n",
      "Epoch: 50, Batch: 36, D Loss Real: 0.28689783811569214, D Loss Fake: 1.1663047075271606, G Loss: [9.918828010559082, 0.7531483173370361, 0.09165680408477783]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 37, SSIM Loss: 0.0932765007019043\n",
      "Epoch: 50, Batch: 37, D Loss Real: 0.30194681882858276, D Loss Fake: 1.2004224061965942, G Loss: [9.966980934143066, 0.7225152254104614, 0.09244465827941895]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 38, SSIM Loss: 0.09351801872253418\n",
      "Epoch: 50, Batch: 38, D Loss Real: 0.19244113564491272, D Loss Fake: 1.2787728309631348, G Loss: [10.059735298156738, 0.7219878435134888, 0.09337747097015381]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 39, SSIM Loss: 0.09221547842025757\n",
      "Epoch: 50, Batch: 39, D Loss Real: 0.2340674251317978, D Loss Fake: 1.137880802154541, G Loss: [10.048110961914062, 0.790841817855835, 0.09257268905639648]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 40, SSIM Loss: 0.09590601921081543\n",
      "Epoch: 50, Batch: 40, D Loss Real: 0.25937241315841675, D Loss Fake: 1.1303081512451172, G Loss: [10.403051376342773, 0.8178192973136902, 0.0958523154258728]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 41, SSIM Loss: 0.09026384353637695\n",
      "Epoch: 50, Batch: 41, D Loss Real: 0.363601952791214, D Loss Fake: 1.0460600852966309, G Loss: [9.889389991760254, 0.8421312570571899, 0.09047257900238037]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 50, Batch: 42, SSIM Loss: 0.09166300296783447\n",
      "Epoch: 50, Batch: 42, D Loss Real: 0.2664440870285034, D Loss Fake: 1.1481273174285889, G Loss: [9.863764762878418, 0.7277793884277344, 0.09135985374450684]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 43, SSIM Loss: 0.09417152404785156\n",
      "Epoch: 50, Batch: 43, D Loss Real: 0.12967446446418762, D Loss Fake: 1.1832243204116821, G Loss: [10.245647430419922, 0.809630274772644, 0.09436017274856567]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 44, SSIM Loss: 0.09060359001159668\n",
      "Epoch: 50, Batch: 44, D Loss Real: 0.15747909247875214, D Loss Fake: 1.2723720073699951, G Loss: [9.813081741333008, 0.7577593326568604, 0.09055322408676147]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 45, SSIM Loss: 0.09926599264144897\n",
      "Epoch: 50, Batch: 45, D Loss Real: 0.15147149562835693, D Loss Fake: 1.1285866498947144, G Loss: [10.750048637390137, 0.8356143832206726, 0.0991443395614624]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 46, SSIM Loss: 0.09350180625915527\n",
      "Epoch: 50, Batch: 46, D Loss Real: 0.34261801838874817, D Loss Fake: 0.9907687902450562, G Loss: [10.184988975524902, 0.8311070203781128, 0.09353882074356079]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 47, SSIM Loss: 0.0966138243675232\n",
      "Epoch: 50, Batch: 47, D Loss Real: 0.147133469581604, D Loss Fake: 1.0521918535232544, G Loss: [10.523849487304688, 0.873923122882843, 0.09649926424026489]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 48, SSIM Loss: 0.09364056587219238\n",
      "Epoch: 50, Batch: 48, D Loss Real: 0.13320565223693848, D Loss Fake: 0.9635176062583923, G Loss: [10.244384765625, 0.9311462044715881, 0.0931323766708374]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 49, SSIM Loss: 0.09288370609283447\n",
      "Epoch: 50, Batch: 49, D Loss Real: 0.1622428297996521, D Loss Fake: 0.8861774802207947, G Loss: [10.28938102722168, 0.9821212291717529, 0.09307259321212769]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 50, SSIM Loss: 0.0937911868095398\n",
      "Epoch: 50, Batch: 50, D Loss Real: 0.08645838499069214, D Loss Fake: 0.983754575252533, G Loss: [10.31110954284668, 0.9052635431289673, 0.09405845403671265]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 50, Batch: 51, SSIM Loss: 0.09164905548095703\n",
      "Epoch: 50, Batch: 51, D Loss Real: 0.07808659970760345, D Loss Fake: 1.037803053855896, G Loss: [10.092909812927246, 0.9054261445999146, 0.09187483787536621]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 52, SSIM Loss: 0.09564536809921265\n",
      "Epoch: 50, Batch: 52, D Loss Real: 0.05364770069718361, D Loss Fake: 1.1080094575881958, G Loss: [10.458944320678711, 0.9051011204719543, 0.0955384373664856]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 53, SSIM Loss: 0.0905766487121582\n",
      "Epoch: 50, Batch: 53, D Loss Real: 0.10905314236879349, D Loss Fake: 0.9663547277450562, G Loss: [9.977659225463867, 0.9156373739242554, 0.09062021970748901]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 50, Batch: 54, SSIM Loss: 0.09487944841384888\n",
      "Epoch: 50, Batch: 54, D Loss Real: 0.1659182608127594, D Loss Fake: 1.0620790719985962, G Loss: [10.32541561126709, 0.8620519042015076, 0.09463363885879517]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 55, SSIM Loss: 0.092509925365448\n",
      "Epoch: 50, Batch: 55, D Loss Real: 0.21021777391433716, D Loss Fake: 1.2248923778533936, G Loss: [10.181286811828613, 0.8377820253372192, 0.09343504905700684]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 56, SSIM Loss: 0.09273207187652588\n",
      "Epoch: 50, Batch: 56, D Loss Real: 0.145104318857193, D Loss Fake: 1.1178010702133179, G Loss: [10.152989387512207, 0.8336479663848877, 0.0931934118270874]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 57, SSIM Loss: 0.09462630748748779\n",
      "Epoch: 50, Batch: 57, D Loss Real: 0.1651667207479477, D Loss Fake: 1.1297281980514526, G Loss: [10.314950942993164, 0.8178090453147888, 0.0949714183807373]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 58, SSIM Loss: 0.09333914518356323\n",
      "Epoch: 50, Batch: 58, D Loss Real: 0.22894783318042755, D Loss Fake: 1.1285009384155273, G Loss: [10.080174446105957, 0.8072653412818909, 0.09272909164428711]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 50, Batch: 59, SSIM Loss: 0.09226363897323608\n",
      "Epoch: 50, Batch: 59, D Loss Real: 0.2242664247751236, D Loss Fake: 1.219467282295227, G Loss: [9.99254035949707, 0.8028391599655151, 0.09189701080322266]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 60, SSIM Loss: 0.09490680694580078\n",
      "Epoch: 50, Batch: 60, D Loss Real: 0.190555602312088, D Loss Fake: 1.01400625705719, G Loss: [10.374933242797852, 0.8770526647567749, 0.09497880935668945]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 61, SSIM Loss: 0.0911218523979187\n",
      "Epoch: 50, Batch: 61, D Loss Real: 0.19771187007427216, D Loss Fake: 1.0262174606323242, G Loss: [10.009563446044922, 0.8646075129508972, 0.0914495587348938]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch 50, Batch: 62, SSIM Loss: 0.09616994857788086\n",
      "Epoch: 50, Batch: 62, D Loss Real: 0.17021691799163818, D Loss Fake: 1.0639233589172363, G Loss: [10.460363388061523, 0.8665538430213928, 0.09593808650970459]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already defined and created the generator model (g_model)\n",
    "batch_size = 32\n",
    "patch_shape = 8  # Example patch shape, adjust as necessary\n",
    "  # Example dataset, replace with actual data\n",
    "epochs = 50\n",
    "\n",
    "data_gen = DataGenerator('fluor_images_transposed_asnumpy.npz', batch_size, patch_shape, g_model)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for batch in range(len(data_gen)):\n",
    "        [X_realA, X_realB], [y_real, X_fakeB, y_fake] = data_gen[batch]\n",
    "        \n",
    "        # Train the discriminator\n",
    "        d_loss_real = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "        d_loss_fake = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # Train the generator\n",
    "        g_loss = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "        \n",
    "        # Calculate SSIM loss\n",
    "        ssim_loss = calculate_ssim_loss(X_realB, X_fakeB)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Batch: {batch+1}, SSIM Loss: {ssim_loss}')\n",
    "        print(f\"Epoch: {epoch+1}, Batch: {batch+1}, D Loss Real: {d_loss_real}, D Loss Fake: {d_loss_fake}, G Loss: {g_loss}\")\n",
    "      \n",
    "        \n",
    "    custom_checkpoint.on_epoch_end(epoch, logs={'val_loss': g_loss})\n",
    "    # Clear the Keras session\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# Ensure to call on_train_end at the end of training\n",
    "custom_checkpoint.on_train_end(logs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f619edd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 3-dimensional, but 4 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26681/609594390.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_realA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_realA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m7\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inferno'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 3-dimensional, but 4 were indexed"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for j in range(X_realA.shape[-1]):\n",
    "    img = X_realA[0,:, :, j]\n",
    "    plt.subplot(1, 7, 0 * 7 + j + 1)\n",
    "    plt.imshow(img, cmap='inferno')\n",
    "    plt.title(f'Image {1}, Channel {j}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "685f1866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038222205 0.06987223\n",
      "0.031359576 0.097515054\n",
      "0.023596004 0.10381638\n",
      "0.009904739 0.044494286\n",
      "0.08324486 0.21900696\n",
      "-0.015659561 0.032621674\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for j in range(X_fakeB.shape[-1]):\n",
    "    img = X_fakeB[0,:, :, j]\n",
    "    plt.subplot(1, 7, 0 * 7 + j + 1)\n",
    "    plt.imshow(img, cmap='inferno')\n",
    "    plt.title(f'Image {1}, Channel {j}')\n",
    "    plt.axis('off')\n",
    "    print(img.min(), img.max())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984c920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643dad9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ff11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27262ad9-4348-4b85-a387-3a16fa25e16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b4f11-01aa-44f5-8bf5-2ac92c258dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247eb21-ec04-43c8-88ca-830566d2305f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
